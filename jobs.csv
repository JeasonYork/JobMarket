title,company,location,link,description,skills
Data Engineer (H/F) - Lille,Logic@l Conseils,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3782133344?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=pwOdnUGc6NYA8db3%2B5%2BpzA%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card,"Dans le cadre du développement de nos activités sur la métropole Lilloise, nous recherchons un consultant data engineer (H/F) pour intervenir chez l'un de nos grands comptes clients.Vos missions :Recueillir les besoins métiers et des équipes dataConcevoir et mettre en place les traitements de donnéesRéaliser les tests de validation Assurer l’alimentation du datawareRéaliser les ordonnancements des traitementsEtre garant de la mise en place, du suivi et de l’exploitation des outils déployésAssurer une veille technologique régulièreEnvironnement technique :Développement : Python, Scala, R, Java, Framework : Spark, Hadoop, Outils Big data : Yarn, Pig, Hive, Kafka, SplunkBases de données : MongoDB, HBase, CassandraETL : Talend, ODI, StambiaPlateforme : Hortonworks, Cloudera, Map Reduce, AWS, GCP, Azure Votre profil :Vous disposez d’une expérience d’au moins 2 ans en tant que data engineer ou dans le domaine de l’analyse et du traitement de données.Véritable passionné de la data, vous êtes force de proposition sur les solutions techniques à mettre en œuvre. Vous maitrisez l’anglais dans un contexte professionnel.Compétences requises :Analyses qualitatives et quantitatives (Intermédiaire)Anglais (Intermédiaire)Architecture fonctionnelle SI (Débutant)Développement d'ouvrages, produits ou événements (Débutant)Gestion des contrôles, tests et diagnostics (Débutant)Gestion des risques (Intermédiaire)Maîtrise des logiciels (Intermédiaire)Mise en exploitation / Production et maintenance (Débutant)Nos valeursNous avons décidé de renverser la pyramide du management pour placer nos collaborateurs en tête des priorités de l’entreprise.En effet, attaché à des valeurs fortes, telles que la proximité, la sincérité, la fidélité, la confiance et le respect, nous sommes persuadés que la réussite réside dans le bien-être de nos collaborateurs.Cela se traduit par un accompagnement de proximité, de la transparence sans langue de bois, des échanges réguliers avec les managers référents, un accompagnement dans le développement de carrière qui est construit et jalonné avec les formations et certifications nécessaires et les missions en adéquation, pour mener à bien l’évolution de carrière. Pour vous convaincre de nous rejoindre, nos avantages salariés complémentaires :Environnement bienveillant et stimulant au sein de 3 pôles d’expertisesFormations et Certifications à la demandeTickets restaurants : 13€ par ticketRemboursement à 100 % des abonnements de transports en communMutuelle frais de santé avec de hautes garantiesPrise en charge à 100% de l’assurance PrévoyanceChèque Cadeau Culture 120 €Compte CSE avec une cagnotte de 390 €Compte CE : billetterie, voyages, culture, sorties, à des tarifs préférentielsDes évènements chaque mois : activités associatives, sportives, afterwork, séminaire,Partenariat Losc (participation aux match dans la loge VIP logical conseils – (Une Vingtaine de match par an)Possibilité de télétravailEn intégrant Logic@l Conseils, vous participez à une réelle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !Tous nos postes sont ouverts, à compétences égales, aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [' MongoDB', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Crédit Agricole de Champagne-Bourgogne,"Dijon, Bourgogne-Franche-Comté, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-cr%C3%A9dit-agricole-de-champagne-bourgogne-3734715864?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=9dgoE6Y0TMkHBFhkNsKgzw%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card,"Ingénieur.e DATA avec une sensibilité marketing ? Reconnu.e pour votre esprit d’équipe et votre aisance relationnelle ?  Vous aimez vous impliquer ? Ce job est fait pour vous ! Rejoignez le service Marketing du Crédit Agricole de Champagne-Bourgogne à Dijon. Vous serez accueilli.e par Catherine, votre manager. Au sein d’un pôle dédié à la Data Client, vous travaillerez en complémentarité d’une équipe de datascientists et d’experts du marketing.En tant qu’ingénieur.e data, vous serez un véritable appui au développement des modèles de datascience. Vous serez responsable de la création des architectures et de l’infrastructure data analytique ainsi que de sa maintenance opérationnelle. Vos principales missions : Créer et maintenir des infrastructures de données :Assurer la conception de bases de données, leurs évolutions, l’architecture, la modélisation des données, l’aide à la data préparation.Industrialiser, automatiser et mettre en production les traitements sur les données.Déployer et maintenir des infrastructures serveurs :Installer des middlewaresConfigurer des serveurs (Windows & Linux) Accompagner les équipes et assurer une veille technologique sur les outils autour de la data :Travailler en collaboration avec les interlocuteurs internes et externes à notre Caisse Régionale.Mettre à disposition des flux de données (interne et/ou externe) pour exploitation par les datascientists.Assurer une assistance et la montée en compétences des membres de l’équipe dans la mise en pratique de développements informatiques Pour réussir ce défi, vous avez au moins une expérience réussie dans la conception de bases de données et vous avez une forte expertise sur le stockage des données et des outils ETL. Vous avez une vision systémique, technologique et globale des systèmes d’information ainsi que des notions avancées en PHP/JavaScript/SQL.Des connaissances en R/Python/Go ainsi qu’en architecture logicielle et dans les outils Big Data (Hadoop, Spark, HDFS, …) sont un plus.Vous avez une expérience en administration système et connaissez au moins un système d’exploitation parmi Windows et Linux. Vous avez déjà travaillé sur un outil de gestion des flux de type Kafka, Apache Flink. Pourquoi nous rejoindre ?- Pour le challenge d’être au cœur de la construction d’une infrastructure de gestion des données.- Intégrer une entreprise toujours en mouvement, innovante et leader sur son secteur. Une entreprise attachée à des valeurs humaines et de proximité, actrice sur son territoire et en matière de RSE.- Travailler au sein d’une d’une équipe dynamique et conviviale (8 personnes).- Des évolutions possibles au sein du Groupe. - Des avantages : Un intéressement entre 2 et 4 mois de salaire, un 13ème mois, une variable, une mutuelle prise en charge à 90%, des avantages salariés sur certains produits bancaires et d’assurance, 24 jours de RTT/an, un accord de télétravail, une prise en charge des transports en commun à 75% et une restauration d’entreprise sur place.Statut cadre, salaire fixe en fonction de votre expérience.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux', 'Windows'], 'SoftDB': [], 'SoftBigDataProcessing': ['Apache Flink'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Lille - I&D (F/H),Capgemini,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-lille-i-d-f-h-at-capgemini-3759212804?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=qqWDFHpahDNc6dW%2BfBqGlA%3D%3D&position=4&pageNum=0&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques motsCapgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans près de 50 pays. Partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie, le Groupe est guidé au quotidien par sa raison d’être : libérer les énergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d’expérience, Capgemini est reconnu par ses clients pour répondre à l’ensemble de leurs besoins, de la stratégie et du design jusqu’au management des opérations, en tirant parti des innovations dans les domaines en perpétuelle évolution.Insights & Data en quelques motsDans ce contexte, notre practice Insights & Data (I&D) s’appuie sur une équipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette équipe combine des compétences métiers avec une forte expertise data, analytique et d’intelligence artificielle pour mettre en œuvre des solutions qui visent à améliorer la gestion et la valorisation des données. Pour renforcer les équipes d’I&D, nous recherchons actuellement un.e Data Engineer (H/F).Pourquoi nous rejoindre ?Une culture forte et bienveillante, et une grande place laissée à la libertéLes avantages d'un grand groupe (Participation, Intéressement, Plan d'épargne... avec abondement, congés d'ancienneté)Un accompagnement personnalisé tout au long de votre carrière avec des perspectives variées et ambitieusesLa diversité de nos clients et nos projets d'envergureUne approche pragmatique, qui répond aux vrais enjeux des entreprises.Votre rôle, vos compétences : Vous maîtrisez au minimum un langage de programmation appliqué à l’analyse de données (SQL, Scala, Python, Java)Vous êtes passionné par le Big Data et le Machine LearningVous concevez et mettez en œuvre des stratégies sécurisées d'acquisition et d'intégration de donnéesVous configurez des référentiels de données à la pointe de la technologie dans des environnements distribués, majoritairement dans le cloud (Google Cloud Platform, Azure, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks).Votre profil : Vous comptez au moins 2 ans d’expérience (au sein d’une ESN ou chez un intégrateur) en conseil clientèle et une solide culture technologique, un bon niveau d’anglais.« CAPGEMINI, Entreprise handi accueillante, conformément à la norme ANFOR NF X50-783, est également signataire de la charte de la diversité en entreprise »


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),MERITIS,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3797191392?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=%2BNDWcADHGzebekvZquYTIg%3D%3D&position=5&pageNum=0&trk=public_jobs_jserp-result_search-card,"Descriptif de l’entreprise et du poste :Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent sur tout le territoire français.Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.Nous accompagnons nos clients dans l’intégralité de leurs besoins à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.Proches de nos collaborateurs, nous les accompagnons de manière individualisée quelles que soient leurs fonctions dans l’entreprise. Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.En tant que DevOps Sénior (H/F), vous intégrerez une entreprise dynamique évoluant dans un contexte international et un environnement de travail agile.Vos missions chez notre client seront :Collecte, nettoyage transformation et analyse des données via différents sources, outilsConception des bases de données pour stocker efficacement les informationsDéveloppement d'algorithmes et de procédures informatiques pour veiller à la qualité des donnéesSécurité des données : Protéger les informations sensiblesVisualisation des données : Créer des graphiques et des tableaux pour rendre les résultats compréhensiblesConfiguration de référentiels de données à la pointe de la technologie dans des environnements distribués, sur site ou dans le cloud (AWS, Google Cloud, Microsoft Azure)Travailler avec d'autres équipes pour répondre aux besoins de l'entrepriseVeille technologiqueEnvironnement technique :Frameworks : Spark, Hadoop, KafkaLangages de programmation : Scala, Python, SQL, Java,..Data visualisation : PowerBI, Qliksense...Bases de données : Oracle, PosgresSQL, NoSQL, Teradata,...Outils DevOps : Jenkins, Docker, KubernetesCloud : GCP, AWS, AzureCe poste est-il fait pour vous ?Vous avez un diplôme d’ingénieur (Bac+5)Vous avez une expérience d'au moins trois ans sur ce métierVous êtes à l'aise sur DataikuVous maîtrisez l'anglais aussi bien à l'oral qu'à l'écritCe poste est uniquement ouvert à du CDI.Prêt.e à démarrer de nouveaux challenges dans une structure où il fait bon vivre ?Être consultant.e chez Meritis c’est :Evoluer dans un environnement où l’apprentissage est favorisé : formations certifiantes, e-learning, meetUp, concours de code, parcours d’évolutions etc.Faire partie de communautés d’experts qui partagent leurs savoirs et expériencesAvoir le choix de sa missionBénéficier d’un réseau de clients qui nous font confiance et que nous étoffons d’années en annéesTravailler dans un environnement convivial avec de nombreux événements : déjeuners, afterworks, teambuilding, soirées annuelles etc.Rejoindre une entreprise où il fait bon vivre, certifiée « Great Place to Work »Nos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap.Nous sommes à votre écoute. Vous pouvez contacter ethiquegroup@meritis.fr si vous pensez être victime ou témoin d’une discrimination.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data engineer H/F,Inetum,"St.-Ouen, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3798407382?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=3ZPCvpRwsMLz7r7pp%2FuAmA%3D%3D&position=6&pageNum=0&trk=public_jobs_jserp-result_search-card,"Détail de l'offre  Informations générales  Entité de rattachement  Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste Métier Métier AS (Application Services) - Développement Intitulé du poste Data engineer H/F Contrat CDIDescription De La MissionDans le cadre de son développement, Inetum recrute un Data Engineer (H/F) pour sa branche Applications Services.Vous interviendrez chez l’un de nos clients sur des projets BI et/ou Big Data en méthode agile.Le Data Engineer sera en charge deApporter une expertise en Data permettant la manipulation de donnéesAccompagner nos clients dans la réalisation de projets dans un contexte Big Data et CloudParticiper à réunions permettant de valider les principes techniques et algorithmiques pour des projets Profil De formation Bac +5, vous justifiez d'une expérience d’au moins 4 ans dans le domaine de la Data. Vous avez évolué dans le monde du développement (Python, Spark, Aws...)Vous êtes capable de prendre des initiatives, autonome, rigoureux(se) et vous savez vous adaptez à de nouveaux environnements.Vous appréciez le travail en équipe dans un contexte agile, et aimez relever des défis.La maîtrise de l’anglais est un vrai plusLocalisation du poste Localisation du poste France, Ile-de-France, 93 Seine-Saint-Denis Ville saint ouenCritères candidat Niveau d'études min. requis Bac+5 Niveau d'expérience min. requis Plus de 2 ans Langues Anglais (Professionnel)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Ippon Technologies,"Bouches-du-Rhône, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3800692629?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=D68LwkttRqUPnoiWE1VXeg%3D%3D&position=7&pageNum=0&trk=public_jobs_jserp-result_search-card,"IPPON l’énergie du collectif au service de la technologie positive !IPPON est une société de conseil et d’expertise spécialisée dans des solutions digitales innovantes.Nos équipes dans le monde accompagnent les organisations dans la transformation d'idées innovantes en solutions logicielles de haute qualité avec un focus particulier sur le Time To Market.Nos valeurs : PERFORMANCE : vous permettre de monter en compétences avec nos formations internes : programme de mentoring BlackBeltPARTAGE : communauté d’expertises, meetups internes & externes, blog techniqueSOLIDARITÉ : la fondation IPPON vient en aide au plus démunis et accompagne les anciens sportifs dans leur reconversionNotre culture d’entreprise :BIENVEILLANCE : la transparence et la confianceEXCELLENCE : le test & learn, n’ayons pas peur de bousculer l’existant !Le job :intervenir sur les data platforms de nos clients pour développer de nouveaux pipelines de données (ingestion, traitement, exposition),travailler en collaboration avec les métiers et les data scientists pour leur fournir un support à l’industrialisation de leurs travaux (tests, intégration continue, scalabilité des modèles, craftsmanship etc...),déployer des infrastructures cloud full infra-as-code (Terraform, CloudFormation),participer aux évènements internes à la communauté data (BBL, webinar, datapéro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups),capitaliser sur les missions et les différents évènements de la communauté au travers d’articles de blogs, REX, BBL interne.Le profil recherché : Vous êtes de tempérament curieux, force de proposition, vous avez le sens du partage, l’envie de vous améliorer en continue et de participer activement à une communauté data pleine de projets.De formation Bac+5 avec une première solide expérience en data engineering, vous maîtrisez quelques technologies parmi les suivantes :un framework de calcul distribué tel que Spark, Storm, Flinkun ou plusieurs langages de programmation (Python, Scala, Java...)différents systèmes de stockage de données (SQL ou NoSQL) et bien sûr le langage SQL. la connaissance de Snowflake est bienvenueun framework de streaming de données tel que Kafka ou Amazon Kinesisune expérience sur les technologies Cloud : AWS, GCP, AzureLe delivery et les projets en production faisant partie de notre ADN, vous êtes capable de livrer du code de qualité dans des environnements agiles.Les + du job :travailler avec une équipe où vous pourrez apporter vos propres idéesdevenir ceinture noire en Data grâce à notre programme d’accompagnement de carrière Blackbelt ! (formations, certifications AWS/GCP/Azure, mentoring, coaching)une évolution de carrière adaptée à votre expérience et vos souhaitsune charte de télétravail (2 jours par semaine en situation “normale”)la possibilité de s’engager auprès de notre Fondation pour participer à la réduction de la fracture numérique au travers d’actions sociales et humanitaires en France et dans le mondeSi vous vous retrouvez dans ce profil, alors vous vous épanouirez sans aucun doute au sein de la team data !En attendant voici le live d’un de nos projets data : https://www.youtube.com/watch?v=47hMhZWaavY&t=5sNous sommes à la recherche de passionnés qui aiment apprendre, partager et qui ont de l’ambition.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H en CDI,La Banque Postale Consumer Finance,"St.-Denis, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-en-cdi-at-la-banque-postale-consumer-finance-3794947500?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=0XKCVPKlepHtRJnYDbNMIA%3D%3D&position=8&pageNum=0&trk=public_jobs_jserp-result_search-card,"Rejoindre La Banque Postale Consumer Finance, c’est participer à un projet ambitieux : celui de devenir l’un des acteurs incontournables du Crédit à la consommation !Au quotidien, nous nous appuyons sur des pratiques responsables, pédagogiques et solidaires que ce soit en matière d’offres et d’accompagnement de nos clients ; ou au travers de notre politique de développement des compétences de nos collaborateurs !Vous avez le goût du challenge et l’envie de participer à une aventure humaine ?N’attendez plus, rejoignez-nous !Rattaché au responsable pôle data, vos principales missions en tant que data Engineer :Administration, exploitation technique et gestion de l’environnent SAS ; et de l’environnement python et développements machine learning,Maintenance évolutive et corrective et suivi des applications et bases de données sas,Gestion habilitations et suivi de circuit des habilitations,Participation aux projets LBPCF en lien avec les données,Assurer une bonne qualité des données et sécurisation d’accès aux environnements,Support aux utilisateurs sas et python.Descriptions des activités principales:- Comprendre, analyser et proposer des solutions techniques répondant aux besoins des divers clients des données de pôle data de la direction Score et Data Science ;- Maintenance, exploitation et suivi des applications et bases de données sous sas ;- Participation aux différentes phases de conception des datamarts utilisateurs et recette avec les équipes de dwh LBPCF (DWH BIRD/oracle) ;- Contrôle qualité des données et sécurisation d’accès aux données ;- Export de données, requêtage et production de reportings et tableaux de bord nécessaires au pilotage de l’activité ;- Création d’outils de suivi et pilotage des traitements de production ;- Pilotage et mise en œuvre de projets en lien avec les data de la direction score et data science et en particulier la mise en place d’un environnement industrialisé big-data ;- Administration et maintenance de la plateforme SAS et les environnements python ;- Référent technique SAS et python.Votre profil:Bac + 4/5 ingénieurMaitrise SASVous disposez d'une expérience d'au moins 3 ans à un poste similaire.Vos compétences :- Solide connaissance en data architecture et traitement des données ;- Maitrise de l’environnement SAS (de préférence 9.4) et de sql oracle (Une première expérience sur la plateforme SAS Viya serait appréciée) ;- Solide connaissance de l’environnement python et big-data (Une première expérience sur la plateforme Dataiku serait appréciée) ;-Maitrise de système d’exploitation UNIX et Windows (scripting, ksh, sh, bat) ;- Solide connaissance en qualité, sécurité et protection des données (RGPD) ;- Maitrise de la micro-informatique et bureautique ; Vos aptitudes et qualités Autonomie, organisationPoste basé à la Plaine Saint-Denis (93) – accessible RER D ou RER BDate de prise de poste : Dès que possible AvantagesSalaire fixe + part variable + participationAccès parking entreprise, restaurant d’entreprise2 jours de télétravail par semaineOffres CSERemboursement du Titre de transport à hauteur de 75%""Banque citoyenne, La Banque Postale s'engage en faveur de la diversité et de l'égalité des chances pour donner accès à tous ses métiers sans discrimination de genre, d'origine sociale ou culturelle, d'orientation sexuelle ou de handicap. Rejoignez notre Groupe et construisons ensemble La Banque Préférée des Français.""


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Windows'], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),MERITIS,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3796119551?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=Y%2F9b0Xy8efhW%2Bj6Fh8OU6g%3D%3D&position=9&pageNum=0&trk=public_jobs_jserp-result_search-card,"Descriptif de l’entreprise :​Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise. Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​Les missions qui vous attendent :Au sein du pôle Data , vous intégrerez les équipes qui sont responsables de la collecte des données, vous serez en charge de :Récupérer, organiser et mettre en forme la donnéeDévelopper de nouvelles fonctionnalitésRéaliser les tests techniquesFaire évoluer l'architectureProduire la documentationCe poste est-il fait pour vous ?​Vous avez un diplôme d'ingénieur ou équivalent Bac +5.Vous avez un minimum de 3 ans d'expérience professionnelle en tant Data Engineer.Vous disposez de plus de 3 ans d'expérience en développement JavaVous êtes autonome, rigoureux.se et organisé.eVous parlez couramment anglaisCe poste est uniquement ouvert à du CDI.Outils / technologies :JavaSparkSQLHadoopTeradataDevenir collaborateur Meritis c’est :​Des parcours professionnels sur mesure (évolution de carrière, formations adaptées, mentoring…) ;​Avoir le choix de sa mission et un accompagnement personnalisé tout au long de votre carrière ;​Evoluer dans un environnement où l’apprentissage est favorisé : formations certifiantes, e-learning, meetUp, concours de code, parcours d’évolutions etc ;​Faire partie de communautés d’experts qui partagent leurs savoirs et expériences au sein de nos centres de compétences ;​Un environnement convivial avec de nombreux événements festifs (soirée annuelle, séminaires & teambuiding, déjeuners et afterworks…) ;​​Meritis est engagée dans la Responsabilité Sociétale des Entreprises. Nous valorisons notre impact positif sur la société et l'environnement. Notre démarche RSE guide chacune de nos actions pour promouvoir l'équité, la durabilité et le bien-être de nos collaborateurs. Rejoignez-nous pour être partie prenante de cette démarche responsable, où chacun de nos talents contribue à construire un avenir meilleur.Nos différences sont nos atouts. C’est pourquoi Meritis s'implique en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Ippon Technologies,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3792840687?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=5aDCz8RKap3omVgMbWeKrg%3D%3D&position=10&pageNum=0&trk=public_jobs_jserp-result_search-card,"Le contexte - la Practice DataEnvie de rejoindre la communauté data la plus dynamique de France ? Notre spécialité est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.Membre de la Practice Data, la.e futur.e Data Engineer sera intégré.e à nos équipes de conseil et sera suivi par un.e mentor qui l’aidera à monter en compétences.Pour s’impliquer dans la Practice c’est très simple, il suffit de participer aux événements comme les datapéros ou des data lunchs, puis pourquoi pas de proposer tes propres sujets.Votre champs d’expertiseIntervenir sur les data platforms de nos clients pour développer de nouveaux pipelines de données (ingestion, traitement, exposition).Travailler en collaboration avec les métiers et les data scientists pour leur fournir un support à l’industrialisation de leurs travaux (tests, intégration continue, scalabilité des modèles, craftsmanship etc…)Déployer des infrastructures cloud full infra-as-code (Terraform, CloudFormation).Participer aux évènements internes à la communauté data (BBL, webinar, datapéro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups)Capitaliser sur les missions et les différents évènements de la communauté au travers d’articles de blogs, REX, BBL interne.Vos connaissances Un framework de calcul distribué tel que Spark, Storm, Flink.Un ou plusieurs langages de programmation (Python, Scala, Java...)Différents systèmes de stockage de données (SQL ou NoSQL) et bien sûr le langage SQL.La connaissance de Snowflake est bienvenue ;-)Un framework de streaming de données tel que Kafka ou Amazon Kinesis.Une expérience sur les technologies Cloud : AWS, GCP, AzureLe delivery et les projets en production faisant partie de notre ADN, vous êtes capable de livrer du code de qualité dans des environnements agiles.De plus en plus de nos projets se font en remote avec des clients du monde entier, il devient nécessaire d’être à l’aise en Anglais.Ippon technologies c’est aussi :👍Bénéficier d'un suivi de proximité réalisé par votre manager technique : points réguliers pour votre suivi en mission, votre formation et votre évolution de carrière✌️Rejoindre une entreprise où les valeurs du sport sont nos leitmotiv : dépassement de soi, travail en équipe, bienveillance.🗒️Apprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcIL😁Travailler en pair programming ou avec un.e mentor pour gravir les échelons !💪Pouvoir participer à une aventure humaine au sein de notre Fondation Ippon pour réduire la fracture numérique dans le monde !🤝Participer à nos apéros et divers évènements internes pour consolider la cohésion d’équipeEt après ?Et oui alors ? Que se passe-t-il une fois que vous êtes convaincu d’avoir lu l’offre d’emploi qui vous correspond bien ?Nous vous proposons de prendre contact et de nous rencontrer !Les Next Steps :1 call RH1 Entretien RH1 Entretien TechniqueSi le match est bon des deux côtés : Hadjimé ! Vous vous lancerez sur le tatami Ippon !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - DataBricks,Visian,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-databricks-at-visian-3796114769?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=a4ndLcO6egs5x%2Bl1DFaJTQ%3D%3D&position=11&pageNum=0&trk=public_jobs_jserp-result_search-card,"Opportunité CDI - DATA EngineerResponsabilités :En tant que Data Engineer chez Visian, vous serez responsable du développement, de la gestion et de l'optimisation de nos pipelines de données. Vous collaborerez étroitement avec nos équipes multidisciplinaires pour garantir une gestion efficace des données, de l'acquisition à l'analyse. Les principales responsabilités incluent :Concevoir, développer et maintenir des pipelines de données robustes.Utiliser Python et DataBricks pour créer des solutions efficaces et évolutives.Travailler en étroite collaboration avec les équipes de conception produit, d'innovation et de gestion de projet IT.Optimiser les performances des pipelines existants et résoudre les problèmes liés aux données.Collaborer avec les Data Scientists pour assurer une intégration fluide des modèles dans les pipelines de données.Exigences :Minimum 3 ans d'expérience en tant que Data Engineer.Diplôme d'une école d'ingénieur ou équivalent.Excellente maîtrise de Python et de l'écosystème des bibliothèques de données.Expérience pratique avec DataBricks.Bonne compréhension des meilleures pratiques en matière de gestion de données.Compétences avancées en anglais et en français (à l'oral et à l'écrit).


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer H/F,Extia,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3599188121?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=jrv0hePZQCkiLs3%2Bc%2BxczA%3D%3D&position=12&pageNum=0&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l’humain au cœur de ses préoccupations ? On vous attend chez Extia !Société de conseil spécialisée dans les métiers de l’IT, de l’ingénierie et du digital, Extia privilégie depuis sa création en 2007 une approche qui allie performance et bien-être au travail. Une vision de l’entreprise partagée aujourd’hui par plus de 2 500 Extiens en France et à l'international et récompensée depuis 2012 par le label Great Place to Work®.Chez Extia, c’est « D’abord qui, ensuite quoi » alors, allons-y !D'abord quiVous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple,Vous maitrisez les bases de l’analyse statistique,Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,Vous maitrisez Spark et HadoopVous êtes familiarisé avec l’environnement Linux,Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts.Ensuite quoiVous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse…Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes.Vous serez en charge de :Participer à la définition des besoins et à la rédaction des User Stories,Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,Concevoir et construire des architectures de données,Intégrer des sources de données,Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Expérimenté (F/H) - I&D Toulouse,Capgemini,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-exp%C3%A9riment%C3%A9-f-h-i-d-toulouse-at-capgemini-3802713821?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=XToYpk2PNzN55aBGJUeAkQ%3D%3D&position=13&pageNum=0&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques motsCapgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans près de 50 pays. Partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie, le Groupe est guidé au quotidien par sa raison d’être : libérer les énergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d’expérience, Capgemini est reconnu par ses clients pour répondre à l’ensemble de leurs besoins, de la stratégie et du design jusqu’au management des opérations, en tirant parti des innovations dans les domaines en perpétuelle évolution.  Insights & Data en quelques motsDans ce contexte, notre practice Insights & Data (I&D) s’appuie sur une équipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette équipe combine des compétences métiers avec une forte expertise data, analytique et d’intelligence artificielle pour mettre en œuvre des solutions qui visent à améliorer la gestion et la valorisation des données. Pour renforcer les équipes d’I&D Toulouse, nous recherchons actuellement un(e) Data Engineer Expérimenté(e).  Votre quotidienVous concevez et mettez en œuvre des stratégies sécurisées d'acquisition et d'intégration de donnéesVous configurez des référentiels de données à la pointe de la technologie dans des environnements distribués, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks)Vous construisez des pipelines de données pour collecter, transformer et traiter des données en collaboration avec des scientifiques de données afin de répondre aux exigences de la modélisation de données d'analyse avancée  Votre profilDiplômé(e) de Bac+5 en informatique, vous comptez au moins 3 ans d’expérience (au sein d’une ESN ou chez un intégrateur) en conseil clientèle et une solide culture technologique, un bon niveau d’anglais.Vous êtes passionné par le Big Data et le Machine Learning.Vous maitrisez au minimum un langage de programmation appliqué à l’analyse de données(Java, Python, Scala).  Les plus du posteEn plus de votre quotidien, vous pourrez entreprendre, être formé, utiliser nos incubateurs pour innover, et vous dessiner une trajectoire de carrière personnalisée. Vous intégrerez une équipe ambitieuse, fun et dynamique ! Une culture forte et bienveillante, et une grande place laissée à la libertéDes clients variés, leaders de leur secteurUne approche pragmatique, qui répond aux vrais enjeux des entreprisesUn véritable accompagnement dans l’évolution de votre carrièreUne équipe à taille humaine, en renouvellement et en hyper croissanceUne priorité accordée au développement des collaborateurs – un management qui aide les équipes à progresser, à réussir  C’est quoi la suite ?Nous vous proposons un processus de recrutement court, un accompagnement personnalisé, une évolution qui s’adapte à vous. « Capgemini, Entreprise handi accueillante, conformément à la norme AFNOR NF X50-783, est également signataire de la charte de la diversité en entreprise »


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,Valeuriad,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-valeuriad-3741223009?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=5QV40J6Ll8hDCdLYnsVvwA%3D%3D&position=14&pageNum=0&trk=public_jobs_jserp-result_search-card,"Rejoins la Team Data créée par Nicolas Greffard, Docteur en Intelligence Artificielle, déjà composée de 20 Data Engineers et Datascientists talentueux 😍Nous recherchons de nouvelles pépites pour rejoindre notre équipe de choc et répondre aux multiples problématiques Big Data de nos clients nantais mais également contribuer à nos projets de R&D et travailler sur des conférences incroyables (DevFest, Salon de la Data) 🤩Ta future mission si tu l'acceptes 😉Nous te proposons d'intervenir au sein de nos grandes DSI clientes, sur des sujets de collecte, d'alimentation et de transformation de données sur un environnement Big Data Apache (Hadoop, Spark, Ambari, Hive) sur les technologies suivantes : Hadoop, Apache Ambari, RabbitMQ, Java, Scala, YarnApplication, Teradata, Squoop, Kudu, Hue, Hive, Impala, Dataiku, Flink, Kafka, Spark, Kibana, Oozie, Git, GitLabCI, Jenkins, AWS. Le job en détail 🤩 Étude, conception et réalisation de traitements Big Data ; Échange avec les architectes, les PO et PPO, les développeurs et la gouvernance de données ; Exploration des données et des usages des utilisateurs avec Impala ; Import de données (SFTP, Kafka, RabbitMQ) ; Alimentation du cluster Hadoop via des composants développé en Java avec le Framework Spark sur IntelliJ ; Utilisation d’Apache Ambari pour gérer et surveiller un cluster Hadoop, visualisation des jobs en cours via YarnApplication et des flux Oozie ; Collecte des données depuis Teradata via l’outil Sqoop dans une base de données Hive ; Transformation des données avec Spark (HDFS, Hive, Kafka, Hbase, Phoenix) ; Utilisation de Apache Kudu afin d'optimiser les requêtes utilisateurs sur les données chaudes ; Exposition de données sur Dataiku pour la création de modèle de DataScience ; Réalisation en Java – Flink pour gérer les traitements complexe et volumineux ; Gestion de configuration sous Git avec GitLab ; Intégration continue avec Jenkins et Sonar ; Lecture de fichier parquet depuis un répertoire S3 sous AWS ; Requêtage de bases de donnée depuis l'outil Athena d'AWS ; Transformation des données et calcul d'indicateurs sous Hive ; Utilisation de Oozie pour l’ordonnancement de flux ; Utilisation de Kibana pour visualiser et mesurer la volumétrie de traitements quotidien et en streaming.Pourquoi choisir Valeuriad ? 😊En plus d’être aujourd’hui un acteur nantais reconnu de l’expertise IT, nous nous inscrivons depuis notre création dans une démarche d'entreprise Opale et Holacratique, où l'ensemble de nos prises de décisions et projets sont réalisés par et avec l'ensemble de nos 119 coéquipiers 💪Rejoindre Valeuriad, c'est pouvoir s'investir dans la co-construction de l'entreprise : Par un rôle, avec une fiche de poste et un temps dédié (gestionnaire des Ci’s, porteur des partenariats écoles, organisateur d’événements, PO des projets internes, gestion de l'Académie Valeuriad…). Par les projets stratégiques (200 jours mis à disposition pour les coéquipiers chaque année) pour créer et faire grandir des projets structurants (création de nouveaux avantages à l'ancienneté, création d'indicateurs mensuels pour être toujours plus transparents, mécénat de compétences pour des associations caritatives...). Par les projets cagnottes (150€ par coéquipiers et par an) pour réaliser des projets collaboratifs qui te tiennent à cœur avec d'autres Valeurieux (découverte du cécifoot, challenge écologique, challenges sportifs pour des dons à des associations humanitaires, borne photo...). Par les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont proposés par les différents porteurs de projets et sont ouverts à tous les volontaires.Mais avant-tout nous sommes une équipe soudée, des collègues qui apprécient passer du temps ensemble lors de nos soirées hebdomadaires et se créer des souvenirs inoubliables 🤩 C'est pour ça que chez Valeuriad, le plus important pour nous reste le savoir-être : des passionnés, du dynamisme, des sourires, de l'écoute et le sens de la fête 😉
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Wewyse,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-wewyse-3703684760?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=Hy1kpmgmJ8S6bhGoUiBeDg%3D%3D&position=15&pageNum=0&trk=public_jobs_jserp-result_search-card,"Wewyse est un cabinet de conseil spécialisé en Data et en Intelligence Artificielle. C'est aussi et surtout une communauté de passionnés partageant l'ambition de grandir ensemble et d'ouvrir le champ des possibles dans leurs domaines.Si vous pensez que la Data et l'Intelligence Artificielle ont beaucoup à offrir au monde de demain, et si vous souhaitez apporter votre contribution à ce monde, avec humilité et enthousiasme, alors vous êtes un Wyser en puissance.Être Data Engineer chez Wewyse c'est :Intégrer une communauté d’experts Data passionnés.Recevoir et partager de la connaissance et des savoirs-faire lors de nombreux évènements.Intervenir chez des clients pour y porter l'expertise Wewyse dans des contextes et des secteurs variés.Participer à des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires académiques et des start up.Viser l’excellence des développement en s’appuyant sur le Software craftsmanshipConcevoir des architectures logicielles modernes.Penser DevOps pour l’automatisation des déploiements et la continuité des services.Être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles.Faire partie de la famille Wemanity avec ses évènements et ses multiples opportunités de carrière.Ce que nous aimons :Les personnalités ouvertes, curieuses, ambitieusesLes langages Scala, Python et JavaLe cloud : AWS, GCP, AzureLes écosystèmes : Hadoop et SparkLa conteneurisation : Docker et KubernetesLes méthodes AgilesLe SQL et le NoSQL .L'approche DevOps : Jenkins, Ansible et TerraformLe versionning : GitL'anglaisVous vous reconnaissez ? Alors n'hésitez pas à postuler !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer,MERITIS,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-meritis-3767627899?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=pgziwUHwCaIkG4JLUGp6Gg%3D%3D&position=16&pageNum=0&trk=public_jobs_jserp-result_search-card,"Descriptif de l’entreprise :​Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise.Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​Nous recherchons un Data Engineer Spark/Scala H/F, ayant au moins 4 ans d'expérience, pour intervenir chez notre client leader du secteur du retail, pour les accompagner dans l'établissement d'une stratégie de gestion de données ambitieuse pour le groupe et ses marques en développant des données et des pipelines de donnéesVos missions :Créer et maintenir une architecture optimale de pipeline de données Assembler de grands ensembles de données complexes qui répondent aux besoins fonctionnels / non fonctionnels de l’entrepriseConstruire l’infrastructure requise pour optimiser l’extraction, la transformation et le chargement de données provenant de sources très diverses au moyen des technologies « big data » SQL et AWS Travailler avec les Data Scientists et l’IT pour résoudre les problèmes techniques liés aux données et répondre à leurs besoins d’infrastructure de donnéesTravailler avec les experts en analyse de données pour améliorer la fonctionnalité des systèmes de donnéesCe poste est à pourvoir en CDIEnvironnement technique :Framework : SparkLangages de programmation : Scala, Python, SQLBases de données : NoSQL, Teradata,...Cloud : AWS (EC2, EMR, RDS, Redshift)Ce poste est-il fait pour vous ? :Vous êtes diplômé d'un Bac +5 et justifiez d'au moins 4 ans d'expérience en tant que Data EngineerVous avez de l'expérience sur les outils Python, SQL Server et avez de l'expérience sur GCPVous parlez anglais courammentVous avez une passion pour le domaine de la Data et souhaitez monter en compétencesVos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez être victime ou témoin d’une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. »


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),FBD Group,"Tremblay-en-France, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-fbd-group-3804327995?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=us0%2BhOZNshnWJSPoK%2BMzTw%3D%3D&position=17&pageNum=0&trk=public_jobs_jserp-result_search-card,"Vous aimez :Conduire le changement dans le secteur de la distributionPartager les challenges d’une entreprise agile en forte croissanceL’esprit d’équipe et l’ambiance qui règnent dans un groupe à taille humaine (250 collaborateurs)L’innovation, le numérique et les nouvelles technologies au service de l’expérience clientLa gestion de projet Vous aimerez accompagner l’entreprise dans son évolution en concoctant de belles histoires.FBD recrute dans le cadre d'un CDI, un(e) Data Engineer, pour sa direction Achats/Produits.Rattaché(e) à la Directrice Achats et développement de l’offre vos missions seront les suivantes :Garant(e) de la qualité des données catalogues produits et du respect des processAccompagnement dans le quotidien des gestionnaires (aide, suivi d’activité, gestion des priorités, contrôle des anomalies, formations ..) Gestion des projets évolution, amélioration continue, création de programmes et process utilisés par la base de données (cdc, plan de recette, règles de gestion, recettage, formation utilisateurs, création et mises à jour des modes opératoires) Relation et coordination avec les services achats, produits, IT, fournisseurs Participer aux différents projets lancés par le groupe ou initiés en interne.Issu(e) d’une formation supérieure en data sciences, big data, ou en statistiques. Vous avez une expérience confirmée en gestion base de données dans le retail (minimum 5 ans).Vous avez une bonne maitrise des outils techniques et bureautique, plus particulièrement d'Excel et de ses formules, vous avez également :un grand sens de la rigueur et de l'organisationun esprit d'analyse et de synthèseune bonne anticipation et réactivitéCompétences :Coordination, pilotage, suivi des process et projets. Anglais professionnel/ courant souhaité. Pourquoi nous rejoindre ?La brigadeUne Direction qui accorde une attention particulière au bien être des collaborateurs : Nous sommes Great Place to Work !Les ingrédientsVous aurez tous les ustensiles nécessaires pour votre recette (ordinateur, téléphone portable professionnel etc.)Une rémunération fixe + Prime annuelle liée à vos objectifs + Prime de participationLes assaisonnementsUne mutuelle familiale prise en charge à 100% par le Groupe FBDL’accès à un Restaurant Interentreprises2 jours de télétravail par semaine sans condition d’anciennetéDes locaux à Roissy à 200m du RER B et une annexe à Paris 9èmeUn réseau social Entreprise pour vous mettre au courant et participer à la vie d’entrepriseLa cerise sur le gâteauBoissons chaudes et fruits Bio à disposition pour bien commencer la journée !Des activités tous les mois pour les collaborateurs, préparés par notre service Com Interne + 2 évènements groupe par an. En cuisine, le meilleur reste à inventer ! Nous vous attendons !
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3800671866?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=hdNEqUve3hPOCNwpe1O%2BoQ%3D%3D&position=18&pageNum=0&trk=public_jobs_jserp-result_search-card,"Big Data, Data Science, Data analyse, Data architecture ... Ça n’a pas de secret pour vous ?Que vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l’une de ces disciplines, intégrer notre communauté Data, c’est l’assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.Si vous souhaitez intégrer nos équipes à Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous intéresser.En tant que Data Engineer, vous serez responsable de la conception, du développement, de la gestion et de l'intégration des systèmes basés sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce rôle implique la mise en place d'architectures évolutives et hautement disponibles pour répondre aux besoins de traitement et de stockage de données de l'entreprise.Fonctions et responsabilitésVos responsabilités seront les suivantes:-Maintenir et développer des solutions basées sur les services AWS pour le stockage, le traitement et l'analyse de données-Utiliser les services AWS appropriés tels que Amazon EC2, S3, RDS, Lambda, etc., pour répondre aux exigences du projet.-Créer et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS-Participer à la maintenance et à la mise en place d'environnements OpenShift pour l'hébergement d'applications et de services-Gérer et administrer les clusters Kafka pour garantir la disponibilité, la performance et la sécurité du système de messagerieParticiper à l’assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data-Travailler avec les projets et les devOps pour assurer un traitement efficace des donnéesEn rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,...).Qualités requises pour réussir dans ce rôleAyant une première expérience en tant que Data Engineer, vous avez une première expérience relative aux points suivants:-Développement et intégration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop-Connaissance avancée de l'administration Kafka, y compris la configuration, la gestion et la résolution des problèmes-Mise en œuvre de l'infrastructure en tant que code à l'aide de Terraform-Bonne compréhension des bonnes pratiques de sécurité pour les systèmes cloud, les clusters Kafka et les plateformes HadoopCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': []}"
Stage Data & Analytics Engineer H/F,Sonepar,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-analytics-engineer-h-f-at-sonepar-3797425590?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=4lqbulqFXsNJjdyoPEd8Hg%3D%3D&position=19&pageNum=0&trk=public_jobs_jserp-result_search-card,"Qui sommes nous ?Sonepar est un groupe familial indépendant, leader mondial de la distribution aux professionnels de matériels électriques, solutions et services associés. Grâce à la densité de son réseau d’enseignes opérant dans 40 pays, le Groupe conduit une ambitieuse transformation pour devenir le premier distributeur de matériel électrique au monde à proposer à tous ses clients une expérience omnicanale entièrement numérisée et synchronisée. Fort des compétences et de la passion de ses 44 000 collaborateurs, Sonepar a réalisé un chiffre d’affaires de 32,4 milliards d’euros en 2022.Le groupe Sonepar met tout en œuvre pour faciliter la vie de ses clients, en agence, en visite sur le terrain, par téléphone ou via un site Internet – quel que soit le mode d’interaction souhaité.🚀 Vous avez de l’ambition et de l’énergie ?Nous partageons cet état d’esprit. Nous valorisons le sens de l’initiative et la créativité : nos collaborateurs sont libres d’exprimer leurs idées et initiatives et de les mettre en pratique. Nous apprécions les esprits audacieux. Chez Sonepar, nous avons à cœur que chaque collaborateur se sente bien dans son poste et que son travail et son investissement soient reconnus. En 50 ans de croissance, nous avons toujours favorisé les investissements à long terme plutôt que les gains à court terme.Les compétences, la personnalité et la diversité de nos collaborateurs sont les moteurs de notre activité, tant sur les marchés locaux que mondiaux. Cette alliance du local et de l’international nous permet d’être le leader mondial de notre secteur et soutient notre volonté d’être « La Référence ».🎯 Vos missions :Au sein du service Data & Analytics Engineering composé d’une équipe internationale, vous aurez notamment les missions principales suivantes :-Contribuer à la mise en place des pratiques Data & Analytics afin d’accélérer l’industrialisation des solutions développées en interne.• Fournir à l’entreprise l’information Business nécessaire pour comprendre et décider,• Contribuer à mettre en place les mécanismes d’ingestion de la donnée et à leur documentation,• Contribuer au développement des pipelines de données et l’enrichissement du Datalake de Sonepar,• Contribuer au développement des outils analytiques.-Réaliser les analyses Business demandées par la Direction Marketing et achat.• L’extraction ad hoc ou automatique des données (par exemple en R, Python, etc.),• L’analyse et la visualisation des données,• La restitution de l’analyse et la formulation de recommandations.Les missions sont susceptibles d’évoluer selon vos appétences.⭐ Votre Profil :· Vous recherchez un stage d'études (Big data, SI et Génie Logiciel, Data Engineering, IA, Intelligence Opérationnelle ...),· Vous avez une forte appétence pour la conception de bases de données, l'architecture data & BI· Vous avez un esprit d'analyse et de synthèse, le sens du résultat et une bonne aisance relationnelle,· Vous êtes à l'aise avec Pack Office, Java/scala, R, DataOps,· Idéalement, vous connaissez Azure et PowerBi,· Vous êtes à l’aise en anglais, à l’écrit comme à l’oral (minimum B2)Ce à quoi vous pouvez vous attendre ?Le rôle - Vos activités quotidiennes seront intéressantes, stimulantes et diversifiées... Aucun jour ne ressemble à un autre !L'organisation - Vous travaillerez pour le leader mondial dans un environnement international.L'équipe - Intégrez une équipe dynamique, ouverte d'esprit et talentueuse qui est impatiente d'accueillir un autre membre !La culture - Faites partie de la famille Sonepar en partageant les mêmes valeurs !✅ Les avantages – nombreux au sein de Sonepar, voici les principaux :· Remboursement de votre pass mensuel ou annuel de transport à hauteur de 75%.· Carte de ticket restaurant Swile· Salle de sportQuel est le process de recrutement ?1. Entretien RH & N+1 (Tuteur)2. Entretien N+2Que devez-vous retenir ?📍 La localisation - Holding – Paris 8e📝Stage, à partir de mars (6 mois)✋ Êtes-vous prêt à faire la différence ?👉Veuillez postuler en envoyant votre CV !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Devoteam G Cloud,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-devoteam-g-cloud-3163526462?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=AASL9FMzyHWzusUXKp8VnA%3D%3D&position=20&pageNum=0&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseCréée en 2009, Devoteam G Cloud a pour mission de conseiller et d'accompagner les sociétés dans leurs transformations digitales avec les solutions Google Cloud (G Suite, Google Cloud Platform, Google Maps Platform, Devices…).Avec plus de 1 300 clients et 1 000 000 utilisateurs déployés, Devoteam G Cloud s'impose depuis 10 ans comme 1er partenaire EMEA de Google Cloud sur l'intégration des nouvelles plateformes SaaS. En savoir plus : http://devoteamgcloud.com.  Description du posteTu auras pour mission d’accompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l’écosystème solutions open source associé.Intégré(e) à une équipe d’experts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d’étudier et cadrer les besoins clientsPréconiser les solutions et architectures ciblesDéfinir les méthodologies de déploiement et plans de migrationRédiger les dossiers d’architecture et spécifications techniquesConstruire les architectures de donnéesConcevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels)Construire et déployer les pipelines de données (ETL)Assurer la migration des données vers les nouveaux environnementsAnalyser les donnéesAnalyser les données sources afin d’identifier et évaluer des cas d’usage métierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio…)Sélectionner, entraîner, évaluer et déployer des modèles prédictifs en s’appuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les équipes clients aux méthodes et concepts du cloudTu seras accompagné(e) en interne pour monter rapidement en compétences sur GCP dans l’objectif de devenir certifié Google sur ta practice.  Qualifications Diplômé(e) d'une école d'ingénieurs ou d'un Master 2 en Informatique, tu disposes d'une expérience significative au sein de projets Data : architecture, traitement ou analyse de données.Tu maîtrises au minimum un langage de programmation appliqué à l’analyse de données (Scala, R, Python).Tu as de bonnes compétences dans de l’architecture des systèmes, bases de données, méthodologies d’analyseTu es passionné(e) par la Business Intelligence, le Big Data, l’Internet des objets (IoT) et le Machine LearningUne connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, …) est un plus.Tu as une solide compréhension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et à l’écoute, tu possèdes un réel esprit d’analyseTa maîtrise de l'anglais te permettra de gérer des projets en contexte international  Informations supplémentairesLe Groupe Devoteam oeuvre pour l'égalité des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au mérite et lutte activement contre toute forme de discrimination. Nous sommes persuadés que la diversité contribue à la créativité, au dynamisme et à l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Sidetrade,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-sidetrade-3799018498?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=2epQHcPf8HsTPSSzqycLXg%3D%3D&position=21&pageNum=0&trk=public_jobs_jserp-result_search-card,"Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic Data Engineer? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.() https://go.sidetrade.com/GartnerMagicQuadrant22.ht... Indulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a Data Engineer and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry! About Sidetrade and its amazing R&D team Sidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.The R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.RequirementsWe are seeking a passionate and knowledgeable Data Engineer with a multifaceted skill set. Immerse yourself in the exhilarating world of Microservices & AI within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem. As a key member of our development team you will : Design and develop robust data pipelines. Data is at the heart of everything we do. The pipelines you build will power our analytics, machine learning and product featuresYou will build and improve our Dataflows (ETL, Daemon, workers, ... ) and Datastorage.   Build tools and automation      capabilities for data pipelines. The data we ingest and the appetite to      consume it is ever increasing - and therefore so is the importance of      making data integration more reliable and scalable Extend our Data Warehouse and      Data Lake to empower data-driven decisions Help build a data-platform to      democratize data - we want to create a single source of truth of all our      data, which is open to and consumable by everyone at Sidetrade Ensure unit tests are created      and green with sufficient coverage Ensure code analysis are green      (sonar) Support implementation of      secure design principles according to policies and standards of      Information Security  You'll have most of the following key skills and experience: Master's degree in related      field preferred 5 years' experience in Data      Engineering Excellent knowledge of SQL and      Python Object Tableau, talend, Elastic Ssearch, Kafka, GreenPlum, DBT Good understanding of      relational and NoSQL, databases (including data modelling, data      warehousing) Mastery of data mining      technologies  Knowledge of Rest API Experience developing and      supporting robust, automated and reliable data pipelines Attention to detail -      downstream analytics, machine learning and product features are only as      good as the data integrity and quality from the data pipeline Be familiar with Agile and      DevOps frameworks Sound knowledge of data      architecture, scalability and security/compliance Knowledge of security concepts      for data storage Native-level proficiency in French and fluent in EnglishYour first 90 days: Join our Immersive BootcampReview your onboarding plan with your manager and develop an action plan to achieve your goalsCollaborate with the team and participate to the roadmap Build your internal network across all departmentsExpand your skill set, share your expertise and unlock your full potential   At Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace. Discover more on http://www.sidetrade.com/ Agencies : Only applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3800673691?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=CnpFrwUiV9ZWH5xbooluoQ%3D%3D&position=22&pageNum=0&trk=public_jobs_jserp-result_search-card,"Big Data, Data Science, Data analyse, Data architecture ... Ça n’a pas de secret pour vous ?Que vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l’une de ces disciplines, intégrer notre communauté Data, c’est l’assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.Si vous souhaitez intégrer nos équipes à Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous intéresser.En tant que Data Engineer, vous serez responsable de la conception, du développement, de la gestion et de l'intégration des systèmes basés sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce rôle implique la mise en place d'architectures évolutives et hautement disponibles pour répondre aux besoins de traitement et de stockage de données de l'entreprise.Fonctions et responsabilitésVos responsabilités seront les suivantes:-Maintenir et développer des solutions basées sur les services AWS pour le stockage, le traitement et l'analyse de données-Utiliser les services AWS appropriés tels que Amazon EC2, S3, RDS, Lambda, etc., pour répondre aux exigences du projet.-Créer et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS-Participer à la maintenance et à la mise en place d'environnements OpenShift pour l'hébergement d'applications et de services-Gérer et administrer les clusters Kafka pour garantir la disponibilité, la performance et la sécurité du système de messagerieParticiper à l’assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data-Travailler avec les projets et les devOps pour assurer un traitement efficace des donnéesEn rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,...).Qualités requises pour réussir dans ce rôleAyant une première expérience en tant que Data Engineer, vous avez une première expérience relative aux points suivants:-Développement et intégration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop-Connaissance avancée de l'administration Kafka, y compris la configuration, la gestion et la résolution des problèmes-Mise en œuvre de l'infrastructure en tant que code à l'aide de Terraform-Bonne compréhension des bonnes pratiques de sécurité pour les systèmes cloud, les clusters Kafka et les plateformes HadoopCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': []}"
Data Engineer,Reply,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-reply-3803195911?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=OPnVsjGwz9PIgMEwgZ9%2Bng%3D%3D&position=23&pageNum=0&trk=public_jobs_jserp-result_search-card,"DATA ENGINEERQui sommes nous:Data Reply est une marque du groupe Reply offrant une réelle expertise dans les domaines de la Data et de l'intelligence artificielle. Nous sommes présents dans plusieurs pays avec plus de 300 experts dans la Data.Forts de notre expertise en Data Engineering et en Data Science, nous accompagnons nos clients dans leurs projets de transformation Data et dans la mise en place de solutions innovantes. Nous conseillons nos clients dans le choix de la technologie la plus appropriée ainsi qu'à la mise en place d'Architectures Data robustes et évolutives.Nous nous appuyons sur notre notoriété à l’échelle internationale afin de fédérer nos connaissances, de développer des accélérateurs et de créer une émulation entre toutes les entités Data Reply dans le monde.Nous sommes résolument tournés vers l’innovation et les nouvelles technologies. Nos différents partenariats technologiques, nos campagnes régulières de certification de nos consultants et les cas d’usages que nous mettons en place pour nos clients nous assurent une forte éminence sur le marché.Vos Missions:Nous avons besoin de vous pour nous aider à :Accompagner nos clients à :• Implémenter les nouveaux cas d’usage :• Cartographier des données et des flux de données• Implémenter les pipelines d’analyse et de traitement de données• Industrialiser les flux de données et leurs visualisations en dashboards, reporting.• Réaliser les tests unitaires et les tests d’intégrationParticiper à la vie de Data Reply :• Participer à la diffusion et le partage de connaissance au sein de Data Reply• Participer aux événements organisés par Data Reply (Reply eXchange, hackathon, AWS summit …)• Participer au développement des offres packagées en appui des teams leadersCe que nous vous proposons:Vastes possibilités de formation et d'apprentissageProgression de carrière structurée - chez Reply, nous encourageons l'evolution de carrière et vous donnerons les outils et les conseils pour acquérir une expertise technique et managerialeRémunération compétitiveProgrammes de certification pour votre évolution de carrièreEnvironnement de travail diversifié et dynamique - vous serez entouré de collègues qui partagent votre passion pour la technologieOpportunités de participer à des Hackathons, Code Challenges et Lab Camps ainsi qu'à la diffusion et le partage de connaissance au sein de l'équipe Data ReplyVotre savoir ne doit pas se limiter à vos acquis! Nous sommes fiers de notre culture d'apprentissage continu sur les technologies émérgentesPossibilité de travailler sur des projets avec les plus grandes marques mondialesVos Qualifications:• Vous êtes diplômé.e d'une école d’ingénieur ou d’un master dans un domaine lié à la Data et à l’informatique• Vous avez le goût pour le métier du conseil et vous avez une vraie dimension humaine• Vous avez au moins 3 ans d’expérience sur des problématiques de data engineering, de construction de pipelines de transformation de données en batch ou en streaming, d’industrialisation d’applications data science, de modélisation de base de données• Vous avez de solides compétences en Python et/ou en Scala• La connaissance d’un ETL (Talend, Informatica), des technologies de Data Visualisation (power BI, Tableau), des technologies temps réel (Kafka, CDC) est un plus• Vous maitrisez le SQL et un ou plusieurs langages dans l’écosystème NoSQL (cassandra, mongodb)• Vous êtes certifié.e et/ou avez de l’expérience sur un ou plusieurs environnements cloud (GCP, Azure, AWS)• Vous avez déjà travaillé en mode agile et avez une bonne connaissance des processus et outils de développement modernes (DevOps, Git, CI/CD)• Vous mettez en application les bonnes pratiques de développement (TDD, peer-programming)• Vous êtes curieu.x.se et avez l’envie d’entreprendre• Vous maîtrisez l’anglais à l’écrit comme à l’oral


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER,Blue Consulting,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-blue-consulting-3798309749?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=Mm%2BQPSxp34morAvEPtcsaQ%3D%3D&position=24&pageNum=0&trk=public_jobs_jserp-result_search-card,"Titre du Poste : Data EngineerLieu : Ile-de-FranceSéniorité : 5 à 7 ans d’expérience Définition de la prestation :Fiche de poste : Principales activités : - Recueillir les besoins métiers des différentes unités demandeuses- Concevoir des applications transforment les données brutes en informations exploitables- Gérer le développement et de la maintenance de ses applications- Gérer l’infrastructure de données et de déployer des applications de traitement des données- Industrialiser et automatiser le nettoyage de la donnée selon les spécifications retenues- Gérer le cycle de vie de la donnée conformément aux directives inscrites dans le RGPD- Mise à jour permanente sur les technologies et langages utilisés dans le but de partager ses connaissances et aider à l’avancement du projet.Expertises :- Langage : Python, Scala, Spark, SQL- Bass de données : PostgreSQL, NoSQL- Orchestration : Airflow, Luigi- DevOps : GitLab, CI-CD, Docker, Ansible, Terraform- Outils Cloud : GCP, Databricks- Les plus : Dbt, Looker Studio, BigQuery, Airflow, Kafka, Dataflow, Firestore


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
DATA ENGINEER F/H,CENISIS,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cenisis-data-agency-3793647312?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=fVA%2BBpNR4S8E0uYsMShMpg%3D%3D&position=25&pageNum=0&trk=public_jobs_jserp-result_search-card,"💼 Data Engineer F/H 💼A propos de nous Rejoindre CENISIS Agency, c’est rejoindre une entreprise qui place l’ambition et le développement national au cœur de nos objectifs dans un environnement riche et stimulant, une ère en plein changement et offrir ainsi de nouvelles perspectives à ton projet professionnel.Depuis 26 ans, CENISIS accompagne les grands comptes dans la gestion et la valorisation de leurs données.Basé sur Euratechnologies, nous avons mené, en 2020, 32 projets avec succès pour les entreprises telles que AG2R La Mondiale, Auchan, CGI Finance, Orange, Labeyrie, ADEO/Leroy Merlin, Macif, Saint-Maclou. Nos consultants spécialisés en data interviennent sur la gouvernance des données, le data usage, la data quality mais aussi sur le master data management. CENISIS mise beaucoup sur le dynamisme et la prise d’initiative de ses consultants. Il faut sortir des sentiers battus afin d’évoluer dans un domaine en constante Data-évolution. Tu souhaites rejoindre une communauté Data Addict à taille humaine ?Nous recherchons un Data Analyst Marketing F/H qui aura un rôle à part entière dans la communauté CENISIS.Nous t’apportons l’opportunité d’intervenir sur un large choix de projets mais également de faire partie de la CENISIS Academy.Tes missions ?Gérer et mettre en place les structures nécessaires ainsi que les données de type big data pour permettre l'exploitabilité par les data scientistsPermettre la collecte, le stockage et l'exploitabilité fluide des donnéesConstruire les outils de collecte et d'analyse de données (structurées et non structurées)Choisir la ou les méthode(s)/technologie(s) les plus adaptée.Rejoindre CENISIS, c’est rejoindre une entreprise qui :♟Positionne ses consultants au cœur de la stratégie de transformation digitale 🚀⚡️Permet à ses collaborateurs d’avoir un réel impact, d’innover, tester et construire notre avenir 💥🌏Choisit de porter des valeurs fortes et d’être avancé au niveau social et environnemental avec une forte politique de diversité et d’inclusion #TeamRSE 🍃🏟 Anime des formations en interne et en externe #CENISISAcademy 📚Ce qui nous anime ?Nos valeurs basées sur l’audace, la cohésion, l’authenticité et la responsabilité nous poussent à l’innovation et à la croissance. Pour cela, en 2020, CENISIS a intégré l’accélérateur BPI dédié aux entreprises ambitieuses pour ainsi, devenir une Data Agency.En tant qu’entreprise engagée dans une démarche responsable, nous accordons une grande importance à l’impact du bien-être personnel et collectif et à l’engagement envers la diversité, l’équité et l’inclusion.Ton profil ? Tu es issu(e) d’une formation supérieure Bac+3/5 de type licence ou master dans le domaine de l'ingénierie avec une orientation Data. Idéalement tu possèdes une expérience significative de 3 ans dans la Data.Ton savoir être : Ta capacité à fédérer une équipe et à contribuer à la réussite de celle-ci dans ses différents projetsTa curiosité, ton envie de toujours innover, et ton autonomieTu es force de proposition et tu aimes le challenge et challenger les autresTa différence, ce qui fait ta force et ta richesse pour l'entreprise Ton savoir-faire : Ton expertise élevée dans les technologies de manipulation des donnéesTa maîtrise des technologies de base de données (NoSql, SQL),Ta maîtrise des technologies type Cassandra, Python, R, Ta compréhension des problématiques des datascientists Ta capacité à mettre en musique des solutions dans une démarche DataOpsAlors tu es partant(e) pour relever le défi ? N’hésite pas à postuler, ce serait le début d’une superbe aventure ensemble !A compétences égales, tous nos postes sont ouverts aux personnes en situation de handicap. Le processus de recrutement ? Première rencontre avec Marine, Human Resource Manager.Deuxième échange avec ton futur Manager,Troisième échange avec Gilles, Directeur Offres et Innovation et/ou Cédric, Dirigeant.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Omnilog,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-omnilog-3800958837?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=tic5ShPuIeRBRnVOtGwsYQ%3D%3D&position=1&pageNum=1&trk=public_jobs_jserp-result_search-card,"Qui sommes nous ?Depuis son lancement en 1999, OMNILOG met au cœur de ses priorités l’accompagnement, la proximité et la stabilité de ses collaborateurs. Accrédités par le label ""Choosemycompany : HappyAtWork®"", nous permettons à nos collaborateurs d’évoluer dans un cadre professionnel idéal (événements, formations, missions longues, équilibre vie pro/vie perso, télétravail...). Nos clients sont les acteurs majeurs des médias, de l'énergie et du e-commerce, avec lesquels nous collaborons depuis plus de 20 ans (TF1, Canal+, l’Equipe, la FFF, Place des Tendances, JCDecaux…) et bien d’autres. Répartis entre Paris, Bordeaux et Lyon, nos 300 Omnilogiens sont spécialisés dans l’IT de précision.Que recherchons-nous ?Nous recherchons un(e) Ingénieur Data H/F pour intervenir auprès de l'un de nos clients, un acteur majeur du secteur de l'énergie, dans le but d'assurer la qualité technique de ses applications. Le poste est basé à La Défense, avec un rythme de 3 jours en présentiel et 2 jours en télétravail.Vos missions seront les suivantes :Intervenir dans la mise en place et l'optimisation des processus techniques des pipelines de données.Participer à l'étude opérationnelle de cadrage et d'architecture en anticipant les contraintes avec les référents de l'équipe.Réaliser des POC et contribuer à l'éclaircissement du backlog.Participer à la préparation des environnements techniques, notamment la configuration et l'automatisation des processus, ainsi que la templatisation des procédures.Assumer la responsabilité des Run, MCO, MEP, et de la partie CI/CD.Enrichir l'équipe avec des compétences en ingénierie de données et en développement.Maîtriser le scripting Python, avoir une expertise sur les API, les tests, les bonnes pratiques, etc.L’environnement technique du projet est le suivant :Cloud : AWS DEV : Python, API (Fast ou Flask), GraphQL, Airflow, Linux, Git (Code review, Merge Request, etc.), DockerDevOps : Docker, Terraform, CI/CD, Gitlab, Gitlab CI, etc. DATA : BDD, SGBDR, DataWarehouse,SQL, NOSQL BIGDATA : HDFS, SPARK, Hadoop, etc. Data Science (Modélisation, MLOPS)Les indispensables :Empathie, écoute active et communication auprès d'utilisateursExpérience de 4 ans minimum en tant qu’ingénieur DataForte capacité d’anticipation, d’organisation et de coordinationMotivation et esprit d’équipeLe poste est à pourvoir immédiatement, un membre de la Team Recrutement reviendra vers vous prochainement !See you soon ! 😊


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
ML Ops / Data & Machine Learning Engineer,Allianz Trade en France,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/ml-ops-data-machine-learning-engineer-at-allianz-trade-en-france-3727090615?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=TAWG%2BfJLEPPWKlecNpiP5A%3D%3D&position=2&pageNum=1&trk=public_jobs_jserp-result_search-card,"As a member of the Group Data Analytics teams, the Machine learning engineer has to Design & build industrial Machine Learning platforms and technical assets to support the ambitious roadmap of the team in implementing data science within Allianz Trade. Work autonomously and act as a technical referent for junior colleagues.Your Responsibilities Review technical implementations (code, architecture) from colleagues  Act as a technical referent on ML Engineering topics  Given requirements for a model, propose technical implementation  Develop relevant pieces of the technical stack to ensure the build/run of data science models  Develop data pipelines  Develop generic data analytics tooling  Ensure MLOps role for the production & work platforms  Your background  Master’s degree in informatics and at least 2 years in a similar role  Good background in Python development in CI/CD. Knowledge of unit test practice and Sonarqube  Previous Data Science experience or knowledge of Machine Learning pipelines is a plus – you will learn about it very quickly with us  Knowledge of AWS related to data management or data science  Knowledge of Terraform and Gitlab  Fluent in English  Knowledge of Prometheus and Graphana is a plus  Technical curiosity and ability to dive deep into topics to solve issues  Ability to work on various projects at the same time and prioritize  Curiosity and teamwork  Good written and verbal communication skills #FRANCE#PARISIf you are interested in the position above and think you have the right profile please follow the online application process. For more detailed information on the company and our career opportunities please go to our website: https://www.allianz-trade.com/en_global/careers/


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer Assistant,Teads,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/software-engineer-assistant-at-teads-3768799543?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=bszW2MgoDTPkONRpkJqohQ%3D%3D&position=3&pageNum=1&trk=public_jobs_jserp-result_search-card,"Teads, The Global Media Platform, has an engineering team that brings together 200+ talented individuals in 3 main locations (Montpellier, Paris, and Bucharest). We are organized in agile and autonomous feature teams and share technical knowledge within several communities of practice.To innovate, we promote diversity and are committed to creating an inclusive environment for all employees.Our organization gives the possibility to work remotely part of the time and more flexibility is open to discussion.👉 Join a team of passionate people who build quality and responsible advertising, at scale!Our main Engineering challenges at Teads Working in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).Rich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.Management of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).Build efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.A fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.Bring a wide diversity of profiles to the same level of quality and knowledge.What will you do?As a Software Engineer Assistant, your missions will be to:Provide technical leadership and consultation for infrastructure engineers and developers to ensure the secure deployment of technologyAs part of a team, ensure the adoption of security architecture and engineering initiatives in order to effectively and securely support the organization in meeting specific business technology needsDrive consideration of cybersecurity tools and datasets to enhance detective and preventative control setsUnderstand technical security issues and the implications to Teads businesses and be able to communicate them to management Understand emerging security technologies and determine the appropriate use within business applicationsMaintain and enforce Teads cybersecurity policies and secure design baselinesExecute and improve Teads Security architecture review process and ensure compliance for all business initiativesArchitect global programs that deploy strong security patterns and controls across applications and computing environments, while addressing security, business resiliency, privacy and compliance frameworksIdentify security vulnerabilities and guide developers and engineers in addressing these issuesImprove architectural adoption through automation and efficiently use security tools to solve challenges at scaleValidate reference architectures for security best practices and recommend changes to enhance security and reduce riskCollaborate with the corporate functions including Finance, HR, Legal and Privacy to ensure that Teads maintains a strong cybersecurity postureWhat will you bring to the team?Good programming abilities. Testing your development is a second nature to you, and you are very mindful about your application’s architecture, performance and maintainability and its’ overall qualityMultiple shipped projects in Software EngineeringStrong problem solving skillsWorking collaboratively with the team, be able to explain your decision and share your knowledgeWhy work at Teads?At Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to scale our business while continuing to create new and exciting products.We value team spirit, pragmatism, listening and we encourage initiatives.We promote end-to-end development: “You build it, you run it, you monitor it”.We share knowledge and support with each other beyond any organizational boundary.We fix issues during a blameless postmortem and learn from it so that it doesn’t happen twice.We are working together to create great engineering, but we are also supportive to promote a great work-life balance.We Care About YouSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).Career Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).Life Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.Wellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).Discover more about our culture and benefits on our Engineering website.About TeadsTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.As an end-to-end solution, Teads’ modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world’s best publishers and content providers.Through exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.Teads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.We're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3798195830?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=iODW4hmRraSz4Oyy473eUA%3D%3D&position=4&pageNum=1&trk=public_jobs_jserp-result_search-card,"Big Data, Data Science, Data analyse, Data architecture ... Ça n’a pas de secret pour vous ?Que vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l’une de ces disciplines, intégrer notre communauté Data, c’est l’assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.Si vous souhaitez intégrer nos équipes à Bordeaux et accompagner les plus grands acteurs du secteur bancaire, cette annonce est susceptible de vous intéresser.En tant que Data Engineer, vous serez responsable de la conception, du développement, de la gestion et de l'intégration des systèmes basés sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce rôle implique la mise en place d'architectures évolutives et hautement disponibles pour répondre aux besoins de traitement et de stockage de données de l'entreprise.Fonctions et responsabilitésVos responsabilités seront les suivantes:-Maintenir et développer des solutions basées sur les services AWS pour le stockage, le traitement et l'analyse de données-Utiliser les services AWS appropriés tels que Amazon EC2, S3, RDS, Lambda, etc., pour répondre aux exigences du projet.-Créer et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS-Participer à la maintenance et à la mise en place d'environnements OpenShift pour l'hébergement d'applications et de services-Gérer et administrer les clusters Kafka pour garantir la disponibilité, la performance et la sécurité du système de messagerieParticiper à l’assistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data-Travailler avec les projets et les devOps pour assurer un traitement efficace des donnéesEn rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,...).Qualités requises pour réussir dans ce rôleAyant une première expérience en tant que Data Engineer, vous avez une première expérience relative aux points suivants:-Développement et intégration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop-Connaissance avancée de l'administration Kafka, y compris la configuration, la gestion et la résolution des problèmes-Mise en œuvre de l'infrastructure en tant que code à l'aide de Terraform-Bonne compréhension des bonnes pratiques de sécurité pour les systèmes cloud, les clusters Kafka et les plateformes HadoopCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': []}"
Data Engineer H/F,Altitude Infra,"Val-de-Reuil, Normandy, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-altitude-infra-3799077872?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=XfG1GP3ZEscNjn8rW602Ww%3D%3D&position=5&pageNum=1&trk=public_jobs_jserp-result_search-card,"À propos de nousDu Très Haut Débit pour tous, voilà notre mission !Expert en fibre optique, Altitude Infra a le privilège de contribuer au déploiement du nouveau réseau Très Haut Débit français. Nous construisons, exploitons et commercialisons des réseaux fibre optique permettant un accès Internet Très Haut Débit pour tous, à la ville comme à la campagne !« Notre activité a une vraie utilité citoyenne ! »Dorothée Lebarbier, PDG du groupe AltitudeNotre grande équipe est composée de 900 collaborateurs et d’autant de personnalités, de compétences et d’histoires à partager. Reconnue pour notre audace et sous nos airs de « startup », nous embarquons avec nous, de nouveaux collaborateurs aux 4 coins du territoire à la conquête de nouveaux projets ! Aucun profil ou diplôme n’est privilégié, l’essentiel : Être soi-même et avoir envie.« Nous préférons des têtes bien faites aux têtes bien pleines. L’important est d’être dynamique, motivé et d’avoir le goût pour le travail d’équipe »Dorothée Lebarbier, PDG du groupe AltitudeEntreprise en hyper croissance, il nous tient à cœur d’intégrer avec soins et bienveillance, les talents qui nous porteront vers demain.MissionAu cœur de la DSI, sous la responsabilité du responsable SI Gestion, vous intégrez l’équipe DATA. Vous Serez Amenez à TravaillerDans le développement global de l’environnement décisionnel, de la conception du DWH jusqu’aux dataviz sous Power BIAvec tous les métiers de l’entreprise. Construction, exploitation, production, commerce, finance et bien d’autresEn dominante la politique RSE groupeVous devez être en mesure de comprendre d’où vient la donnée et challenger la sourceAnalyser la meilleure façon d’automatiser la récupération de la donnéeConcevoir « l’architecture » de récolte et de compilation de la donnéePréparer/anticiper la future restitution, en intégrant le croisement de dimension avec d’autres reportings (notamment financiers et Indicateurs)ProfilEntitésTemporalité et granularité dans le tempsScénarios : Budget ou Réel Groupe / Sous Groupe / ConsoEn collaboration avec les chefs de projet SI afin de consolider les différents référentiels SIEn environnement Full Microsoft : MSSQL, SSIS, SSAS, SSRS, Power BIVous êtes titulaire d’un Master ou cycle d’ingénieur spécialisé dans l’IT Vous avez une première expérience sur un poste équivalentVous maitrisé le langage SQL, Langages, Python, RVous maitrise des environnements SSIS, MSSQL, SSAS, PowerBIPourquoi nous ? Une formation à nos méthodes, process, outils, techniques et services Des possibilités d’évolution De bonnes conditions de travail (investissement, proximité, réactivité…) Un fonctionnement collaboratif en mode projet et dans le support aux métiers Une entreprise à la pointe de la technologie (R&D, High Tech, Innovations digitales…)Référence de l'offre : 409b6h3w0q
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Inetum,"St.-Ouen, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3782168944?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=MrWi9FDzxdf%2BlPr%2FxCOw6A%3D%3D&position=6&pageNum=1&trk=public_jobs_jserp-result_search-card,"Détail de l'offre  Informations générales  Entité de rattachement  Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste Métier Métier AS (Application Services) - Technique AS Intitulé du poste Data Engineer H/F Contrat CDIDescription De La MissionLe pôle BFA de la branche Application Services du groupe INETUM, recherche plusieurs Data Engineers afin d'intervenir auprès de clients grands comptes au sein des marchés bancaires et de l'assurance.Au sein de l'équipe Data, en tant que Data Engineer, vous participez à la réalisation de divers projets et vos missions sontApporter votre connaissance en Big Data permettant la manipulation des donnéesConcevoir les plateformes permettant de traiter des volumes de données importantsMettre en place des bases de donnéesPréparer le pipeline de données pour que les données déployées soient sécurisées et claires afin d'être analysées et transformées. Profil De formation ingénieure en informatique Bac + 5 informatique ou scientifiqueBonne communication orale et écrite en français et niveau d’anglais professionnelSavoir- être Bon esprit d'analyse et de synthèse, sens de l'organisation et de la qualité, force de proposition, rigueur, travail en équipe, adaptabilité.Si vous vous reconnaissez, n'hésitez pas à postuler !Localisation du poste Localisation du poste France Ville Saint-OuenCritères candidat Niveau d'études min. requis Bac+5 Niveau d'expérience min. requis Plus de 2 ans Compétences SQL
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,EarthDaily Agro,"Balma, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-earthdaily-agro-3787906604?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=Y1Cncg8Hco6VXxP6j5G9zg%3D%3D&position=7&pageNum=1&trk=public_jobs_jserp-result_search-card,"About UsEarthDaily Agro provides space age data and analytics to the organizations and people who feed the planet!  With 35 years of industry experience, EarthDaily Agro provides customers with the data, analysis and knowledge they need to make more efficient and effective decisions. B2B services range from global risk management and monitoring of agricultural commodities to the marketing of inputs and precision agriculture consulting, using the latest research in agronomy, information technologies and remote sensing.   EarthDaily Agro also develops highly customized business solutions for agricultural lenders, insurers, input suppliers and food companies, with easy-to-use analytics, that help reduce the daily risks of agriculture.   EarthDaily Agro is headquartered in Minneapolis, MN, USA, with offices in France, Brazil, Australia and Switzerland and is a division of EarthDaily Analytics Corp.    EarthDaily Analytics Corp., a vertically-integrated data processing and analytics company, is launching a new constellation of earth observation satellites. The EarthDaily satellite constellation will significantly enhance geospatial analytics capabilities in agriculture, forestry, environment, financial services, and intelligence, among many other verticals.  Main Job Tasks And ResponsibilitiesAs a EarthDailyAgro Data Engineer, your primary responsibility will be to design, develop, and manage data pipelines and infrastructure specialized for geospatial and remote sensing applications. You will work closely with data scientists, geospatial analysts, remote sensing experts, software engineers, and DevOps teams to ensure the successful deployment and scaling of data pipeline to feed geospatial data machine learning models. Your role will be crucial in optimizing the geospatial machine learning ecosystem and ensuring the seamless integration of AI-driven geospatial solutions into real-world applications. Your Responsibilities IncludeCloud-based data pipeline Conceptualization, Development and Scaling: Build up pipeline to ingest large volumes of geospatial data, pre-process them and meet data scientists’ requirements, in terms of accessibility, speed, format, quality. Automation and CI/CD: Industrialization of pipeline deployment, orchestration, workflows, and versioning. Cost & Speed Optimization: Collaborate with infrastructure team to develop, optimize, and fine-tune pipeline.  Cloud and Containerization: Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization tools.   Infrastructure Management: Utilize containerization technologies and cloud-based services to set up and manage infrastructure, enabling seamless deployment and scalability.  Monitoring and Anomaly Detection: Implement monitoring systems to track pipeline performance and identify anomalies.  Version Control and Data Version Control: Proficient with version control systems like Git and DVC.  Security and Compliance: Ensure the security and privacy of geospatial data, adhering to relevant data protection regulations and industry best practices.  Collaboration and Communication: Collaborate with interdisciplinary teams to integrate data pipeline into existing applications or develop new geospatial products. Issue Resolution and Troubleshooting: Identify and resolve promptly technical issues related to geospatial data processing, performance, or infrastructure.  Education, Knowledge And AbilitiesRequirements Education: Master's degree in Computer Science, specialisation in Geomatics and/or Remote sensing would be a plus.  Experience: 3+ years experiences with data pipeline processes and deployment is a must-have. Proven hands-on experience in setting up pipelines and data processes with opensource tools (e.g., MLFlow, Argo, Kubeflow) is desirable.  Programming Skills: Proficiency in Python and with data manipulation frameworks (e.g., dataframe, numpy, pandas, xarray, rasterio) and librairies (e.g., Dask).  Problem-Solving Skills: Autonomous, and strong analytical and problem-solving abilities to address complex geospatial data and analysis challenges.  Communication Skills: Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams and stakeholders.  French mandatory (job based in France). Fluent in English (oral and written): meetings with internal are mostly in English.   Preferred Additional SkillsExperience with Earth Observation (EO) data analysis and processing.  Experience with geospatial data formats (e.g., GeoTIFF, Shapefile, NetCDF). Spatial Analysis Techniques: Understanding of spatial analysis techniques and algorithms commonly used in geospatial data manipulation.  Remote Sensing Integration: Knowledge of remote sensing data sources (e.g., STAC catalog, satellite imagery, LiDAR, SAR) integration into data pipelines for accurate and up-to-date geospatial analysis.  CONDITIONS Full time job based in Balma, near Toulouse, France. Fixed + Bonuses TR / ""Family"" insurance / CSE Powered by JazzHRW9rcjWJtyB
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer GCP (F/H),Apside,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2859485219?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=h01FjIq7mtDbTPbCn%2BXtIg%3D%3D&position=8&pageNum=1&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une entreprise apprenante ? Engagée pour t’accompagner dans ton évolution professionnelle et dans tes projets personnels ?Rejoins Apside Paris pour travailler sur nos projets de demain !Le poste :Tu seras amené à participer à la migration des données et le traitements Big Data depuis un cluster Hadoop interne vers l'infrastructure Google Cloud Platform.Dans ce sens, tes missions seront les suivantes : Participation aux chantiers de cadrage de la migrationContribution à la mise en place des environnements et outils de déploiement automatisésAccompagnement et formation des équipes à l’outil GCP...Environnement technique :Jira Big dataCloud GCPHadoopKubernetesSpark, Kafka, PythonToi ?Tu as déjà participé à un projet demigration Google Cloud Platform (GCP) ? Tu es rigoureux, bon communiquant ? Tu souhaites participer à un projet d’envergure associant cloud et Big Data ? Alors ce poste de Data Engineer GCP est fait pour toi !Et la suite ?Tu rencontres d’abord l’équipe RH pour parler de tes attentes, ton projet, ton futur !Puis les managers pour parler concret : missions, projets, parcours de carrière, et bien sûr salaire et avantages :)  Et tu discutes avec un de nos Tech Leads, pour évaluer tes compétences et te challenger.Tu souhaites donner un nouvel élan à ta carrière ? Rejoins la vie Apsidienne !Pour en savoir plus à www.apside.com


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': ['JIRA']}"
DATA ENGINEER SCALA/SPARK JUNIOR - H-F,ITNOVEM.,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-scala-spark-junior-h-f-at-itnovem-3781872584?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=zfYU5XMv8uZQ2NTpYmNwfw%3D%3D&position=9&pageNum=1&trk=public_jobs_jserp-result_search-card,"ITNOVEM, qui sommes-nous ? Filiale technologique du groupe SNCF, intégrée à la Direction du Digital et des Systèmes d’information, Itnovem. se positionne comme expert de l’Internet Industriel. Porteuse de grands projets de la révolution digitale, notre société est en constante recherche de profils pour rejoindre la grande aventure de l’Internet des objets, de la data science et de l’accompagnement des projets digitaux.Qu’il s’agisse de maintenance prédictive, d’aide à la décision sur la maintenance des infrastructures, de gare 4.0, d’usine du futur, ou de sécurisation des assets, nos équipes font valoir à la fois une expérience métier et une expertise technique sans cesse renouvelée, dans le respect des valeurs du groupe : Excellence, Innovation, Collectif, Agile, Engagement.CONTEXTEAu sein du pôle Factory Data & IA et dans le cadre de la montée en charge des projets, nous sommes à la recherche d'un·e data engineer Scala/Spark junior.  Rattaché·e aux équipes Data Engineering et en collaboration avec les membres de l’équipe, son rôle sera de contribuer aux projets data sur stack Scala/Spark et à l’amélioration de l’outillage et des process internes.  Le recrutement intervient dans le cadre de la création d’un plateau projet dédié à l’activité TGV sur Nantes.   MISSIONS  Participer au développement des projets data sur stack Scala/Spark Etre acteur de la mise en place de bonnes pratiques de communication entre les plateaux nantais et parisiens Avec l’appui de l’équipe, être impliqué·e dans la roadmap technologique (pratiques, outils) et de l’amélioration continue du périmètre Scala/Spark Contribuer proactivement à la qualité et aux compétences des équipes Data Science et Engineering : veille techno, capitalisation…  LE PROFIL RECHERCHE  Compétences métiers & outils :  Expérience professionnelle (alternance, stage) ou académique sur le langage Scala et le développement d’applications Spark Connaissances autour du SQL (principes, langage, modélisation) Appétence sur les aspects fonctionnels et métiers d’un projet Notions de CI/CD (notre stack : Maven, Gitlab, Jenkins, Artifactory, Ansible) Compétences transverses :  Intérêt prononcé pour le software engineering Aisance relationnelle Proactivité et clarté dans la communication Rigueur et organisation Force de proposition Bonne communication écrite et orale Expériences et formations  Titulaire d’un bac+5 spécialisé génie logiciel / développement ou expérience équivalente.  Vous venez d’obtenir votre diplôme ou occupez déjà votre premier poste dans le domaine du développement de pipelines Data. Localisation Poste basé à Nantes sur plateau métier dédié, avec des déplacements ponctuels (France) pour participer aux réunions d’équipe Data Engineering et Factory Data & IA (Saint Denis). Télétravail jusqu’à 3 jours par semaine.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA Engineer - Bordeaux H/F,Capgemini Engineering,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-bordeaux-h-f-at-capgemini-engineering-3804527199?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=LdU8AO9GMvsKYShLx3hplA%3D%3D&position=10&pageNum=1&trk=public_jobs_jserp-result_search-card,"Capgemini Engineering est la marque du groupe Capgemini réunissant les services d'ingénierie et de R&D d’Altran, leader mondial du secteur dont Capgemini a finalisé l’acquisition en 2020, et l’expertise de Capgemini dans le domaine du digital manufacturing. Grâce à une connaissance sectorielle approfondie et à la maîtrise des technologies digitales et logicielles de pointe, Capgemini Engineering accompagne la convergence des mondes physique et numérique. Conjuguée avec l’ensemble des capacités du Groupe, elle aide les entreprises à accélérer leur transformation vers l'Intelligent Industry. Capgemini Engineering compte plus de 52 000 ingénieurs et scientifiques dans plus de 30 pays, dans des secteurs tels que l'aéronautique, l'automobile, le ferroviaire, les communications, l'énergie, les sciences de la vie, les semi-conducteurs, les logiciels et l'Internet, le spatial et la défense, et les biens de consommation.Vous êtes passionné.e par la DATA et vous souhaitez prendre part à un projet d’envergure dans le secteur des telecom ? Rejoignez notre équipe Hybrid Intelligence au sein de Capgemini Engineering en tant que DATA Engineer.Vous avez acquis une expérience solide dans le développement de pipelines de données et de solutions pour le traitement d'un grand volume de données, vous êtes capable de créer des solutions qui répondent aux besoins de différentes parties prenantes telles que les spécialistes de la visualisation de données, les scientifiques de données et les analystes de données. En qualité de Data engineer, vos missions sont les suivantes : ▪ Concevoir et développer des solutions Data/IA à des fins analytics & dashboarding▪ Accompagner les Métier dans la compréhension des Analytics et mise en œuvre de solution ""data driven""▪ Collaborer avec les data scientist et data ops dans la construction d'une culture axée sur les données▪ Gérer un écosystème de partenaires data science et assurer un haut niveau d'expertise▪ Assurer un rôle de veille technologique sur tous les outils autours de la data, IA et BI.Vous êtes issu.e d’une formation ingénieur ou équivalent bac+5 informatique spécialisé en DATA et vous justifiez d’une expérience réussie dans le domaine du développement de pipelines de données et de solution Data (2 ans min).Vous maîtrisez les technologies informatiques pour manipuler des bases de données de type : Oracle, posgres, NoSQL,.. et framework : Hadoop, spark , hive , oozie , Nifi, jupyter, kafka , ... Votre maîtrise des langages : SQL, SCALA, Pyhton, JAVA, shell... vous permettent d’être autonome sur la manipulation de données. Enfin, vous avez acquis une expérience dans les outils BI, data visualisation : Kibana, qliksense , power bi ... La maîtrise de l’Anglais est nécessaire pour ce poste. Vous pensez avoir toutes les compétences pour mener à bien les missions ? N’attendez plus et prenez votre place au sein de nos équipes !CAPGEMINI, entreprise handi accueillante, conformément à la norme AFNOR NF X50-783, est également signataire de la charte de la diversité en entreprise


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer Assistant,Teads,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-assistant-at-teads-3781123010?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=EfC6bWo4IKFUXh1lTz%2FrCA%3D%3D&position=11&pageNum=1&trk=public_jobs_jserp-result_search-card,"Teads, The Global Media Platform, has an engineering team that brings together 200+ talented individuals in 3 main locations (Montpellier, Paris, and Bucharest). We are organized in agile and autonomous feature teams and share technical knowledge within several communities of practice.To innovate, we promote diversity and are committed to creating an inclusive environment for all employees.Our organization gives the possibility to work remotely part of the time and more flexibility is open to discussion.👉 Join a team of passionate people who build quality and responsible advertising, at scale!Our main Engineering challenges at TeadsWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).Rich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.Management of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).Build efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.A fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.Bring a wide diversity of profiles to the same level of quality and knowledge.What will you do?As a Software Engineer Assistant, your missions will be to:Collaborate with a variety of teams to develop complex services Create, design develop test and monitor your code in production autonomously and reliablyWork with the Engineering Manager to frame projects and be accountable for their executionGet a good understanding of the business to provide relevant solution to clients Be a work facilitator and help communication inside and outside TeadsStay up-to-date on new technologies and architectures, and share it with the team. Eventually you will propose ways to implement them into our current software engineering processWhat will you bring to the team?Good programming abilities. Testing your development is a second nature to you, and you are very mindful about your application’s architecture, performance and maintainability and its’ overall qualityMultiple shipped projects in Software EngineeringStrong problem solving skillsWorking collaboratively with the team, be able to explain your decision and share your knowledgeWhy work at Teads?At Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to scale our business while continuing to create new and exciting products.We value team spirit, pragmatism, listening and we encourage initiatives.We promote end-to-end development: “You build it, you run it, you monitor it”.We share knowledge and support with each other beyond any organizational boundary.We fix issues during a blameless postmortem and learn from it so that it doesn’t happen twice.We are working together to create great engineering, but we are also supportive to promote a great work-life balance.We Care About YouSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).Career Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).Life Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.Wellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).Discover more about our culture and benefits on our Engineering website.About TeadsTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.As an end-to-end solution, Teads’ modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world’s best publishers and content providers.Through exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.Teads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.We're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),APGAR,"Neuilly-sur-Seine, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-apgar-3803710671?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=8vqnWTzLzYf4mtUMEiDXgw%3D%3D&position=12&pageNum=1&trk=public_jobs_jserp-result_search-card,"Apgar Consulting, fondée en 2013, est une société de conseil en Data de premier plan, reconnue par les analystes comme Gartner, qui accompagne ses clients dans leur parcours pour construire une base de données fiables.De la sensibilisation des personnes aux changements organisationnels en passant par l'activation et le support technologiques, nous concevons et fournissons des solutions sur mesure qui fournissent des données de manière cohérente, sécurisée et précise.Nous sommes des experts dans la Data Advisory, la Data Arcthitecture, la Data Academy et la Data for Green, ainsi que dans la mise en œuvre et le support de solutions de Platform Data telles que la Data Preparation, le Master Data Management, le Meta Data Management et la Data Integration.Apgar Consulting agit pour les petites et grandes entreprises, en Europe, aux États-Unis et au Moyen-Orient.Construit avec des valeurs fortes, Apgar Consulting a pour objectif de fournir des services de conseil durables.L'innovation et le pragmatisme sont les clés de notre approche orientée Data.Nous sommes une véritable entreprise centrée sur les personnes et axée sur les objectifs et nous offrons un environnement de développement personnel et de croissance de carrière avec une véritable conscience sociale.Nous recrutons des profils Data et nous misons en priorité sur les Soft-Skills sachant que nous ne spécialisons pas nos talents sur des secteurs d'activité et que nous favorisons l'accompagnement et la montée en compétences.Le PosteEn qualité de Data Engineer, vous travaillez au sein d'une équipe intervenant directement sur un projet client pour participer aux missions suivantes : Vous êtes impliqué(e) sur l'ensemble du projet dès son démarrage et serez en interaction avec le client / métier et les consultants techniques ; Vous participez à toutes les phases de mise en œuvre de solutions de Data Management ; Vous participez à l'analyse des besoins, rédigez les spécifications fonctionnelles et assurez l'adéquation de la solution avec le besoin du client ; Vous assurez un reporting fiable et pertinent de votre activité auprès de votre responsable ; Vous accompagnez le client dans la recette et la mise en service de la solution ; Vous êtes responsable de la qualité des livrables et des prestations fournis et contribuez à la qualité globale des projets et missions auxquels vous participez.En fonction de votre degré d'expérience, vous êtes amené(e) à intervenir sur un périmètre plus important : Vous prenez la responsabilité d'un chantier qui vous aura été confié par votre chef de projet ; Vous êtes impliqué(e) sur l'ensemble du projet dès son démarrage et serez en interaction avec le client / métier et les consultants techniques ; Vous assurez un reporting fiable et pertinent de votre activité auprès de votre responsable ; Vous animez les ateliers de conception fonctionnelles et rédigez les comptes-rendus.Selon vos souhaits de carrière et appétences vous aurez la possibilité d'évoluer progressivement vers un poste de consultant(e) technico-fonctionnel(le), vous continuerez à jouer votre rôle de consultant(e) fonctionnel(le) tout en intervenant sur la configuration et paramétrage de la solution.ProfilProfil recherché : De formation Bac+5 minimum au sein d'une grande école d'ingénieur ou d'informatique, vous disposez de minimum 2 ans d'expérience sur ce type de fonction ; Vous avez des appétences relationnelles et avez des facilités à rédiger et à vous exprimer ; Vous avez la capacité de comprendre et de rédiger des spécifications fonctionnelles ; Une expérience en lien avec l'une de nos offres (MDM, Méta data, Data Integration et Data Preparation) est un plus.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Back-End Software Engineer H/F,Air France,"Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/back-end-software-engineer-h-f-at-air-france-3761231260?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=JYgLyWBqDpQRVmVuvxP91A%3D%3D&position=13&pageNum=1&trk=public_jobs_jserp-result_search-card,"Description du poste Intitulé du poste Back-End Software Engineer H/F Métier Systèmes d'informations - Développement Catégorie socio-professionnelle Cadre Présentation du contexte Le Système Informatique de notre compagnie est un élément stratégique pour l'ensemble de nos activités.Nos équipes IT développent et déploient de nombreuses solutions informatiques pour accompagner les différents métiers de la compagnie (Cargo, Marketing, Suivi des vols, Maintenance des avions....)La clé de la réussite de toutes ces solutions innovantes est l'Intégration. Sans communication inter-applicative efficace, il n'y a pas de projet possible.En rejoignant le Centre de Services Integration (SCI), vous participerez à la conception, au développement et au déploiement des projets d'Integration de l’ensemble des métiers du groupe Air France-KLM.Pour cela, rien de plus simple, postulez !Description De La MissionAccompagné de collègues passionnés par les sujets d'Intégration : Vous participez à la mise en place de solutions d'intégrations performantes pour les projets informatiques du groupe Air France KLM (API, Services REST, SOAP, Events...) Vous aidez les équipes de développement en participant au support offert par le Centre de Services En tant que développeur, vous participez à la réalisation de l'outillage nécessaire à la gestion des solutions d'integration (Référentiel de services, gestion des habilitations, Frameworks d'intégration...)Vous serez en contact avec l'ensemble des directions du groupe Air France KLM. Profil recherché De formation ingénieur ou Master 2 en informatique, vous êtes jeune diplômé(e) avec une expérience de moins de 3 ans avec une appétence pour les projects back-end et les communications inter applicatives.Vous abordez le changement et les nouvelles technologies telles que les technologies cloud et/ou bigData sans frilosité, et mesurez l'intérêt des organisations « agile ».Vous avez à cœur d’acquérir de nouvelles compétences, techniques et fonctionnelles.Vos qualités de communication et votre souci du client vous permettent d'être à son écoute et produire la solution dont il a besoin.Ce que nous vous offrons De la création de valeur pour l’ensemble des métiers d’Air France KLM Des challenges et problématiques complexes à résoudre Des parcours de carrière riches et variés Un accompagnement permanent, une offre de formation adaptée Un esprit d’équipe avec des collègues sympathiques et brillantsOn vous attend le plus rapidement possible ! Et pour une durée indéterminéePlus d'informations ?Les femmes et les hommes qui composent nos équipes nous ont choisis pour nos valeurs, notre détermination à satisfaire nos clients et à doter les métiers et clients d’Air France et du groupe Air France-KLM d’outils informatiques performants, atouts concurrentiels déterminants pour l’avenir de la compagnie et du groupe.Travaillant en étroite collaboration avec les métiers, nos collaboratrices et collaborateurs ont à cœur d’apporter leur expertise IT afin d’accompagner la digitalisation du groupe et ses nombreux projets de transformation.Afin de maintenir un haut niveau d’excellence, nous attachons beaucoup d'importance au développement des compétences de nos salariés tout leur apportant un accompagnement permanent dans leur parcours professionnel.C’est également la qualité de vie sur nos centres informatiques dont celui de Sophia Antipolis et notre attachement à l’humain qui est plébiscité. Entrer à Air France, c’est rejoindre un employeur qui sait reconnaitre la valeur de ses collaborateurs, développer leurs compétences et leur donner la possibilité de construire un parcours professionnel évolutif, riche en expériences fonctionnelles et techniques.Tous les métiers de l’IT se trouvent représentés sur nos centres informatiques et les opportunités professionnelles sont nombreuses.Toutes nos offres sont ouvertes aux candidats en situation de handicap. Air France s’engage à créer un environnement de travail inclusif.Notre richesse à l’IT ce sont les femmes et les hommes qui la composent. Type de contrat CDI Temps partiel possible Non Type d'horaires AdministratifProfil candidat Niveau d'études min. requis Bac + 5 et plus / 3ème année grande école Niveau d'expérience min. requis Moins de 3 ans Langue Anglais (4 - Confirmé / C1)Langues - Informations complémentaires Score minimum requis au TOEIC en anglais (datant de moins de 2 ans) Plus de 850Localisation du poste Localisation du poste France, Provence-Alpes-Côte d'Azur, Alpes Maritimes (06) Site ValbonneInformations CCA Titulaire du CCA Non
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER SCALA/SPARK JUNIOR - H/F,ITNOVEM.,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-scala-spark-junior-h-f-at-itnovem-3740805832?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=zpr5JGOu8eFKH9FlDqb26g%3D%3D&position=14&pageNum=1&trk=public_jobs_jserp-result_search-card,"ITNOVEM, qui sommes-nous ? Filiale technologique du groupe SNCF, intégrée à la Direction du Digital et des Systèmes d’information, Itnovem. se positionne comme expert de l’Internet Industriel. Porteuse de grands projets de la révolution digitale, notre société est en constante recherche de profils pour rejoindre la grande aventure de l’Internet des objets, de la data science et de l’accompagnement des projets digitaux.Qu’il s’agisse de maintenance prédictive, d’aide à la décision sur la maintenance des infrastructures, de gare 4.0, d’usine du futur, ou de sécurisation des assets, nos équipes font valoir à la fois une expérience métier et une expertise technique sans cesse renouvelée, dans le respect des valeurs du groupe : Excellence, Innovation, Collectif, Agile, Engagement.CONTEXTEAu sein du pôle Factory Data & IA et dans le cadre de la montée en charge des projets, nous sommes à la recherche d'un·e data engineer Scala/Spark junior.Rattaché·e aux équipes Data Engineering et en collaboration avec les membres de l’équipe, son rôle sera de contribuer aux projets data sur stack Scala/Spark et à l’amélioration de l’outillage et des process internes.Le recrutement intervient dans le cadre de la création d’un plateau projet dédié à l’activité TGV sur Nantes.MISSIONS Participer au développement des projets data sur stack Scala/SparkEtre acteur de la mise en place de bonnes pratiques de communication entre les plateaux nantais et parisiensAvec l’appui de l’équipe, être impliqué·e dans la roadmap technologique (pratiques, outils) et de l’amélioration continue du périmètre Scala/SparkContribuer proactivement à la qualité et aux compétences des équipes Data Science et Engineering : veille techno, capitalisation…LE PROFIL RECHERCHE Compétences métiers & outils :Expérience professionnelle (alternance, stage) ou académique sur le langage Scala et le développement d’applications SparkConnaissances autour du SQL (principes, langage, modélisation)Appétence sur les aspects fonctionnels et métiers d’un projetNotions de CI/CD (notre stack : Maven, Gitlab, Jenkins, Artifactory, Ansible)Compétences transverses :Intérêt prononcé pour le software engineeringAisance relationnelleProactivité et clarté dans la communicationRigueur et organisationForce de propositionBonne communication écrite et oraleExpériences et formationsTitulaire d’un bac+5 spécialisé génie logiciel / développement ou expérience équivalente.Vous venez d’obtenir votre diplôme ou occupez déjà votre premier poste dans le domaine du développement de pipelines Data.LocalisationPoste basé à Lyon sur plateau métier dédié, avec des déplacements ponctuels (France) pour participer aux réunions d’équipe Data Engineering et Factory Data & IA (Saint Denis).Télétravail jusqu’à 3 jours par semaine.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,ELOSI,"Villeneuve-d’Ascq, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-elosi-3800230436?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=VQk44VPsZZuEKSh1MLjOXA%3D%3D&position=15&pageNum=1&trk=public_jobs_jserp-result_search-card,"A propos d'ElosiCréée en 2005, Elosi réunit maintenant 120 collaborateurs pour mener à bien les projets digitaux de ses clients depuis leurs locaux ou depuis notre centre de service et R&D à Villeneuve d’Ascq.Le poste et vos missionsPour l'un de nos clients grand compte de la métropole lilloise, nous recherchons un data engineer. Vous travaillerez en collaboration avec les équipes de développement.Vos missions :Correction et création des nouvelles features d'intégration de données sur plusieurs produits digitaux ;Création des pipeline d'intégration des données stambia ou outils internes vers google BigQuery ;Mise en place des dashboard powerBI ; Transformation des données en élaborant des modèles conceptuels. L'environnement techniqueStambia, Google BiQuery, PowerBIVotre profilDe formation supérieure en informatique, vous avec une expérience en développement de flux Stambia d'au moins 2 ans, vous connaissez Google BigQuery.Vous aimez ""préparer"" les données brutes, faciliter leur exploitation et les rendre ""propres"" pour l'analyse qui suivra.Votre anglais est opérationnel.Nous rejoindre, c'est :Rejoindre une communauté de passionnés et la participation à des conférences techniques (DevoXX, DevFest Lille, atelier LiveCoding, Pair programming, Apér’Ops…) ; De la convivialité, du partage, de la proximité ; Des perspectives d’évolutions tant technique que métier ! Des avantages : carte restaurant, formations, primes…Si ce poste vous anime, n'hésitez plus et postulez !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Tours, Centre-Val de Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3803138116?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=JYbgdP6tzPhfw1X8qDShqA%3D%3D&position=16&pageNum=1&trk=public_jobs_jserp-result_search-card,"Description de posteBig Data, Data Science, Data analyse, Data architecture, ... Ça n’a pas de secret pour vous ?Que vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l’une de ces disciplines, intégrer notre communauté Data, c’est l’assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.Rejoignez notre centre d’excellence en innovation à Tours et rendez unique l’expérience digitale de nos clients en travaillant sur des sujets tels que le marketing digital, User eXperience, CRM, RPA, data, développement web et mobile, API management ou encore cybersécurité.Environnement Technique :Développement : Python, R, Java, ScalaFramework : Hadoop, SparkOutils Big data : Talend for Big Data, Yarn, Pig, Hive, Kafka, SplunkBases de données : MongoDB, HBase, Cassandra, SQL Server, Postgresql, OracleETL : Talend, MSBI, Informatica, Datastage, ODI, StambiaPlateforme : Hortonworks, Cloudera, Map Reduce, AWS, GCP, AzureFonctions et responsabilitésVos missions sont :- Recueillir les besoins métiers et des équipes data- Concevoir et mettre en place les traitements de données- Réaliser les tests de validation- Assurer l’alimentation du dataware- Réaliser les ordonnancements des traitements- Être garant de la mise en place, du suivi et de l’exploitation des outils déployés- Assurer une veille technologique régulièreEn rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,...).Qualités requises pour réussir dans ce rôle- Passionné(e) d’informatique et de données, vous aimez le travail en équipe, apprendre et partager. Vous êtes également doté(e) d'un esprit audacieux et ambitieux.- Vous faites preuve d’initiative et travaillez sur le long terme.- Vous justifiez de 2 à 5 ans d'expérience professionnelle au sein d’une entreprise de services numériques ou d’un cabinet de conseil dans le domaine de la Data.- Vous disposez d'une vision large des technologies et vous maîtrisez au moins une technologie Big Data.CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer BI - Nantes F/H,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-f-h-at-capgemini-3791935676?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=Q%2FoquJSx9XOau226mMwavQ%3D%3D&position=17&pageNum=1&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques motsCapgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans près de 50 pays. Partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie, le Groupe est guidé au quotidien par sa raison d’être : libérer les énergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d’expérience, Capgemini est reconnu par ses clients pour répondre à l’ensemble de leurs besoins, de la stratégie et du design jusqu’au management des opérations, en tirant parti des innovations dans les domaines en perpétuelle évolution. Insights & Data en quelques motsDans ce contexte, notre practice Insights & Data (I&D) s’appuie sur une équipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette équipe combine des compétences métiers avec une forte expertise data, analytique et d’intelligence artificielle pour mettre en œuvre des solutions qui visent à améliorer la gestion et la valorisation des données. Pour renforcer les équipes d’I&D, nous recherchons actuellement un.e Data Engineer BI.A propos du poste :  Intégré au sein d’une équipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activités divers, vous serez notamment en charge des missions suivantes :Mener les analyses fonctionnelles destinées à traduire les besoins du client,Mener les travaux de conception et de modélisation,Diriger le développement de la solution / des traitements d'alimentation du DataWareHouse,Organiser et préparer les travaux de recette utilisateurs,Mettre en place les processus d'industrialisation et mener cette dernière.Pourquoi nous rejoindre ? Une culture forte et bienveillante, et une grande place laissée à la libertéDes clients variés, leaders de leur secteurUne approche pragmatique, qui répond aux vrais enjeux des entreprises.Vous arrivez au bon moment pour prendre place dans une équipe à taille humaine, en renouvellement et en hyper croissance. Pas de profil type chez Capgemini, mais quelques ingrédients pour laisser la magie opérer ... ! Diplômé d'un Bac + 5 en école d’ingénieur ou équivalent universitaire, vous avez au moins 3 ans d’expérience en BI ou en lien avec un ETLVous avez déjà encadré des équipesVous êtes un(e) passionné(e) de la Data, enthousiaste et curieux(se)Vous êtes prêt(e) à partager de façon accessible à une audience non « data expert »Vous maîtrisez une ou plusieurs des technologies suivantes :BI : SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB InitioDataviz : Microsoft Power BI, Tableau, QlikviewBig Data : Ecosystème Hadoop (HIVE, PIG, Mahout…), Cloudera, Pivotal, Spark, HNXAnalytics : R, SAS, IBM SPSSEnglish speaker, because we are French but also international « Capgemini, Entreprise handi accueillante, conformément à la norme AFNOR NF X50-783, est également signataire de la charte de la diversité en entreprise »


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Big Data,Beelix,Greater Bordeaux Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-big-data-at-beelix-3798708272?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=Rr9ehZ%2BUZajM9xcZ%2FsTzvA%3D%3D&position=18&pageNum=1&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui crée et améliore les produits digitaux des marques ambitieuses ?Depuis 2016, nous complétons les équipes de nos clients avec les meilleurs consultants en Product Management et Data Thinking.Aujourd'hui, plus de 100 clients font confiance à Beelix, des startups aux plus grands groupes tels que : Renault, EDF, Engie ou encore la Société Générale.Nous recherchons actuellement pour intervenir chez l'un de nos clients grands comptes un Data Engineer Big Data (F/H).Vos missions principales seront les suivantes:Participation aux développements informatiques sur les technologies Hadoop, HDFS, Hive, Spark Sql et PySpark, SqoopParticipation au maintien en conditions opérationnellesConceptionDéveloppementsLivraisonsRecettesProfil recherché: Une expérience significative de 4 ans minimum sur un poste similaireVous travaillez en méthode agileVous maîtrisez les outils, technologies et domaines suivants: Hadoop, PySpark, Python, SQL Vous parlez anglais courammentVous vous reconnaissez dans cette offre ? N'hésitez plus, postulez chez nous!


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Inetum,"St.-Ouen, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3782175142?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=MV6qalHo7QARdPRsglNqFA%3D%3D&position=19&pageNum=1&trk=public_jobs_jserp-result_search-card,"Détail de l'offre  Informations générales  Entité de rattachement  Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste Métier Métier AS (Application Services) - Développement Intitulé du poste Data Engineer H/F Contrat CDIDescription De La MissionDans un environnement en constante évolution, Inetum souhaite relever les défis de ses clients en proposant les solutions et les produits adaptés, ainsi que les méthodes du futur sur des technologies innovantes.Dans le cadre d'un projet innovant nous recherchons un Ingénieur Développeur Big DataVotre rôle sera d'intervenir au sein d'une équipe axé sur le développement d'une application innovante. en tant qu'Ingénieur big data sur l'ensemble des phases du projet l'étude, la conception, le développement, l'optimisation d'applications.Vous rejoindrez notre équipe et participez aux phases d’analyses d’impact, d’étude de solution, architecture et conception technique et fonctionnelle détaillée, dans un cycle de projet agile. Profil Compétences techniquesSpark / Spark StreamingStockage MongoDBMessage Broker KafkaWebService RESTTravail en méthode Agile/SafeUn bon niveau en Anglais est aussi requis.Une sensibilité au RealTime, au monitoring est indispensable.Profil recherchéDiplôme / niveau d'études Bac +5 en informatiqueExpérience 2 ans minimumLocalisation du poste Localisation du poste France, Ile-de-France, 93 Seine-Saint-Denis Ville Saint-OuenCritères candidat Niveau d'études min. requis Bac+5 Niveau d'expérience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Snowflake,Key Performance Consulting (KPC),"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-kpc-3794833700?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=mkhd0zcJ7ZsEKbWTdXevHA%3D%3D&position=20&pageNum=1&trk=public_jobs_jserp-result_search-card,"Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous !VOS MISSIONS :Elaboration d'architectures optimisées dans un contexte Snowflake,Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des coûts d utilisation Snowflake (FinOps)VOTRE PROFIL :Vous êtes issu d'une école d'ingénieur ou d'un Master 2Vous avez une première expérience sur du Snowflake ou au moins 2 ans de SQLDEVENEZ NOTRE PROCHAIN(E) Data Engineer Snowflake !Vous recherchez une entreprise où vous pouvez télétravailler tout en gardant un lien de proximité, qui laisse de l’autonomie, et où il fait bon travailler, alors nous vous souhaitons la bienvenue chez KPC.Vous avez une expérience d'au moins 2 ans en développement SQL ou une première expérience sur Snowflake ?Vous souhaitez travailler au sein d’une équipe d'experts technico-fonctionnels ?Rejoignez l’entreprise KPC ! Une entreprise à taille humaine avec un mode de management dynamique et de proximité.Notre cœur de métier de KPC : la business intelligence. Nous sommes intégrateurs de solutions GOLD PARTENAIRE de SAP, Qlik, Microsoft BI, Tableau, Snowflake, Semarchy etc.Notre gold partenariat nous permet d'offrir des formations certifiantes pour nos collaborateurs, d'avoir des liens de proximités avec les éditeurs et de revendre leurs solutions.Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous !VOS MISSIONS :Elaboration d'architectures optimisées dans un contexte Snowflake,Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des coûts d utilisation Snowflake (FinOps)VOTRE PROFIL :Vous êtes issu d'une école d'ingénieur ou d'un Master 2Vous avez une première expérience sur du Snowflake ou deux/trois ans de SQLPROCESSUS DE RECRUTEMENT :Vous pensez être celui, celle qu’il nous faut et vous vous êtes reconnu dans notre organisation, alors venez vivre votre première expérience KPC en postulant à cette offre :Vous serez appelé(e) par Ludivine (chargée de recrutement) pour une première prise de contactNous pourrons poursuivre les échanges avec Olivier (Directeur Sud-Ouest) pour l’approche projet et techniquePour clore ce processus de recrutement, nous vous inviterons à rencontrer Gabriel (Directeur Sud-Ouest)Et tout ça dans un temps record 😊 : 15 jours en moyenne pour allier réactivité et efficacité.Nous garantissons l’égalité des chances pour toutes et tous car pour nous la diversité est une force !KPC EN QUELQUES MOTS ?Nous sommes une entreprise spécialisée dans la Data.Depuis treize ans, nous accompagnons nos clients à valoriser leurs données de manière innovante et efficace pour développer leur performance, améliorer leurs processus et expériences utilisateurs. Nous intervenons en mode projet (50% régie, 50% forfait)Nous avons développé 3 grandes activités :ANALYTICS (BI, Data Science/Big Data, Data Gouvernance, EPM, Digital)ERP SAPCRMPour cela, nous travaillons en partenariat avec les plus grands éditeurs du marché tels que : SAP, QLIK, DATAGALAXY, SALESFORCES, SNOWFLAKE, TALEND, MICROSOFT, ONESTREAM, IMAGINO.En forte croissance, nous cherchons de nouveaux talents pour participer à cette aventure humaine au service des entreprises de demain.KPC EN QUELQUES CHIFFRES :300 collaborateurs20 % Croissance annuelle8 agences en France (Aix-en-Provence, Nice, Montpellier, Lyon, Toulouse, Bordeaux, Paris et Nantes)Des grands groupes en tant que clients : CMA CGM, PERNOD RICARD, AIRBUS, CDISCOUNT, CULTURA, GIFI, POLE EMPLOI, L'OREAL ...VOS AVANTAGES :Organisation du travail 100% flexible avec du télétravail, participation aux frais téléphonique et internet et un forfait équipement fournitureUn parcours d'intégrationDes formations et des certifications avec les éditeurs sur les technos de pointeIK voiture, véloCarte resto, mutuelle, prévoyance santéPrime « Vacances »POURQUOI NOUS REJOINDRE ?Une entreprise à taille humaineUn mode de management dynamique, agile et de proximitéUne vie d'agence animée, engagée et conviviale dans des locaux sympasUne attention particulière à un équilibre de vie pro / persoUne entreprise qui encourage les initiatives et l'autonomieUne entreprise certifiée Ecovadis Silver pour des actions concrètes en termes de RSEUn cadre de travail agréable prenant en compte les enjeux sociétaux et environnementauxVous êtes ou voulez être consultant(e), chef de projet, expert(e) technique, manager ? Notre promesse : vous accompagner de façon personnalisée et continue quel que soit votre projet à court, moyen et long terme.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),Hilti Group,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-hilti-group-3803059730?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=XKZKDzZFgSgn1ToVKZN0tA%3D%3D&position=21&pageNum=1&trk=public_jobs_jserp-result_search-card,"What's the role?As a Data Engineer, you will be responsible for analyzing & profiling data for designing scalable solutions. You will help the team troubleshoot complex data issues & perform root cause analysis to proactively resolve product & operational issues. Within a team of data engineers, you will be responsible for implementing data models & data structures needed for each use case as defined by Data Architect, in the most convenient format to be used by Data ScientistWho is Hilti?If you’re new to the industry, you might not have heard of us. We provide leading-edge tools, technologies, software and services for the global construction sector. We have a proud heritage, built over 75 years, and a worldwide reputation for pioneering products and exceptional service. With 30,000 people in more than 120 countries we operate with a unique direct sales model and generate around 250,000 customer interactions every day.What does the role involve? Provide technical support related to data structures, data models and meta data management to Data Architect and other relevant stakeholders.  Participate in early data modeling and testing for use case development, provide input on how to improve proposed solutions and implement necessary changes  Work closely with IT teams on internal data acquisition (e.g., CRM, ERP, Website) and with Data Architect for external data acquisition We have more than 200,000 interactions with our customers every day. It’s how we get to know their businesses, understand their needs and develop the precise products and services that will help them.What do we offer?To further accelerate in digital marketing, we are building our Global Digital Hub in Paris. You will experience the agile mentality combining the stabilityof a sound business model and the working environment of an award-winning culture. You can make an impact from day one in an international and diverse team by shaping the future of digital at Hilti and revolutionize customer interactions. You’ll be the owner of your professional development and will have the ownership to design your career map.Job benefits: From 60k to 82 €  25 vacation days + RTT  Childcare Health insurance fully covered  Retirement plans What you need is: Master’s degree in Computer Science, Information systems  5+ years experience with advanced data management platform (e.g., Hadoop, AWS Redshift, Google cloud platform)  3-4 years of experience with ETL development  Experience in SQL  Experience with AWS Sagemaker , AWS cloudFormation, EMR, Glue, Lambda , S3, Athena, lakeformation, EC2  Deep expertise in data modeling and structuring, experience in high volume data environments,  Expertise in Python (Pyspark is a plus)  Knowledge in Jupiter Notebooks  Understanding of Map reduce concept  Ability to quickly learn new technologies  Good analytical and problem solving skills  Fluency in English Why should you apply? Implements complex automated workflows and routines using workflow scheduling tools.  Build continuous integration, test-driven development and production deployment frameworks.  Drive collaborative reviews of design, code, test plans and dataset implementation performed by data engineers in support of maintaining data engineering standards.  Resolves roadblocks and gives guidance to team members.  Enjoy high freedom to act.  Open excellent international and cross-functional career prospects in a dynamic environment During your interviews, you will meet several members of the digital team including leadership. This way you get to know more about us, and we get to know more about you.Tempted to apply? Click “apply now” and send us your resume (  English version  ) today!Do you want to know more? Go to https://careers.hilti.com/en/digital-marketingJoin us and #TransformDigital
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage - Data Engineer,Numberly,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-at-numberly-1000mercis-group-3802295348?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=TcCPtnnyhYcqRAxVX2ww8A%3D%3D&position=22&pageNum=1&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseNumberly est reconnu comme l’un des meilleurs spécialistes mondiaux du Data Marketing avec près de 500 collaborateurs et 8 bureaux dans le monde au service de clients de premier plan (LVMH, BNP Paribas, Hill’s, Beneteau, L'Oréal, Ipsen, Ouigo, Maje, HSBC...).En mettant la technologie au service des marques et des consommateurs, Numberly est au cœur de la croissance des entreprises et de l’aspiration de chacun à un marketing plus responsable et plus pertinent. Numberly s’appuie sur les avancées les plus récentes en matière de traitement, d’analyse et d’activation media et CRM des données, dans un contexte vertueux alliant compétitivité des entreprises et respect renforcé de la vie privée et de la protection des données.Nous analysons des sets de données comportementales, personnelles, contextuelles et transactionnelles, dans tous les environnements technologiques existants, et les articulons avec les enjeux business et digitaux de nos clients.Nous construisons chaque jour des stratégies data et marketing digital qui améliorent la pertinence et l’impact des interactions de nos clients avec leurs audiences, en alimentant nos recommandations stratégiques avec toute l’expertise technologique, data, et opérationnelle du groupe.Description du posteNumberly recherche un(e) Data Engineer en stage pour rejoindre son équipe dédiée aux problématiques Data. Vous participerez aux traitements, transformations et restitutions des données auprès des équipes internes afin d’améliorer les performances des campagnes et des stratégies marketing de nos clients.Vous :Aimez la donnée sous toutes ses formes : brute, travaillée et analysée ;Avez le désir de la comprendre et de la faire parler ;Possédez une formation axée sur la big data, la fouille de données ou plus généralement en software engineering;Appréciez le travail bien fait, avez le sens du détail et vous aimez comprendre les problématiques de vos clients ;Aspirez à travailler pour des clients variés et prestigieux sur des problématiques pointues ;Êtes à l’affût des nouveaux langages/technologies et des dernières tendances open source;Êtes spontané(e) et appréciez le travail en équipe en collaborant avec différents métiers de la data;Portez de l'intérêt au Marketing et souhaitez découvrir ce domaine. Stage de 6 mois débutant en février 2024.Rémunération : 1400 € brut mensuel en M1 et 1700 € brut mensuel en M2.QualificationsVous connaissez :ModélisationSQL PythonETL Encore mieux si vous connaissez :Workflows management platformsEnvironnement HadoopSystèmes et calculs distribuésAPI REST, Web ServicesRealtime / StreamingDocker Ce que nous utilisons :UbuntuSuite Microsoft (SSMS, SSIS, SSRS, Power BI)Hdfs Spark / HiveGit / CICDAirflowKafkaKubernetesInformations supplémentairesChez Numberly, nous partageons une passion pour la transmission à nos équipes comme à nos clients : des talks internes hebdomadaires, des rencontres avec des professionnels experts dans leur domaine, un apprentissage permanent. Un onboarding rapide et puissant, notamment grâce aux Vis ma vie dans des équipes différentes ; aux Happy Meetings (des rendez-vous mensuels internes pour se retrouver avec toutes nos équipes dans le monde et partager l’actualité du groupe). Nous cultivons la liberté de parole qui permet à tous de participer au développement du groupe. Nous agissons positivement sur notre écosystème à travers 1000mercis impacts et via nos activités qui créent de la valeur dans l’Open Internet et participent à l’enrichissement de l’Open Source : https://github.com/numberlyNumberly est acteur de la diversité et Gender Equal by design (certification WeConnect International et gender equity score de 97/100). Numberly propose un environnement international avec plus de 30 nationalités. Des bureaux à l’image de chacune des équipes, une bibliothèque généreuse, un grand studio de musique tout équipé, deux chats, du tri sélectif et du lombricompostage, la possibilité de venir avec votre animal de compagnie et de la place pour les vélos ! Dans chaque cuisine : café, thé, infusions à volonté et aussi des mystery lunchs. Un abonnement Gymlib, des cours de sport et des soirées (souvent déguisées). Possibilité d'être en remote jusqu'à 50% de votre temps (à organiser comme vous le souhaitez). Carte Swile (titres-restaurants). Numberly accueille les personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer H/F,Inetum,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3782175181?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=qQm8ygOo3axtPKy46LMCCw%3D%3D&position=23&pageNum=1&trk=public_jobs_jserp-result_search-card,"Détail de l'offre  Informations générales  Entité de rattachement  Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste Métier Métier AS (Application Services) - Consultant Intitulé du poste DATA Engineer H/F Contrat CDIDescription De La MissionDans le cadre de la croissance de notre agence lilloise, nous développons notre Practice Data et recrutons des profils Data de divers horizons Data Analyst, Data Engineer, Data Scientist et Data Gouv.Les besoins métiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversité de compétences.Vous pourriez être l’un d’eux et rejoindre Inetum.En tant que Data Engineer, vos principales missions consistent àAnalyser et retranscrire le besoin clientConcevoir et mettre en œuvre les solutions permettant de traiter des volumes de données important afin de les mettre à disposition des Data Analyst ou Data ScientistVous êtes le premier maillon de la chaîne garantissant l'intégrité et la qualité de la donnée Profil Pour mener à bien votre rôle, il vous fautUne maîtrise de la conception des entrepôts de donnéesUne expertise dans le stockage de données et leurs manipulationsBase de données parmi les SGBD MySQL, PostgreSQL, Oracle, Snowflake, BigQuery, etc...NoSQL parmi MongoDB, Cassandra, HBase, Neo4J, etc...ETL parmi Talend, Stambia, SSIS, etc...Une appétence pour la programmation parmi Python, Scala, Java, NodeJS, etc..Et si en plus vous disposez des compétences dans les environnements cloud et/ou dans les technologies BigData Hadoop, Spark, Kafka, etc...un choix de missions encore plus large s'offre à vous.Vous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !Notre plus Rejoindre la région Nord-Est, c’est bénéficier des avantages d’un Grand Groupe tout en gardant la proximité régionale.Nous mettrons tout en œuvre pour vous apporter un équilibre vie perso / vie pro. C’est pourquoi nous vous proposons un rythme hybride (selon les contraintes clients).Inetum a d’ailleurs signé un accord de télétravail en 2021 pour que chaque collaborateur puisse adapter son rythme de travail.Une trajectoire de carrière personnalisée et adaptée à vos souhaits d'évolution grâce à une implantation à l’international (26 pays, 7 Fablab), des formations ciblées et des projets couvrant l’ensemble de la chaîne de valeur IT (+25 filières métiers).Intégrer un collectif d’experts partageant des valeurs de solidarité et d’excellence.Localisation du poste Localisation du poste France, Nord Ville LilleCritères candidat Niveau d'études min. requis Bac+5 Niveau d'expérience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'Neo4j', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['MySQL', 'PostgreSQL', 'Oracle', 'Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Inetum,"St.-Ouen, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3782170788?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=kxFTyM%2FLfeYS%2FwrTKreLbw%3D%3D&position=24&pageNum=1&trk=public_jobs_jserp-result_search-card,"Détail de l'offre  Informations générales  Entité de rattachement  Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste Métier Métier AS (Application Services) - Consultant Intitulé du poste Data Engineer H/F Contrat CDIDescription De La MissionDans le cadre de son développement, Inetum recrute un Data Engineer (H/F) pour sa branche Applications Services.Le Data Engineer interviendra chez l’un de nos clients sur des projets BI et/ou Big Data avec une approche Data Driven et ce, en méthode agile.Le Data Engineer sera en charge de Apporter une expertise en Big Data permettant la manipulation de données Accompagner nos clients dans la réalisation de projets dans un contexte Big Data et Cloud Participer à des POCs (Proof Of Concept) permettant de valider les principes techniques et algorithmiques pour des projets Concevoir des plateformes permettant de traiter des volumes importants de données Développer des pipelines de données pour assembler les données en provenance de multiples systèmes Développer des applications d’injection et de traitements massifs sur des volumétries importantes Participer à l’industrialisation d’applications partiellement réalisées (optimisation du code, optimisation des performances, utilisation maximisée des possibilités des outils et du cluster disponible) Mettre en place des bases de données (SQL, NoSQL…) Profil De formation ingénieure en informatique (Bac+5), vous avez évolué dans le monde du développement (langages Java, Scala, python, R, Spark, Tensorflow) avec une culture Devops, une maîtrise des BDD, du Shell/Unix…Vous disposez d'une expérience significative dans le développement (2/3ans) et une expérience également sur une distribution Hadoop (Cloudera, Horthonworks ou MAP-R).Vous êtes à l’aise avec les principes du cloud, une première expérience avec l’un des cloud provider suivant AWS, Azure, GCP serait un plus...Vous avez un esprit d'analyse, orienté sur la mise en place d’algorithmes de manipulation de données volumineuses, sur la manière de les rendre plus performantes (parallélisation, distribution de charge) et dans des conditions de hautes disponibilités.Vous appréciez le travail en équipe et les challenges.Vous possédez des qualités de communication qui vous amène naturellement à partager vos connaissances avec vos clients et vos collaborateurs.Si vous vous reconnaissez, n'hésitez pas à postuler !Localisation du poste Localisation du poste France, Ile-de-France, 93 Seine-Saint-Denis Ville Saint OuenCritères candidat Niveau d'études min. requis Bac+5 Niveau d'expérience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER F/H,Ministère de la Défense,"La Rochelle, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-minist%C3%A8re-des-arm%C3%A9es-3803147909?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=k8rIm2lWQi3jHK1T1gGEVA%3D%3D&position=25&pageNum=1&trk=public_jobs_jserp-result_search-card,"Description du service : Le service des pensions et des risques professionnels (SPRP) a en charge la pré-liquidation des pensions de retraite et d'invalidité des fonctionnaires et des militaires et la liquidation des pensions et rentes des ouvriers de l'Etat. Le bureau du pilotage des chaînes pensions est chargé :d’animer les chaînes et fournir un appui fonctionnel et technique aux employeurs ;de réaliser la maintenance corrective et évolutive du SI Pensions ;de garantir la gestion des flux entrants et sortants ainsi que l’archivage intermédiaire ;d’assurer la conduite, l’animation et le suivi des projets de transformation numérique.Le SPRP a demandé la création d’un infocentre dans le cadre des travaux d’urbanisation de l’écosystème numérique Pensions.Au sein de la section « management du système d’information », le Data Engineer est en charge de l'infocentre mais également en charge de la collecte et la mise à disposition des données en lien avec les équipes métier, ainsi que l’exploitation des résultats sous forme de publication des résultats, de tableaux de bord et d'outils d'aide à la décision.Vos missions :Modéliser les chaînes de collecte, de stockage, de traitement et de restitution des données.Concevoir et créer les modèles à réaliser ainsi que les algorithmes servant à la corrélation des données avec les règles de gestion de l’organisme.Appliquer les techniques (statistiques, text mining, …) d’extraction et d’analyse des informations.Organiser, étudier et synthétiser les sources de données sous forme de résultats exploitables.Maîtriser la qualité des données tout au long de leur traitement.Concevoir les produits de diffusion permettant de répondre aux commandes adressées.Profil recherché : Ingénieur diplômé d’une école spécialisée dans la manipulation de la donnée, vous disposez d’une expérience significative dans le domaine de la statistique et de la data science ou en Big Data. Vous maitrisez le fonctionnement d’un Extract-transform-load (ETL) et connaissez les outils Qlik Sense et TALEND.Doté d’esprit d’analyse, vous maitrisez les méthodes d’ingénierie et la conduite de projets en système d’information.Si vous vous reconnaissez, n’hésitez plus à postuler !Informations complémentaires :Localisation : LA ROCHELLEType de contrat : CDD de 3 ans (renouvelable)Rémunération : Soumise à la grille statutaire de la fonction publiquePossibilités de restauration sur place (MESS) ;Télétravail (1 jour) ;18 RTT ;Accessible par les transports (train et bus);Formation d'adaptation à l'emploi.A réception de votre CV, ce dernier sera étudié et fera l’objet d’un retour dans un délai de 15 jours, si votre profil correspond, votre candidature sera transmise au manager opérationnel qui prendra attache avec vous pour vous recevoir à l’occasion d’un entretien en présentiel. Consultez l’ensemble de nos offres d’emploi via : https://contractuels.civils.defense.gouv.fr/Le ministère des armées est engagé dans une politique active en faveur de la diversité, de l’égalité professionnelle et du handicap.Tous les postes du ministère des Armées sont ouverts aux candidatures d’une RQTH.A ce titre, les candidats F/H ne doivent indiquer aucune information personnelle (âge, situation de famille, photographie) sur leur candidature.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer (Lille),Cenova,"Hauts-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-lille-at-cenova-3799076593?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=F5bG69a57OHSZvbSXqh8ng%3D%3D&position=1&pageNum=2&trk=public_jobs_jserp-result_search-card,"Entrez dans notre univers « être sérieux sans se prendre au sérieux » !Cabinet à forte croissance, à Lille, Cenova accompagne ses clients, grands comptes des secteurs du #Retail dans leurs projets de transformation Data et Digitale, et ce sur l’ensemble des problématiques métiers (marketing, produit, supply, RSE, …).VOS MISSIONS :Vous travaillerez chez l’un de nos clients, spécialiste du #Retail, au sein de l’équipe Data sur le développement de solutions Data Analytics. Vos missions, si vous les acceptez, seront les suivantes :· Participer aux rituels agiles de l'équipe,· Analyser les besoins des utilisateurs et proposer des solutions innovantes et en phase avec les drivers de l'entreprise,· Être garant de l'accès qualitatif aux sources de données,· S’assurer de la maîtrise de la donnée et être garant de la qualité de son utilisation (référencement, normalisation, et qualification) afin d'en faciliter l'exploitation par les équipes (Data Analysts et Data Scientists),· Contribuer à la définition de la politique de la donnée et à la structuration de son cycle de vie dans le respect des réglementations en vigueur,· Être capable d’intervenir sur les systèmes applicatifs autour de la gestion de la donnée et du traitement, et sur les plateformes Big Data,· Assurer la supervision et l'intégration des données de diverse nature qui proviennent de ces sources multiples et vérifier la qualité des données qui entrent dans le Data Lake.Environnement technique :SQL, Python, ETLPower BI, Data Studio, Looker, Tableau, Business ObjectCI/CD, Github, Terraform, Kafka, Airflow, DatabricksGCP (BigQuery), AWS, AzureVOTRE PROFIL :Vous avez une expérience minimale de 2 ans sur des missions de Data Engineering et vous disposez d’une grande appétence technique.Vous appréciez comprendre le cycle de vie de la donnée et vous êtes à l’aise avec les concepts de data lineage, data gouvernance, data privacy. Vous êtes amateur.e de datavisualisation, idéalement avec PowerBI.Travailler en mode agile ? Vous adorez !Vous avez par ailleurs, le contact facile et vous comprenez les enjeux business et adaptez vos analyses en ce sens.Vous êtes proactif(ve), autonome, bon(ne) communiquant(e) et vous êtes à l’aise en anglais.Votre personnalité et votre savoir-faire feront le reste.POURQUOI NOUS REJOINDRE ?Au-delà de missions passionnantes chez des clients de notoriété internationale, Cenova c'est avant tout un cabinet à taille humaine présent sur Lille et Paris.Rejoindre Cenova c’est :✅ Un respect de vos attentes concernant vos missions, un équilibre vie pro/ perso et une réelle proximité managériale pour vous accompagner dans votre évolution.✅ Sa CenoAcademy et sa CenoLife, vous permettront d’évoluer dans vos expertises et d’avoir une vie de cabinet stimulante, tout en profitant d’autres avantages significatifs, en plus de la rémunération attractive.Ces quelques mots suscitent votre curiosité ? Candidatez !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Chantelle,"Cachan, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-chantelle-3809716037?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=F5d5cJkAYHBiBXAqMo%2Fn%2FQ%3D%3D&position=2&pageNum=2&trk=public_jobs_jserp-result_search-card,"La Direction des Systèmes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer H/F H/F, pour le lancement du grand chantier de rénovation de l'architecture Data : la bascule de l'intégralité de son Data Warehouse historique vers Google Big Query.Nous souhaitons recruter un Senior Data Engineer H/F, chargé.e de contribuer à la définition de la feuille de route de la Chantelle Data Plaform. En tant que Data Engineer vous travaillerez au sein de l'équipe Data Intégration en charge de la Chantelle Data Platform.Vos Missions Mettre en œuvre une infrastructure autour de Google Cloud Platform permettant de collecter, transformer, exposer (dataviz, applications, ...) et historiser les données générées par l'entreprise. Travailler en étroite proximité avec les responsables des différents domaines fonctionnels (Référentiels, Supply Chain, Manufacturing, B2B, Retail & e-commerce, Finance, ...), avec notre équipe de Data Analysts ainsi qu'avec l'équipe technique en charge des infrastructures transverses Être force de proposition sur tous les sujets d'architecture et de modélisation (choix de mise en place de pipeline temps réels ou au contraire de flux de données en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage). Définir les éléments structurants, en justifiant vos choix, et les mettez en œuvre. Rationaliser et moderniser notre architecture d'intégration inter-applicative Faire la refonte de la BI de nombreux use cases tels que le pilotage de nos stocks, personnalisation de nos sites e-commerce en temps réel en fonction de nos profils client, etc…Pourquoi travailler chez Chantelle ?Une flexibilité dans votre lieu de travail, selon la politique de télétravail de l'entreprise.11 jours de RTT/an ainsi qu'un 13ème mois.Une culture d'entreprise familiale basée sur des valeurs de respect, de créativité, de durabilité et de transparenceUne aventure dans laquelle vous pourrez vous épanouir, apprendre et entreprendre, avec une grande variété de missions et beaucoup d'autonomieDes équipes ressources humaines et des managers à votre écoute pour vous accompagner dans votre parcours professionnelDes réductions sur nos produits et des ventes au personnelDes avantages dans votre qualité de vie au travail : une conciergerie complète proposant un large panel de services, des activités en interne, un CSE.Vous souhaitez rejoindre un Groupe familial, innovant, engagé et leader dans son secteur en France comme à l'international et vous souhaitez apporter votre expertise et authenticité pour guider votre équipe vers le succès : postulez et rejoignez le Groupe Chantelle !
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H/X),Goaheadspace,"Pantin, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-x-at-goaheadspace-3805968002?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=2sa4k%2BtdbiUrpA30K2E6sA%3D%3D&position=3&pageNum=2&trk=public_jobs_jserp-result_search-card,"MFG Labs est une société de conseil et réalisation experte en data, qui aide les entreprises à améliorer leurs prises de décision, à automatiser leurs processus et à créer de nouveaux services grâce à la data science, au design et à l'utilisation des dernières technologies.MFG Labs intervient à toutes les étapes de votre transformation data : de la création d'une feuille de route de projets data, à la découverte d'insights, à la modélisation de problématiques complexes, de la création d'un modèle prédictif à l'implémentation technique d'une solution data sur-mesureMFG Labs accompagne ses clients de différentes manières :StratégieSolutionsFondationsMFG Labs déploie une approche holistique pluridisciplinaire, en mêlant des data scientists, des designers, des data engineers et des consultants, afin d'apporter des solutions complètes de bout en bout à des problématiques complexes.Dans le cadre du développement de l’équipe, nous recherchons un.e Data Engineer à Pantin (magasins généraux).Au sein de l’équipe Data Technology, vous aurez pour mission de travailler sur des problématiques de collecte de la donnée sur tout type de support digital : web, mobile, application, voire IoT.Votre rôle au sein de l’équipe : Faire partie d’une équipe pluridisciplinaire avec des talents en Design de Service, Consulting et Data science. Développer des applications de production intégrant différents outils : des Mathématiques Appliqués, Machine (Deep) Learning, Recherche Opérationnelle, Statistiques. Développer des pipelines de traitement de données avec l’équipe de Data Science pour : ingérer, transformer et délivrer des données et modèles à nos applications. Déployer des applications utilisant les derniers outils mis à disposition par les différents Clouds publics. À propos de vous : Vous êtes titulaire d'un niveau Bac +4/Bac +5 d'une école d'ingénieurVous êtes rigoureux·se vis-à-vis de vous-même et des autres quant à la qualité du code.Vous avez quelques connaissances et compétences solides en développement et en en Data Ingénierie au sens large.En développementPython 3 et SQL Framework de traitement de données (Spark ou équivalent) Docker GIT En +Framework permettant de déployer des APIs (Flask ou équivalent) CI/CDEn Data IngénierieDatawarehouse ou Datalake Data Pipelines Batch et/ou Straming En +Outils de BI (Tableau, Power BI…) Outils MLOps (Sagemaker, VertexAI, etc.) Compétences spécifiques :Expérience ou intérêt pour l’intelligence artificielle générative et en particulier les Large Langage Models.Si vous vous reconnaissez dans cette annonce, n'hésitez pas à postuler !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer,Onepoint,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-onepoint-3030924688?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=Urq0Sd1Sg04EC%2BOKcbn2EA%3D%3D&position=4&pageNum=2&trk=public_jobs_jserp-result_search-card,"Un data engineer est en charge de concevoir, de construire et de déployer des pipelines de traitement de données. Curieux, il est à l’aise avec du batch et du temps réel, de l’on premise et du cloud, des datalakes ou des data warehouses modernes. Ses traitements sont robustes, sécurisés, et performants, et il n’hésite pas à les factoriser et les automatiser.Vos Missions Seront Les SuivantesÉtudier les systèmes sources ; Choisir et implémenter les solutions de stockage et les modèles de données adéquats ; Extraire et charger les données des systèmes sources ; Uniformiser, structurer et transformer les données ; Exposer ces données (API, Web services …) ; Planifier et orchestrer ces traitements ; Industrialiser selon les pratiques CI/CD ; Mettre en place des solutions de monitoring ; Documenter le code ; Expérimenter, évaluer, faire de la veille technologique. #TECH #DATAVous Maitrisez Une Ou Plusieurs Des Solutions SuivantesLes langages SQL, Python, Scala, Java … L’écosystème Hadoop (Spark, HDFS, Hive, HBase …) Les services Data de GCP, Azure et AWS : Azure Data Factory, Azure Synapse Analytics, Dataflow, BigQuery, Glue, Redshift … Les data platforms Cloudera, Databricks, Snowflake, Confluent, Dremio … Les ETL Informatica (PowerCenter, iPaas), Talend Data Fabric et NiFi Les bases de données ElasticSearch (et la suite ELK), Cassandra, MongoDB, Neo4J … Les outils d’Ops : github/gitlab, Jenkins, CircleCI … De Plus Vous avez une ou plusieurs certifications en cours de validité sur l’une des technologies citées ci-dessus ; Vous disposez d’un très bon relationnel, d’un bon sens de l’écoute et d’empathie ; Vous faites preuve d’initiative, vous êtes naturellement force de proposition, vous avez envie de partager vos connaissances et savoir-faires et d’apprendre de vos pairs.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB', 'Cassandra', 'Neo4j', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer,Experfy,France,https://fr.linkedin.com/jobs/view/data-engineer-at-experfy-3719405786?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=jlZBgriIPmVEdvNIMRym1A%3D%3D&position=5&pageNum=2&trk=public_jobs_jserp-result_search-card,"Iterative. They are excited to prototype at all levels of fidelity—and have the humility to walk away from ideas when they failCollaborative. They have the ability and enthusiasm to work with researchers, engineers, business consultants, and other designers who will challenge and support one anotherComfortable with ambiguity. They know projects and businesses move fast. That means the path forward isn't always well-defined. They are comfortable and collaborative through our processInterdisciplinary. They deliver data products for digital solutions, deploy analytical models into production, fix existing data platforms, or coach and enable other teams in best practices depending on needYou're Good At:Working with a diverse set of clients across domains and industriesImplement data orchestration pipelines, data sourcing, cleansing, and augmentation and quality control processesDeploying machine learning models in productionLeading data architects in designing data architecturesDesign flexible and scalable data architectures tailor made for the clientMentoring data engineers to further their personal and professional growthLeading other engineering staff on projectsDeveloping team's talent by providing direction and facilitating technical architectural discussionsContribute to the running of BCG Platinion | MAYA Design's consulting business by: Assisting with business development through writing proposals, scoping projects; Contributing to our thought leadership through written publications and speaking at events and conferencesTranslating business needs into solutionsDesigning overall data solution, integration, and enterprise architectureYou'll Bring:6+ years of experience working on large scale, full lifecycle data implementation projectsBS/BA in data engineering, software engineering, data science, computer science, applied mathematics, or equivalent experience5+ years of experience in a client facing role2+ years professional development experience with some of the AWS/Azure/GCP data stack: S3, Redshift, AWS glue, EMR, Azure Data Warehouse, Azure Blob Store, Google Big QuerySubject matter expert in at least one area related to data management: An RDBMS technology; a Big Data technology; Enterprise Data Management, Governance, Strategy, etcA deep knowledge of performant SQL and understanding of relational database technologyHands-on RDBMS experience (data modeling, analysis, programming, stored procedures)Expertise in developing ETL/ELT workflows with one or more of the following: Python, Scala, JavaDeployment of data pipelines in the Cloud in at least AWS, Azure, or GCPA deep understanding of relational and warehousing database technology, working with at least one of the major databases platforms (Oracle, SQLServer, Teradata, MySQL, Postgres)Additional consideration to candidates who possess some of the following criteria:Experience working with Big Data technologies such as Spark, Hive, Impala, Druid, or PrestoA solid foundation in data structures, algorithms, and OO Design with fundamentally strong programming skillsProven success working in and promoting a rapidly changing, collaborative, and iterative product development environmentStrong interpersonal and analytical skillsIntellectual curiosity and an ability to execute projectsAn understanding of ""big picture"" business requirements that drive architecture and design decisionsDevOps and DataOps skills including ""infrastructure as code"" systems like CloudFormation or TerraformData system performance tuningImplementation of predictive analytics and machine learning models (MLlib, scikit-learn, etcWillingness to travel around the globe to work with clients and BCG teams. At times, this role involves significant travel to client sites. The amount of travel will depend on client needs and nature of projectsWhat to include in your application:A link to your portfolio that demonstrates your affinity for data engineering and shows how you approach digital challenges


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['Scikit-Learn'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['MySQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Software Engineer, Chrome",Google,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-chrome-at-google-3797082498?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=YEjPc5pueuOgb5EGMHqxVA%3D%3D&position=6&pageNum=2&trk=public_jobs_jserp-result_search-card,"Google welcomes people with disabilities.Minimum qualifications:Bachelor’s degree or equivalent practical experience.2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting.Preferred qualifications:Experience developing end-user applications.Experience with iOS development.Excellent attention to detail and an interest in user interface.About The JobGoogle's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.Chrome is dedicated to building a better, more open web. We’re focused on making a better browser (on both desktop and mobile) to help users take advantage of all the web has to offer in a safe and secure way.Chrome is available across all major platforms — iOS, Android, Windows, Mac, Linux and Chrome OS. We also built Chrome as an open source project so the entire web ecosystem could benefit from the latest innovations in speed, simplicity and security.ResponsibilitiesDesign new user-facing features in Chrome for iOS, in collaboration with Product Managers and UX designers.Implement, test, and launch features with peers.Own features long-term, evolving with the platform and the product.Manage project priorities, deadlines, and deliverables.Work in the open-source repository as well as Google’s proprietary code base.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux', 'Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Junior Data Engineer,Helsing,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/junior-data-engineer-at-helsing-3809390920?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=YbkoaGy9ozSyMaZP2fVEVg%3D%3D&position=7&pageNum=2&trk=public_jobs_jserp-result_search-card,"Who we areHelsing is a defence AI company. Our mission is to protect our democracies. We aim to achieve technological leadership, so that open societies can continue to make sovereign decisions and control their ethical standards.As democracies, we believe we have a special responsibility to be thoughtful about the development and deployment of powerful technologies like AI. We take this responsibility seriously.We are an ambitious and committed team of engineers, AI specialists and customer-facing programme managers. We are looking for mission-driven people to join our European teams – and apply their skills to solve the most complex and impactful problems. We embrace an open and transparent culture that welcomes healthy debates on the use of technology in defence, its benefits, and its ethical implications.The role At Helsing, data lies at the core of our AI capabilities and we put huge emphasis on acquiring real world records to validate our algorithms . As this is an entry level role, you are given the task of leading the data acquisition and labelling process for the development of our AI algorithms, enabling you to learn how advanced AI algorithms are trained and deployed in real life applications. Over time you will become a recognised expert at Helsing on how to collect and annotate data most useful for our products and grow your career by working closely with our AI researchers and software engineers. The day-to-day You will support the engineering team, in various steps of the data preparation pipeline (collection, annotation, quality control, storage & management of mission critical datasets)When requested, working outdoors to collect / record video data, such as by flying drones, driving vehicles, and operating camerasYou will use our data annotation tools to tag captured images / videos with metadata and upload them for access by other Helsing engineersYou will assess, scope, and prioritise requests for data from other teams at Helsing You should apply if youHold a BSc in computer science, engineering or related fieldAre an independent and creative problem solving skills (you can make use of duct tape and a screwdriver)Possess strong communication skills, written and verballyHold a driving licence valid in EUHave experience operating from a terminal and writing scripts to automate tasks, using a programming language such as PythonAre meticulous at housekeeping and pay extra attention to detail Note: The above bullet points describe the ideal candidate. None of us matched all of these at once when we first joined Helsing. We encourage you to apply even if you believe you meet only part of our wish list.Nice to have An interest in computer vision applications and familiarity with annotation tools such as CVATExperience in data acquisition / annotationA license to fly drones ( Open A3 )An interest in defence hardware or previous service in the armed forces Join Helsing and work with world-leading experts in their fields Helsing’s work is important. You’ll be directly contributing to the protection of democratic countries while balancing both ethical and geopolitical concernsThe work is unique. We operate in a domain that has highly unusual technical requirements and constraints, and where robustness, safety, and ethical considerations are vital. You will face unique Engineering and AI challenges that make a meaningful impact in the worldOur work frequently takes us right up to the state of the art in technical innovation, be it reinforcement learning, distributed systems, generative AI, or deployment infrastructure. The defence industry is entering the most exciting phase of the technological development curve. Advances in our field of world are not incremental: Helsing is part of, and often leading, historic leaps forwardIn our domain, success is a matter of order-of-magnitude improvements and novel capabilities. This means we take bets, aim high, and focus on big opportunities. Despite being a relatively young company, Helsing has already been selected for multiple significant government contractsWe actively encourage healthy, proactive, and diverse debate internally about what we do and how we choose to do it. Teams and individual engineers are trusted (and encouraged) to practise responsible autonomy and critical thinking, and to focus on outcomes, not conformity. At Helsing you will have a say in how we (and you!) work, the opportunity to engage on what does and doesn’t work, and to take ownership of aspects of our culture that you care deeply about What we offer A focus on outcomes, not time-trackingCompetitive compensation and stock optionsRelocation supportSocial and education allowancesRegular company events and all-hands to bring together employees as one team across EuropeA hands-on onboarding program (affectionately labelled “Infraduction”), in which you will be building tooling and applications to be used across the company. This is your opportunity to learn our tech stack, explore the company, and learn how we get things done - all whilst working with other engineering teams from day one Helsing is an equal opportunities employer. We are committed to equal employment opportunity regardless of race, religion, sexual orientation, age, marital status, disability or gender identity. Please do not submit personal data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, trade union membership, data concerning your health, or data concerning your sexual orientation.Helsing's Candidate Privacy and Confidentiality Regime can be found here: https://helsing.ai/candidate-privacy-and-confidentiality-regime/


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage - Data Engineer - ML (H/F),Withings,"Issy-les-Moulineaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=0vK6jUJOONxiInjbs5SCZA%3D%3D&position=8&pageNum=2&trk=public_jobs_jserp-result_search-card,"Chez Withings, nous développons des appareils de santé connectée : nos balances connectées, montres hybrides, tensiomètres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilisés par des millions d'utilisateurs. Notre objectif est de permettre la prévention, le dépistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de révolutionner la manière dont on prend soin de notre santé.Au sein de l'équipe Machine Learning, nous développons des algorithmes pour extraire des informations physiologiques et médicales pour nos utilisateurs tels que le SPO2, la fréquence cardiaque, la détection de diverses pathologies comme la fibrillation atriale, l'apnée du sommeil...Intégré.e au sein de l'équipe Machine Learning, tu auras une ou plusieurs des responsabilités suivantes :Développer un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de sécurité ; Construire des dashboards de visualisation ; Construire un système d'alerte pour notifier les contributeurs d'éventuels problèmes ; Développer des outils permettant de corriger les éventuels problèmes de façon automatisée ; RequirementsÀ la recherche d'un stage d'une durée de 3 à 6 mois ; Préparation d'un Master en école d'ingénieur ou équivalent / année de césure possible ; Maîtrise de Python ; Maîtrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ; Première expérience sur du développement logiciel ; Culture DevOps (omniprésence du monitoring, automatisation des tâches, ...) Compréhension de la culture et des besoins des différents membres de l'équipe ; Rigueur, autonomie, prise d'initiative, curiositéBenefitsRejoindre l'aventure Withings, c'est :Intégrer un des pionniers et leaders mondiaux de la santé connectée, plusieurs fois primé au Consumer Electronic Show Contribuer à des projets innovants et ambitieux pour la santé de demain dans un environnement agile et en constante évolution Intégrer une entreprise internationale, membre de la FrenchTech 120, dont les équipes sont basées à Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen Participer à l'amélioration continue de nos produits et services en les bêta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre collègues Participer à la Withings Med Academy en assistant à des conférences de professionnels de santé afin de renforcer ses connaissances dans le domaine médical Collaborer avec des collègues passionnés et célébrer ensemble chacune de nos réussites ! Toutes les candidatures reçues sont étudiées indépendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la santé des candidats. Withings aspire à offrir et garantir l'égalité des chances aux candidats et seules les personnes habilitées (RH et Management) auront accès aux informations concernant votre candidature.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,ADVANCED Schema,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-advanced-schema-3235566526?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=BMibyItZHaNjPFuKpZ9Y8Q%3D%3D&position=9&pageNum=2&trk=public_jobs_jserp-result_search-card,"En tant que Data Engineer, vous aurez les missions suivantes :Concevoir des modélisations physiquesConstruire des mappings techniques et rédaction de spécifications d’alimentation.Développer des flux des donnéesContribuer au pilotage de projets, de proof of conceptsParticiper à des missions d’expertiseCompétences professionnelles & niveau d'études requis : Vous êtes titulaire d'un diplôme Bac +3 minimum dans le domaine de la dataVous possédez minimum 1 an d'expérience dans le métier Être enthousiaste à l'idée d'apprendre de nouvelles technologiesExpérience de la méthodologie Agile / ScrumCapacité à planifier et à prioriser les tâches et les activités confiées en autonomieMaîtrise de l’anglais oral et technique obligatoireExpérience avérée dans l'écriture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQL


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Bash'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,ADVANCED Schema,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-at-advanced-schema-3539059697?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=URdTDdpBGfQm4SV0GnPTVQ%3D%3D&position=10&pageNum=2&trk=public_jobs_jserp-result_search-card,"ADVANCED SCHEMA est une société de services informatiques spécialisée dans la donnée.Depuis 20 ans, nous créons des plateformes data sur mesure pour nos clients, orientées usages et alliant qualité, performance, sécurité et gouvernance. ADVANCED SCHEMA a développé de nouvelles activités pour réaliser l'ambition du groupe : devenir une entreprise end-to-end, en proposant une offre à 360° à nos clients pour les accompagner à chaque étape de leurs projets. À ce jour, nous sommes près de 220 passionnés répartis entre Paris, Lille, Nantes, Lyon mettant à profit leur expertises aussi bien dans le domaine du retail, de la finance/assurance, du luxe, des médias, de la santé et de l'industrie.Aujourd’hui, nous souhaitons intégrer de nouveaux renforts dans nos équipes Lilloises.En tant que Data Engineer, vous aurez les missions suivantes :Concevoir des modélisations physiquesConstruire des mappings techniques et rédaction de spécifications d’alimentation.Développer des flux des donnéesContribuer au pilotage de projets, de proof of conceptsParticiper à des missions d’expertiseCompétences professionnelles & niveau d'études requis :Vous êtes titulaire d'un diplôme Bac +3 minimum dans le domaine de la dataVous possédez minimum 2 ans d'expérience dans le métierPositif(ve), curieux(se), rigoureux(se) et doté(e) d'une bonne aisance relationnelleÊtre enthousiaste à l'idée d'apprendre de nouvelles technologiesExpérience de la méthodologie Agile / ScrumCapacité à planifier et à prioriser les tâches et les activités confiées en autonomieMaîtrise de l’anglais oral et technique obligatoireExpérience avérée dans l'écriture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQLNotre proposition :Temps plein en CDI avec un salaire attractif + participation aux bénéfices + prime(s) sur investissement personnelMode de travail hybride (agence, site, télétravail selon projets/clients)Ticket restaurant (Sodexo)Mutuelle financée à 50%PrévoyanceComité entreprise5 jours d’onboarding plein temps via la ADVANCED SCHEMA AcademyNotre investissement :Chez ADVANCED SCHEMA, nous t’offrons un environnement de travail stimulant et collaboratif ainsi que des possibilités de croissance et de développement professionnel. Également un accompagnement/support au quotidien pour te faire grandir et monter en compétences, sur des projets qui répondent à de vrais enjeux pour nos clients. Si tu es passionné(e) par les données et prêt(e) à relever de nouveaux défis, alors nous aussi nous aimerions te rencontrerProcess de recrutement :Si ta candidature retient notre attention, nous te proposons :Un premier échange téléphonique/visioUn entretien physique (+questionnaire d’évaluation) avec un senior managerUn entretien final à notre siège Parisien afin de rencontrer le DG


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - DBA MySQL/MariaDB Senior M/F,Transatel | NTT,"Puteaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-dba-mysql-mariadb-senior-m-f-at-transatel-ntt-3756893073?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=IX7FAqd5nGRjfvxVgscOJw%3D%3D&position=11&pageNum=2&trk=public_jobs_jserp-result_search-card,"Transatel est un fournisseur mondial de solutions de connectivité cellulaire et le 1er agrégateur d’opérateurs mobiles alternatifs MVNO en Europe. Et si vous connectiez le monde, au-delà des frontières ?Votre mission Vous êtes passionné(e) par les nouvelles technologies? Vous rêvez de construire des infrastructures et des services qui ont une envergure mondiale dans une société multiculturelle ? Vous souhaitez progresser techniquement et bosser sur des sujets intéressants ? Vous aimez travailler dans une bonne ambiance ? Alors rejoignez-nous !Le rôle du DBA est de concevoir, maintenir, superviser et développer l’infrastructure des bases de données pour la plateforme Transatel afin de répondre aux exigences de services pour les clients externes et les usages internes. Transatel propose ses services à l’international pour des grands comptes ayant une haute exigence de disponibilité et d’efficacité. Cette activité permet aux DBA d’avoir des responsabilités variées et stimulantes avec de belles opportunités d’évolution.Au sein de la DTSI, rattaché(e) au Responsable Infrastructure, vous intégrez une équipe de 12 personnes dans les périmètres SysAdmins, DBA, Monitoring.Vos principales missions :Assurer le maintien en conditions optimales des bases de données (performances, disponibilité)Optimiser les performances des traitements SQL effectués par les plateformes TransatelAméliorer l’automatisation des tâches récurrentes et des tests de supervisionParticiper aux mises en production des composants développés et opérés par TransatelRafraichir les environnements de développement/test avec des données à jour et désensibiliséesSuperviser et analyser l’activité DB, Surveiller les jobs, Traiter les incidentsAppliquer la politique de sécurité, Gérer les utilisateursConserver un environnement propre en assurant l’archivage des données et le nettoyage des structures de donnéesMaintenir la qualité des données maitres et données de références, en relation avec les chefs de projetsApporter son expertise aux développeurs pour la conception des structures de données et le développement SQL Signes particuliers de la plateforme :Trafic en forte croissancePlateforme en Dual site et hybride (Cloud Public)Environ 30 instances SQL ServerPlus de 2TB de données pour MySQL.Etc.Votre profil Bonne gestion du stress,Capacité d'analyse (investigation) méthodique et sens relationnel,Bonne gestion des priorités et respect des délais,Travail collaboratif dans une direction technique avec des chefs de projets, développeurs, sysadmin, réseau et télécom, BDD, Support,Capacité rédactionnelle, esprit synthétique afin de rendre compte des actions et des réalisations entreprises,Capacité à transmettre son savoir et son savoir-faire,Expérience de 3 ans minimum (hors stage) en tant que DBA MySQL & NoSQL.Le monde des Telecom ne vous est pas inconnuAnglais techniqueVotre univers technologique :MySQL/MariaDB, Percona, ColumStore, Galera Cluster,ElasticSearch 6.X Etc.Linux Debian, Centos, RedhatBash, Python, AnsibleNotre process de recrutement Chez Transatel, nous nous efforçons d’avoir un process global efficace afin de finaliser nos recrutements dans les meilleurs délais (environ 3 semaines).Voici les différentes étapes du processus de recrutement :1ière prise de contact RH par téléphoneEntretiens : Un entretien Manager / RH + un ou plusieurs entretien(s) opérationnel(s) ou technique(s)Un test de personnalité en ligneUn appel RH vous présentant l’offre de collaboration en détails puis réception de celle-ci par mail Accueil & parcours d’intégrationLes avantages Package salarial : fixe + bonus individuel + intéressement semestriel et participation (plaçables sur PEE ou PER)Comités de salaire tous les 6 moisJusqu’à 2 jours de télétravail, 25 jours de congés + des jours offertsCSE, restaurant d’entreprise dans les locaux, mutuelle avantageuse, remboursement navigo à 50% ou forfait mobilité durablePour plus d’information, se référer à la page carrière de Transatel : https://www.transatel.com/fr/nous-rejoindre/remuneration-et-avantages/Si vous êtes arrivés jusqu’en bas de cette offre, il serait dommage de remettre votre candidature à plus tard, postulez !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'NoSQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
R&D Software Data Engineer (H/F) - CDI,AYRO,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/r-d-software-data-engineer-h-f-cdi-at-ayro-3799031985?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=v1UuRyuWVP6HM7BvAlVgvw%3D%3D&position=12&pageNum=2&trk=public_jobs_jserp-result_search-card,"About AYROAYRO is a French, Deep Tech startup, with the global ambition of enabling the decarbonization of the maritime shipping industry worldwide. We design, build and sell the OceanWings, enabling commercial vessels to reduce their fuel consumption and therefore their CO2 emissions by up to 50% using the power of the wind. By 2050, shipping could represent 15% of all CO2 emissions: the emission reduction potential of our solution could be measured in Gigatons of CO2 in the next 5-10 years. Our OceanWings 363 have recently been installed on the Canopée shipping vessel who will transport the Ariane 6 rocket from Europe to Kourou in French Guyana and many other large projects are in the worksJob OverviewYour mission is to participate in the design and industrialization of OceanWings® by contributing to the development of our control software platform for OceanWings® on board ships, as well as the software and tools necessary for R&D. You will join AYRO's R&D team of about thirty people, with a specific focus on the software development team in its early stages.Main MissionsYou are tasked with developing our data analysis environment, including the following:• Consolidating the data harvesting architecture of OceanWings® installed on boats.• Consolidating the architecture for data storage, cleaning, and enrichment.You will implement this exciting project in the following technical environment:• Development in Python, with a focus on PySpark.• Use of an SQL database.• Integration with AWS/Azure services.Profil et compétences requises• Your knowledge acquired through your Master's degree (Bac+5),• Your experience as a data engineer (2-4 years),• Knowledge in databases (SQL language),• Fluency in English,• A first experience in Agile software development, preferably Scrum,• Analytical and synthesis skills, autonomy.Your additional assets to help us develop the team and projects:• Knowledge of ETL/ELT processes,• Familiarity with cloud environments is appreciated (ideally AWS or Azure),• Advanced programming skills in Python (knowledge in PySpark would be appreciated).What we offer• Work on innovative projects contributing to the decarbonization of the planet.• Contribute to building a team from the ground up.• Join a motivated team that is receptive to your suggestions.• Work in a pioneering spirit with sustained growth.• Enjoy a permanent contract (CDI) as a salaried employee with 218 working days, following the metallurgy industry's collective bargaining agreement.• Be based in Paris, in modern offices, with occasional travel within France (factory located in Caen) and potential international travel (initially in Europe).• Be available to start as soon as possible.• Receive an attractive salary based on your experience, meal vouchers, 50% reimbursement for public transportation, and opportunities to participate in foosball and darts tournaments.• Experience a personalized recruitment process that includes technical and HR interviews, with an additional AYRONAUT available at your request.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Big Data - Java Spark - I&D (H/F),Capgemini,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-big-data-java-spark-i-d-h-f-at-capgemini-3779429753?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=EbLYRc20PV1JH4np86HXpg%3D%3D&position=13&pageNum=2&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques motsCapgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans près de 50 pays. Partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie, le Groupe est guidé au quotidien par sa raison d’être : libérer les énergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d’expérience, Capgemini est reconnu par ses clients pour répondre à l’ensemble de leurs besoins, de la stratégie et du design jusqu’au management des opérations, en tirant parti des innovations dans les domaines en perpétuelle évolution.Insights & Data en quelques motsDans ce contexte, notre practice Insights & Data (I&D) s’appuie sur une équipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette équipe combine des compétences métiers avec une forte expertise data, analytique et d’intelligence artificielle pour mettre en œuvre des solutions qui visent à améliorer la gestion et la valorisation des données. Pour renforcer les équipes d’I&D, nous recherchons actuellement un.e Data Engineer Java/Spark. A quoi ressemblera ton quotidien ? Vous concevrez et mettez en œuvre des stratégies sécurisées d'acquisition et d'intégration de donnéesVous construirez des pipelines de données pour collecter, transformer et traiter des données en collaboration avec des scientifiques de données afin de répondre aux exigences de la modélisation de données d'analyse avancéeVous participerez au développement du data processingSparkSQL en Java (connaissances solides en Java 11 ET Spark ET SQL indispensables), mais aussi HiveQL, Shell.Vous exploiterez des outils DevOps (GitLab, Jenkins, K8S , ArgoCD, Sonar, Nexus, Maven…) pour l’intégration dans le process CI/CDVous effectuerez le chargement des données en streaming (Kafka / MaprES) et en batch dans des bases Hive/ MapRDB / Mongo DB.Les données proviendront en grande majorité du mainframe (CDC / DB2 / Fichiers MVS) mais également de SGBD.VOTRE PROFIL· Diplômé(e) d'un Bac+5 en informatique· Vous comptez au moins 3 ans d’expérience (au sein d’une ESN ou chez un intégrateur ou éditeur) en conseil clientèle· Vous maîtrisez le langage Java Spark· Vous êtes familier à l’écosystème Big Data (Hadoop, Spark, Kafka)· Vous avez une expérience en Build et en Run· Vous avez déjà exploité des outils DevOps (GitLab, Jenkins, Nexus, Maven…)· Vous avez de bonnes connaissances des pratiques Agiles / SAFe, utilisation de JIRALES PLUS DU POSTE En plus de votre quotidien, vous pourrez entreprendre, être formé, utiliser nos incubateurs pour innover, et vous dessiner une trajectoire de carrière personnalisée.Vous intégrerez une équipe ambitieuse, fun et dynamique !· Une culture forte et bienveillante, et une grande place laissée à la liberté· Des clients variés, leaders de leur secteur· Une approche pragmatique, qui répond aux vrais enjeux des entreprises· Un véritable accompagnement dans l’évolution de votre carrière· Une équipe à taille humaine, en renouvellement et en hyper croissance· Une priorité accordée au développement des collaborateurs – un management qui aide les équipes à progresser, à réussir


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA']}"
Data engineer confirmé (CDI),Retail Shake,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-cdi-at-retail-shake-competitive-intelligence-3784292969?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=3%2FIhnysj2AvFXckySxHr7g%3D%3D&position=14&pageNum=2&trk=public_jobs_jserp-result_search-card,"Que faisons-nous chez Retail Shake ?Nous proposons une solution SaaS (abonnement) ainsi que des projets sur-mesure aux pros de la grande distribution (généraliste ou spécialisée), aux marketplaces ainsi qu’aux marques, quel que soit leur domaine d’activité ! Cet outil permet à nos clients d'avoir une vision 360° de leur environnement concurrentiel sur leur marché et d’être alertés quotidiennement : produits, veille tarifaire, promos, surveillance des stocks géolocalisée, distribution, avis client, benchmark prix, le plan merchandising et la stratégie marketing. Tes aptitudes et compétencesTu es organisé(e), doté(e) d’un bon relationnel afin de travailler en équipeTu es autonome et rigoureux(se) : livrer de la qualité et à tempsEnfin, tu es intéressé́(e) par le milieu du retail et des nouvelles technologiesTes missionsSous la responsabilité du CTO (Chief Technology Officer) tes missions seront les suivantes :Scraping :  conception de solutions permettant le traitement de volumes importants de pipelines data. Matching : structuration de la dataAssurance qualité : monitoring des pipelines de donnéesBusiness Intelligence : construction de dashboards pour comprendre la dataMise à jour permanente sur les technologies et langages utilisés dans le but de partager ses connaissances et aider à l’avancement des projets.Tes technologiesPython, Scrapy, Google Cloud (Storage, BigQuery, Looker), Azure (Storage, PowerBI), Grafana, ElasticSearch, Docker, TensorFlow.Ton profil Tu aimes les projets innovants, l’entreprenariat, les environnements dynamiques, les “petites” équipes (nous sommes une startup). Tu es débrouillard(e), sérieux(se), autonome, bon(ne) communicant(e), tu aimes travailler en équipe, l'entraide et partager tes compétences.Ta rémunérationDe 30K€ à 50K€ bruts en fonction de ton profil + tickets restaurant + 100% mutuelle prise en charge + 50% transports en commun.Lieu74 rue des Arts, Lille = quartier Lille Centre / Opéra / Vieux Lille A deux pas des gares, du métro et du tram On est entourés de beaux immeubles et de belles boutiques, c’est le quartier le plus agréable de la Métropole !Le process de recrutementÉchange visio introductif avec le CTOEntretien physique et mise en situation avec Irwan, le fondateur


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow'], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer Snowflake F/H,Key Performance Consulting (KPC),"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-f-h-at-kpc-3794836507?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=EPjgSw0jC32Iuua4nsjb6w%3D%3D&position=15&pageNum=2&trk=public_jobs_jserp-result_search-card,"DEVENEZ NOTRE PROCHAIN(E) Data Engineer Snowflake ! Vous recherchez une entreprise où vous pouvez télétravailler tout en gardant un lien de proximité, qui laisse de l’autonomie, et où il fait bon travailler, alors nous vous souhaitons la bienvenue chez KPC.Vous avez une expérience d'au moins 2 ans en développement SQL ou une première expérience sur Snowflake ?Vous souhaitez travailler au sein d’une équipe d'experts technico-fonctionnels ?Rejoignez l’entreprise KPC ! Une entreprise à taille humaine avec un mode de management dynamique et de proximité.Notre cœur de métier de KPC : la business intelligence. Nous sommes intégrateurs de solutions GOLD PARTENAIRE de SAP, Qlik, Microsoft BI, Tableau, Snowflake, Semarchy etc.Notre gold partenariat nous permet d'offrir des formations certifiantes pour nos collaborateurs, d'avoir des liens de proximités avec les éditeurs et de revendre leurs solutions.Rejoignez la plus grosse équipe SNOWFLAKE certifiée en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.Vous souhaitez intégrer une ESN à taille humaine vous permettant de travailler sur des projets challengeant et de monter en compétences ? Ce poste est pour vous !VOS MISSIONS :Elaboration d'architectures optimisées dans un contexte Snowflake,Conception et mise en place des ingestions de données (temps réel, Kafka, Snowpipe),Modélisation de données (Star Schéma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des données (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des coûts d utilisation Snowflake (FinOps)VOTRE PROFIL :Vous êtes issu d'une école d'ingénieur ou d'un Master 2Vous avez une première expérience sur du Snowflake ou deux/trois ans de SQLPROCESSUS DE RECRUTEMENT :Vous pensez être celui, celle qu’il nous faut et vous vous êtes reconnu dans notre organisation, alors venez vivre votre première expérience KPC en postulant à cette offre :Vous serez appelé(e) par Camille ou Angélique (chargées de recrutement) pour une première prise de contactNous pourrons poursuivre les échanges avec Anthony (consultant manager Snowflake) et/ou Mickael (Directeur Data) pour l’approche projet et techniquePour clore ce processus de recrutement, nous vous inviterons à rencontrer Stéphane (directeur d'agences PACA)Et tout ça dans un temps record 😊 : 15 jours en moyenne pour allier réactivité et efficacité.Nous garantissons l’égalité des chances pour toutes et tous car pour nous la diversité est une force !KPC EN QUELQUES MOTS ? Nous sommes une entreprise spécialisée dans la Data. Depuis treize ans, nous accompagnons nos clients à valoriser leurs données de manière innovante et efficace pour développer leur performance, améliorer leurs processus et expériences utilisateurs. Nous intervenons en mode projet (50% régie, 50% forfait) Nous avons développé 3 grandes activités : ANALYTICS (BI, Data Science/Big Data, Data Gouvernance, EPM, Digital) ERP SAP CRM Pour cela, nous travaillons en partenariat avec les plus grands éditeurs du marché tels que : SAP, QLIK, DATAGALAXY, SALESFORCES, SNOWFLAKE, TALEND, MICROSOFT, ONESTREAM, IMAGINO. En forte croissance, nous cherchons de nouveaux talents pour participer à cette aventure humaine au service des entreprises de demain. KPC EN QUELQUES CHIFFRES :300 collaborateurs20 % Croissance annuelle8 agences en France (Aix-en-Provence, Nice, Montpellier, Lyon, Toulouse, Bordeaux, Paris et Nantes)Des grands groupes en tant que clients : CMA CGM, PERNOD RICARD, AIRBUS, CDISCOUNT, CULTURA, GIFI, POLE EMPLOI, L'OREAL ...NOS AVANTAGES :Organisation du travail 100% flexible avec du télétravail, participation aux frais téléphonique et internet et un forfait équipement fournitureUn parcours d'intégrationDes formations et des certifications avec les éditeurs sur les technos de pointeIK voiture, véloCarte resto, mutuelle, prévoyance santéPrime « Vacances »POURQUOI NOUS REJOINDRE ?Une entreprise à taille humaineUn mode de management dynamique, agile et de proximitéUne vie d'agence animée, engagée et conviviale dans des locaux sympasUne attention particulière à un équilibre de vie pro / persoUne entreprise qui encourage les initiatives et l'autonomieUne entreprise certifiée Ecovadis Silver pour des actions concrètes en termes de RSEUn cadre de travail agréable prenant en compte les enjeux sociétaux et environnementauxVous êtes ou voulez être consultant(e), chef de projet, expert(e) technique, manager ? Notre promesse : vous accompagner de façon personnalisée et continue quel que soit votre projet à court, moyen et long terme.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Scientist / Engineer,Cephalgo,France,https://fr.linkedin.com/jobs/view/data-scientist-engineer-at-cephalgo-3760013350?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=Pe%2Fs%2Fr7zNA9BX1J8p8c9og%3D%3D&position=16&pageNum=2&trk=public_jobs_jserp-result_search-card,"The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.  ResponsibilitiesCollect, process, and clean data from diverse sources to prepare it for analysis, ensuring consistency and reliabilityAnalyze raw data: assessing quality, cleansing, structuring for downstream processing and applying machine learning (ML) and deep learning (DL) techniquesA focus on quantitative analytics and data modeling.Design accurate and scalable prediction algorithmsEnsuring scalable ML/DL pipeline constructionImplementing data storage solutions that optimize for volume, velocity, and variety of EEG dataCollaborate with the team to bring analytical prototypes to productionStay up-to-date with the latest technologies and trends in data science and machine learningQualificationsMaster's degree or equivalent experience in quantitative field (Statistics, Mathematics, Computer Science, Engineering, etc.)At least 1 - 2 years' of experience in ML/DL, quantitative analytics and data modelingA strong statistical and programming backgroundExperienced in MLOP pipeline construction and big data technologies like Spark, MLFlow, Snowflake, Hadoop for hosting the dataDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Excellent problem-solving skills and ability to work independently or as part of a teamExperienced in working interdisciplinary tasksWe OfferCompetitive salary and benefits packageA collaborative work environment with a supportive teamOpportunities for professional growth and developmentAccess to the latest tools and technologies.Flexible working hours and remote work optionsCEPHALGO focuses on introducing technological innovations to assist medical professionals to provide better mental health care. Located in Strasbourg, extended beyond Europe, CEPHALGO’s patient monitoring technique using EEG and AI has been applied in psychiatry across Europe. Further information can be found at https://cephalgo.com.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Consultant Junior Data Engineer - Paris - 2023,Mazars,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/consultant-junior-data-engineer-paris-2023-at-mazars-3771285480?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=QZuar61jEkMzRFwL87fDUA%3D%3D&position=17&pageNum=2&trk=public_jobs_jserp-result_search-card,"Votre posteMazars est un groupe international et intégré spécialisé dans l’audit, la fiscalité et le conseil ainsi que dans les services comptables et juridiques*. Présents dans plus de 95 pays et territoires à travers le monde, nous nous appuyons sur l’expertise de plus de 47 000 professionnels – plus de 30 000 au sein de notre partnership intégré et plus de 17 000 via « Mazars North America Alliance » – pour accompagner les clients de toutes tailles à chaque étape de leur développement.*Dans les pays où les lois en vigueur l’autorisent.Vos principales missionsL’équipe Data Services de Mazars, c’est plus de 150 consultants spécialistes de la data, répartis sur 2 hubs (Paris La Défense, New-York). Ils couvrent l’ensemble de la chaîne de valeur de la donnée : Data Strategy et qualification de cas d’usage, Gouvernance et qualité des données, Data Visualisation, Data Science, Data Engineering et Data Architecture.Nous sommes convaincus que le Data Engineering est la pierre angulaire de cette industrie. Nous mobilisons, pour servir nos clients, une stack technologique riche et variée, tant sur les outils open-sources (Python, Pandas, PySpark, FastAPI, Vim, SQL/NoSQL, ...) que sur les solutions du marché (Snowflake, AWS, Azure, ...).Notre équipe de Data Engineers travaille au quotidien avec les membres de Mazars R&D et nos Data Analysts. Pour nos clients, nous produisons des solutions qui intégrent le DevOps (GitLab, Ansible, Docker, Terraform, ...) dès la phase de conception.Vous serez formé(e) à nos méthodologies et aurez l’opportunité de travailler au sein d’équipes pluridisciplinaires, y compris les équipes de R&D qui développent et maintiennent nos outils d’Analytics ainsi que notre infrastructure interne (GitLab-CI, VMs OpenNebula, CephFS, etc...).Vous interviendrez de façon opérationnelle sur des missions de conseil data ambitieuses et innovantes pour nos clients du CAC40 et SBF120, en France et à l’international.Vous Participerez Notamment à L’amélioration de la performance opérationnelle de nos clients au travers de l’exploitation et la valorisation de données sur des cas d’usage métier concrets (stratégie, marketing et vente, R&D, finance, RSE, etc.). Le développement de bout en bout de flux de données, de l’extraction / transformation jusqu’à leur consommation (API, BI / Visualisation, ...) Le déploiement et l’intégration continus de pipelines sur plusieurs paradigmes : serverless cloud (AWS Lambdas, Azure Functions, GC Functions, Kubernetes) ou cloud privé (OpenNebula, CloudStack, CephFS)Pourquoi nous rejoindre ? ACCOMPAGNEMENT PAR DES EXPERTS : Les Associés en charge de l’équipe Data Services cumulent une expertise rare dans leurs domaines respectifs, e.g. équipe pionnière du MLOps (CI/CD opérationnelle depuis 2013). Ils participent activement à la mise en place des activités les plus pointues du cabinet et de la création de start-up technologiques acquises par Mazars. Cet environnement à la fois exigeant et formateur vous propulsera au top des bonnes pratiques coding et opérationnelles pour assurer un delivery projet de qualité ! AUTONOMIE ET AMBITION : Écosystème jeune, dynamique et très responsabilisant, aux fortes ambitions de croissance. Venez vous impliquer dans le développement du Lab Mazars et construire l’offre de service en conseil data du cabinet ! HACKING SPIRIT : Veille technologique omniprésente, à la pointe des technologies open-source les plus performantes du moment. Nos consultant(e)s se forment en permanence pour élargir leur socle de compétences. CABINET INTERNATIONAL : Rejoindre Mazars c’est intégrer un cabinet aux dimensions internationales et bénéficier d’opportunités d’évolution de carrière : bootcamp data, learning center de pointe (Mazars Academy, LinkedIn learning, etc.) et mobilités internationales.Venez partager avec nous cette fierté que nous avons d’apporter des réponses pertinentes à nos clients. Vous vous dépassez sur des sujets techniques variés et ambitieux, au sein d’une équipe humaine et bienveillante !#JTVotre profilDe Formation Bac+5 Type École D’ingénieur Généraliste Ou Spécialisée, Ou D’un 3ème Cycle Dans Un Domaine Connexe à La Data (systèmes D’informations, Traitements De Données, Big Data, Statistiques, Génie Logiciel, Etc.) Vous avez déjà montré un intérêt pour le domaine du développement applicatif intégrant une composante Data, à travers des stages, cours ou projets personnels impliquant le développement back-end et/ou front-end d’une application. Vous avez une expérience pratique et une bonne connaissance de : Un ou plusieurs langages de programmation analytique (Python, R, Haskell, Rust, etc.) Une ou plusieurs couches de persistance (MySQL, MongoDB, ElasticSearch, S3, Node4j) Vous n’envisagez pas de travaux sérieux en dehors d’un système Linux (Ubuntu, Debian, CentOS), ou sans système de contrôle de version (Git), et l’utilisation d’une chaîne d’intégration vous parait naturelle Vous pensez que l’écosystème tech open-source est un puissant terrain de jeu à la pointe de la technologie, qui met à disposition l’ensemble des outils nécessaires à la réalisation des projets les plus ambitieux. Vous souhaitez travailler avec les utilisateurs métiers et les clients pour comprendre leurs besoins. Vous êtes curieux (se), autonome, entreprenant(e) et savez faire preuve d’initiatives. Vous maîtrisez l’anglais oral et écrit.Une première expérience des technologies suivantes est un plus : Sensibilisation à la qualité logicielle et aux chaînes d’intégration continue (DevOps) Sensibilisation à l’interaction avec des équipes fullstack (RestAPI, VueJS, ReactNative) Expérience sur l’un des cloud providers (Azure, AWS, GCP) Chaîne d’analyse prédictive (scikit-learn, TensorFlow, etc.) Outil de Business Intelligence (Power BI, Qlik, Tableau, etc.)Vous serez basé(e) à Paris, avec d’éventuels déplacements en province et à l’étranger.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow'], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': ['MySQL', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer,DEXTON Consulting,"Issy-les-Moulineaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-dexton-consulting-3724473517?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=UQMFJTTBOJxOyD4w07G1eA%3D%3D&position=18&pageNum=2&trk=public_jobs_jserp-result_search-card,"Vous souhaitez intégrer un groupe à taille humaine ayant un grand potentiel ? Notre groupe est en pleine croissance notamment en France. Rejoignez-nous et soyez au cœur de notre expansion, vous bénéficierez d’un positionnement riche en opportunités.Vous aurez l’occasion de collaborer avec les meilleurs talents du conseil pour créer des solutions innovantes et de haute qualité qui répondent aux besoins de nos clients.Au sein d’une équipe de consultants experts, vous intervenez en tant que consultant dans le but de contribuer aux évolutions majeures des SI de nos clients. Vos principales missions sont :Le recueil des besoins auprès des utilisateurs/clients.La conception, la construction et la maintenance de pipelines pour l'extraction, le chargement et la transformation de données à grande échelleLa mise en place et la gestion des bases de données SQL ou NoSQLLe développement des systèmes d’analyse de données en utilisant des technologies telles que SparkSQL et Spark StreamingL’évaluation et l’amélioration des performances des pipelines de données pour garantir une haute disponibilité et une faible latence, en utilisant des technologies basées sur le CloudLe travail en étroite collaboration avec les équipes de Data Science pour fournir des solutions appropriéesLe reporting aux équipes métiers des solutions mises en place via des outils de Dashboarding (PowerBI, Tableau, etc.)Exigences :Vous justifiez d’au moins 3 ans d’expérience en tant que Data Engineer ou dans un rôle similaireVous bénéficiez d’une expérience d’au moins 6 mois sur la technologie Spark (Pyspark ou Scala)Vous justifiez d’une expérience sur le Cloud Azure d’au moins 6 mois (Databricks, Data Factory, Data Lake Gen 2, etc.)Vous maîtrisez les langages Python et SQLVous avez des compétences en conception de bases de données non relationnelles (Hbase, Cassandra,etc.)Vous avez de bonnes connaissances sur l’environnement Hadoop (Hive, Pig, Oozie, etc.)Idéalement, vous avez déjà travaillé avec des outils de planification et d’automatisation de pipelines (Apache Airflow, Apache Nifi, Azure Pipeline, Azure Data Factory, etc.)Vous êtes autonome.Vous êtes force de proposition et capable de soumettre et défendre des recommandations.Vous avez un bon niveau d’anglais.En rejoignant nos équipes, vous travaillerez au quotidien auprès des experts reconnus du monde du Big Data. Vous maîtriserez une méthodologie performante et progresserez grâce à un large choix de formation. Et surtout, vous aurez un impact majeur sur les transformations stratégiques des entreprises.Programmation :Du lundi au vendrediHoraires flexiblesPériode de travail de 8 heuresTravail en journéePackage de rémunération :. Salaire fixe + Bonus. Type d'emploi : Temps plein, CDI. Statut : Cadre. Salaire : En fonction de l'expérience. Primes. Primes annuellesAvantages :Prise en charge du transport quotidienRTTTitre-restaurantLieu du poste : Télétravail hybride (Paris (75))


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks', 'Apache Airflow'], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Intern,STATION F,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-intern-at-station-f-3792803573?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=l4R%2FLe3w9DaiX6EouC9yyg%3D%3D&position=19&pageNum=2&trk=public_jobs_jserp-result_search-card,"AboutData&Data is an intelligence technology company that provides services to Luxury brands to help them gain market insights about their online distribution and growth of their products in the grey market, leveraging all through the power of Artificial Intelligence. After launching our anti-counterfeiting solution in 2015, we launched an unprecedented solution against grey market sales in 2016.Follow us to know more about the company culture and updates:LinkedIn: https://www.linkedin.com/company/data&data-consultingFacebook: https://www.facebook.com/DataandDataYouTube: https://www.youtube.com/channel/UC2YP_PN4Z9qWPMivVhUJQyQJob DescriptionWe are looking for a developer to help us implement new functionalities in our product. You will have the possibility to work on a wide variety of projects, including: Enhancing our crawling and scraping algorithms. Untangling the APIs of services from around the world. Designing data processing and analysis algorithms. Scaling our architecture to process more bytes faster. Implementing a bulletproof strategy for testing and maintenance. Developing internal monitoring or productivity tools.Why join us? Challenges: never short of those, you’ll have the opportunity to apply many skills. Responsibilities: expect your first release into production on week one. Work life: flexible hours, flat hierarchy, casual Fridays everyday. Team: a small and dynamic team. Location: Station F, the largest startup incubator - Paris. Salary: €6k – €18kYou Preferred Experience  Are fluent in at least one scripting or OO language, ideally Python. Know the basics of SQL, and can find your way around in a Unix terminal. Are driven, with strong interpersonal, analytical and problem solving skills. Are well rounded, proactive, can multitask and ship high-caliber solutions on time.SkillsPython, Machine Learning, SQL, Cloud Computing, Big Data, Databases, DevOps, Backend Development, Unix, Microsoft AzureA Unicorn Would Have Experience With Big data, cloud or NoSQL technologies (Hadoop, Azure, Neo4j, etc.). Applied machine learning or computer vision. Working with startups or agile teams. Foosball and perks of working at STATION F.Additional Information Contract Type: Internship  Location: Paris  Salary: between 1000€ and 1500€ / month


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Neo4j'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER (H/F),SFR,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sfr-3675546210?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=rl9LVmup%2F2Uq1x4nGqCGzA%3D%3D&position=20&pageNum=2&trk=public_jobs_jserp-result_search-card,"En tant que Data Ingénieur expérimenté, vous occuperez un rôle essentiel dans notre équipe Data Science. Vous serez responsable de la conception, du développement et de la maintenance des pipelines de données ainsi que de l'intégration de sources de données multiples. Votre expertise sera cruciale pour garantir une gestion efficace des flux de données, ainsi que pour faciliter l'analyse et la visualisation des données en plus du support aux data scientists vos missions seront les suivantes : Architecture projet des données : Concevoir et développer des architectures projet de données robustes, évolutives et performantes pour intégrer et gérer de grandes quantités de données provenant de sources multiples. Assurer la fiabilité, l'évolutivité et la sécurité des flux de données entrant d’un projet Data Science.Intégration des données : Élaborer des pipelines de données efficaces pour l'extraction, la transformation et le chargement des données (via notre Framework ELT/ETL interne) provenant de différentes sources. Mettre en place des processus d'intégration automatisés et veiller à la qualité des données.Gestion des bases de données : Concevoir et optimiser des bases de données pour répondre aux besoins analytiques et de reporting. Assurer la performance, la disponibilité et la sécurité des bases de données, ainsi que la gestion efficace des requêtes.Collaboration interfonctionnelle : Support des Data Scientists, vous travaillerez avec les équipes business pour comprendre leurs besoins et fournir des conseils et des recommandations basés sur les données.Optimisation des performances : Surveiller et optimiser les performances des pipelines de données, des bases de données et des requêtes. Identifier les goulots d'étranglement et les points d'optimisation, et proposer des améliorations pour garantir des performances optimales.Sécurité et conformité : Veiller à ce que les données soient traitées et stockées conformément aux normes de sécurité et de confidentialité. Mettre en place des mécanismes de sécurité pour protéger les données sensibles et garantir la conformité aux réglementations en vigueur.Votre profil : Vous avez un Diplôme universitaire en informatique, en génie logiciel, en science des données ou dans un domaine connexe et vous avez à minima 5 ans d'expérience en tant que Data Ingénieur. Vous possédez également une solide maîtrise des technologies et des outils suivants : Hadoop, Spark, SQL, Kafka, GCP BigQuery, De plus vous avez une bonne compréhension des architectures, des modèles et des concepts de base de donnés avec une expérience avancée dans la mise en œuvre de pipelines ETL et dans la gestion de bases de données.Vos connaissances en matière de sécurité des données, de conformité aux réglementations ainsi que vos compétences en programmation scripting et en développement logiciel seront un plus. Vos excellentes compétences en communication seront des qualités appréciées et un niveau d'anglais (appliquée au domaine technique) est un plus.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer (Python) H/F,WINSEARCH,"Salasc, Occitanie, France",https://fr.linkedin.com/jobs/view/software-engineer-python-h-f-at-winsearch-3804496383?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=cALC62%2Bp9MhE1f3te0Xc5w%3D%3D&position=21&pageNum=2&trk=public_jobs_jserp-result_search-card,"Le cabinet Winsearch, recrute pour l'un de ses clients, spécialisé dans la préservation de l'environnement et dans l'accompagnement des acteurs des énergies renouvelables, un Développeur Logiciel Python en CDIMissions du poste :Vous réalisez le codage et les tests des produits logiciels et des outils d'exploitation, et réalisez la documentation associée, Vous effectuez les tests de validation, et réalisez la documentation associée, Vous installez et paramétrez les logiciels sur les matériels avant déploiement, Vous analysez les données et les remontées terrain et identifiez les améliorations et solutions à mettre en oeuvre. Vous travaillez en étroite collaboration avec les autres services de la Société, pour l'exploitation ou l'installation des sitesTECH : Python, environnement Linux et Windows, MySQLExpérience de 5 ans en développement en Python pour des environnements Windows et Linux Expérience dans les domaines du traitement et de l'analyse de données dans un milieu industriel embarqué La maitrise des bases de données (mySQL) est nécessaire. La maitrise des réseaux informatiques et des technologies de communication sécurisées (VPN, SSH) est un plus Rigueur, autonomie, capacité d'organisation et de structuration, sens de la communication et du travail en équipe Parfaite maitrise du français et bonne maîtrise de l'anglais obligatoire19139856-55584
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux', 'Windows'], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': ['VPN'], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER - H/F,Generali France,"Seine-St.-Denis, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-generali-france-3806809881?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=rwkdUS1yBbooMpU8NgoP%2BA%3D%3D&position=22&pageNum=2&trk=public_jobs_jserp-result_search-card,"GeneraliAvec plus de 69 millions de clients et un chiffre d’affaires de 81,5 milliards d’euros en 2022, Generali est l’un des leaders de l’assurance et de la gestion d’actifs dans le monde. Assureur responsable, nous plaçons la durabilité au cœur de notre stratégie.Notre directionLe marché des particuliers IARD et prévoyance assure l'offre, la commercialisation, la gestion et l'indemnisation de nos produits IARD et prévoyance destinés aux particuliers. Il assure également la Relation client et intermédiaires, le marketing, le digital et la prévoyance individuelle ainsi que la gestion et l'indemnisation des contrats emprunteurs pour l'ensemble de notre entreprise.Vos missionsL'expertise Marketing, Digital & Data est plus que jamais clé pour mener à bien la transformation de Generali France et faire face aux enjeux auxquels sont confrontés les acteurs de l'Assurance.Au sein de la Direction Marketing & Digital,nous recherchons un(e) Data Scientist ayant au minimum 5ans d’expérience sur des problématiques d’exploitation des données (clients, prospects, digitales, campagnes, transactionnelles, …) à des fins Marketing (ciblage, création de score, reporting de bout-en-bout, optimisation des opérations Marketing, …).Les principales missions :Développer, automatiser et industrialiser :Les traitements de données sous différents environnements/outilsLes reporting dynamiques et app sous Tableau / PowerBI ou Streamlit (suivi de la performance des leads de bout-en-bout, des intermédiaires …)Les outils de suivi des actions marketing (campagnes développement clients, bilan d'activité …)Développer ou superviser les développements des traitements en Python (PySpark en cas de forte volumétrie) pour préparer les données, entraîner et optimiser les modèles de data science, évaluer et valider leur performanceAssurer la documentation des travaux et analyses qui vous sont confiésProduire les études & analyses :Aider à la décision sur des sujets marketing en apportant une approche quantitative via des études et des analyses (analyses d'impact des opérations marketing)Réaliser ou encadrer la réalisation des analyses nécessaires à une bonne prise en charge des données à disposition, au contrôle de la cohérence, la validation de leur lectureEnrichir les Données :Définir la trajectoire d’enrichissement de données notamment sur l’intégration de celles-ci dans Salesforce Marketing Cloud avec le métierIdentifier les sources adéquates et les règles de gestion appropriées auprès des directions techniquesPiloter et assurer la mise en œuvre de cette trajectoireReprésenter le Marketing dans la Gouvernance des donnéesProfil recherchéC’est dans ce cadre que nous recherchons un(e) Data Engineer ayant avec au minimum 5 ans d’expérience sur des problématiques de pilotage data.Compétences :Rigueur, organisation, autonomie, goût pour le travail en équipe, sens de l'analyse, force de proposition.Environnements & outils :Langage PythonEnvironnement Azur (ADLS)HadoopPysparkSolutions de dataviz : Power BI, Tableau & StreamlitNous rejoindre, c'est :intégrer une entreprise dynamique qui place l’innovation et la durabilité au cœur de sa stratégierelever des challenges, faire preuve d’initiative et organiser son travail en mode hybrideconstruire sa carrière et développer ses compétencesse nourrir des différences de chacun dans une entreprise qui mène des actions concrètes en faveur de la diversité, l’équité et l’inclusionavoir la possibilité de s’engager au sein de notre fondation The Human Safety Net, pour soutenir les personnes vulnérables et participer à l’impact positif que nous générons.Pour en savoir plus, visitez notre site.Engagé en faveur de l'égalité des chances, Generali étudie avec la plus grande attention les candidatures de personnes en situation de handicap et leurs éventuels besoins spécifiques.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F) - Paris,BPCE Solutions informatiques,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-paris-at-bpce-solutions-informatiques-3802921297?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=fRXpyi1PvxceRcs12u%2FK0g%3D%3D&position=23&pageNum=2&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseBPCE SI est une entreprise informatique du Groupe BPCE. Avec ses 19 implantations en régions, BPCE SI intervient au plus près des établissements bancaires.Chaque jour, plus de 2600 collaborateurs imaginent, inventent, testent des solutions innovantes pour faciliter la vie des utilisateurs des Caisses d’Epargne, des Banques Populaires et de plusieurs filiales et établissements bancaires comme le Crédit Coopératif et la SocFim.A travers l’utilisation de nos solutions bancaires, nous sommes présents dans le quotidien de près de 1 Français sur 2 !Plus de 80 métiers sont présents au sein de BPCE SI et plus de 50 technologies et langages de développement sont utilisés dans nos solutions bancaires !Entreprise humaine et engagée, notre politique de Responsabilité sociale de l’entreprise porte des sujets clés comme la mixité, la diversité, le handicap, la qualité de vie au travail et le développement durable.Nous attachons une attention particulière à la réussite de chacun(e). Nos équipes sont accompagnées tout au long de leur parcours et évoluent dans un environnement de travail stimulant pour exprimer leurs talents.Alors, pour booster votre carrière et profiter de la diversité des terrains de jeux que proposent BPCE Solutions informatiques et le Groupe BPCE, rejoignez-nous !Poste et missionsAu sein de la « Plateforme Assurances » vous intégrez l’équipe Data Management Office sous la responsabilité du manager de l’équipe.L’équipe DMO est en charge de mettre en place les nouveaux projets liés à la feuille de route Data des métiers de l’assurance non vie et de maintennir les solutions décisionnelles.Vous Interviendrez Sur Le Périmètre IndemnisationSur le périmètre RUN, vous assurez la gestion, l'analyse et le suivi de résolution des incidents et des évolutions remontées par les utilisateurs.Sur le périmètre projet, vous assurez le cadrage fonctionnel du projet avec les métiers, le suivi des développements et les tests.Votre Rôle Sera DeCollaborer avec les référents métier pour recueillir leurs besoin ;Rédiger des spécifications techniques et fonctionnelles ;Collaborer avec les référents applicatifs pour établir les mapping liés aux besoins métier ;Collaborer avec les intervenants IT (Infrasctructure, DBA) ;Participer aux phases de modélisation (modélisation relationnelle / BI) ;Assurer la conception et le développement des flux d’intégration du DWH et des Datamart métier ;Mise en place des stratégies de tests unitaires et fonctionnelles ;La mise en place des normes de développements et les bonnes pratiques (modèles de traitements, …) ;Mise en place des documents de référence ;Pilotage des développeurs intervenant sur le périmètre indemnisation.Profil et compétences requisesVous avez déjà participé à un ou plusieurs projets BI, sur des problématiques de Data Integration (mise en place des bonnes pratiques pour des flux otpimisés) ou plus généralement dans la mise en place de Datawarehouses/Datamarts.Vous attachez une importance particulière à la qualité de vos développements (respect de l’architecture, normes de codage, tests unitaires,…).Vous avez une très bonne maîtrise des outils suivants :Stambia: TalendSGBD : SQL Server, OracleReporting : Microstrategy, PowerBIInformations complémentaires sur le poste
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Cloud H/F,Inetum,"St.-Ouen, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-h-f-at-inetum-3802985453?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=qdV7o%2B4mkiwymjU2DfhZfw%3D%3D&position=24&pageNum=2&trk=public_jobs_jserp-result_search-card,"Détail de l'offre Informations générales Entité de rattachement Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 27 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste Métier Métier AS (Application Services) - DéveloppementIntitulé du poste Data Engineer Cloud H/FContrat CDIREJOINDRE LES EQUIPES DATA D’INETUM, C’EST Intégrer une communauté d’experts de plus de 700 collaborateurs en France,Travailler en « mode projet » autour des Modern DATA Platform & accompagner nos clients sur des problématiques de Gouvernance, d’Intégration, de Visualisation…Avoir des missions challengeantes chez nos clients spécialisés sur les secteurs Banque, Telecom, Energie, Finance, Assurance, Industrie, Secteur Public,...Evoluer au sein d’une structure avec de nombreux partenariats stratégiques (Microsoft Azure, AWS, GCP…)CE QUE NOUS RECHERCHONSInetum recherche un(e) Data Engineer Cloud, disposant de solides connaissances techniques.CE QUE NOUS ATTENDONS DE VOUSEn tant que Data Engineer Cloud, vous concevez, mettez en place et administrez des solutions Big Data.Vos missions détaillées Analyse et compréhension des besoins métiers,Participation à la définition et à la conception de l’architecture,Gestion des données préparation, ingestion, traitement, contrôle qualité,Développements des jobs (Par exemple Spark) et automatisation des flux d’alimentation du Data Lake,Tests de charge, tests unitaires…Maintenabilité de la solution Big Data /Cloud (Optimisation et performance des traitements).VOUS ETESIngénieur de formation, vous disposez d’une expérience de 3 ans minimum en tant que Data Engineer. Vous maîtrisez les langages Java, Scala ou Python et êtes expert sur les framework Spark et/ou Hadoop. Vous avez idéalement déjà travaillé sur Microsoft Azure, GCP ou AWS. Vous avez une expertise sur les services Cloud Data Platform suivants Azure Data Lake, Azure Synapse, Azure Data Factory, Azure Data Explorer, Azure Databricks, Cloud Storage, BigQuery, DataPrep, DataProc ...NOUS VOUS OFFRONSDes missions engageantes auprès des grands acteurs du marché,Un management de proximité toujours bienveillant et à l’écoute et avec qui vous pourrez échanger au quotidien sur les enjeux de votre mission et évoquer vos futurs projets afin que nous puissions vous aider à les réaliser.La possibilité d’évoluer et de monter en compétences grâce à des formations et à des certifications notamment via notre Data Academy.La possibilité d'appartenir à une vraie communauté Data.INETUM SPIRITDes communautés d’expertises sur les sujets de la Data,De super nouveaux locaux qui sont en plus accessibles facilement,Une école de formation intégrée,Des évènements des soirées avec les consultants, des 12@13…Une entreprise labellisée ""Top Employer Europe 2023"".N’attendez plus, rejoignez INETUM et venez nous rencontrer dans nos nouveaux locaux situés à Saint-Ouen#DevenezInetumien!Localisation du poste Localisation du poste France, Ile-de-France, 93 Seine-Saint-DenisVille Saint-Ouen-Sur-SeineCritères candidat Niveau d'études min. requis Bac+5Niveau d'expérience min. requis Plus de 2 ans


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirmé - Scala (F/H/X),AVIV Group,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-scala-f-h-x-at-aviv-group-3802366537?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=I5KtAc6G7i0QAr9GhdvMFQ%3D%3D&position=25&pageNum=2&trk=public_jobs_jserp-result_search-card,"Description De L'entrepriseVous rejoindrez l'une des plus grandes entreprises privées de technologie immobilière au monde et une filiale d'Axel Springer. Notre mission est de trouver l'endroit idéal pour chacun ! Vous travaillerez sur certaines des marques immobilières numériques les plus connues d'Europe, notamment : 🇫🇷 Meilleurs Agents, 🇫🇷 Groupe SeLoger, 🇧🇪 Immoweb, 🇩🇪 Immowelt, 🇪🇸 Housell et 🇮🇱 Yad2.Au sein du groupe AVIV, vous aurez l'autonomie nécessaire pour travailler dans le style qui vous convient le mieux pour être le plus productif.Cette autonomie et la liberté de travailler quand et où vous le souhaitez nous ont permis d'attirer les meilleurs talents à nos côtés.Vous travaillerez avec des équipes très performantes pour construire une plateforme commune qui alimente plusieurs marques et nous aide à devenir la solution de choix pour tout ce qui concerne l'immobilier.Les développeurs jouent un rôle clé dans l'amélioration de l'expérience d'achat de domicile de nos clients en utilisant une combinaison de logiciels open source, de solutions cloud et d'approches axées sur les données pour élaborer des solutions innovantes.Description Du PosteRejoignez l’équipe Marketplace Design AVIVLa marketplace AVIV est le lieu de rencontre privilégié de tous les acteurs de l’annonce immobilière: potentiels acquéreurs ou locataires, propriétaires ou agents, … Afin de garder notre position, nous devons fournir la meilleure qualité de service possible en termes de sécurité, de confiance, d’efficacité et de pertinence des échanges entre ces acteurs. Plusieurs facteurs entrent en ligne de compte: qualité et sérieux des prospects et des agents ainsi que la qualité des informations affichées.Le rôle de l’équipe Marketplace design est de concevoir et exécuter toutes les actions nécessaires pour assurer la satisfaction de nos utilisateurs : qualité et correction des données, scoring, matching, gamification, et amélioration continue. Ces actions requièrent un usage important des données, l’équipe Data Operations est responsable de la gouvernance, la modélisation et la qualité des données ainsi que de fournir les data-sets clés et maintenir une data platform robuste et efficace pour tout le groupe AVIV.Vos responsabilités :En tant que Data Engineer au sein de l’équipe Data Operations, vous travaillez en étroite collaboration avec un Product Manager et votre Engineering Manager. Vos développements respectent les bonnes pratiques en place et sont alignés avec l’architecture d’entreprise AVIV. Vous apportez votre expertise technique à votre équipe, vous créez, adaptez et améliorez la qualité des data-sets et des outils largement utilisés chez AVIV.L’équipe Data OperationsL’équipe est constituée d’environ 40 personnes, avec notamment:Coach AgileData EngineersData Quality EngineersData Analysts & ModelersDevops EngineersEnterprise & Solution ArchitectsProduct ManagersLes projetsDécentraliser la data et Mettre en place le Data Mesh au sein du groupe AvivFournir les insights sur les usages des différents sites et apps mobiles européens Notre Stack Technique dataAWS (CloudFormation, EMR, S3, Glue, Athena, Redshift, SNS/SQS)SparkGit, CircleCI, DatadogScala, JavaVous avez idéalement des connaissances complémentaires telles que :Python Apache Airflow, KubernetesJenkins, Argo CD, Grafana, VictoriaMetricsQualificationsNous recherchons une personne capable de:Créer et maintenir des datasets complexes et à gros volumes selon des spécifications fonctionnelles précises. Participer à la création d’une infrastructure solide et optimale pour l’extraction, la transformation et le chargement (ETL) de données à partir de nombreuses sources. Utilisation de SQL et de technologies big data cloud. Identifier, concevoir et implémenter les processus internes d’amélioration: automatisation, optimisation du delivery, scalabilité, etc…Travailler avec des experts data et données analytiques au développement de nouvelles fonctionnalités Maitriser la méthodologie Agile: communication directe, adaptation, fail fast, amélioration continue et Software CraftsmanMaîtriser le produit et le business, impactant l’amélioration du service aux clients, du produit et de l’architectureRigueur, curiosité, autonomie et état d’esprit positif Partager des connaissances et ouvert aux nouveautésMaîtriser les sujets RGPD, sécurité et respect de la vie privéeExpérience recherchéeExpérience réussie de data engineering, dans différents environnements, notamment Spark. Maîtrise des design patterns actuels et des architectures développements courants. Maîtrise de l’anglais professionnel. Informations supplémentairesCe que nous vous offrons :Nous sommes l'une des principales plateformes PropTech en Europe. Si vous avez déjà loué ou acheté un bien immobilier, vous avez peut-être utilisé l'un de nos portails de petites annonces. C'est le moment idéal pour nous rejoindre et contribuer à l'élévation de notre marque AVIV. La possibilité de travailler de manière hybride au sein de notre zone d'activité, avec des déplacements internationaux vers nos sites en France, en Belgique et en Allemagne. L'autonomie pour travailler dans le style qui vous convient le mieux pour être le plus productif. La liberté de nous dire quels sont les outils dont vous avez besoin pour réussir dans votre travail, afin que nous puissions vous préparer à y parvenir. Ce poste est ouvert UNIQUEMENT en CDIChez Aviv, nous sommes un employeur garantissant l'égalité des chances et où chacun est invité à être lui-même. Aussi nous vous invitons à postuler quelle que soit votre origine, que vous soyez parent, membre de la communauté LGBTQIA+, ou encore en situation de handicap. Si vous avez besoin d'ajustements, lors du processus de candidature, ou si vous souhaitez discuter de demandes de travail à temps partiel ou flexible, veuillez nous en informer.Dans votre candidature, n’hésitez pas à indiquer les pronoms que vous utilisez (ex: elle/il/iel, etc.). A très vite !Notre ambition est d'être le premier employeur de PropTech à travers l'Europe et c'est un moment clé pour nous rejoindre et trouver votre emploi idéal !INDSPO


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Apache Airflow'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Engineer Confirmé(e)/Senior (CDI),CBTW,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-e-senior-cdi-at-cbtw-3797662873?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=gS6IKNug19rZHMtPsH1wXg%3D%3D&position=1&pageNum=3&trk=public_jobs_jserp-result_search-card,"Salut à tous les Data wizards !Chez Positive Thinking Company, on est toujours en quête de talents audacieux pour rejoindre notre communauté d'experts en pleine croissance. Si tu as l'esprit créatif, une passion pour l'innovation et un désir d'apprendre constamment, tu es exactement le profil que nous recherchons.En tant que notre futur(e) Data Engineer, tu auras l'opportunité de travailler sur des projets stimulants, de développer tes compétences techniques et de contribuer à la croissance d'une entreprise dynamique et inclusive.Nous recherchons un Data engineer minimum 3 ans d'expérience significative, passionné par l'ingénierie des données et possédant une solide expérience en conception, développement et maintenance de pipelines de données robustes et évolutifs. Nous cherchons quelqu'un qui a des compétences techniques solides dans les domaines suivants :Conception et développement de solutions de stockage de données, telles que des data warehouses et des data lakesMise en place de flux de travail pour l'extraction, la transformation et le chargement de données (ETL)Maîtrise d'au moins un langage de programmation couramment utilisé dans l'ingénierie des données, tels que Python ou ScalaConnaissance de l'utilisation de technologies de traitement de données distribuées, telles que Hadoop, SparkCompréhension des principes fondamentaux des bases de données relationnelles et non relationnellesCapacité à travailler avec des outils d'automatisation et de gestion de code, tels que Git, Jenkins ou AnsibleLe candidat idéal sera également capable de travailler en équipe et de communiquer efficacement avec des collègues ayant des compétences techniques différentes.Si vous êtes prêt à relever des défis stimulants et à faire partie d'une équipe dynamique, n'hésitez pas à postuler dès maintenant. Nous avons hâte de vous rencontrer !PS : Démarrage en Septembre


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data Engineer – Lille, France (H/F)",Astek,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-lille-france-h-f-at-astek-3780224382?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=yp0hihXpk51b0VG999Ab7w%3D%3D&position=2&pageNum=3&trk=public_jobs_jserp-result_search-card,"CDILille - FrancePubliée il y a 2 joursData Engineer – Lille, France (H/F)Ce Que Nous Allons Accomplir Ensemble :Intervenir au sein d’une direction informatique dans le domaine du retail au sein de l’équipe Data.Votre Future Équipe :Vous intégrerez une squad Data à taille humaine en charge d’un périmètre fonctionnel.Votre mission (…si vous l’acceptez !) :Participer aux rituels agiles de l’équipe.Participer aux différentes réunions de travail liées au projet.Analyser les besoins des utilisateurs et proposer des solutions innovantes en phase avec les drivers de l’entreprise.Développer des solutions Data (Alimentation, Stockage, Modélisation, Restitution).Améliorer et optimiser le patrimoine actuel de son équipe.Maintenir des solutions existantes (Run).Contribuer à la construction du nouveau socle et des services sur la plateforme GCP.Accompagner et acculturer les métiers sur les bonnes pratiques de l’exploitation de la Data.Vos stacks de jeu : SQL / BigQuery / ETL / ELT / github / Terraform / UML / LookML / Power BI / Data Studio / Looker vizLes Petits Plus Du Projet :Il s’agit d’une mission qui s’inscrit sur du long terme (3 ans) où vous interviendrez sur les systèmes applicatifs et sur les plateformes Big Data, IoT.Vous ?De formation Ingénieur, vous justifiez d’une première expérience en tant que Data Engineer. Vous aimez être garant de la maîtrise de la donnée et de la qualité de son utilisation.Vous souhaitez être un acteur déterminant dans la définition de la politique de la donnée et de la structuration de son cycle de vie dans le respect des réglementations en vigueur.Nous ?Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale. Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 7800 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes. Rejoignez un Groupe en fort développement en France et à travers le monde et ayant réalisé un chiffre d’affaires de 600 M€ hors acquisition en 2023.✨ Tous les détails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : blog.groupeastek.com.Rencontrons-nous !Vous vous êtes reconnu sur l’annonce et Astek vous plaît !Pour en savoir plus sur vous, Clarisse, notre chargée de recrutement vous contactera. Puis, vous aurez 3 entretiens max, avec Louis (votre futur n+1), et Jonathan notre responsable de Business Unit !Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !Caractéristiques de l'emploiCatégorie IngénieurLieu Lille - Hauts-de-FranceExpérience Data EngineerPostuler en ligneNom *Prénom *Email *Un email valide est requis.Téléphone *Un numéro de téléphone valide est requis.Joindre un CV *Data Engineer – Lille, France (H/F)Les Petits Plus Du Projet :Il s’agit d’une mission qui s’inscrit sur du long terme (3 ans) où vous interviendrez sur les systèmes applicatifs et sur les plateformes Big Data, IoT.Vous ?De formation Ingénieur, vous justifiez d’une première expérience en tant que Data Engineer. Vous aimez être garant de la maîtrise de la donnée et de la qualité de son utilisation.Vous souhaitez être un acteur déterminant dans la définition de la politique de la donnée et de la structuration de son cycle de vie dans le respect des réglementations en vigueur.Nous ?Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale. Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 7800 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes. Rejoignez un Groupe en fort développement en France et à travers le monde et ayant réalisé un chiffre d’affaires de 600 M€ hors acquisition en 2023.✨ Tous les détails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : blog.groupeastek.com.Rencontrons-nous !Vous vous êtes reconnu sur l’annonce et Astek vous plaît !Pour en savoir plus sur vous, Clarisse, notre chargée de recrutement vous contactera. Puis, vous aurez 3 entretiens max, avec Louis (votre futur n+1), et Jonathan notre responsable de Business Unit !Bienvenue dans la team ! Allez-y, maintenant c’est à vous de jouer !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),Groupe SII,"Rouen, Normandy, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-groupe-sii-3807748993?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=I%2Fic6jXW%2FnB1jtLDFObQXg%3D%3D&position=3&pageNum=3&trk=public_jobs_jserp-result_search-card,"Nous recherchons un(e) Data Engineer (H/F) pour accompagner les développements faits auprès des applications de l’un de nos clients Grand Compte.En mode Agile et organisée en ""Feature Team"", l'équipe technophile vous permettra de participer à toute la chaîne projet.En quête de défis techniques ? Alors n’hésitez plus, postulez! Votre Mission Préparer les données à traiter,  Analyser les modèles,  Concevoir des algorithmes,  Programmer en back-end,  Interpréter et présenter les résultats,  Mettre en production des solutions. Votre ProfilDiplômé(e) d’un Bac+5 en informatique, mathématique ou statistique (Grandes Ecoles, Universités), vous justifiez d'au moins une première expérience significative dans le traitement de donnée avec utilisation ou connaissance d’un ETL (Talend ou Informatica).Vous êtes curieux(se), investi(e) et surtout passionné(e) par le monde du web. Vous savez travailler en équipe et vous vous intégrer rapidement, vous êtes autonome, organisé(e) et rigoureux (se), bon communiquant et doué(e) du sens de l'écoute . Qui sommes-nous ? Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés.En 2023, pour la 6e année consécutive, SII France a obtenu le label Great Place To Work®. Nous avons été reconnus 3e entreprise de « + de 2500 salariés » où il fait bon vivre et nous en sommes très fiers ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières.En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),LesJeudis,"Clermont-Ferrand, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3795161577?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=16%2BDOZ5CXlJBgIztTpRgUA%3D%3D&position=4&pageNum=3&trk=public_jobs_jserp-result_search-card,"Bienvenue chez Atos, où nous imaginons le futur de la tech.Leader international du numérique sécurisé et décarboné, Atos contribue à façonner les nouvelles technologies avec ses clients.Dans un environnement multiculturel, collaboratif et agile, nous offrons des parcours de carrière valorisants basés sur des programmes de formation, de certification et de mobilité.C'est pourquoi chez Atos, la diversité des compétences et des expériences de nos équipes nous permet, ensemble, de faire les bons choix avec nos clients, pour l'avenir de notre entreprise et de la société.La Mission Que L'on Vous ConfieVous maintenir au top des nouvelles technologies les plus modernes, c'est essentiel pour vous ?Nous avons les projets ambitieux et les clients qui veulent prendre un temps d'avance.Vous aimez partager vos convictions en matière de technos pour nous faire tous progresser ? Nous sommes preneurs !Au sein d'équipes dynamiques, vous aurez pour missions principales :Conseiller en architecture en gouvernance de la donnée.Intervenir dans les aspects Data Ingestion, Data Analytiques et Data Science / IA.Mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud pour les projets stratégiques de nos clients.Votre Profil Pour RéussirDe formation supérieure BAC +5 en Informatique d'une Ecole d'Ingénieur ou d'un Mastère universitaire dans le domaine des sciences informatiques que vous avez complété par une expérience significative en Data Science / Data Engineering.Votre stack technique :Requis :Connaissance des écosystèmes Data (NoSQL/DW/Hadoop) : ELK (ElasticSearch, Logstash, Kibana), MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS...Expertise en développement Python ou Java Spring Boot.Expertise sur un des framework suivants : Spark, Kafka Connect&Streams, Apache Beam.Connaissance des architectures conteneurs : Docker, Kubernetes. Apprécié :Connaissance d'un des services managés BigData de Google Cloud Platform / AWS / Microsoft Azure.Connaissance des approches Agile&DevOps.Compétences ObligatoiresDocker, KubernetesSoft SkillsPassionné(e) d'informatique en progressant et en vous tenant à jour sur toutes les technologies et architectures, vous êtes créatif(ve), autonome, rigoureux(se), curieux(se), motivé(e) et avez le sens du travail en équipe et du relationnel alors rejoignez-nous !Niveau De LangueAnglais : niveau intermédiaire minimum recommandé et Français exigé.Chez Atos, la diversité, l'inclusion et l'accessibilité numérique font partie intégrante de notre ADN. Découvrez nos engagements en faveur d'un environnement de travail équitable pour toutes et tous. Atos est un leader reconnu dans son secteur pour les critères environnementaux, sociaux et de gouvernance (ESG). Pour en savoir plus sur notre engagement en matière de RSE.Chez Atos, la diversité, l'inclusion et l'accessibilité numérique font partie intégrante de notre ADN. Découvrez nos engagements en faveur d'un environnement de travail équitable pour toutes et tous.Atos est un leader reconnu dans son secteur pour les critères environnementaux, sociaux et de gouvernance (ESG). Pour en savoir plus sur notre engagement en matière de RSE, cliquez ici .Choose your future. Choose Atos.buttontextdc9b8a99d9905f96 a{ border: 1px solid transparent; } .buttontextdc9b8a99d9905f96 a:focus{ border: 1px dashed #0596ff !important; outline: none !important; }Learn More About UsAt Atos, we embrace diversity as the ultimate engine of ingenuity for our clients, and we constantly strive to create a culture where people feel supported and encouraged. Read more about our commitment here .Whether it is fighting climate change, promoting digital inclusion, or ensuring trust in data management - tech for good sits at the core of our identity. With numerous global recognitions for our ESG practices, we are committed to building a better future for all by harnessing the power of technology. Learn more here
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data engineer (H/F),relevanC,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-relevanc-3795333022?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=gjoQXzhbr1IpBZdHpaZZ7w%3D%3D&position=5&pageNum=3&trk=public_jobs_jserp-result_search-card,"relevanC est une filiale du Groupe Casino et a été fondée en 2017.Nous avons des bureaux en France, au Brésil et en Colombie et opérons à l'échelle mondiale.Nos solutions de Retail Media permettent à nos clients de générer de nouvelles sources de revenus publicitaires grâce à des annonces pertinentes et personnalisées.En tant que Data Engineer tu auras accès aux données de nos clients internes (enseignes du groupe Casino) et externes à traiter au sein de notre data warehouse. Tes missions seront les suivantes :travailler en étroite collaboration avec tous les autres membres de la squadécrire / relire du code en respectant les bonnes pratiques de développement ainsi que les tests unitaires et participerassurer la co-responsabilité du déroulement des déploiements, des mises en production et du bon fonctionnement des applications avec les autres membres de la squadrédiger la documentation technique quand cela est nécessairemettre en œuvre les bonnes pratiques relatives au RGPD telles que définies par le tech leadCe CDI basé à Paris centre (1er arrondissement) débutera dès que possible.Faire partie de relevanC, qu’est-ce que ça signifie ?Travailler sur une stack technologique de pointe (Python, PySpark, Google BigQuery, Apache, Airflow…)Être membre à part entière d’une équipe dynamique et passionnée aux profils très variés (chefs de projets, développeurs, designers, animations commerciales)Travailler dans un environnement stimulant et relever des nouveaux défis chaque jourRejoindre une entreprise en pleine expansion avec des opportunités fortes de développements et d’innovationProfil recherchéDiplômé(e) d’une grande école d’ingénieur ou profil universitaire spécialisé en Data / Informatique / Math / Stats.5 ans (et plus) d’expérience en Data EngineeringAppétence forte pour le marketing digital et le retail, force de proposition, business oriented et moteur d’innovationUne maitrise parfaites des bonnes pratiques de développementSolides compétences en Python, Spark et SQLUne expérience sur Google Cloud Platform est un plusLien vers notre politique de traitement des données : https://relevanc.com/fr/politique-de-protection-des-donn%C3%A9es-recrutemen


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Ingénieur data (H/F),LR TECHNOLOGIES - GROUPE,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-at-lr-technologies-groupe-3799954038?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=UIROaUnv39m8QY3mn1dGhA%3D%3D&position=6&pageNum=3&trk=public_jobs_jserp-result_search-card,"Chez notre client, tu interviendras au sein de la direction informatique, dans le service Data.Tu intégreras une Squad Data en charge d'un périmètre fonctionnel.Tu es garant de l'accès qualitatif aux sources de données.Tu t'assures de la maîtrise de la donnée et est garant de la qualité de son utilisation (référencement, normalisation, et qualification) afin d'en faciliter l'exploitation par les équipes (Data Analysts et Data Scientists).Tu contribues également à la définition de la politique de la donnée et à la structuration de son cycle de vie dans le respect des réglementations en vigueur, en collaboration avec le Chief Data Officer.Ton périmètre d'intervention est axé sur les systèmes applicatifs autour de la gestion de la données et du traitement, et sur les plateformes Big Data, IoT,Tu assures la supervision et l'intégration des données de diverses natures qui proviennent de ces sources multiples et vérifie la qualité des données qui entrent dans le Data Lake (recetter de la donnée, supprimer les doublons).Qualification et gestion des données : Capter les données (structurées et non structurées) produites dans les différentes applications ou à l'extérieur de l'entité Intégrer les éléments Structurer la donnée (sémantique, etc.) Cartographier les éléments à disposition Nettoyer la donnée (élimination des doublons, ) Valider la donnée Créer le référentiel de donnéesLes livrables : Data Lake approprié et partagé et son dimensionnement Cartographie des données Les éléments permettant de garantir la qualité de la donnéeAu cours de ta mission, tu : Participeras aux rituels agiles de l'équipe, Analyseras les besoins des utilisateurs et proposeras des solutions innovantes et en phase avec les drivers de l'entreprises, Développeras les solutions data (Alimentation, stockage, modélisation, restitution), Valideras la qualité des développements de son équipe, Amélioreras et optimiseras le patrimoine actuel de son équipe, Maintiendras les solutions existantes (Run), Contribueras à la construction du nouveau socle et des services sur la plateforme Google Cloud, Accompagneras et accultureras les métiers sur les bonnes pratiques de l'exploitation de la DataEnvironnement technique :Expertise SQL/BigQuery, ETL/ELTCI/CD, github, TerraformModélisation, UML / LookML, Business ObjectPower BI, Data Studio, Looker vizIngénieur ou Universitaire Bac +5, avec une spécialisation en informatique, tu possèdes une première expérience professionnelle sur le même type de poste.Tu es le/la candidat(e) idéal(e) si :Tu as un bon relationnel et tu sais travailler en toute autonomieTu as un niveau professionnel en anglaisTes valeurs sont le partage et la cohésionViens rejoindre l'équipe lilloise de Laurie, composée de Christelle, Raumane et Jordane ! Elles seront là pour toi, pour t'accompagner, t'écouter, te soutenir dans tes moments de doute ou célébrer tes accomplissements !Elles organisent régulièrement des événements où tu retrouveras toute la team de consultants pour des moments conviviaux (galette des rois, raclette, escape game, goûter de Noël avec la famille ).En ce qui concerne nos petits avantages sympas : carte restaurant, télétravail, 10 jours de RTT...« Toutes les Sociétés de Conseil se ressemblent »,Toutes ?LR TECHNOLOGIES GROUPE c’est 500 Libelliens qui nous ont élus Great Place To Work en 2016, 2018 et à présent 3e France et Europe 2021. Nous sommes également la 99e société française labellisée B CORP pour notre engagement RSE.Depuis 2014 nous avons créé 11 implantations et 5 pôles d'activités complémentaires :Aéronautique / Spatial / Défense Drone / Robotique / IoT / Automobile/ Ferroviaire / Industries / Multimédia Médical / Pharmaceutique Énergie / Environnement Systèmes d’Informations / Banque / Finance / Assurance3 raisons de rejoindre : 500 Libelliens, sollicités par tous comme vous devez l’être, nous ont rencontrés et ont décidé de nous rejoindre. 94 % des Libelliens déclarent que nous sommes un Groupe où il fait vraiment bon travailler. Nous grandissons vite mais nous grandissons bien : B CORP | Great Place To Work | ISO 9001 | CIR.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirmé,Rayn,"Biot, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-at-rayn-3799043076?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=KBKmFEh34AyMI0Vw%2FU6Q7g%3D%3D&position=7&pageNum=3&trk=public_jobs_jserp-result_search-card,"Automata, start-up en plein croissance dans le domaine de la Fintech, développe l'application bancaire digitale « RAYN » réunissant l'univers de la finance décentralisée, les investissements innovants, un compte épargne révolutionnaire, la gestion de patrimoine et les solutions de paiement sur une seule et même plateforme.Plus besoin de multiplier les comptes et de jongler entre un compte courant pour les dépenses du quotidien, une application pour les cagnottes en ligne ou pour payer ses amis, une autre pour investir en bourse, et encore un compte différent pour acheter ses cryptos?C'est la première Fintech qui ne se focus pas sur les dépenses mais sur le fait de faire travailler l'argent des clients pour eux, tout en étant disponible à la dépense.C'est plus simple, plus rapide, et en un mot c'est moderne.Nos clients sortent de la préhistoire : ils économisent du temps, du stress, et de l'argent.ResponsabilitésMission 1 : Acheminement de la donnéeRecueillir les besoins métiers des différentes unités demandeuses et utilisatrices de solutions de collecte et stockage de la donnée.Développer les solutions techniques de collecte de la donnée via des API.Développer des solutions techniques de stockage de la donnée.Réaliser les tests unitaires et d’intégration.Mettre en place et maintenir les mécanismes de synchronisation en production (jobs spark).Mission 2 : Mise à disposition des données aux équipes utilisatricesIndustrialiser et automatiser le nettoyage de la donnée selon les spécifications retenues.Gérer, maintenir et documenter de multiples bases de données (via l’importation de données externes en open data ou de données internes par exemple).Gérer le cycle de vie de la donnée conformément aux directives inscrites dans le RGPD.Assurer le suivi de production et la maintenance.Mission 3 : Mise en production de modèles statistiques dans les applicationsDévelopper l’industrialisation de modèles statistiques ou de machine learning.Implémentation du suivi de la validité du modèle statistique.Assurer le suivi de production et la maintenance.Mission 4 : Suivi des projets de développementÉtablir les spécifications techniques à partir de l’analyse des besoins.Reporter l’activité auprès du chef de projet.Compétences et aptitudesSavoirMaster 2 en informatique, en data science, ou en statistiques INDISPENSABLEÉcole d’ingénieurs en informatique, en data science, ou en statistiques INDISPENSABLESavoir FaireMaîtrise de l’environnement Hive/Spark (que ce soit en local ou dans le cloud) INDISPENSABLEMaîtrise des bases de données et gestion de bases de données (SQL/NoSQL) INDISPENSABLEMaîtrise de langages de programmation (Scala, Java, Python…) INDISPENSABLEMaîtrise de l’infrastructure cloud (AWS, EKS, Kube) INDISPENSABLEMaîtrise les méthodes de développement agile INDISPENSABLEConnaissance de la réglementation concernant les données personnelles et des principes de cybersécurité INDISPENSABLEMaîtrise des systèmes d’exploitation (Unix, Windows…) INDISPENSABLEConnaissance des solutions de manipulation des données  SOUHAITÉSavoir ÊtreForce de proposition INDISPENSABLEOrganisation INDISPENSABLEAutonomie INDISPENSABLERigueur INDISPENSABLECuriosité sectorielle et goût pour l’innovation INDISPENSABLE


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Microsoft Azure F/H,VISEO,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-microsoft-azure-f-h-at-viseo-3779392193?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=guRgox1cK6dEXtfkwE0V4A%3D%3D&position=8&pageNum=3&trk=public_jobs_jserp-result_search-card,"Vous avez de l’expérience dans la mise en place des Modern Data Platform dans Microsoft Azure ?Vous étiez à l’initiative ou contributeur de projet de mise en place des plateformes de données dans Azure ?Vous êtes familiarisé avec les technologies de transformation de donnée à grande échelle (Spark, Hadoop) ?Au sein de VISEO Modern Data Platform, nous recherchons un Data Engineer Cloud - Microsoft Azure F/H pour intervenir au sein de notre centre d'excellence toulousain.Nous sommes des “Positive Digital Makers”, l’agilité fait partie intégrante de notre ADN. VISEO a bâti un partenariat fort et stratégique avec Microsoft depuis près de 20 ans. Nous avons massivement investi ces 10 dernières années pour que cette approche nous aide à mieux délivrer nos projets et accompagner nos clients dans la gestion de leur produit tout en restant focus sur la valeur métier apportée.  Vos missions : Accompagner et conseiller le client dans son adoption des Modern Data Platform dans Azure (Etude d’architecture, préparation des DAT, FinOps, DevOps) Concevoir des architectures Cloud Data exploitant efficacement les services de données managés de AzureConduire des projets de déploiement des Modern Data Platform (Applications Cloud Native, Migration d’applications existantes) et participer à la mise en œuvre  Etablir des relations de confiance avec les décisionnaires techniques et métiers afin de favoriser l’adoption du Cloud Azure à long terme au sein de l’entreprise.  Fournir une expertise technique approfondie aux équipes projets  Assister et former le client sur les usages et outils Data du Cloud Azure Réaliser une veille technologique permanente sur les tendances du marché et les perspectives concurrentielles   Votre profil :  Vous êtes diplômé d’une formation Bac+5 en informatique. Vous justifiez d’une expertise reconnue et d'une expérience de 2 ans dans un rôle de Data Engineer avec une expérience significative sur Azure.  Vous possédez une compréhension approfondie des technologies du Cloud   Vous avez plusieurs années d’expérience dans la conception d’architecture, la mise en œuvre et/ou le support d’applications hautement distribuées  Vous avez des compétences approfondies dans un ou plusieurs de ces domaines : Opérations / Gestion des systèmes  Conception ou développement de logiciels  Processus DevOps et outillage  Stratégie d'entreprise  Infrastructure Cloud (virtualisation, mise en réseau, stockage, base de données)  Sécurité et conformité  Vous êtes sensibilisé à la démarche DevOps et connaissez au moins un outil pour la mise en œuvre de Continuous Integration/Continuous Delivery (CI-CD)  Vous êtes reconnu(e) pour votre leadership, votre capacité à pourvoir fédérer des équipes.  Vous avez une grande aisance dans la communication orale et écrite alliée à un esprit de synthèse, de la rigueur et un très bon sens de la formalisation  La possession de certifications sur des services Azure est un plus.  Intégrer nos équipes Cloud au quotidien, ça veut dire quoi ?   Vous ferez partie de la communauté Cloud : la proximité et la taille humaine de notre organisation vous permettront de rendre visible vos initiatives et d’évoquer facilement vos projets. En parallèle, le dynamisme de l’entreprise et sa croissance perpétuelle multiplieront vos opportunités d’évolution. Vous bénéficierez d’un management de proximité par votre mentor tout au long de votre parcours chez VISEO : Votre mentor, consultant expérimenté de votre practice, viendra régulièrement échanger avec vous sur les challenges de votre mission, faire chaque semestre le bilan de vos réalisations et évoquer vos ambitions futures et les moyens de les réaliser. Vous disposerez de multiples moyens pour monter en compétences et découvrir de nouveaux domaines : formations, certifications, Brown Bag Lunchs, ateliers, meet-ups, rencontre d’experts, séminaires techniques…  #VISEO SPIRIT : Un management flat qui encourage la communication et la prise d'initiative  Des centres d’excellence en IoT / Cloud / Smart Factory  Des missions d’audit, d’expertise technique et des POCs  Un programme d’apprentissage en e-learning : accès digital academy et 7-speaking  Deux jours de télétravail par semaine  N’attendez plus, rejoignez VISEO. Devenez un #PositiveDigitalMaker GDPR MESSAGE: Our privacy policy has been updated to comply with the new regulations. We invite you to consult it by clicking here: https://www.viseo.com/fr/politique-de-confidentialite. The VISEO Group uses the data collected as part of your application to assess your suitability for the job in question. We use the Jazz HR tool to help us in our recruitment process. This tool complies with current regulations on the protection of personal data. The tool is hosted in the United States and is PrivacyShield certified for HR data. In all cases, we may keep your file for 5 years so that we can contact you again if another position matches your profile. You may, of course, object to this. To find out more about how your data is used and how you can exercise your rights, please consult our privacy policy https://www.viseo.com/fr/politique-de-confidentialite.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Expérimenté - H/F,Devoteam G Cloud,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-exp%C3%A9riment%C3%A9-h-f-at-devoteam-g-cloud-3801924988?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=4eDfTEHPspuzVtu3VIL7Hw%3D%3D&position=9&pageNum=3&trk=public_jobs_jserp-result_search-card,"Tu auras pour mission d’accompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place et l’encadrement de projets data avec Google Cloud Platform et l’écosystème solutions open source associé.Intégré(e) à une équipe d’experts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d’étudier et cadrer les besoins clientsPréconiser les solutions et architectures ciblesDéfinir les méthodologies de déploiement et plans de migrationRédiger les dossiers d’architecture et spécifications techniquesConstruire les architectures de donnéesConcevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels)Construire et déployer les pipelines de données (ETL / ELT)Assurer la migration des données vers les nouveaux environnementsAnalyser les donnéesAnalyser les données sources afin d’identifier et évaluer des cas d’usage métierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, DataStudio…)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les équipes clients aux méthodes et concepts du cloudTu seras accompagné(e) en interne pour monter rapidement en compétences sur GCP dans l’objectif de devenir certifié Google sur ta practice.Ton Profil : Diplômé(e) d'une école d'ingénieurs, tu disposes d'une expérience significative au sein de projets Data : architecture, traitement ou analyse de données. Tu as déjà piloté un projet Data avec l’encadrement de d’une équipe de data engineers. Expérience minimum souhaitée : 5 ansTu maîtrises au minimum un langage de programmation appliqué à l’analyse de données (Scala, R, Python, Java).Tu as de bonnes compétences dans l’architecture des systèmes, bases de données, méthodologies d’analyse. Tu sais te repérer dans le vaste écosystème Data et tu sais notamment quelle brique utiliser en fonction des cas d’usages. Tu es sensible à la Business Intelligence, le Big Data, l’Internet des objets (IoT) et le Machine LearningUne connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, …) est un pre-requis.Tu as une solide compréhension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et à l’écoute, tu possèdes un réel esprit d’analyseTa maîtrise de l'anglais te permettra de gérer des projets en contexte internationalLe Groupe Devoteam œuvre pour l'égalité des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au mérite et lutte activement contre toute forme de discrimination. Nous sommes persuadés que la diversité contribue à la créativité, au dynamisme et à l'excellence de notre organisation.Tous nos postes sont ouverts aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),Thales,"Vélizy-Villacoublay, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-thales-3767964087?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=RHRxhMGnbOSJvj%2F5fAibZg%3D%3D&position=10&pageNum=3&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs présents sur tous les continents. Le Groupe investit dans les innovations du numérique et de la « deep tech » – big data, intelligence artificielle, connectivité, cybersécurité et quantique – pour construire un avenir de confiance, essentiel au développement de nos sociétés, en plaçant l’humain au cœur des décisions. Thales propose des solutions, services et produits qui aident ses clients – entreprises, organisations, Etats – dans cinq grands marchés vitaux pour le fonctionnement de nos sociétés : identité et sécurité numériques, défense, aéronautique, espace, et transport. QUI ETES-VOUS ?De formation Ingénieur ou Bac+5, Ecole d’ingénieur ou Université vous justifiez d'une expérience professionnelle d’au moins 4 ans. Compétences techniques :Compétences en développement (Shell unix, Perl, PHP, Python, git, github) PostGreSQL Python   CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :  L’accélération de la transformation digitale des métiers du Groupe s’appuie sur les actions suivantes :Construire une infrastructure technique performante et sûreMieux mobiliser nos ressources « Tech & Data » pour générer de la valeurGagner en agilité et en efficacité dans notre manière de servir les métiersProposer à nos clients une meilleure expérience numériqueVous serez intégré au sein d’une équipe agile et à ce titre vous réaliserez la mission en collaboration avec les membres de l’équipe et dans les standards de développement du groupe.   A ce titre, vous serez en charge : · Du développement de nouvelles fonctionnalités sur la plateforme· Du maintien en condition opérationnelle de l’application,· De la mise en œuvre et l’évangélisation des bonnes pratiques de développement au sein de l’équipe,· De la résolution des recommandations d’architecture et de sécurité sur la plateforme,· De la mise en œuvre de pipeline de build, tests, déploiement   En nous rejoignant, vous vous verrez confier les missions suivantes :   · Code pour en améliorer la qualité, la performance, la sécurité, et la maintenabilité   · Bonnes pratiques en matière de développement   · Fonctionnalités complémentaires permettant d’améliorer l’expérience des utilisateurs finaux, en fonction de leurs besoins et retours d’expérience.   · Recueil de l’existant : récupération, tests et mise en repository des codes / scripts / données utilisés dans les prototypes   · Documentation du fonctionnement des prototypes : cinématique globale, description des fonctions   · Améliorations (qualité, performance, sécurité) sur les parties qui seront reprises des prototypes   · Evolutions fonctionnelles suite aux échanges avec les utilisateurs finaux   · Design de la solution tactique basée sur les socles digitaux du groupe. Solutions de backup en cas de délais sur la disponibilité des socles groupes.   · Tests unitaires et globaux   · Conduite du changement des entités internes   · Support aux entités internes / utilisateurs finaux sur l'exploitation de la solution    Nous vous offrons :  - Une diversité de projets vouspermettant de découvrir l’ensemble de nos métiers,- Des conditions de travail motivantes et un plan de carrière personnalisé offrant de réelles perspectives d’évolution,- La possibilité de vous investir dans une entreprise dont la réputation est mondiale avec des ambitions constantes d’innovations techniques. Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer Fluxvision F/H,Orange Business,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-engineer-fluxvision-f-h-at-orange-business-3778381208?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=T832mEivH94jtrhxl%2FF4lA%3D%3D&position=11&pageNum=3&trk=public_jobs_jserp-result_search-card,"Votre mission consistera à travailler sur les indicateurs métier des clients de l’offre Flux Vision, notamment dans les domaines du géomarketing, du transport et du tourisme.Vous aurez en tant que Data Engineer pour mission de travailler au sein d’une équipe Data sur les sujets suivants :Préparation et qualification des données livrées aux clientsMise en place d’algorithmes de data science pour la création et la qualification de nouveaux indicateurs statistiquesParticipation à l’amélioration de l’appareil de production en optimisant les modèles visant à stocker et traiter les donnéesVous participerez également à l’élaboration et à l’amélioration des livrables clients (rapport d’analyse, tableaux de bord, intégration dans les outils de traitement de la donnée, …)Vous travaillez en coordination avec les équipes de développement et les équipes d’exploitation.Profil recherchéVous êtes titulaire d’un Bac+5 master ou école d’ingénieur, vous justifiez d'une expérience d’au moins 3 ans d’expérience dans la mise en œuvre de projets Big Data et BI.Vous disposez:D’une bonne maitrise de Python et SQL,De compétences en architecture de données dans des environnements big data / fast data.Des connaissances dans les environnements cloud big data (Azure, AWS, GCP)Une expérience dans l’utilisation d’outils de Data Science tel que Pandas serait un plus.Dynamique, doté(e) d'un bon relationnel, vous avez le sens de l'équipe, et vous aimez avoir de l'autonomie pour mener une activité de manière longitudinale.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Database Engineer,Glocomms,"Mulhouse, Grand Est, France",https://fr.linkedin.com/jobs/view/database-engineer-at-glocomms-3801327476?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=s5tiNCl96OU4rMhCpBpdtw%3D%3D&position=12&pageNum=3&trk=public_jobs_jserp-result_search-card,"We have a current opportunity for a Database Administrator/ Engineer on a contract basis. The position will be based in Mulhouse, France. For further information about this position please apply.Job Title: Database Engineer/ AdministratorContract Length: 6 month extendable (3 year project)Location: Mulhouse, FranceRemote work: HybridContext:We are working with a Global Consultancy who have defined an ambitious Master Plan for Information Systems, the implementation of which requires a strong strengthening of the Information Systems Department.ResponsibilitiesResponsible for the optimal functioning of the tools and systems under his/her charge.Implement tools while ensuring data consistency.Operate and manages database servers (administration, automation, development of procedures, security and access authorisation, optimisation of processing and queries, etc.).Create, at the request of the studies or the operation, specific tools to support the operation.Validates the installation and integration of new tools into the production environment.Manages security and access to servers and applications based on profiles.Support:Participates in corrective maintenance actions by ensuring their qualityProposes improvements to optimise existing resources and their organisationCarries out the transfer of skills and technical assistance of procedures to the teamsHandles Tier 3 external supportProjects:Identifies technical needs and the financial consequences of technical needs.Leads the various infrastructure development projects in his/her area of expertise according to constraints. TechnologyOraclePostgreSQLLinux/ Unix


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data analyst,eXalt,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-at-exalt-3791765658?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=R6ChLheJ%2ByTSRN0ToRwNJw%3D%3D&position=13&pageNum=3&trk=public_jobs_jserp-result_search-card,"L’entreprise, qui sommes-nous ?Cabinet de conseil en Transformation Digitale, eXalt est avant tout une formidable aventure humaine, et une communauté de plus de 850 collaborateurs, basés à Paris (siège social), mais également à Lyon, Lille, Nantes, Bordeaux, Aix-en-Provence, Bogota, New-York et Madrid. Fondée en juillet 2018 autour des valeurs d'intrapreneuriat, de co-apprentissage et de co-construction, eXalt inscrit son développement dans un engagement fort auprès de ses clients et de ses équipes. Multi-spécialiste, le groupe décline son modèle dans différents domaines à travers ses filiales dédiées :· Le Product Management & la Gestion de Projet au sein d’eXalt P&P· La Finance de Marché au sein d'eXalt Fi,· La Tech au sein d'eXalt IT (Développeur)· La Cybersécurité au sein d'eXalt Shield· La Data & IA au sein d'eXalt Value.Descriptif du posteeXalt Value, filiale du groupe spécialisée sur les métiers de la Data, et recherche son/ sa nouveau/elle Data Analyst pour aller à la conquête de nouveaux projets ! Vous évoluerez dans un contexte multi sociétés et challengeant.Vous serez rattaché(e) à notre bureau parisien.Vos principales missions seront de :Comprendre les problématiques métiers et les traduire de manières analytiquesExtraire les données nécessaires à l’analyse.Définir et réaliser le nettoyage de la base de données.S’assurer la qualité des données tout au long de leur traitementAnalyser et exploiter les donnéesCréer des dashboards via des outils de visualisationsEffectuer une veille sur les nouvelles technologies et solutions logicielles d’analyse des données.Profil recherchéNous recherchons avant tout une personne animée par l’esprit et l’ADN d’eXalt ☀️ ayant l’envie de prendre part à un superbe challenge et à notre aventure !Vous êtes diplômé(e) d’un Bac+5Vous bénéficiez d’une expérience d’au moins 4 ans en tant que Data AnalystVous avez une expertise en base de données et gestion de base de données (SQL/ NoSQL)Vous maitrisez des outils de data visualisation (Tableau, Qlikview, PowerBI) et/ou des outils de fouille et analyse de données (Dataiku)Vous avez une aisance rédactionnelle & relationnelleVous avez une passion pour les chiffres et le goût pour l’innovationVous êtes reconnu(e) pour votre rigueur, votre organisation et votre adaptabilité.L’anglais professionnel est requisPourquoi nous rejoindre ? · Une société en pleine croissance· Un modèle innovant, réunissant le meilleur du monde du Consulting et de la Tech !· Un espace de travail dédié à nos consultants dans nos locaux en plein centre de Paris !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),METEOJOB by CleverConnect,"Villeurbanne, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3807408356?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=A2L92Ouaz2qr%2Fg%2Fey8r4Dg%3D%3D&position=14&pageNum=3&trk=public_jobs_jserp-result_search-card,"EntrepriseAdsearch vous propose des milliers d''opportunités de carrières dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Intérim et Freelance sur notre site internet !Description Du PosteEn bref : Data Engineer (H/F) - Aix en Provence - CDI - 45/50k€Notre client basé à Aix-en-Provence recherche, dans le cadre du développement de leur activité, un Data Engineer (H/F).Les données collectées grâce à votre travail profiteront à de nombreux services dans l'entreprise.Les MissionsAu sein de l'équipe DATA, vous travaillerez sur différents sujets en mode agile dont :Intégrer, transformer et maintenir des donnéesMettre en place et industrialiser les processus d'intégration des données : Orchestration, monitoring, API, tests unitaires et d'intégrationIndustrialiser et automatiser le nettoyage de la donnée, mettre en œuvre le machine LearningGérer la donnée conformément aux directives RGPDDescription Du ProfilLe profil :De Formation Informatique, Vous MaitrisezLangage : Python, R, ShellOutils et bases de données : GDAL, ETL, BDD Postgres/Postgis, NoSQLSystèmes : OS Linux Debian/Ubuntu, Docker, KubernetesGitlab et Jira sont un plus.Les AvantagesLe poste est à pouvoir en CDI à plein temps. Rémunération entre 45/50k selon profil.12 jours de RTT par anIntéressementCarte titre RestaurantPoste situé à Aix-en-Provence.Processus De Recrutement1er entretien avec Romane, consultante en recrutement IT chez Adsearch2ème entretien avec le RH sur Aix-en-provence3ème entretien avec le N+1 du poste à pourvoirVous êtes de nature curieuse et rigoureuse et vous vous attachez à rendre une solution de qualité ; postulez en ligne dès maintenant.Candidatez en contactant ************************* ou le **************.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['JIRA']}"
Data Engineer Paris/ Ile-de-France H/F,Jems Group,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-paris-ile-de-france-h-f-at-jems-3802349437?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=e7qqa5Z%2FDCpqg7NY58KFqg%3D%3D&position=15&pageNum=3&trk=public_jobs_jserp-result_search-card,"A propos de JEMSNous sommes le seul industriel de la donnée en Europe. Notre métier est de créer, manager et exploiter le patrimoine data de nos clients.Nous avons la conviction que chaque entreprise peut adopter une démarche innovante de gestion de la donnée et créer des cas d’usage disruptifs en réduisant l'impact écologique et en diminuant la dette technique.Nous comptons plus de 840 collaborateurs en mission chez nos clients grands comptes dans tout secteur d’activité : banque, assurance, santé, énergie, e-commerce, automobile, luxe, retail, transport, agritech…Vos missionsNous recherchons un(e) data engineer capable de trouver des solutions innovantes et robustes à l'ensemble des problématiques Data.Vous aurez la charge de :Participer à la conception et réalisation d'une solution Data depuis l'acquisition jusqu'à l'exploitation de la donnée en accompagnant la réflexion des directions métiersIdentifier, collecter et intégrer les données nécessaires à la résolution de problématiques métier et opérationnellesGarantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats en appliquant les règles de Data Gouvernance et de Data ManagementTranscrire des besoins métier en règles de gestion dataIndustrialiser le déploiement de vos réalisations à travers l'implémentation de tests unitaires, d'intégration et de non-régressionVos compétencesEn tant que Data Engineer vous maîtrisez :Le langage SQLUn langage objet (Python, JAVA, Scala)Un framework de calcul distribuéL'intégration continue (Git, JUnit, SonarQube, Jenkins)Un cloud provider (AWS, GCP, Azure) ou une distribution Big Data (Hortonworks, Cloudera, Datastax)Les concepts de la modélisation relationnelle et non-relationnelleVotre profilDiplômé(e) d'une école d'ingénieur ou d'une université, vous justifiez d'une expérience professionnelle dans un contexte projet Data. Rigoureux, proactif et autonome vous restez en veille technologique et êtes force de proposition. Vous êtes capable de prendre de la hauteur et vous adapter aux enjeux du projet.Avantages à travailler chez JEMSUne JEMS Académie au service de votre montée en compétences (formations et certifications sur les technologies de pointe)Un accompagnement personnalisé et un management de proximité pour vous proposer des évolutions de carrièreUne intégration dans des communautés techniques et de pratiques JEMS (encadrement par des experts, échanges sur les bonnes pratiques, favoriser l'innovation...) Une entreprise reconnue ""Great Place To Work""Des évènements et séminaires inoubliables, des soirées d'agence convivialesMobilitéUne mobilité nationale et internationale pour vous accompagner dans vos projets de vie.DiversitéLe Groupe JEMS porte fièrement sa valeur ""Diversité"" en se mobilisant pour l'inclusion et l'égalité des chances et en luttant contre toutes formes de discrimination.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Azure,Visian,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-azure-at-visian-3796113770?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=%2FV3KqGHCMP%2Fv5yIkjqpVag%3D%3D&position=16&pageNum=3&trk=public_jobs_jserp-result_search-card,"Opportunité CDIPour le compte d'une société de conseil et en tant que Data Engineer avec une expérience sur Azure pour un client dans le domaine des transports. Nous recherchons un Data Engineer talentueux et passionné pour rejoindre notre équipe dynamique. Le Data Engineer sera chargé de la conception, du développement et de la gestion de l'infrastructure de données de notre entreprise. Il ou elle jouera un rôle clé dans la transformation de données brutes en informations exploitables pour notre organisation.Missions :Cadrage en amont de la phase de développement avec les métiers.Mise en place de nouveaux flux de données sous Talend et Azure.Une migration de Talend à Azure est en cours de réalisationDéploiement as code des pipelines (Cloud, CI/CD)Déploiement de nouvelle base de données as code ou pas.Analyse des couts de mise en place pour les nouvelles demandes.Stack :Les technos / méthodo / Logiciels Cloud / Data (Talend /GIT/BDD SQL/Azure/Python)Azure Data Factory, Azure DevopsProfil recherché :Vous êtes êtes diplômé.e d’un Bac+5 (écoles d’ingénieur ou université)Vous avez au moins 4 ans sur les stacks techniquesMaîtrise des langages de programmation tels que Python, SQL, TalendMaîtrise de AzureAnglais et Français opérationnels exigés : vous évoluerez dans un environnement international nécessitant de communiquer régulièrement en Anglais et en Français avec les parties prenantes.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Ingénieur data / dataviz H/F,Lectra,"Cestas, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-dataviz-h-f-at-lectra-3804095667?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=AmbX11Us9BO3ahKGpJ4jAg%3D%3D&position=17&pageNum=3&trk=public_jobs_jserp-result_search-card,"Description du poste :Acteur majeur sur les marchés de la mode, de l’automobile et de l’ameublement, Lectra contribue au développement de l’industrie 4.0 avec audace et passion.Dans un contexte en constante évolution : Industrie 4.0, Déploiement d’un ERP unique, moderne, avec une couverture mondiale. Nous recherchons un(e) Ingénieur(e) Data/Dataviz pour notre direction digitale qui assure le fonctionnement et l’évolution du système d’information de l’ensemble du Groupe Lectra et de ses filiales à travers le monde MissionsConcevoir et développer nos projets autour de notre nouvelle Data Platform (Power BI, Snowflake,…)Contribuer aux développements de flux d’alimentationMaintenir les développements actuels (Power BI, Snowflake, SAP BI)Participer à l’amélioration continue de l’équipe (pratiques de développement, qualité de la donnée, organisation d’équipe, montée en compétence)  Le poste est basé à Cestas (23 chemin de Marticot) - pour nous rejoindre :Accessible par l'autoroute sortie 25 de l'A63 (parking voiture et deux-roues sur place)Depuis Bordeaux centre en 20-25 min : en TER 12 min Bordeaux St-Jean - Cestas-Gazinet et 10 min de vélo/trottinette pour accéder au campus sur piste cyclable hors route.Depuis Pessac - Arrêt Unitec via le Transgironde 602 : arrêt Marticot : 20min  Ce que Lectra vous propose ?Travailler dans un environnement international, multiculturel (32 nationalités) et agile,Des locaux refaits à neuf récemment sur un site boisé de 12 hectares,Un CSE attractif proposant des subventions pour les voyages, de la location de matériel (randonnée, surf, réception…), activités culturelles et sportives, une médiathèque…Mise à disposition du complexe sportif du Bouzet à Cestas (badminton, court de tennis, piscine…),Un restaurant d’entreprise,70 jours de télétravail par an.  Description du profil :Expérience d’Ingénieur(e) BI ou expérience significative dans le monde de la data, d’au moins 3 ans.Vous avez les compétences techniques suivantes :Dataviz, sous PowerBI, une connaissance de SAP BI serait un plus,Modélisation de Base de données. La modélisation en Etoile ou Flocons n’ont pas de secret pour vous,Maitrise du langage SQL,Ingestion/Transformation : à l’aide d’outils ETL/ELT comme Talend ou Data Factory, … Et vous vous retrouvez dans ces valeurs :Curiosité, recherche du sens de la valeur des fonctionnalités qui vous sont demandées,Qualités relationnelles, communication, partage, goût pour le travail en équipeSensibilité aux contraintes liées aux traitements de données, N'hésitez pas à postuler !Nous proposons :Ce que Lectra vous propose ?Travailler dans un environnement international, multiculturel (32 nationalités) et agile,Des locaux refaits à neuf récemment sur un site boisé de 12 hectares,Un CSE attractif proposant des subventions pour les voyages, de la location de matériel (randonnée, surf, réception…), activités culturelles et sportives, une médiathèque…Mise à disposition du complexe sportif du Bouzet à Cestas (badminton, court de tennis, piscine…),Un restaurant d’entreprise,70 jours de télétravail par an.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage - Data Engineer (H/F),Equancy | Groupe EDG,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-h-f-at-equancy-%C2%A0groupe-edg-3797383036?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=%2FOpbDEg6WwoKXi2AwWTOTA%3D%3D&position=18&pageNum=3&trk=public_jobs_jserp-result_search-card,"Equancy est un cabinet de conseil international, basé à Paris et Dubaï, spécialisé dans la transformation data des entreprises.Nous planifions, concevons et mettons en œuvre des solutions Big Data, Data Science et Intelligence Artificielle pour nos clients. Nos projets vont de la mise en œuvre d’infrastructures spécialisées dans le traitement de la donnée de nos clients, de lacs de données jusqu’au développement de systèmes opérationnels intégrant des algorithmes de machine learning ou de deep learning. Nous sommes experts dans l’industrialisation de ces plates-formes, en appliquant les principes du devops à nos infrastructures data.Nos clients sont de grands groupes français et internationaux (LVMH, Picard, Chanel VINCI, Volkswagen). Ils nous font confiance autant dans l’accompagnement au cadrage de leurs besoins que dans la réalisation des solutions data innovantesAfin d’accompagner la croissance de son activité, Equancy recherche un Stagiaire Data Engineer Junior (H/F) pour intégrer sa Practice data.Dans ce cadre :Vous évoluez dans des équipes fonctionnant en méthode Agile;Vous réalisez les fonctions de collecte, de stockage et de traitement des données;Vous automatisez des tâches de traitement et mettrez en place les outils permettant d'assurer leur supervision dans une vision industrielle;Vous documentez vos travaux et les processus de mise en production;Vous accompagnez vos collègues dans l'usage et le transfert de vos travaux;Vous participez aux activités de veille technologique dans le domaine Big Data (recherches, expérimentations) ;Vous utilisez les outils DevOps déployés sur nos chaînes d'intégration continue (Jenkins, Docker, Git).Profil recherché:Vous êtes en Ecole d'ingénieur en Informatique, Système d'information, Master spécialisé Data;Capacité à travailler en équipe (tests unitaires, revue de code, partage de code, sprints);Maitrise de Python (connaissance d’autres langages de scripting également appréciée);A l’aise (ou ayant envie de le devenir) dans des environnements cloud (Google Cloud Platform, Amazon Web Services, MS Azure);Bonnes notions en bases de données relationnelles (MySql, BigQuery) et non-relationnelles (MongoDB, ElasticSearch, Redis);Réactif, avec le sens du service, vous justifiez de bonnes capacités d'écoute, d'un bon relationnel et d’une bonne gestion du stress;Curieux, autonome et proactif;Intérêt pour le conseil, les systèmes d'informations et le secteur de l'automobile, le tourisme, la grande distribution et la finance.Equancy c'est aussi :Un cadre de travail :· Superbes locaux au cœur de Paris : Espace WeWork Jules Lefebvre, à coté de Saint Lazare, au sein d’un bâtiment historique, avec de grands espaces et vue panoramique sur tout Paris;· Equilibre vie pro / vie perso;· Une politique de télétravail de deux jours par semaine;· Équipement pour travailler en remote + participation aux frais du télétravail (allocation mensuelle);· Engagement environnemental;· Des activités sportives proposées· Une conciergerie proposée par We Work.Environnement de travail stimulant, proximité forte avec les directeurs et les associés ;Équipe dynamique, passionnée et internationale.L’aventure vous tente ? Écrivez-nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer/MLOps,Mauna Kea Technologies,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-mlops-at-mauna-kea-technologies-3799120531?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=6Z%2BhtCjyjPZjusjgBO9Png%3D%3D&position=19&pageNum=3&trk=public_jobs_jserp-result_search-card,"Mauna Kea Technologies, a leader in confocal laser endomicroscopy imaging, is seeking a highly skilled and motivated Data Engineer / MLOps to join its innovative R&D / SW and Imaging Team. The candidate will play a crucial role in managing and optimizing data and data systems, ensuring the integrity and accessibility of large sets of data crucial for advanced medical imaging analysis and decision support tool developments.KEY RESPONSIBILITIESData Infrastructure Architecture and MaintenanceDesign, construct, install, test, and maintain scalable data management systems.Ensure systems meet business requirements and industry practices for CLE imaging data.Design and implement efficient and secure data storage solutions for large-scale medical imaging data, particularly focusing on high-resolution CLE images.Regularly assess and upgrade data systems to accommodate evolving data needs and technology advancements in medical imaging.Help define, formalize, implement and maintain all GMLP-related processesData Management, Curation and annotationDevelop data schemas and models that are optimized for both performance and data integrity, while ensuring compliance with medical data regulations and standards.Perform data curationParticipate in the data annotation process, develop an expertise in annotating and being able to train the annotators on CLE images, working closely with product and clinical teams.Integrate new data in the data system and ensure compliance with existing processes and defines data schemasData Integration and Pipeline DevelopmentDevelop data set processes for data modeling, mining, and production.Recommend ways to improve data reliability, efficiency, and quality.Construct and maintain robust data pipelines for efficient extraction, transformation, and loading (ETL) of large datasets from various sources, including real-time CLE imaging devices.Automate data workflows and integrate AI and machine learning models into the data pipeline to enhance image analysis and diagnostic capabilities.Collaborate with IT and cybersecurity-related teams to ensure secure data transfer and storage, adhering to HIPAA, GDPR and other relevant regulations.Cloud-Based Infrastructure DevelopmentDesign and implement a robust, scalable cloud-based infrastructure tailored for machine learning workloads. Utilize cloud services (e.g., AWS, Azure, GCP) to set up and manage data processing and machine learning environments. Ensure that the infrastructure supports various machine learning frameworks and tools efficiently.Collaboration with Cross-Functional TeamsWork closely with product teams, data scientists, software developers, clinical teams and regulatory teams to understand and aid their data needs and ensure the data architecture supports clinical decision-making.Translate complex functional and technical requirements into detailed architecture, design, and high-performing software.Work directly with data scientists to understand their data requirements for algorithm development and image processing tasks.Assist software developers in creating and optimizing applications for data visualization and analysis of CLE images.Assist clinical and product teams to define proper collection protocols with external sitesData Analysis and ReportingUtilize data sets to address CLE imaging-related business challenges.Create analytics tools that utilize the data pipeline to provide actionable insights.Develop and implement tools for advanced analytics, enabling the extraction of meaningful insights from complex medical imaging data sets.Produce regular reports and dashboards that highlight key metrics and trends in imaging data, supporting clinical research and operational efficiency.Contribute to the continuous improvement of data quality through rigorous testing, validation, and refinement of analytics tools.REQUIRED QUALIFICATIONSBachelor’s/Master’s degree in Computer Science, Engineering, or a related field.Proven experience as a Data Engineer or similar role.Strong analytical skills with experience in software development and data architecture.Knowledge of data modeling, data access, and data storage techniques.Proficiency in SQL/NoSQL, Python, and other programming languages.Familiarity with data pipeline and workflow management tools (e.g., Spark, Kafka…).Experience with cloud services (e.g., AWS, Azure, GCP)Experience with containerization technologies (e.g., Docker, Kubernetes). PREFERRED QUALIFICATIONSExperience in medical imaging or a related field.Understanding of medical imaging technology and its data characteristics.Familiarity with machine learning frameworks (e.g., Tensorflow, Keras, Pytorch.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['TensorFlow', 'Keras', 'PyTorch'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer H/F,Amiltone,"Toulon, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-amiltone-3738884777?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=PNZPtaGzZekoslbc5N74Fg%3D%3D&position=20&pageNum=3&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?Nous sommes passionnés par les nouvelles technologies, et vous ?Rejoindre Amiltone, c’est intégrer des équipes dynamiques et soudées dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.Pourquoi choisir Amiltone ?Amiltone, plus qu’une entreprise, un état d’esprit !Notre objectif ? Votre épanouissement professionnel !Nous Avons à Cœur DeVous accompagner au mieux au travers d’un suivi personnaliséVous faire monter en compétences en vous proposant des formations tout au long de votre carrièreComprendre vos besoins et respecter nos engagementsVous proposer des missions de qualité avec des technologies innovantesCultivervotre potentiel grâce à notre programme de développement personnel Addvise Votre bien-être passe aussi par des activités extraprofessionnelles, c’est pourquoi nous vous proposons des séances sportives animées par nos coachs, soirées pour se retrouver et animations (à l'agence ou en visio), Gaming nights…Les Missions D'un AmiltonienEn tant que Data Engineer (H/F), vous serez en charge des missions suivantes :– En lien avec l’équipe DevOps, construire, maintenir et faire évoluer la plateforme de données;– Définir et piloter la cohérence de la collecte, la gestion et l’alimentation des données internes et externes, en différents modes : batch, streaming, API (architecture micro-services);– Préparer et mettre en qualité les données pour les rendre disponibles dans les différents environnement de travail (datalake, datawarehouse, datamart);– Vérifier la qualité des données, de leur bonne et régulière exécution ainsi que de leur utilisation adéquate (gestion des coûts);– Travailler en étroite collaboration avec les data analysts, scientists et data stewards et business de l’entreprise ;– En lien avec l’IT et la sécurité, veiller aux règles d'intégrité et de sécurité des données;– Veille technologique.La Stack TechniqueNifi pour Injestion Spark/Java pour le traitement/nettoyage Hadoop pour le stockage Le Profil D’un AmiltonienDiplômé Bac+4/5 (Ecole d'ingénieur/Master), vous disposez de 2 années d'expérience dans le développement de data.Toujours sur le qui-vive des nouveautés technologiques, vous êtes force de proposition sur des technos, des outils ou des process qui permettent d'améliorer la qualité du code et la stabilité de nos applications.Outre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.Nos postes sont ouverts aux personnes en situation de handicap.Postuler
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data Engineer Junior F/H - Système, réseaux, données (H/F)",Visian,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-junior-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-visian-3806358145?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=bE8zJ8yCKfbZLmnSQETNjg%3D%3D&position=21&pageNum=3&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi DescriptionDescriptif du poste: Tu es un Data engineer doté d'une première expérience professionnelle (stage, alternance, CDD, CDI) ? Visian, cabinet de conseil IT, recherche un DATA ENGINEER en réponse aux nombreux besoins de nos clients ! Rôles et responsabilités : * Requêter sous SQL. * Développement sous Python et Spark de gros volumes de données. * Participer aux ateliers de conception techniques ou fonctionnels. * Conception et mise en place de système de gestion des données en utilisant un processus ETL avancé. Ce que nous te proposons : * Un CDI dans une entreprise en pleine croissance * Un package : télétravail, RTT, mutuelle, tickets restaurants ... * Un environnement de travail convivial et stimulant * Des opportunités d'évolution Nous serons ravis de te rencontrer ;). Profil recherché: Pour ce poste, nous recherchons un Data Engineer avec les compétences suivantes : * Maitrise du langage Python et SQL * Connaissance de différents frameworks Python (Pyspark, Pytorch, ...) * La connaissance d'API serait un plus * Être force de propositions techniques * Savoir travailler en équipe et en méthodes agiles * Avoir un niveau avancé en Anglais (lu, écrit, parlé)PROFIL SOUHAITÉExpérienceExpérience exigée de 1 An(s)Source: Pole emploi (https://www.pole-emploi.fr)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['PyTorch'], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Shaw Daniels Solutions,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-at-shaw-daniels-solutions-3806181098?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=aDv8UjzF9%2FDpXMGvSPYMSQ%3D%3D&position=22&pageNum=3&trk=public_jobs_jserp-result_search-card,"Main ResponsibilitiesDevelop, maintain, and optimize ETL pipelines, specifically tailored to meet the data requirements of our clients systematic trading activities, with a focus on building robust data solutions that empower profitable trading algorithms.Responsible of structuring complex and large financial time series data (e.g. Futures contracts), ensuring that our clients trading strategies are backed by accurate and high-quality data.Design and implement robust software solutions in Python, focusing on scalability, performance, and reliability.Schedule and automate workflows, enhancing operational efficiency and accuracy.Collaborate in the development and maintenance of cloud-based infrastructure, applying best practices in DevOps to ensure high data availability and scalability.Work closely with data scientists, quantitative researchers, and trading teams to understand their data needs, providing technical solutions that enable effective data analysis and strategy implementation.Ensure code quality and maintainability by implementing strong CI/CD practices, code versioning, automated tests, and conducting thorough peer-reviews.Stay current with emerging trends and advancements in software development, data engineering, and cloud technologies, integrating new tools and techniques where beneficial.Play a key role in MLOps initiatives, facilitating seamless integration of machine learning models into production environments.Provide technical support and troubleshooting for the new systematic trading framework, ensuring timely and effective resolution. QualificationsBSc or MSc in Computer Science, Engineering, Information Systems, or a related field.Professional experience in data engineering and software development.Proficiency in Python programming and experience with software development best practices.Solid knowledge with ETL processes and familiarity with data modelling and warehousing.Experience with Jenkins or similar scheduling tools, and strong understanding of CI/CD principles.Hands-on experience with cloud technologies and services, preferably in Azure.Familiarity with MLOps principles and practices is advantageous.Strong problem-solver, attention to detail, and ability to work independently and collaboratively.Excellent communication skills, fluent in English, and strong at collaborating across diverse teams.Previous experience in financial services or trading environments, particularly in systematic trading or agricultural commodities sectors, is highly desirable.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Fidérim,"Annecy, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-fid%C3%A9rim-3799879358?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=u8%2BU6qy%2BloVRc8BO6hMNCw%3D%3D&position=23&pageNum=3&trk=public_jobs_jserp-result_search-card,"Fidérim Consulting est une équipe impliquée, professionnelle et experte des recrutements tertiaires depuis plus de 18 ans sur les deux Savoies.Nous recrutons les meilleurs talents et les accompagnons pour intégrer les entreprises dans lesquelles ils vont s'épanouir.Nous recrutons notre futur talent : un Data Engineer (h/f), pour notre client, Bailleur social sur Annecy.En charge de la collecte et de l'intégration des données alimentant le SI, dont vous garantissez l'intégrité et la qualité. Vous collaborez avec l'administrateur fonctionnel dans le cadre des transferts de données entre l'entreprise et les institutions, afin de répondre aux obligations réglementaires. Vous êtes amené(e) à collaborer avec le contrôle de gestion dans les demandes d'extractions.Vous aurez pour principales missions :Intégration des données : Assurer la collecte et l'intégration des données de diverses natures, provenant de sources multiples (internes externes) Vérifier et garantir la qualité des données qui entrent dans le SI : mettre en place des contrôles de cohérence, réaliser des tests unitaires et d'intégration Procéder aux apurements de données dans le SI : gérer le cycle de vie de la donnée conformément au RGPD et aux règles appliquées au logement social Assister l'administrateur fonctionnel dans les demandes de transferts de données entre l'entreprise et les institutionsExtraction de données : Répondre aux demandes d'extractions formulées par les directions métiers Accompagner le contrôle de gestion dans la mise en place de tableaux de bordGestion de la data : Cartographier et documenter les sources de données Contribuer à la gestion des référentiels de données Être force de proposition auprès des métiers dans l'amélioration de la qualité de la donnée. Participation aux projets métiers nécessitant une analyse d'impacts sur les données et/ou des intégrationsContrat à pourvoir en CDI sur la base de 35 heures sur 4.5 jours.Salaire fixe + 13.5ème mois + tickets restaurant.Venez rejoindre une belle entreprise à fortes valeurs humaines !Vous êtes issu(e) de formation supérieure en informatique et justifiez d'une expérience réussie d'au moins 2 ans, sur un poste similaire.Maîtrise des concepts de la conception et de ta gestion de bases de données (SQL/NoSQL)Maîtrise d'outils de gestion d'entrepôt de données type ETLConnaissance de langages de programmation (C++, Scala, Java, Python...)Connaissance des outils de gestion de flux ((Kafka, Flink...)Connaissance des principes de la réglementation concernant les données personnelles (RGPD)Vous correspondez au profil que nous recherchons : Alors postulez et venez rejoindre une équipe dynamique et motivée !Pour plus d'information, vous pouvez nous joindre à l'agence.19069463-55584
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Working In,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-at-working-in-3804259615?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=YPkBeF7xHjyWgUMCoU3esw%3D%3D&position=24&pageNum=3&trk=public_jobs_jserp-result_search-card,"Description💻 Data Engineer🎯 Secteur : retail💼 CDI📍 Lyon🏡 Télétravail : 3j/semaine💻 À propos du projet :Il s'agit de concevoir des solutions sur mesure pour accompagner la transformation digitale des entreprises et de leurs systèmes d'informations. Aujourd'hui nous cherchons à renforcer une équipe dynamique Scrum (PO, Développeurs, QA et support) en charge d'un projet de centralisation de données métier au sein d'un data lake unique. Ce projet a pour but d'aider un client du secteur du retail à avoir une meilleure vision globale sur ses données.🎯 Tes missions en bref :En tant que data engineer, tu devras : Participer à la réalisation des projets métiers (usages) Prendre en charge les demandes de corrections provenant d’incidents ou d’anomalies Participer à la monté en compétences des équipes de développement Mettre en pratique les méthodes ""DevOps"" Contribuer aux chiffrages des usages et à la constitution des releasesExigences🤩 Ce poste est fait pour toi si : Tu es à l'aise sur Spark et Scala (2-3 ans d'xp minimum sur ces technos en particulier) Tu connais les méthodes / technos DevOps ou tu désires profondément monter en compétences sur cet aspect Tu aimes les projets Big Data🧰 Quelques détails sur l'environnement technique :Spark, scala, java, Bitbucket, Cloud GCP, ElasticSearch, Jenkins, Kafka, Kubernetes, Ansible, BigQuery, Dataproc…AvantagesUne rémunération avantageuse qui s'adapte à ton réel niveau de compétences  3 jours de télétravail par semaineEt... si tu le souhaites nous rejoindre c'est aussi la possibilité d'inclure le logement comme avantage en nature, ce qui signifie:💭 Partager des convictions communes au sein d’un modèle innovant te proposant un package de vie (comme une voiture de société, mais ici c’est un logement stylé !)🧘‍♂️ Dire “Bye bye” à l’administratif, aux factures, aux loyers exorbitants! Place à la tranquillité d’esprit (ménage included) avec un pouvoir d’achat redoré !🎨 Découvrir et apprendre ! Mais quoi ? De nouvelles visions, expériences, langues, cultures, compétences, etc. avec des autres membres de la Communauté !🧰 Un accompagnement régulier, du coaching, une bouée de secours pour t’épauler, t’encourager et soutenir ta réussite !🌍 Vivre l’économie de partage, aller vers un mode de consommation plus responsable, durable et écologique, parce que m**** le temps presse pour notre belle Planète !BREF NOUS REJOINDRE C’EST ADOPTER UN #ARTDEVIVRE


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': ['Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Stage - Data Engineer F/H,Fnac Darty,"Ivry-sur-Seine, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-f-h-at-fnac-darty-3805369566?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=wh8EEfaASdYZsGnt0gkFZA%3D%3D&position=25&pageNum=3&trk=public_jobs_jserp-result_search-card,"Fnac Darty, un leader européen de la distribution omnicanal. Acteur omnicanal et européen, spécialisé dans la distribution de produits techniques et d'électroménager, de biens culturels et de loisirs, et leader du service après-vente : 975 magasins dans le monde, 27 Millions de visiteurs uniques cumulés par mois sur nos sites marchands. Nos 25 000 collaborateurs sont notre meilleur atout. Ils font vivre la raison d'être du Groupe au quotidien, qui consiste à « s'engager pour un choix éclairé et une consommation durable », auprès de nos clients. Fnac Darty recrute partout en France des talents aux profils, formations et expériences très diverses, que ce soit pour ses magasins, mais aussi dans les domaines de la logistique, de la réparation et service après-vente, de la livraison, de la relation client ou encore pour ses fonctions support. Votre prochain emploi vous attend chez Fnac Darty !Envie de te perfectionner ? Intègre la Digital Factory !Fnac Darty, est le Leader européen de la distribution spécialisée et un acteur majeur du E-commerce : 24 millions de visiteurs uniques par mois sur nos sites marchands en France, avec 8 milliards d’euros de CA Groupe, 987 magasins présents dans 12 pays et 25 000 collaborateurs.La Digital Factory est une organisation agile constituée d’une vingtaine d’équipes Produits pluridisciplinaires (Orderpipe, Commercialité, CustomerCare…) ainsi que d’équipes support transverses (architecture, UX, Data…) sur le périmètre e-commerce. L’agilité à l’échelle permet de faire travailler les différentes équipes ensemble.Nous recherchons un.e Data Scientist pour rejoindre le pôle Data de la Digital Factory. Les missions du pôle Data sont la collecte de données de navigation et de données produits, leur traitement, consolidation et stockage et enfin leur exploitation via des visualisations et des algorithmes de machine learning à forte valeur ajoutée (par exemple le moteur de recherche interne du site fnac.com ou le moteur de recommandation de produits).« La mission de la Direction Digitale est de proposer à nos clients des parcours omnicanaux, sans couture online et offline. Notre ambition est très forte, on dirait une grosse startup à l’intérieur d’un grand groupe, ça donne énormément de moyens pour faire aboutir les projets, tout en ayant un esprit d’équipe et une agilité très forte » Jean. L Directeur Digital.Tes Missions Principales Seront Implémenter des pipelines data sur GCP : orchestration via Cloud Composer (Airflow) Participer à la mise en place de DBT (Data Build Tool) sur le périmètre de l’équipe Participer aux code reviews Mise en place et monitoring des pipelines de CI/CD (intégration et déploiement continus) Participer au cadrage des nouveaux projets Participer aux rituels Agile d’équipeTu veux en savoir plus sur ta future équipe ? Bonne cohésion d’équipe et dynamique De la formation et de l’entraide en continue sur les bonnes pratiques de code Un cadre responsabilisant qui offre la possibilité de progresser Organisation d’Afterwork Tous les jeudis midi foot Des collègues qui apprécient travailler sur des projets chalengeant dans des environnements à fortes contraintes techniques.Informations ComplémentairesStage de fin d'études de 6 mois à partir d'avril 2024 base à Ivry sur Seine.
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER – TOTALENERGIES DIGITAL FACTORY,TotalEnergies,"Saint-Martin-d’Hères, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-totalenergies-digital-factory-at-totalenergies-3793494861?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=5mNfCgpiTjkE7voLtheGrg%3D%3D&position=1&pageNum=4&trk=public_jobs_jserp-result_search-card,"Profil du candidat Tu as une expérience d’au moins 4 ans en data engineering, tu es diplômé d’un master ou d’une école d’ingénieur spécialisée en informatique ou mathématiques.Les compétences qui sont attendues de toi en tant que Data Engineer : La maitrise de Python, Spark et SQL.  Une bonne connaissance sur les bases de données relationnelles et non relationnelles.  La capacité à concevoir et à mettre en œuvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de données à grande échelle.  Une bonne compréhension du machine learning. Une première expérience sur un provider de Cloud, AWS de préférence. Activités En tant Data Engineer, nous attendons techniquement de toi que tu : Conçoives, construises et intègres des données au sein de la Squad et en collaboration avec les autres Squads.  Assures le stockage, la consommation, l’intégration et la gestion des données des cas d’utilisation.  Fasses l’analyse de l’analyse de l’accessibilité des données et que tu recommandes des solutions pour leur intégration.  Coordonnes la mise en place, l’industrialisation et la maintenance de l’architecture data : infrastructure, cloud, flux de données. Tu intègres également les données dans le data lake.  Collabores avec les data scientists pour la réalisation des modèles de prédiction.  Produises un code de qualité, mettes en place des tests automatisés et systématiques pour le contrôler.  Interagisses avec les architectes et les autres Data Engineers pour s’assurer de l’efficacité des solutions et apporter des préconisations techniques. En parallèle, tu auras également des missions transverse. Pour ce faire, nous attendons de toi que tu : Assures la veille technologique sur les architectures data et les nouvelles technologies.Coaches et accompagnes la communauté des Data Engineers de la Digital Factory en participant au Communities of Practice (CoP) par exemple. Contexte et environnement Rejoins-nous en plein cœur de Paris en tant que Data Engineer et intègre une de nos 30 squads qui réunit 8 à 10 personnes (data scientist, data engineer, software engineers…). Chacune des squads est dédiée à un projet métier et intervient dans la production des Minimum Viable Products (MVPs).Tu évolueras dans un contexte agile (scrum/scrumban), en mode itératif et co-constructif, en t’appuyant sur l’intelligence collective.En tant que Data Engineer, tu garantis la qualité des pipelines data du produit, tu assures le développement des programmes pour collecter, préparer, transformer et diffuser les données.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst H/F,Valeuriad,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-valeuriad-3741219622?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=FcWHuVPYJgwb7kkuXorZ%2Fg%3D%3D&position=2&pageNum=4&trk=public_jobs_jserp-result_search-card,"Rejoins la Team Data créée par Nicolas Greffard, Docteur en Intelligence Artificielle, déjà composée de 20 Data Scientists et Data Engineer talentueux 😍Nous recherchons de nouvelles pépites pour rejoindre notre équipe de choc et répondre aux multiples problématiques Data science de nos clients nantais mais également contribuer à nos projets de R&D et travailler sur des conférences incroyables (DevFest, Salon de la Data) 🤩Ta future mission si tu l'acceptes 😉Nous te proposons d'intervenir au sein de nos grandes DSI clientes, sur des sujets de collecte, d'alimentation et de transformation de données autour de l’intelligence artificielle.Le job en détail 🤩Toutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Analyst Sont Intervenus Mettre en oeuvre des outils informatiques, des techniques et des méthodes statistiques pour permettre d'organiser, synthétiser et traduire efficacement des données ; Fournir un appui analytique à la conduite d'exploration et à l'analyse complexe de données ; Créer des algorithmes de recherche de données qui permettent d'explorer les données utiles ; Procéder à l'industrialisation du procédé pour les données les plus intéressantes. Et organiser, synthétiser et traduire les informations pour faciliter la prise de décision ; Gérer les opérations et l'administration, la modélisation et l'architecture des sources de données. Et s'assurer que les bases de données existantes soient opérationnelles et intègres ; Donner un sens aux données à l'aide de ses connaissances analytiques (SQL, analytics/BI, statistiques basiques) ; D’intégrer de nouveaux jeux de données (Open Data, crowd sourcing, API, fichiers, etc.).Nous intervenons sur des données Big Data (Hadoop, Hive, Spark, etc...), NoSQL (Neo4j, Redis Graph, Redis, mongo) avec toujours quelques bases de données Oracle indéboulonnables. Mais aussi régulièrement sur des environnements Cloud (principalement AWS et GCP). Côté outillage et ETL, les missions récentes étaient principalement sur Informatica, Dataiku et Dig Dash. A retenir : nous faisons de tout !Pourquoi choisir Valeuriad ? 😊En plus d’être aujourd’hui un acteur nantais reconnu de l’expertise IT, nous nous inscrivons depuis notre création dans une démarche d'entreprise Opale et Holacratique, où l'ensemble de nos prises de décisions et projets sont réalisés par et avec l'ensemble de nos 120 coéquipiers 💪Rejoindre Valeuriad, c'est pouvoir s'investir dans la co-construction de l'entreprise : Par un rôle, avec une fiche de poste et un temps dédié (gestionnaire des Ci’s, porteur des partenariats écoles, organisateur d’événements, PO des projets internes, gestion de l'Académie Valeuriad…). Par les projets stratégiques (200 jours mis à disposition pour les coéquipiers chaque année) pour créer et faire grandir des projets structurants (création de nouveaux avantages à l'ancienneté, création d'indicateurs mensuels pour être toujours plus transparents, mécénat de compétences pour des associations caritatives...). Par les projets cagnottes (150€ par coéquipiers et par an) pour réaliser des projets collaboratifs qui te tiennent à cœur avec d'autres Valeurieux (découverte du cécifoot, challenge écologique, challenges sportifs pour des dons à des associations humanitaires, borne photo...). Par les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont proposés par les différents porteurs de projets et sont ouverts à tous les volontaires.Mais avant-tout nous sommes une équipe soudée, des collègues qui apprécient passer du temps ensemble lors de nos soirées hebdomadaires et se créer des souvenirs inoubliables 🤩 C'est pour ça que chez Valeuriad, le plus important pour nous reste le savoir-être : des passionnés, du dynamisme, des sourires, de l'écoute et le sens de la fête 😉
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Neo4j'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),Aubay,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=9tDxl5oM6thoHA8dp0UgCg%3D%3D&position=3&pageNum=4&trk=public_jobs_jserp-result_search-card,"Passionné par la Data, tu souhaites rejoindre une communauté d’experts dans le domaine afin de développer tes compétences en Data Engineering. Aubay renforce ses équipes Data et recherche des Data Engineers pour intégrer des dispositifs de projets pointus et variés.Ton quotidien en tant que Data Engineer chez Aubay, :Définition de la stratégie de stockage et mise en œuvre des technologie appropriées (base de données SQL, NoSQL, stockage distribué,…)Ingestion des données (structurées, semi-structurées ou non-structurées) selon différentes fréquences : batch, micro-batch ou temps réelConception et mise en œuvre de pipelines de données afin de fournir des données prêtes à l’emploi aux consommateurs : uniformisation, mise en qualité, enrichissement, calcul d’indicateurs,…Conception et développement d’API pour exposer les données auprès d’applications tiercesAppui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine LearningPréparation et animation d’ateliers de travail avec des interlocuteurs variés : recueil/approfondissement des besoins métiers, avancement/restitution des travaux, transfert de compétences,…Ton profil :Tu dispose d’une formation niveau BAC+5 (Master 2 ou école d’ingénieur) spécialisée en informatiqueTu as déjà une première expérience significative (a minima 2 ans) en Data Engineering sur des technologies Big DataLes technologies telles que Hadoop, Spark ou Kafka sont tes technologies de prédilectionLa programmation n’a plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et PythonTu maîtrises les tenants et aboutissants de la philosophie DevOps et des outils orientés CI/CDTu es soucieux de la qualité et de la performance de tes développements et tu t'intéresse à l’innovation frugaleTu es un expert technique dans ton domaine sans pour autant oublier l’importance d’une communication orale et écrite de qualité et adaptée à chacun de tes interlocuteursTu travaille au quotidien en mode agile et tu en maitrise les fondementsCe qui nous caractérise :Des missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs variés (Banque, Assurance, Telecom, Industrie,…) qui permettent à nos collaborateurs de monter en compétences et de devenir des experts Data reconnusDe l’apprentissage en continu avec des formations et des certifications sur les technologies Data d’aujourd’hui et de demainDes experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projetsDes communautés de savoir-faire Data proposant de manière régulière aux collaborateurs d’Aubay du contenu et des évènements de partage (webinar, meetup/afterwork, BBL,…) sur les thématiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,…Aubay encourage la diversité sous toutes ses formes et garantit l'égalité des chances à tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les aménagements nécessaires.Ta carrière chez Aubay :Tu auras la possibilité de développer et certifier tes compétences sur les dernières technologies Data avec un focus fort sur les plateformes Data Cloud telles qu’Azure Synapse Analytics, Google Cloud Platform, Snowflake et DatabricksTu pourras rejoindre la BU d’excellence Data et évoluer au sein d’un environnement humain et professionnel de haut niveau. Tu profiteras d’un management sur-mesure pour t'accompagner dans ta trajectoire de carrièreAu sein de la BU d’excellence, de multiples perspectives s’offriront à toi :Rôle de « Lead » : Vous pourrez gagner en responsabilité sur le plan technologique et devenir un référent auprès de nos clients et des collaborateurs de la communauté Data EngineeringRôle de « Champion » : Vous représenterez Aubay auprès d’un ou plusieurs de nos partenaires éditeurs stratégiques et vous participerez activement à l’animation de la relation sur le plan technologiqueRôle de « Head » : Vous pourrez prendre la responsabilité du savoir-faire Data Engineering et de ses offres et en assurer le développement au sens large (développement business, recrutement, management de collaborateurs, définition de la stratégie et animation de la communauté au sein du groupe Aubay,…)Besoin d’en savoir plus sur le processus de recrutement ?Un échange macro au niveau RH avec DorianeUn entretien technique avec Marius ou Peter, deux de nos référents techniquesUn échange managérial avec le Directeur de la BU Modern BI & DataA savoir que l’ordre des étapes peut varier selon tes envies (ex : échange managérial avec l’échange technique)Aubay encourage la diversité sous toutes ses formes et garantit l'égalité des chances à tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les aménagements nécessaires.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Glocomms,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-glocomms-3805458336?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=zlPd9EonfeJDchWM%2F69pXw%3D%3D&position=4&pageNum=4&trk=public_jobs_jserp-result_search-card,"In collaboration with an established Financial Services client, we are searching for an experienced Data Engineer to work on designing and implementation data solutions on Microsoft Azure environment.Role: Data EngineerDuration: 12 months (2 year project)Location: ParisHybrid RemoteStart Date: Start of FebruaryThe Role:To develop and maintain data pipelinesParticipate in the build of the data models ensuring accuracy and reliabilityCollaborate with stakeholders to understand the requirements and meet the needs of the userMonitor and optimize the performance of Azure data solutionsDevelop scripts to improve and streamline deployment, monitoring and maintenance of data solutionsProfile:Proven experience with cloud-based data pipelines and SQLCloud knowledge with Azure and its servicesTechnical experience with Databricks with AzureExperience of CI/CD best practicesProficiency with traditional database SQL technologiesAdept proficiency in Python, Snowflake and DBTFintech experience appreciated


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Qlik (H/F),Link Consulting SAS,"Créteil, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-qlik-h-f-at-link-consulting-sas-3802291610?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=DqpA%2FET2L12rxWXcf%2BRDHw%3D%3D&position=5&pageNum=4&trk=public_jobs_jserp-result_search-card,"Link Consulting est un partenaire fiable pour nos nombreux clients PME, ETI, Grands Comptes au niveau national.Avec nous, offrez à votre carrière de nouvelles perspectives : évolution, challenge, épanouissement professionnel. Grâce à sa structure dynamique et innovante, Link Consulting favorise l'initiative et la liberté d'entreprendre.Avançons ensemble vers l'aventure qui vous anime.Notre client, acteur ambitieux du marché de service IT, est à la recherche de son futur Data Engineer (H/F) pour intervenir sur l'ensemble de la chaîne Data (infrastructures, intégration de données et le MCO) jusqu'à l'accompagnement des métiers pour la conception de la Data visualisation.Vos MissionsConstituer et entretenir le dictionnaire des données du Groupe,Définir, concevoir et maintenir les pipelines d’alimentation de données,Organiser les données en étant garant de l'alignement et la cohérence des données,Intervenir sur les migrations d’outils de l'on-premise vers le cloud pour ce qui est des bases de données,Assurer le MCO des chaînes de datas par des diagnostics, du support et de la correction en phase de Run.Profil RecherchéVous avez au moins 5 années d'expériences réussi en tant que Data Engineer et êtes diplômé d'un Bac +5 en informatique.Vous Maîtrisez L'environnement Technique Suivant Qlik View et Qlik Sense Cloud AWS et les technos associées Les outils d'automatisationEn plus des compétences techniques, vous devrez vous démarquer par votre capacité d'analyse, votre relationnel et votre capacité à partir d'une feuille blanche pour mettre en place les meilleures solutions possibles.Vous avez un anglais vous permettant d'aborder de la documentation technique en anglais.Télétravail2 jours sur site à Créteil - 3 jours de télétravailRémunération selon profil.La présente annonce d'emploi a été rédigée sous la responsabilité de Matthias PINEAU, mandataire indépendant, ingénieur commercial de la SAS Link Consulting.Retrouvez toutes nos offres sur notre site : https://link-consulting.frLink Consulting c'est la liberté et le choix.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Thales,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3808500283?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=6hRHI3l2txJ6d4rKIU%2BW3A%3D%3D&position=6&pageNum=4&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales propose des systèmes d'information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d'importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d'information critiques et cybersécurité, répondent aux besoins de marchés où l'utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l'activité Systèmes d'information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d'information afin de faire face aux ruptures technologiques et aux cybermenaces.L’équipe recherche un(e) Data Engineer (H/F)QUI ETES-VOUS ?Intégré(e) au centre de compétences « Augmented Data » de Brest, vous interviendrez sur des projets de développement de systèmes d’information « Data oriented ».Au sein de ce centre, vous rejoindrez nos Data Engineers, Data Architects et Data Scientists.De formation Ingénieur ou Bac +5, Ecole d’ingénieur ou Université vous justifiez d'une expérience professionnelle en mise en place de solutions Big Data d’au moins 2 ans et idéalement d’une première expérience réussie en animation d’équipe et/ou pilotage de lots techniques.Plusieurs des affirmations suivantes vous caractérisent :- Vous êtes passionné(e) par le Digital, les données, les enjeux qu’elles représentent et les technologies Big Data avec lesquelles les manipuler (Hadoop, Nifi, Kafka, ElasticSearch, Spark, Storm, HBase, Cassandra, etc.).- Vous êtes familiarisé(e) avec les différentes plateformes et outils qui y sont reliés.- Vous savez et aimez coder avec des langages de programmation communément utilisés pour la manipulation de données (Python, Java, SQL) sur des architectures distribuées en production.- Vous savez implémenter des chaînes de traitement optimisées.- Vous êtes familiarisé(e) avec les concepts et technologies d’intégration continue (Git) et les outils de déploiement (Docker).- Vous êtes familiarisé(e) avec les frameworks Agile tels que Scrum ou Kanban.- Vous êtes motivé(e), appliqué(e), organisé(e) et curieux(se) dans votre travail au quotidien.- Vous êtes titulaire d’un diplôme d’ingénieur ou Master, idéalement avec une spécialisation sur les métiers de la donnée et du Big Data.- Vous parlez français et, idéalement, anglais (écrit et oral)CE QUE NOUS POUVONS FAIRE ENSEMBLE:En tant que Data Engineer, vos missions seront les suivantes :- Comprendre les besoins et les enjeux du client autour de ses données.- Concevoir des solutions innovantes de traitement de données répondant aux besoins, implémenter des chaînes de traitements Big Data et les déployer à l’échelle dans des environnements de production.- Contribuer à la définition d’architecture de données et à l’opérationnalisation de plateformes de données.- Présenter vos propositions de conception et résultats auprès du client et de votre équipe.- Partager et échanger vos connaissances et expériences dans le Data Engineering avec votre équipe.- Contribuer à la préparation et à l’animation d’ateliers avec les interlocuteurs requis.- Effectuer un reporting régulier à votre manager sur l’avancement de vos activités ainsi que sur les risques potentiels identifiés.NOUS VOUS OFFRONS:- Une diversité de projets vous permettant de découvrir plusieurs environnements techniques et fonctionnels ainsi que l’ensemble de nos métiers au sein du groupe Thales,- Des conditions de travail motivantes et un plan de carrière personnalisé offrant de réelles perspectives d’évolution,- La possibilité de vous investir dans une entreprise dont la réputation est mondiale avec des ambitions constantes d’innovations techniques,- Un cadre de travail privilégié dans des bureaux situés à un endroit dynamique du port de commerce de Brest,- La possibilité de télé-travailler jusqu’à 10 jours par mois.Alors n'attendez plus, rejoignez-nous !Thales reconnaît tous les talents : la diversité est notre meilleur atout.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer senior Spark / Scala,BI consulting,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-spark-scala-at-sibylone-3800210863?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=NXxOX2vqjsa2qAmRgKwRSg%3D%3D&position=7&pageNum=4&trk=public_jobs_jserp-result_search-card,"SIBYLONE, société de conseil spécialisée dans les systèmes d’information de synthèse et de pilotage, aide ses clients à tirer toute la valeur de leur patrimoine de données, levier stratégique majeur de développement et de rentabilité.Notre ambition : rendre les différents acteurs de l’entreprise autonomes dans l’exploitation des données, libérer les usages Métier, pour qu’ils soient en mesure de relever les défis de performance, de couverture de risque, de financement, de conquête client, de RSE… qui s’imposent à eux.Spécialistes reconnus, nos consultants s’appuient pour cela sur une connaissance approfondie de l’activité business de nos clients, en lien avec nos trois piliers que sont le Métier, la Data et le Projet.SIBYLONE emploie environ 250 salariés et réalise un CA de 30m€ dans la prestation de services auprès de grandes entreprises (8 grands comptes représentant 80% du CA). SIBYLONE est une filiale du Groupe Smart 4 Engineering créé en 2020. Le groupe s’est constitué en procédant à l’acquisition de 12 sociétés en France (dont SIBYLONE), Italie, et en Espagne dans le domaine de l’ingénierie. Le groupe est détenu par Dzeta Conseil, acteur familial de l’investissement. Avec nos 3,000 ingénieurs / consultants hautement qualifiés, le Groupe offre ses services dans les domaines très porteurs du Digital, de la Data, de l’Intelligence Artificielle, de la Cybersécurité, du Cloud et des Logiciels.Dans le cadre du développement de notre activité Data, nous recherchons plusieurs Data Engineerà l'aise avec spark et scala!Le Data Engineer participe à la conception, la construction, le déploiement et le maintien en production d’architectures Big Data, ces dernières ayant pour objectif de permettre tant l’évolution que l’optimisation du système d’information décisionnel existant en permettant de nouveaux usages Analytics et IA.Vous intégrerez une équipe projet Big Data dont l’objectif premier est de conduire des projets ayant traits à des problématiques d’architecture et de conception dans un contexte Big Data & Cloud.Vos missionsAnalyser, comprendre et cadrer une architecture permettant de répondre aux besoins métiers des clientsConcevoir et mettre en place des plateformes Data en tenant compte des contraintes tant techniques que fonctionnellesIntervenir sur la conception et le déploiement d’environnements « clusterisés » (Hadoop sur des distributions telles que Cloudera ou Hortonworks) ou Cloud publicDéveloppement de pipelines d’ingestion et de préparationGestion du stockage de données (systèmes de fichiers comme HDFS, bases SQL ou NoSQL)Alimentation d’entrepôts de données (Hive, Impala, …)Développer des applications d’exploration et de manipulation de données (SPARK / pySpark, Scala) afin d’alimenter les flux sortants, les reporting et d’exposer les donnéesEvoluer sur l’ordonnancement des traitements de données (Oozie, Bash / Shell)Assurer le maintien en conditions opérationnelles des plateformes produitesEtablir, formaliser, et promouvoir les best practicesPourquoi pas vous ?Profil recherché :De formation supérieure ingénieur en Informatique, vous justifiez d’une première expérience réussie en data engineering acquise dans un contexte projet au sein d’une start-up, d’un pure player, ou d’une ESN.Vous disposez d’une bonne maitrise des langages propres aux environnements Big Data tels que :Hadoop et ses distributionsLes solutions Cloud (Azure, AWS, GPC)Spark, Scala, Python, Unix, SQL.Une connaissance de : Docker, ELK, Kubernetes, Cassandra, Kafka, … serait un plus, de même que des fondamentaux DevOps (CI / CD).Vous avez déjà évolué dans un contexte projet agile ou scrum et faites preuve de flexibilité, d’adaptabilité et savez être force de proposition.Au-delà de vos compétences techniques, vous êtes curieux, autonome, organisé, doté d’un bon sens relationnel et d’un esprit de synthèse.Les PLUS Sibylone !Evoluer au sein d’une société qui exige le meilleur de ses collaborateurs tout en cultivant la cohésion et l’esprit d’équipe !S’engager dans une politique RSE exigeante : labellisation EcovadisAvoir un Partenariat EcoTree France : 1 recrutement = 1 arbre planté !Contribuer activement au bien-être de ses collaborateurs : participation aux frais d’abonnements activités ou achat 2 rouesAvoir de nombreux moments de convivialités : séminaires, afterworks, conférences et petits déjeuners, sports en groupe via l’application United HeroesDonner une offre de formation innovante et à la pointe des nouvelles technologiesAccord de télétravail en vigueurVous vous reconnaissez dans la description du poste ?Vous souhaitez travailler dans un environnement stimulant et dynamique ?Vous souhaitez rejoindre une société ambitieuse ?Vous souhaitez comprendre l’origine de Sibylone ?Venez-nous rencontrer : L'équipe TA sera ravie d’échanger avec vous !Ce poste est ouvert aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Bash'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Ingénieur (H/F) - CDI,SFR,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-h-f-cdi-at-sfr-3798354547?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=exaS%2F%2ByzRzDQBw91zfEeDQ%3D%3D&position=8&pageNum=4&trk=public_jobs_jserp-result_search-card,"SFR Business, groupe Altice France, est la marque Entreprise du deuxième opérateur télécom français.SFR Business développe des solutions télécoms et des services ICT simples, fiables, adaptés aux enjeux de chaque entreprise, quels que soient leur métier et l'usage de leurs collaborateurs où qu'ils soient.SFR Business propose et déploie une palette unique de services alliant des offres convergentes fixe-mobile et des solutions sur-mesure : téléphonie, données, Sécurité informatique, Réseaux d'entreprise, Infrastructure IT, Internet des Objets... Déjà adoptées par 140 000 entreprises clientes, ces solutions simples et performantes permettent aux entreprises, de la TPE à la multinationale, en passant par les administrations, de faire de la transformation numérique un levier de développement à part entièreVous intégrez la Direction Transformation, Risques & Pilotage en qualité de Data Ingénieur(e). Rattaché(e) hiérarchiquement au manager du service « PRV & Pilotage » dont la mission est le pilotage de l'activité commerciale SFR Business et du Plan de Rémunération Variable des équipes commerciales et avant-vente.Vos missions sont les suivantes :Architecture projet des données : concevoir et développer des architectures projet de données robustes, évolutives et performantes pour intégrer et gérer de grandes quantités de données provenant de sources multiples. Assurer la fiabilité, l'évolutivité et la sécurité des flux de données.Intégration des données : élaborer des pipelines de données efficaces pour l'extraction, la transformation et le chargement des données provenant de différentes sources. Mettre en place des processus d'intégration automatisés et veiller à la qualité des données.Gestion des bases de données : concevoir et optimiser des bases de données pour répondre aux besoins d'analyse et de reporting. Assurer la performance, la disponibilité et la sécurité des bases de données, ainsi que la gestion efficace des requêtes.Collaboration interfonctionnelle : en support des Data Scientists, travailler avec l'équipe pour comprendre leurs besoins et fournir des conseils et des recommandations basés sur les données.Optimisation des performances : Surveiller et optimiser les performances des pipelines de données, des bases de données et des requêtes. Identifier les goulots d'étranglement et les points d'optimisation et proposer des améliorations pour garantir des performances optimales.Sécurité et conformité : Veiller à ce que les données soient traitées et stockées conformément aux normes de sécurité et de confidentialité. Mettre en place des mécanismes de sécurité pour protéger les données sensibles et garantir la conformité aux réglementations en vigueur.En tant qu'expert(e) de la donnée, vous serez aussi amené(e) à :Réaliser des simulations statistiques d'impact lors des demandes d'évolutions de règles PRV afin de permettre à la Direction de prendre les décisions,Etudier les impacts des nouvelles règles sur l'efficacité opérationnelle du commerce,Réaliser des études ad-hoc permettant de mettre en évidence les leviers business et faire des recommandations,Piloter pour le service les projets d'évolutions SI décisionnel afin d'améliorer la mise à disposition des données commerce pour notre socle de données (Technologie SAS),Assurer l'expertise sur Tableau et SAS pour le service.Profil :Expérience en entreprise de 5 ans minimum dans le domaine du traitement et de l'analyse de données.Très bonne Maitrise de SQL, SAS, TABLEAU, VBACompétences Statistiques, Big Data, IA & machine learning.Compétences transverses attendues : Gestion/coordination de projet, sens des priorités, adaptabilitéCapacité d'analyse et force de propositionMéthode, organisation, autonomieCommunication écrite/oraleSens client (interne et externe) et écoute activeTravail en équipe et curiosité


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
(Senior) Data Engineer,Mirakl,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3707383397?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=TUvialYsQCp2GKKM33Bi%2BQ%3D%3D&position=9&pageNum=4&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.A propos de Mirakl LabsNos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerçants à travers le monde. Cette solution gère et produit de gros volumes de données qui présentent des challenges extrêmement intéressants pour les spécialistes de la donnée (produits, commandes, clients, niveaux de stock, prix, messages, appels API, données de navigation, séries temporelles, données géolocalisées etc.).En tant que (Senior) Data Engineer au sein de l’équipe Data Mirakl, vos principales missions seront de :contribuer à l'enrichissement de la Data Platform (ETL)améliorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inférence real time etc.)Intégré(e) dans une équipe de spécialistes de la donnée (data engineers, machine learning engineers, data scientists, data analysts), vous êtes un des acteurs clés pour garantir la place de Mirakl comme solution dominante sur son marché.Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, AnsibleAu quotidien, vous allez :Participer à la définition et à l’implémentation d’une architecture performante, robuste, scalable et aux coûts maîtrisés pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (évaluation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et améliorer la CI/CD de l’équipe en collaboration avec l’équipe SREAssurer la montée en compétence des membres de l’équipe sur les sujets de MLOps et Data EngineeringRéfléchir à la meilleure façon d'intégrer les données Google Analytics dans la data platformPartager ses connaissances et présenter les travaux devant toutes les équipes LabsCe qu’on peut vous apporter :Des projets data driven, divers et variés (traitements massifs d’images, de textes, time series etc.) pour des produits différents de MiraklUne culture orientée sur la veille technologiqueDes projets qui ont un vrai impact business devant être déployés sur des centaines de clients dans un contexte multilingueQuelques exemples de sujets en cours :Enrichissement des données produit à partir des images et des descriptionsModération automatique des produitsMapping automatique des données produitIdentification des produits à fort potentielsDétection de comportements frauduleuxSentiment analysis sur les messages échangés entre clients et vendeurs et dans les évaluationsDétermination de prix optimauxMonitoring de la qualité de service des vendeursDes applications d’inférence en synchrone de nos modèles de MLVous aimerez ce job si :Vous êtes passionné(e) par la data et les technologies modernes permettant d'en tirer partieVous vous intéressez à la data science et avez des connaissances générales sur les algorithmes de Machine LearningVous avez un background en développement et avez évolué dans un environnement DataVous avez a minima 4 ans d’expérience en environnement Machine Learning et/ou DataVous avez mis en production avec succès des applications Big Data faisant appel à du Machine Learning, du NLP, du traitement d’images dans des projets d'envergure, à fort volume de donnéesVotre maîtrisez Python, êtes un pro des frameworks data de la fondation Apache et êtes à l'aise dans un environnement AWSVous maîtrisez au moins un outil d’orchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous présentez vos travaux de manière simple et accessibleVous faîtes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et françaisLes plus pour le poste :Vous avez une expérience significative dans le domaine du e-commerceVous avez déjà mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez déployé des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de données avec une approche CDC à l'aide de Debezium ou autreVous maîtrisez Java/ScalaMirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
🚀 Data Engineer,BAO,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/%F0%9F%9A%80-data-engineer-at-bao-3806758472?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=PGfsUgV6W%2FL4CpL2OjBWkQ%3D%3D&position=10&pageNum=4&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une start-up en plein développement qui s'est lancée pour mission de révolutionner la médecine du travail ?L'entreprise en question est une Medtech créée en 2016. C'est une plateforme collaborative de prévention dédiée à la santé au travail qui propose des outils complets de convocation, gestion, prévention et facturation.Destinée aux ""Services de Prévention et de Santé au Travail"", aux employeurs et aux salariés, cette solution a pour but d'optimiser l'organisation de la santé au travail en rendant les échanges plus efficaces et plus fluides. Cela permet également de minimiser les potentiels risques & dangers liés au travail.Aujourd'hui, ce sont près de 2 millions de salariés suivis sur cette plateforme et ce chiffre doit bientôt atteindre les 5 millions !💥 Au sein d'une équipe de 20 personnes, vous serez amené.e à travailler sur :La collecte, l'organisation et le traitement des donnéesL'optimisation et l'automatisation des process & flux de donnéesL'amélioration de la performance et de la qualité des donnéesLa sécurité des donnéesLa Stack: Python, SQL, Javascript🔥 Les plus :Une start-up à impact avec un projet ambitieux et utile pour la sociétéUne entreprise avec un réel challenge technique (migration de données et volumétrie importante)Une équipe jeune et un secteur d'avenir !🧑‍💻 Vous avez le profil idéal si :Vous avez au minimum 1 an d'expérience en tant que Data EngineerMonter en compétences sur Javascript ne vous effraie pasVous avez envie d'évoluer au sein d'une entreprise à cœur de métier tech💰 Rémunération : 44k-48k selon expérience🏠 Poste basé à Paris (17ème) - 2 jours de télétravail/semaineOn en discute ?✉️ louise@bao.jobs


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data Engineer - Clermont-Ferrand, France (H/F)",Astek,"Clermont-Ferrand, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-clermont-ferrand-france-h-f-at-astek-3792944763?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=fFWbXQVNZ0dK8Abf31zmVQ%3D%3D&position=11&pageNum=4&trk=public_jobs_jserp-result_search-card,"Le Groupe Astek Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 7000 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.Rejoignez un Groupe en fort développement en France et ayant réalisé un chiffre d’affaires de 500 M€ en 2022.✨ Tous les détails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog.Ce que nous pouvons accomplir ensemble :Dans le cadre du développement de notre entité, nous recrutons un Data Engineer pour intégrer nos équipes clermontoises !Votre mission (…si vous l’acceptez !) :La mission consiste à renforcer l’équipe data products development en place pour supporter les ambitions de déploiement de services basés sur la data.La mission du Data Engineer consistera à analyser des données de mobilité et développer des pipelines de traitement de données robustes et scalables afin de pouvoir mettre en œuvre des services pour des clients externes et internes. Il procédera également à l’industrialisation et la mise en exploitation de ses modèles.Vous ?Diplômé d’une école d’ingénieurs, vous justifiez d’au moins 5 ans d'expérience professionnelle dans un rôle similaire.Expériences requises :Développement sur les environnements Microsoft AzureDéveloppement R/Python, DataikuExpérience sur les bases de données MongoDB, SQLNotions de traitement de données géographiques - géomatiquesVous vous êtes reconnu sur l’annonce et Astek vous plaît ? Rencontrons-nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Senior,Mobiskill | WEFY Group,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-at-mobiskill-wefy-group-3804041198?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=SpkLtq%2FwW7AmXH1prbwusQ%3D%3D&position=12&pageNum=4&trk=public_jobs_jserp-result_search-card,"La société ?Cette startup a été créée en 2018 et vise à aider la prise de décision de ses clients qui sont principalement dans le secteur du retail ou de l'alimentaire.Ils permettent d'enrichir la donnée afin d'améliorer la stratégie de vente et marketing d'une entreprise grâce à leur plateforme Saas basée sur des algorithmes d'IA.Ils ont besoin de renforcer leur équipe en Data Engineering pour gérer au mieux leur volumétrie.Les missions ?- Editer le cahier des charges des données à collecter auprès de nos partenaires distributeurs- Faire un état des lieux du modèle de données de la société, qui intègre déjà plusieurs types de données issues de différentes sources- Prendre en main la gestion de la donnée dans le cloud de la société pour optimiser les coûts et l’efficacité des analyses effectuées par l’équipe Analytics- Anticiper les évolutions et participer aux choix structurants de la société liés à la gestion de la data ainsi que la stack technique.Stack : Azure / SQL / Snowflake / Kafka / Pyspark / Airflow / DatabricksLe profil recherché ?- Au minimum 3/4 ans d'expérience dans le Data Engineering- Avoir pu travaillé en Python concernant le langage de programmation- La maîtrise des outils tels Spark, Airflow, Kafka et Snowflake seraient un gros plus - Maîtriser un des cloud providers et si possible avoir une expérience sur AzurePetit bonus si tu as pu travailler par le passé dans le retail Pourquoi les rejoindre ?- Une société stable financièrement (fonds propres uniquement)- Une startup en pleine croissance- Une rémunération en fonction de votre séniorité- Volumétrie de données incroyable, il y a de quoi s'amuser !- Faire parti de l'unique retail-tech qui a un impact écologique positif (fin des prospectus, éviter le gâchis alimentaire)Hâte de vous en dire plus rapidement !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Lille H/F,Jems Group,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-lille-h-f-at-jems-3803363459?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=ohSOvjKn5sRyuTTHLtRDiQ%3D%3D&position=13&pageNum=4&trk=public_jobs_jserp-result_search-card,"A propos de JEMSNous sommes le seul industriel de la donnée en Europe. Notre métier est de créer, manager et exploiter le patrimoine data de nos clients.Nous avons la conviction que chaque entreprise peut adopter une démarche innovante de gestion de la donnée et créer des cas d’usage disruptifs en réduisant l'impact écologique et en diminuant la dette technique.Nous comptons plus de 840 collaborateurs en mission chez nos clients grands comptes dans tout secteur d’activité : banque, assurance, santé, énergie, e-commerce, automobile, luxe, retail, transport, agritech…Vos missionsNous recherchons un(e) data engineer capable de trouver des solutions innovantes et robustes à l'ensemble des problématiques Data.Vous aurez la charge de :Participer à la conception et réalisation d'une solution Data depuis l'acquisition jusqu'à l'exploitation de la donnée en accompagnant la réflexion des directions métiersIdentifier, collecter et intégrer les données nécessaires à la résolution de problématiques métier et opérationnellesGarantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats en appliquant les règles de Data Gouvernance et de Data ManagementTranscrire des besoins métier en règles de gestion dataIndustrialiser le déploiement de vos réalisations à travers l'implémentation de tests unitaires, d'intégration et de non-régressionVos compétencesEn tant que Data Engineer vous maîtrisez :Le langage SQLUn langage objet (Python, JAVA, Scala)Un framework de calcul distribuéL'intégration continue (Git, JUnit, SonarQube, Jenkins)Un cloud provider (AWS, GCP, Azure) ou une distribution Big Data (Hortonworks, Cloudera, Datastax)Les concepts de la modélisation relationnelle et non-relationnelleVotre profilDiplômé(e) d'une école d'ingénieur ou d'une université, vous justifiez d'une expérience professionnelle dans un contexte projet Data. Rigoureux, proactif et autonome vous restez en veille technologique et êtes force de proposition. Vous êtes capable de prendre de la hauteur et vous adapter aux enjeux du projet.Avantages à travailler chez JEMSUne JEMS Académie au service de votre montée en compétences (formations et certifications sur les technologies de pointe)Un accompagnement personnalisé et un management de proximité pour vous proposer des évolutions de carrièreUne intégration dans des communautés techniques et de pratiques JEMS (encadrement par des experts, échanges sur les bonnes pratiques, favoriser l'innovation...) Une entreprise reconnue ""Great Place To Work""Des évènements et séminaires inoubliables, des soirées d'agence convivialesMobilitéUne mobilité nationale et internationale pour vous accompagner dans vos projets de vie.DiversitéLe Groupe JEMS porte fièrement sa valeur ""Diversité"" en se mobilisant pour l'inclusion et l'égalité des chances et en luttant contre toutes formes de discrimination.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
head of data engineer,Clémentine,"Île-de-France, France",https://fr.linkedin.com/jobs/view/head-of-data-engineer-at-cl%C3%A9mentine-certified-search-selection-3797494377?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=uwtLodtIRbWFzAr0aqM%2BtA%3D%3D&position=14&pageNum=4&trk=public_jobs_jserp-result_search-card,"SOCIÉTÉ—Clémentine, cabinet de conseil en recrutement depuis 2000 et spécialiste des métiers du digital et de l'IT recherche un(e) Directeur(trice) data engineer pour son client HAVAS DBI.Havas DBi, est une agence de conseil en data marketing, en hyper croissance, opérant à l'échelle internationale : ""donner du sens à la data"".MISSION—Rattaché au comex vous jouez un rôle clé dans l'agence : technique, projet, organisation, management, avant vente, innovation,... En collaboration avec les équipes conseils vous êtes un des moteurs de cette croissance.Missions principales : - Management & innovationVous managez et animez une équipe de 5 à 10 experts (data engineers, data architects)Vous contribuez au développement de la cellule data engineering (formation, nouvelles offres, organisation interne, recrutement, etc.).- Leadership techniqueComprendre les besoins fonctionnels et techniques des projets ainsi que les défis spécifiques de nos clients.Concevoir, mettre en place et administrer des architectures de données.Préparer l'industrialisation et le déploiement de cas d'utilisation en data marketing et data science.Garantir la conformité et la sécurité des données personnelles de nos clients.Développer et maintenir les flux de données d'alimentation.Mettre en œuvre les meilleures pratiques DevOps (Infrastructure as Code (IAC), processus d'intégration continue,...)Animer des ateliers métiers et proposer des solutions adaptées.- Développement :Maintenir et développer les partenariats (Cloud, IA,...)Soutenir le développement de futurs projets (avant-vente).PROFIL— Minimum 8 ans d'expérience, dont une expérience dans le data marketing.Excellente maîtrise des environnements techniques, notamment Google Cloud Platform (GCP), Amazon Web Services (AWS), Microsoft Azure.Solides compétences en Big Data avec Spark, Kafka.Compétences en langages de programmation, notamment Python, Scala et SQL.Connaissance des bases de données telles que BigQuery, SQL Server et MySQL.Expérience avec des ETL tel qu'Airflow.Savoir êtreExpérience en management d’équipeLeadership avéré et désir de contribuer au développement de la cellule data engineering.Maîtrise de l'anglais à un niveau courant.Rigueur, autonomie, gestion des priorités, esprit d'équipe et sens de l'organisation.Compréhension approfondie des enjeux et des impacts des projets dans le secteur du marketing.  POURQUOI POSTULER—Un environnement de travail dynamique et collaboratif.Contribuer à des projets innovants en data science et en IA générative.Formation continue et développement professionnel.Des possibilités d’évolutions de carrière dans un groupe international


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Tech Lead Data Engineer,AXA en France,"Nanterre, Île-de-France, France",https://fr.linkedin.com/jobs/view/tech-lead-data-engineer-at-axa-en-france-3801991762?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=vKe4sIsCFeQiCsCA%2FdetVA%3D%3D&position=15&pageNum=4&trk=public_jobs_jserp-result_search-card,"EnvironnementEn tant que Tech Lead Data Engineer F/H, vous allez contribuer directement aux projets des directions métier (ex : fraude santé, multiéquipements, pricing IARD, optimisation du lead management, fragilité auto, …) d’AXA France et à la construction du socle technique Big Data.Vous allez intégrer une équipe d'une dizaine de personne composée de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus métier de la Direction Transformation Digital Tech et DATA (DT2).La Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :- Une organisation agile en feature teams : tribus, guildes, squads- Des projets sur des applications innovantes à fort trafic (web, mobile…)- Des méthodologies craft (TDD, BDD, clean code, code review…) et DevOps- Une communauté de partage de bonnes pratiques (BBL, dojo, meetup, conf…)Votre rôle et vos missionsVous aurez pour missions principales de développer les projets Big Data demandés par le métier, et notamment :D’accompagner techniquement les Data Engineer de l’équipe (coaching, code review, pair programming…)Passer de la donnée brute à de la donnée exploitable, exposée sous forme de tables requêtables dans le datalakeConsolider ces données au fur et à mesure de leur alimentation récurrente dans le data lakeLes exploiter pour atteindre la finalité business (exposition de business view, réintégration des résultats dans le SI, service de scoring, …)De travailler à la création du socle technique Big Data et industrialiser le cycle de développement de l'équipeDe mettre en place et de garantir le respect dans la durée d'un processus qualité sur l'ensemble du cycle de DEV (documents, tests unitaires / intégration / fonctionnels, commentaires, versionning, etc.)Votre profilD'une formation supérieure en informatique ou scientifique (Master ou Diplôme d'ingénieur), vous justifiez de plusieurs expériences significatives (+ de 7 ans) sur du développement big data, en particulier sur du PySpark.Compétences techniques :Connaissances avancées en développement en PySpark (Spark avec le langage Python)Maitrise de l'environnement Microsoft AzureConnaissances avancées d'outils de BI comme PowerBICompétences transverses :Capacité à interagir avec des parties prenantes diverses : Business analyst, Architectes, MétierExpérience en mode de delivery Agile (Scrum, Kanban, etc...)Driver et accompagner des Data Engineer sur le plan opérationnelEt Idéalement :Avoir une expérience en tant que leadDes Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRAMaitrise des Traitements Big Data en mode StreamingMaitrise des Bases de données relationnelles et NoSQLUne expérience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data FactoryMais pourquoi AXA France ?Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;Equilibre vie Pro / Perso. : D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine, des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longueQui sommes nous ?AXA est un des leaders de l’assurance et de la gestion d’actifs dans le monde.Nous aidons nos 108 millions de clients à traverser les petites et grandes difficultés de la vie.Chaque jour, nous agissons ensemble pour inventer la meilleure manière de les protéger et voulons donner à chacun les moyens de vivre une vie meilleure.Un challenge qui donne le sourire et envie de se lever le matin !Chez AXA, nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C’est pour cette raison que nous menons une politique RH engagée qui favorise la diversité, qui préserve l’équilibre vie privée-vie professionnelle et accélère le développement des compétences et des carrières.Ainsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une véritable culture d’expertise, accélérant le développement des compétences de chacun et proposant une rémunération attractive.Pourquoi nous rejoindre ?Vous êtes porteur d’idées et d’initiatives innovantes ? Vous proposez des solutions et êtes au service du client ? Faites partie de notre grande famille en rejoignantUn leader mondial offrant des opportunités de carrières intéressantesUne entreprise qui donne une place de choix à l’innovation, à l’initiative et aux actions solidaires (notamment via l’association AXA Atout Cœur)Un environnement inclusif à tous les niveaux (mixité, handicap, initiatives pour favoriser l’insertion des jeunes, orientation sexuelle, etc.)Un accès à de multiples avantages (congés, temps partiel, télétravail, etc.)Un cadre stimulant, qui permet de rencontrer des collaborateurs performants et d’enrichir ses compétencesVictime ou témoin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination à alerte.discrimination.harcelement@axa.fr


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA']}"
Data Engineer (H/F),MERITIS,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3799014094?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=UKYQvFyIXdgwG%2FfKvjzDbQ%3D%3D&position=16&pageNum=4&trk=public_jobs_jserp-result_search-card,"Descriptif de l’entreprise :​Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise.Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​Aujourd'hui, nous recherchons un(e) Data Engineer pour intervenir sur plusieurs projets innovants et de grande envergure dans les secteurs de la Banque, de l'Assurances, du Transport, de l'Energie, de la Télécommunication ou encore du Retail !Vos missions :Conception de plateformes permettant de traiter une grosse volumétries de donnéesAnalyse et transformation de donnéesConception de solutions data adaptées pour les besoinsMise en place des bases de donnéesDéploiement des pipelines de données Maintien et déploiement de nouvelles fonctionnalitésSuivi de la qualité de donnéesEnvironnement technique : Spark, Scala, Hadoop, Python, Kafka, Airflow, SQL, MySQLCe poste est-il fait pour vous ? :Vous êtes diplômé d'un Bac +5 et justifiez d'au moins 3 ans d'expérienceVous avez déjà travaillé sur les environnements Spark, Scala , Hadoop, PythonVous parlez anglais courammentVous avez justifiez d'au moins une première expérience réussie ​Meritis est engagée dans la Responsabilité Sociétale des Entreprises. Nous valorisons notre impact positif sur la société et l'environnement. Notre démarche RSE guide chacune de nos actions pour promouvoir l'équité, la durabilité et le bien-être de nos collaborateurs. Rejoignez-nous pour être partie prenante de cette démarche responsable, où chacun de nos talents contribue à construire un avenir meilleur.Vos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez être victime ou témoin d’une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. »


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
(Senior) Data Engineer,Mirakl,France,https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3734528433?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=5lbntimWDuk%2Bjs5%2BPMbXAQ%3D%3D&position=17&pageNum=4&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.A propos de Mirakl LabsNos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerçants à travers le monde. Cette solution gère et produit de gros volumes de données qui présentent des challenges extrêmement intéressants pour les spécialistes de la donnée (produits, commandes, clients, niveaux de stock, prix, messages, appels API, données de navigation, séries temporelles, données géolocalisées etc.).En tant que (Senior) Data Engineer au sein de l’équipe Data Mirakl, vos principales missions seront de :contribuer à l'enrichissement de la Data Platform (ETL)améliorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inférence real time etc.)Intégré(e) dans une équipe de spécialistes de la donnée (data engineers, machine learning engineers, data scientists, data analysts), vous êtes un des acteurs clés pour garantir la place de Mirakl comme solution dominante sur son marché.Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, AnsibleAu quotidien, vous allez :Participer à la définition et à l’implémentation d’une architecture performante, robuste, scalable et aux coûts maîtrisés pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (évaluation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et améliorer la CI/CD de l’équipe en collaboration avec l’équipe SREAssurer la montée en compétence des membres de l’équipe sur les sujets de MLOps et Data EngineeringRéfléchir à la meilleure façon d'intégrer les données Google Analytics dans la data platformPartager ses connaissances et présenter les travaux devant toutes les équipes LabsCe qu’on peut vous apporter :Des projets data driven, divers et variés (traitements massifs d’images, de textes, time series etc.) pour des produits différents de MiraklUne culture orientée sur la veille technologiqueDes projets qui ont un vrai impact business devant être déployés sur des centaines de clients dans un contexte multilingueQuelques exemples de sujets en cours :Enrichissement des données produit à partir des images et des descriptionsModération automatique des produitsMapping automatique des données produitIdentification des produits à fort potentielsDétection de comportements frauduleuxSentiment analysis sur les messages échangés entre clients et vendeurs et dans les évaluationsDétermination de prix optimauxMonitoring de la qualité de service des vendeursDes applications d’inférence en synchrone de nos modèles de MLVous aimerez ce job si :Vous êtes passionné(e) par la data et les technologies modernes permettant d'en tirer partieVous vous intéressez à la data science et avez des connaissances générales sur les algorithmes de Machine LearningVous avez un background en développement et avez évolué dans un environnement DataVous avez a minima 4 ans d’expérience en environnement Machine Learning et/ou DataVous avez mis en production avec succès des applications Big Data faisant appel à du Machine Learning, du NLP, du traitement d’images dans des projets d'envergure, à fort volume de donnéesVotre maîtrisez Python, êtes un pro des frameworks data de la fondation Apache et êtes à l'aise dans un environnement AWSVous maîtrisez au moins un outil d’orchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous présentez vos travaux de manière simple et accessibleVous faîtes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et françaisLes plus pour le poste :Vous avez une expérience significative dans le domaine du e-commerceVous avez déjà mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez déployé des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de données avec une approche CDC à l'aide de Debezium ou autreVous maîtrisez Java/ScalaMirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
(Senior) Data Engineer,Mirakl,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3640038712?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=jAa%2F7RApzcYAoLTAsMNwUw%3D%3D&position=18&pageNum=4&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l’économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.A propos de Mirakl LabsNos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l’ergonomie…Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l’ensemble des produits.Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.Et pour favoriser ce partage avec d’autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerçants à travers le monde. Cette solution gère et produit de gros volumes de données qui présentent des challenges extrêmement intéressants pour les spécialistes de la donnée (produits, commandes, clients, niveaux de stock, prix, messages, appels API, données de navigation, séries temporelles, données géolocalisées etc.).En tant que (Senior) Data Engineer au sein de l’équipe Data Mirakl, vos principales missions seront de :contribuer à l'enrichissement de la Data Platform (ETL)améliorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inférence real time etc.)Intégré(e) dans une équipe de spécialistes de la donnée (data engineers, machine learning engineers, data scientists, data analysts), vous êtes un des acteurs clés pour garantir la place de Mirakl comme solution dominante sur son marché.Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, AnsibleAu quotidien, vous allez :Participer à la définition et à l’implémentation d’une architecture performante, robuste, scalable et aux coûts maîtrisés pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (évaluation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et améliorer la CI/CD de l’équipe en collaboration avec l’équipe SREAssurer la montée en compétence des membres de l’équipe sur les sujets de MLOps et Data EngineeringRéfléchir à la meilleure façon d'intégrer les données Google Analytics dans la data platformPartager ses connaissances et présenter les travaux devant toutes les équipes LabsCe qu’on peut vous apporter :Des projets data driven, divers et variés (traitements massifs d’images, de textes, time series etc.) pour des produits différents de MiraklUne culture orientée sur la veille technologiqueDes projets qui ont un vrai impact business devant être déployés sur des centaines de clients dans un contexte multilingueQuelques exemples de sujets en cours :Enrichissement des données produit à partir des images et des descriptionsModération automatique des produitsMapping automatique des données produitIdentification des produits à fort potentielsDétection de comportements frauduleuxSentiment analysis sur les messages échangés entre clients et vendeurs et dans les évaluationsDétermination de prix optimauxMonitoring de la qualité de service des vendeursDes applications d’inférence en synchrone de nos modèles de MLVous aimerez ce job si :Vous êtes passionné(e) par la data et les technologies modernes permettant d'en tirer partieVous vous intéressez à la data science et avez des connaissances générales sur les algorithmes de Machine LearningVous avez un background en développement et avez évolué dans un environnement DataVous avez a minima 4 ans d’expérience en environnement Machine Learning et/ou DataVous avez mis en production avec succès des applications Big Data faisant appel à du Machine Learning, du NLP, du traitement d’images dans des projets d'envergure, à fort volume de donnéesVotre maîtrisez Python, êtes un pro des frameworks data de la fondation Apache et êtes à l'aise dans un environnement AWSVous maîtrisez au moins un outil d’orchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous présentez vos travaux de manière simple et accessibleVous faîtes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et françaisLes plus pour le poste :Vous avez une expérience significative dans le domaine du e-commerceVous avez déjà mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez déployé des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de données avec une approche CDC à l'aide de Debezium ou autreVous maîtrisez Java/ScalaMirakl est engagée en faveur de la diversité, de l’égalité des chances et de l’inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d’innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Engineer Cloud (H/F) | POEI,DataScientest.com,"Puteaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-h-f-poei-at-datascientest-com-3484992663?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=kfF7%2B7W7enfJQ0RGNwH1fw%3D%3D&position=19&pageNum=4&trk=public_jobs_jserp-result_search-card,"Vous êtes demandeur d’emploi et vivement intéressé(e) par les métiers de la Data ?Rejoignez DataScientest en intégrant une formation 100% financée par Pôle Emploi afin d’acquérir les compétences clés qui vous permettront de booster votre carrière en tant que Data Engineer Cloud, un métier en tension et en plein essor.Cette formation est certifiée par l’Ecole des Mines ParisTech, et inclut le passage de certifications éditeurs (AWS, Microsoft Azure ou encore GCP) qui garantissent votre employabilité.Après avoir suivi notre formation de Cloud Data Engineer, vous rejoindrez, en CDI , notre entreprise partenaire.Les candidats retenus bénéficieront d’une formation intensive, entièrement prise en charge par le dispositif POEI (Préparation Opérationnelle à l’Emploi Individuel) avec Pôle-Emploi.📜MISSIONS : En tant que Cloud Data Engineer, vous aurez pour missions de proposer les meilleures solutions aux entreprises afin d’optimiser leur activité, à travers les missions suivantes :Développement de solutions permettant de traiter des volumes importants de donnéesConception, collection et fabrication des données brutesCréation d’outils et algorithmes pour le traitement des donnéesPréparation des données pour le Data Analyst,Sécurisation des Pipelines données pour les Data Analysts et Data ScientistsOrganisation de l’architecture du cloud👨‍🎓PROFIL : Ce que nous vous offrons :Une certification de l’Ecole des Mines ParisTechUn CDI auprès de notre partenaire JEMS Group, expert européen dans le traitement et l’exploitation des donnéesUn salaire attractif à la clé : 35 000€ à 48 000€ selon le profilVotre profil :Issu(e) d’une filière scientifique ou informatique vous disposez d’un bac+5 ou d’un diplôme d’ingénieurVous disposez idéalement d’une expérience significative en développement informatique, en architecture réseaux ou dans la DataVous maîtrisez un langage objet type Java, Python, C++, etc.Vous êtes inscrit(e) à Pôle Emploi


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
CDI - Data Engineer - F/H/X,CANAL+ Group,"Puteaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/cdi-data-engineer-f-h-x-at-canal%2B-group-3797457997?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=W07IHwR4wc0ISOcwpYeg%2BA%3D%3D&position=20&pageNum=4&trk=public_jobs_jserp-result_search-card,"🌟 Nos super projets en cours ou à venir :Data quality : notre équipe collecte 1,3 milliard de données par jour et 400 gigas par heure en moyenne. Dans ce contexte nous devons veiller à ce que les données soient de qualité, mais aussi disponibles en temps et en heure. La collecte de ces données va nous permettre, entre autres, de recommander du contenu à nos abonné.es ainsi que la transmission de messages ciblés visant au renforcement de leur engagement.🌟 Fun facts :Ces données vont nous permettre de convertir les prospects en abonné.es et de les fidéliser en personnalisant au maximum leurs expériences, mais aussi d'analyser l'impact de certains événements marquants (la signature d'un nouveau partenaire, la prolongation des droits de diffusion de la F1 ou encore la prolongation de Kylian MBAPPE au PSG) sur le comportement de nos abonné.es ! 🎯 Votre rôle et vos missions :Concevoir, implémenter et participer à l'industrialisation des applications dataComprendre les problématiques en jeu de chaque sujetTravailler en collaboration avec des profils DevOps, Tech Lead et POParticiper aux différentes guildes mises en place dans des processus d'amélioration continue autour de la Data Gouvernance, des normes et standards de développements   🏆 Et si on parlait de vous ? Vous justifiez d'une expérience de 3 ans minimum en tant que développeur/développeuse ou ingénieur.e dataVous maitrisez Scala (ou Java), Spark ou justifiez d'une expérience de développement dans un environnement distribué Vous avez une expérience sur AWS ou au moins sur un cloud providerUne expérience sur Airflow ou en ""Infrastructure as Code"" avec Terraform serait appréciéeVous faites preuve d'autonomie, appréciez le travail en équipe et êtes force de propositionVous avez déjà travaillé dans un environnement agileVous êtes sensible aux concepts de clean code, clean architecture et aux best practices pour la réalisation de projets Data fiables et robustesVous avez un bon niveau d'anglais (lu, écrit, parlé)Vous souhaitez rejoindre un grand acteur de l'univers des médias ! Et le process ? Un 1er contact téléphonique avec la tech recruiter + 1 entretien avec le manager, le tech lead et la tech recruiter + 1 test technique + 1 entretien avec notre Directrice Data + 1 café avec l’équipe, environ 3 semaines en tout, en visio ou en physique comme vous le souhaitez !🎁 Les +Un abonnement collaborateur CANAL+ pour être incollable sur nos univers !Des avant-premières de films et séries dans notre salle de cinémaDes visites de nos plateaux et des participations à nos émissionsParticiper aux événements de notre communauté CANAL+ TECH : meetups suivi d’afterworks, tech week, …Participation & IntéressementCSE attractif : chèques vacances et noël, prime mariage / pacs / naissance, réduction billetterie sport / voyages / loisirs, prise en charge d’une partie de votre abonnement sportif, …Disposer d’1 jour d’engagement solidaire par an au profit d’une sélection d’associationsDevenir intrapreneur ou intrapreneuse avec l’Hack’celerator, notre programme d’incubation interneEt parce que nous voulons vous aider à vous épanouir et vous perfectionner : des formations régulières, des participations à des conférences en interne ou en externe … !                      🏡  Et le télétravail dans tout ça ? Vous pourrez en bénéficier jusqu’à 3 jours par semaine ! En tant que média, producteur et distributeur de contenus, le Groupe CANAL+ a une responsabilité particulière. En interne ou à l’écran, nous soutenons une création ambitieuse, inclusive et respectueuse des limites planétaires.👊 On agit pour l’égalité entre les femmes et les hommes, contre toute forme de discrimination ou harcèlement🤝 On agit pour l’égalité des chances et l’inclusion de tous et toutes🌍 On agit pour réduire notre impact environnemental et éco-concevoir nos produitsSi vous voyez cette annonce, c’est que vous avez votre chance et que nous n’avons pas encore trouvé la perle rare !👉 Seulement chez CANAL+ à Puteaux (92).  


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst/Data Engineer (H/F),PROXIAD,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-analyst-data-engineer-h-f-at-proxiad-3810367611?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=Sysp%2B7%2BT9jFfwM3rvz8YkA%3D%3D&position=21&pageNum=4&trk=public_jobs_jserp-result_search-card,"Dans le cadre de notre développement, nous recrutons pour intégrer notre projet sur Lyon (69) un :Data Analyst/Data Engineer (H/F)Vos missions, si vous les acceptez :Apport de compétences Data aux équipes produits et projets de la North Star Flawless Preparation & Delivery :Analyse de données pour les cadrages et Discovery.Construction de dashboards en vue de suivi de KPI Projets/récurrents.Sur la partie préparation de commandes en entrepot : appropriation du modele de données et des données disponibles dans bigquery, construction des dashboard demandés, transfert de Compétences outil aux personnes métier.Sur la partie prep magasin : définition des données utiles pour les besoins de pilotage et reporting, aide aux équipes produit à sourcer et agréger ces données, construction des tableaux de bord.Technologies :JIRAMY SQLSQLLookestudio (maitrise), Google Analytics (maitrise), Big Query (maitrise), MongoDB.Le profil que nous recherchons :De formation informatique avec minimum 3 ans d’expérience en tant que Data Analyst/Data Engineer.Vous êtes reconnu/e pour avoir une expérience similaire avec une connaissance dans le domaine de preparation e-commerce qui serait un vrai plus.Un bon niveau d’anglais et nécessaire pour ce poste.Vous avez une capacité à communiquer avec des personnes qui sont dans le domaine de l’IT.Vous avez une autonomie et vous êtes force de proposition.Pour finir vous avez une maitrise de lookerstudio, google analytics et big query obligatoire.Vous vous reconnaissez dans cette description ? Echangeons !Prise de fonction : A définir selon disponibilitéSalaire : Selon profilPourquoi nous rejoindre ?L’innovation, la qualité et l’agilité sont au cœur du développement de nos activités IT, encadrées et assurées par nos 850 collaborateurs et collaboratrices français(es) et bulgares !Notre savoir-faire ? Conseil, Développement, Analyse et Expertise Informatique pour accompagner nos clients dans l'évolution et la transformation de leur SI.En plus de notre maîtrise des technologies PHP, JavaEE et .Net qui sont des composantes fortes de notre savoir-faire, nous mettons en avant une expertise dédiée aux applications mobiles et XNet (Inter, Intra et Extranet) et au développement de notre offre infrastructure (systèmes, réseaux, cybersécurité…).Nos valeurs ? L’engagement, le pragmatisme, la proximité, l’évolution et le partage. Aussi bien avec nos clients qu’avec nos collaborateurs (F/H).Résultats ? Une entreprise en pleine croissance avec des collaborateurs (F/H) épanouis et reconnus au quotidien ! Des clients fidèles et reconnaissants de la qualité des prestations fournies !Nos collaborateurs œuvrent chaque jour à satisfaire et concrétiser les idées les plus folles et innovantes de nos clients !... N’attendez plus et tentez l’expérience PROXIAD !Proxiad recrute et reconnaît tous les talents.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA']}"
Data Engineer - Spark Scala Hadoop (H/F),DGTL Performance,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-spark-scala-hadoop-h-f-at-dgtl-performance-3785729011?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=GHA2pgLNmRDerRkq2UAndg%3D%3D&position=22&pageNum=4&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi DescriptionDGTL / Signe + est le facilitateur pour tous les acteurs qui recherchent des ressources ou des missions DATA. Spécialiste du marché Data et BI, nous intervenons dans toute la France comme à l'étranger ; en sous-traitance, pré-embauche, recrutement, portage commercial, portage salarial, etc. Depuis 2018, nous accompagnons nos clients avec proximité, juste prix et préoccupation éthique de tous les instants. https://www.dgtl-performance.com Le poste : Data Engineer - Spark Scala Hadoop - minimum 3 ans d'XP Entreprise française du secteur de l'énergie, au sein d'une direction de l'innovation. Recherche un profil Data science/Data analyse pour rejoindre une équipe de 6+ personnes à terme Profil recherché : Compétences clefs obligatoires : Spark Scala langage Java Big Data (environnement Hadoop) Bon relationnel (contact métier/esprit d'équipe), bonne capacité d'analyse Localisation : Issy-les-MoulineauxPROFIL SOUHAITÉExpérienceExpérience exigée de 2 An(s)Source: Pole emploi (https://www.pole-emploi.fr)
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer H/F,Devoteam G Cloud,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-h-f-at-devoteam-g-cloud-3801927760?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=fvRO2mXxSS6aWIS7wsw%2BfQ%3D%3D&position=23&pageNum=4&trk=public_jobs_jserp-result_search-card,"Tu auras pour mission d’accompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l’écosystème solutions open source associé.Intégré(e) à une équipe d’experts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d’étudier et cadrer les besoins clientsPréconiser les solutions et architectures ciblesDéfinir les méthodologies de déploiement et plans de migrationRédiger les dossiers d’architecture et spécifications techniquesConstruire les architectures de donnéesConcevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels)Construire et déployer les pipelines de données (ETL / ELT)Assurer la migration des données vers les nouveaux environnementsAnalyser les donnéesAnalyser les données sources afin d’identifier et évaluer des cas d’usage métierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, DataStudio…)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les équipes clients aux méthodes et concepts du cloudTu seras accompagné(e) en interne pour monter rapidement en compétences sur GCP dans l’objectif de devenir certifié Google sur ta practice.Ton profilDiplômé(e) d'une école d'ingénieurs ou d'un Master 2 en Informatique, tu disposes d'une expérience significative au sein de projets Data : architecture, traitement ou analyse de données.Tu maîtrises au minimum un langage de programmation appliqué à l’analyse de données (Scala, R, Python, Java).Tu as de bonnes compétences dans de l’architecture des systèmes, bases de données, méthodologies d’analyse.Tu sais te repérer dans le vaste écosystème Data et tu sais notamment quelle brique utiliser en fonction des cas d’usages. Tu es passionné(e) par la Business Intelligence, le Big Data, l’Internet des objets (IoT) et le Machine LearningUne connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, …) est un plus.Tu as une solide compréhension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et à l’écoute, tu possèdes un réel esprit d’analyseTa maîtrise de l'anglais te permettra de gérer des projets en contexte internationalLe Groupe Devoteam oeuvre pour l'égalité des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au mérite et lutte activement contre toute forme de discrimination. Nous sommes persuadés que la diversité contribue à la créativité, au dynamisme et à l'excellence de notre organisation.Tous nos postes sont ouverts aux personnes en situation de handicap


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer - F/M,SPARTEO,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-m-at-sparteo-3803665465?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=Ryw73OKCkkuc1QSZ9O88uA%3D%3D&position=24&pageNum=4&trk=public_jobs_jserp-result_search-card,"Sparteo - Suite of Solutions for Web PublishersSince 2016, we have been offering cutting-edge adtech solutions to help publishers generate more value on their websites. How? Thanks to our dedicated and passionate teams! We are committed to providing them with all the means necessary to contribute to realizing ours and our clients' ambitions.Since the inception of Sparteo, four solutions have already been launched: Viously for video, Voxeus for audio, Actirise for display, and FastCMP our consent management platform.Discover our history, our products, and our culture on our website!Your JobTo define, design, implement, and maintain tools and infrastructures for the analysis of data collected by various services and products of Sparteo. Ensure the creation of a solution for processing, storing, and querying large volumes of data while ensuring its security. Collaborate with data scientists, data analysts, and developers to facilitate their use of data.To specifyData Collection:Creation of endpoints.Establishment of pipelines.Configuration of tables.Data Aggregation:Creation and improvement of data marts.Data Governance:Management of access rights.Data Visualization:Development of dashboards.Documentation:Establishment and maintenance of a data catalog.Support:Assistance to teams.Your profile for this jobYou have expertise in data engineering, creation of endpoints, and pipeline management.You possess skills in data visualization, including dashboard creation.You document your work by establishing and maintaining a data catalog.Native-level proficiency in French, along with full proficiency in English (B2 level required).  Your mind set to share our adventureYou want to make an impact and move things forward collectively. Does hearing phrases like ""Yes, but we've been doing it this way for years..."" make your hair stand on end? We feel the same way: progress is made by questioning what already exists.You solve problems pragmatically and analytically.You're looking for a fast-moving environment where your agility will be an asset. The 80-20 (Pareto) principle holds no secrets for you.Your ability to listen encourages you to challenge and improve yourself on an ongoing basis.Our working conditionsA convivial and flexible working environment, with our telecommuting culture integrated into the company's organization.A friendly and small-sized team that you can find in our offices near Lille or in Paris.Social gatherings and company events organized throughout the year.Sparteo is experiencing significant growth both in terms of business and workforce, especially internationally.Additional benefits include an advantageous compensation system with non-taxable and non-mandatory overtime hours, as well as a Swile restaurant ticket card.Ready to join Team Sparteo? Send us your CV and continue the recruitment process!Here are the stages in our recruitment processDiscussions about your driving forces, your ambitions and our Sparteo mindsetAnalytical and business logic testsDiscussions with one or more members of the Sparteo team, including your future managerTaking up referencesOur recruitment process is mainly conducted by videoconference; however, certain stages may require a face-to-face meeting.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Data Engineer,Mobiskill | WEFY Group,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mobiskill-wefy-group-3804049709?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=5y7bzyewo3D15FMNv0pzpg%3D%3D&position=25&pageNum=4&trk=public_jobs_jserp-result_search-card,"La société: Société dans l'e-santé qui vise à digitaliser un protocole de médecine préventive personnalisée pour soigner au mieux et en avance les personnes qui seraient à risque sur le plan médicalLes missions: Travailler sur le design de l'architecture dataDévelopper de nouveaux pipelines de donnéesCréer des tests d'unité et d'intégrationDéployer avec la méthode CI/CD ces nouveaux pipelines de donnéesLes pré-requis :Avoir au minimum 4/5 ans d'expérience en tant que Data EngineerAvoir travaillé plusieurs années avec Pyspark et KafkaÊtre familier avec AWS comme condition obligatoireConnaître Airflow serait un plusÊtre prêt à travailler avec une entreprise early-stage, qui souhaite révolutionner un domaine entier et avec de grandes ambitionsLes++:- Rejoindre une entreprise en plein essor qui a validé ses levées de fonds- Travailler dans le domaine de la santé, bénéfique pour tous- Faire partie d'une aventure humaine forte- Des bureaux dans Paris intra-muros- Rythme hybride de remote avec 3 jours de télétravail possibles- Une rémunération pouvant aller jusqu'à 80kHâte de vous en dire plus !


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data Engineer F/H - Système, réseaux, données (H/F)",UpMan Consulting,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-upman-consulting-3803468769?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=S%2F0Oj7tIVmSdSy2zbfrXcA%3D%3D&position=1&pageNum=5&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi DescriptionDescriptif du poste: C est maintenant l occasion pour toi de rejoindre UpMan Consulting Notre ambition est de trouver les meilleurs profils Data Engineer pour intervenir chez nos clients grands comptes de la métropole lilloise. On te propose une expérience professionnelle en adéquation avec ce que tu souhaites réellement. Tu découvriras une ambiance de travail saine & bienveillante, tu participeras activement au développement d une Happy StartUp, actuellement en forte croissance. Où convivialité rime avec efficacité & où ta performance individuelle contribue à notre réussite globale. Tes missions / compétences techniques Si tu l acceptes, ton rôle & tes missions seront les suivantes : * Réaliser le processus d intégration de nouvelles données (réflexion sur la solution, mise en place d ETL, règles de nettoyage, anonymisation ) * Être garant de l'accès aux sources de données. * Maîtrise de la donnée et être le garant de sa qualité (référencement, normalisation et qualification) afin d'en faciliter l'exploitation par les équipes (Data Analysts et Data Scientists). * Maîtrise de technologies Big Data et Cloud : Hadoop, Spark * Assurer la supervision et l'intégration de données structurées et non structurées venant de sources multiples, tout en veillant à garder des données de qualité. * Assurer le suivi, la cartographie et la documentation des données intégrées * Afin de garantir une bonne exécution de ta mission, nous recherchons les compétences techniques suivantes : Langages de programmation : * SQL * Python / Pyspark * Java/Scala (plus rare, mais important) Différents types d ETL & orchestrateurs : * Airflow * Dagster * Prefect * SSIS/informatica * Talend Plateformes cloud : * GCP * Microsoft Azure * AWS Base de données relationnelles & NoSQL : * postgreSQL, MySQL,... * Redis, graphDB * Data warehouse/data transform : * Snowflake, Bigquery (très important) * DBT Qualité & compétences nécessaires * Communiquant.e dans l âme * Avoir une bonne capacité de synthèse & l esprit critique * Travail d équipe * Curiosité aiguë * Comprendre les objectifs & les besoins Nice to have * Anglais courant * Connaissance de la méthodologie DevOps * Notions en Data-science The office Pas de full remote (pour l instant) mais de l hybride dans la plupart des missions. En moyenne, 2 jours de télétravail par semaine. Cependant, les portes de nos bureaux à Wambrechies sont toujours ouvertes pour accueillir nos collaborateurs pendant leurs journées de télétravail & passer une bonne journée tous ensemble ! Profil recherché: Ton Profil ���� Tu es une personne passionnée & passionnante par ton domaine. Tu as envie d'évoluer, de partager, de participer à une mission collective & découvre LA nouvelle façon de collaborer avec une ESN. Tu peux nous démontrer une expérience significative avec en tant que Data Ingénieur, saches que l'alternance, c'est de l'expérience ! Pas besoin d'avoir trop ou pas assez de diplômes, chez nous, ce sont les compétences qui priment  ! On se rencontre, on discute, on échange sur tes envies professionnelles & on laisse la magie opérer. L'envie de grandir & de monter en compétences est ton moteur au quotidien. Tu aimes les problématiques complexes et les défis technologiques. On dit de toi que tu es un.e agiliste dans l'âme, qui effectue une veille constante, à l'affût de tout ce qui évolue autour de toi... Ne réfléchis plus, saute le pas & découvre UpMan Consulting, tu ne seras pas déçu. Tu balances ta démission ?PROFIL SOUHAITÉExpérienceExpérience exigée de 2 An(s)Source: Pole emploi (https://www.pole-emploi.fr)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['MySQL', 'PostgreSQL', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer | Luxe - Retail (H/F),Cenova,"Île-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-luxe-retail-h-f-at-cenova-3796158092?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=62UxH0ZB%2By6%2FiuDRu2mBUg%3D%3D&position=2&pageNum=5&trk=public_jobs_jserp-result_search-card,"QUI SOMMES NOUS ET POURQUOI NOUS REJOINDRE ?Cabinet à forte croissance, Cenova accompagne ses clients du #Luxe, du #Retail et du #Tourisme/Loisirs dans leurs projets de transformation Data et Digitale, et ce sur l’ensemble des problématiques métiers (marketing, produit, supply, RSE, …).VOTRE MISSIONVous travaillerez pour le compte de l’un de nos clients, au sein de l’équipe Data sur le développement de solutions Data Analytics. Vos missions principales seront les suivantes :Concevoir et mettre en œuvre des solutions de traitement de données dans un environnement CloudMener des études de faisabilité et préconiser les architectures data ciblesCréer, tester et déployer des pipelines de données d'extraction, de transformation et de chargementMettre en application les concepts de CI/CD via les outils dédiésParticiper à la mise en œuvre de produits de Data visualisation : dashboard, reporting...Participer aux ateliers de collecte des besoins auprès des équipes métiersRédiger la documentation (spécification techniques, document d'exploitation, dossier d'architecture...) et analyser les solutions les plus adaptéesAssister les phases de recette utilisateurs (identification ou mise en place de jeux de tests, recueil et traitement des demandes de changements)Accompagner et former les utilisateurs à la prise en main des solutionsEnvironnement technique :Cloud : Azure, GCP, AWSLangages : SQL, Python, Spark, Scala, JavascriptBase de données : SQL Server/SQL Cloud, Google BigQuery, Oracle, MySQL, MongoDBDatamanagement : Azure Data Factory / Databricks/ Synapse (idéalement), Google Cloud Data Fusion / Datafllow, DBT, Talend, SQL Server Integration Services.Datavisualisation : Power BI (idéalement), Tableau, Qlik, DataStudio/LookerRepository : GIT, Azure DevOps, SVNSystèmes d’exploitation : Unix, Linux, WindowsVOTRE PROFILVous avez une expérience minimale de 2 ans sur des missions de Data Engineering et vous disposez d’une grande appétence technique.Vous appréciez comprendre le cycle de vie de la donnée et vous êtes amateur de datavisualisation, notamment sur PowerBI.Vous avez, par ailleurs, le contact facile et vous comprenez les enjeux business et adaptez vos analyses en ce sens.Vous êtes proactif(ve), autonome, bon(ne) communiquant(e) et vous êtes à l'aise en anglais.POURQUOI NOUS REJOINDRE ?Au-delà de missions passionnantes dans des secteurs en pleine transformation, Cenova c'est avant tout un cabinet à taille humaine avec :✅ Un respect de vos attentes concernant vos missions et une réelle proximité managériale pour vous accompagner✅ La CenoAcademy pour vous former et nos CenoTalk pour partager nos expertises et connaissances✅ La CenoLife pour vous apporter une vie de cabinet stimulante (afterworks, séminaires, évènements sportifs...)✅ De multiples avantages en complément d’une rémunération attractive : la mutuelle Alan, un CE, des titres restaurants, des primes vacances, le télétravail et plein d’autres jolis avantages…Ces quelques mots suscitent votre curiosité ? Candidatez ! Votre personnalité et votre savoir-faire feront le reste. Notre processus se déroule en 3 entretiens : RH, Manager et rencontre avec un associé !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': ['Linux', 'Windows'], 'SoftDB': ['MySQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,CGI,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-cgi-3805296774?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=ISE%2FVvbm%2BsvVa%2FpFBjJtBg%3D%3D&position=3&pageNum=5&trk=public_jobs_jserp-result_search-card,"Description de posteEn tant que Data Engineer, vous serez au cœur de la transformation digitale des entreprises de la région Lyonnaise.Développement, traitement de haute volumétrie, cloud transformation/ migration seront autant d’enjeux qui rythmeront votre quotidien aux côtés de nos professionnels.Vous intégrerez une équipe de taille humaine spécialisée sur les domaines de l'Energie, de la chimie & des métiers de la santé.Aux côtés des autres membres de l’équipe et de communauté Data Grand-Est , vous perfectionnerez vos compétences pour devenir un Data Engineer senior sur les technologies les plus modernes du marché Data.Fonctions et responsabilitésAu sein de l’équipe, vous serez en interaction avec toutes les parties prenantes du projet, allant du business, aux équipes d’expert et de déploiement des solutions.Vous participerez au développement stratégique d’un projet d’un client et vous évoluerez dans un contexte international, et bénéficierez de l’expertise de consultants CGI, en immersion chez le client.A ce titre vos principales responsabilités seront : Appréhender le contexte et les enjeux Métier du client ; Comprendre et expérimenter le cadre Agile et Lean ; Analyser les besoins fonctionnels et déterminer le modèle de données nécessaire avec l’accompagnement de Consultant senior ; Participer au développement de ces indicateurs au sein de la plateforme Cloud cible (AWS, GCP , Azure) et des outils de restitution (ex : Power BI, Qliksense) ; Établir et dérouler des scénarios de tests ; Participer à la vie de la communauté Data.Qualités requises pour réussir dans ce rôle De formation bac+5 ou de formation supérieure en informatique, vous disposez de 2 ans expériences réussie dans le déploiement de plateforme de type Kafka , Datalake AWS , Datalake CGP ; Des connaissances métiers dans le domaine de l'Energie, de la chimie & des métiers de la santé , alliés à des compétences techniques fortes sont également des atouts pour la réussite de ce projet ; Votre capacité d'adaptation, votre autonomie, votre sens du service ainsi que vos qualités relationnelles seront vos atouts pour réussir et évoluer ; Vous aimez évoluer dans des contextes internationaux, avec une très bonne maitrise du français et de l'anglais à l’écrit comme à l’oral.CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+.Rejoindre CGI, c’est : Des suivis réguliers avec son manager ; Un accès à une plateforme avec de nombreuses formations disponibles dès son arrivée ; De nombreuses communautés techniques et métiers ; Une mobilité interne facilitée ; Un programme de buddy pour être accompagné(e) durant la première année chez CGI ; Un équilibre vie professionnelle /vie personnelle respecté (dont 0 à 3 j de télétravail/semaine) ; Des événements réguliers (sport, afterworks,…) ; De nombreux avantages sociaux (Régime d’Achat d’Action, forfait mobilité durable, mutuelle à 100%...) ; Une politique RSE ambitieuse ; Un programme de Mécénat de Compétences ; Une Mission Emploi Handicap très développée ;Allier savoir et faireAlors que la technologie s’inscrit au cœur de la transformation numérique de nos clients, nous savons que les individus sont au cœur du succès en affaires.Lorsque vous rejoignez CGI, vous devenez un conseiller de confiance, collaborant avec vos collègues et clients pour proposer des idées exploitables qui produisent des résultats concrets et durables. Nous appelons nos employés ""membres"" parce qu’ils sont actionnaires et propriétaires de CGI. Ils ont du plaisir à travailler et à grandir ensemble pour bâtir une entreprise dont nous sommes fiers. C’est notre rêve depuis 1976. Il nous a menés là où nous sommes aujourd’hui – l’une des plus importantes entreprises indépendantes de conseil en technologie de l’information (TI) et en management au monde.Chez CGI, nous reconnaissons la richesse que la diversité nous apporte. Nous aspirons à créer une culture à laquelle nous appartenons tous et collaborons avec nos clients pour créer des communautés plus inclusives. En tant qu’employeur qui prône l’égalité des chances pour tous, nous voulons donner à tous nos membres les moyens de réussir et de s’épanouir. Si vous avez besoin d’un accompagnement spécifique durant le processus de recrutement et d’intégration, veuillez nous en informer. Nous serons heureux de vous aider.Prêt à faire partie d’une entreprise qui est gage d’excellence? Rejoignez CGI – où vos idées et vos actions changent la donne.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Software Engineer,Teads,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/senior-software-engineer-at-teads-3799283693?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=r1vhwBLWAgLbCPB6Y7ZnCA%3D%3D&position=4&pageNum=5&trk=public_jobs_jserp-result_search-card,"Teads has an engineering team that brings together 200+ talented individuals in 3 main locations (Montpellier, Paris, and Bucharest). We are organized in agile and autonomous feature teams and share technical knowledge within several communities of practice.We promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.Our organization gives the possibility to work remotely part of the time and more flexibility is open to discussion. We also offer relocation packages if you prefer to settle down in one of our engineering offices.👉 Join a team of passionate people who build quality and responsible advertising, at scale!Our main Engineering challenges at TeadsWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).Rich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.Management of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).Build efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.A fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.Bring a wide diversity of profiles to the same level of quality and knowledge.What will you do?As a Senior Software Engineer, your mission will be to:Collaborate with a variety of teams to develop complex services.Create, design, develop, test, and monitor your code in production autonomously and reliably.Work with the Engineering Manager to frame projects and be accountable for their execution.Obtain a good understanding of the business to provide relevant solutions to clients.Be a work facilitator and help communication inside and outside Teads.Stay up-to-date on new technologies and architectures. If they can solve a problem Teads has, propose ways to implement them into our current software engineering process.What will you bring to the team?Good programming abilities. Testing your code is second nature to you. You are very mindful of your application’s architecture, performance, maintainability, and overall quality.Good communication skills and ability to work collaboratively within a team. You are an active listener and a dialogue facilitator, you know how to explain your decision and like sharing your knowledge.Multiple shipped projects in Software Engineering.Strong problem-solving skills.Why work at Teads?At Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to scale our business while continuing to create new and exciting products.We value team spirit, pragmatism, listening and we encourage initiatives.We promote end-to-end development: “You build it, you run it, you monitor it”.We share knowledge and support with each other beyond any organizational boundary.We fix issues during a blameless postmortem and learn from it so that it doesn’t happen twice.We are working together to create great engineering, but we are also supportive to promote a great work-life balance.We care about youSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).Career Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).Life Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.Wellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).Discover more about our culture and benefits on our Engineering website.What are our recruitment process steps?We want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!About TeadsTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.As an end-to-end solution, Teads’ modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world’s best publishers and content providers.Through exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.Teads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.We're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,Mobilize Financial Services – France,"Noisy-le-Grand, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-mobilize-financial-services-%E2%80%93-france-3790154028?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=eDv5abC%2FTccd%2FIoi5o4y7w%3D%3D&position=5&pageNum=5&trk=public_jobs_jserp-result_search-card,"🚗 En route vers Mobilize ! A l’écoute de tous nos clients, nous créons des services financiers innovants pour construire une mobilité durable pour tous.Rejoindre Mobilize Financial Services, c’est d’abord choisir d’intégrer un groupe international, filiale de Renault Group, une banque de financement solide, partenaire des constructeurs Renault–Nissan–Mitsubishi. Nos 4 000 collaborateurs présents dans 35 pays, agissent ensemble au service de nos clients.Nous proposons à nos clients - particuliers comme professionnels - les financements et les services les plus adaptés pour les véhicules neufs et d'occasion.Nous finançons également l'activité des réseaux de concessionnaires des marques de l'Alliance Renault-Nissan-Mitsubishi et nous veillons à faciliter leur gestion au quotidien pour leur permettre de développer leurs ventes et assurer leur pérennité financière.Notre entreprise se ""MOBILIZE"" en faveur de la diversité culturelle, l'égalité hommes-femmes et l'intégration de personnes en situation de Handicap. Nous favorisons un environnement de travail où les différences individuelles sont reconnues, appréciées, respectées et valorisées, de façon à mettre à profit les talents et les forces de chacun.🚘Prenez le volant ! Pas de routine, tous nos itinéraires sont différents ! Au sein de la DSI, votre futur métier consistera à :Accompagner l’équipe dans la transformation du domaine décisionnel construit sur une architecture type DWH et le porter sur la solution GCP (Google Cloud Platform) de Mobilize FSParticiper à la construction du projet de transformation vers GCPParticiper aux projets d’évolution de notre plateforme Suite Elastic (ELK - Kibana)Piloter des projets en étroite collaboration avec les directions métier et en accord avec le TBA (Tableau de Bord des Actions).Assurer la gestion du budget, du planning, de la tenue des jalons et du respect des engagements sur les projets en responsabilitéAssurer la qualité et le bon fonctionnement du chargement des données.Assurer la mise à disposition des données et des outils de reportings à toutes les directions clientes dans le respect des contrats de service Véritable tout-terrain, vous nous intéressez ! L’esprit d’équipe et le sens du service client pour atteindre ensemble les différents objectifs ambitieux et satisfaire les différentes parties avec un haut niveau de qualité.Vous avez un bon relationnel, de l’écoute et une excellente communication afin d’interagir avec des interlocuteurs de différents niveaux (direction technique et métier) et de travailler en transverse.Le sens de l’analyse et de bonnes capacités d’anticipation pour déceler les problèmes avant la naissance de ces derniers.Force de proposition : avec vous il n'y a pas de problèmes, que des solutionsVous avez un niveau d’anglais vous permettant de lire et de comprendre de la documentation technique💻🖱 Environnement technique :Maitrise des langages Python - SQL / NoSQLExpérience significative sur PythonExpérience avec GitUne expérience avec les outils Nifi, Airflow et GCP (BigQuery / Cloud Function / Cloud Storage …) serait un plusGestion de projet, maintenance, évolution, supportAppétence pour les sujets techniques et fonctionnels : outils de modélisation, exploration de données, IA, machine learningPourquoi nous rejoindre ?Votre Pack confort est composé de nombreux avantages 😀 :Rejoindre Mobilize Financial Services c’est intégrer un grand groupe international qui offre des opportunités de carrière.Un environnement de travail moderne et convivial : locaux agréables, salle de sport, terrasse, restaurant d’entreprise, parking avec un CSE dynamique avec de nombreuses offres voyages, sport, famille,Nous sommes mobilisés pour développer la qualité de vie au travail de nos collaborateurs en faisant évoluer nos façons de travailler (méthodes, outils, organisation du travail…) et nous sommes fiers d’être certifiés ⭐Great Place To Work ⭐Possibilité de télétravailler 2 jours par semaineNous proposons une rémunération selon profil + Participation + Intéressement Locaux situés au pied du RER A – Noisy le Grand Mont d’Est❗ Mobilize Financial Services déménage ❗ Les postes à pourvoir en région parisienne seront basés à Boulogne Billancourt à horizon 2026Pour en savoir plus sur notre entreprise, suivez-nous sur LinkedIn !La route du recrutement ?📞 Un rapide entretien téléphonique,🛑 un arrêt au stand / un premier échange avec Marie DE CARLI, Responsable du département DATA↪ et un dernier virage avec Tifaine GIBAUD, Responsale du département Développement des Compétences L’équipe Mobilize FS a hâte de vous recevoir !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,INFOGENE,"Neuilly-sur-Seine, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-infogene-3809754535?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=C147VPkJ4vB7%2F1al%2BMcSJA%3D%3D&position=6&pageNum=5&trk=public_jobs_jserp-result_search-card,"Postuler à cette offreSeul les CVs au format pdf sont acceptésMessage d'erreur Partager sur : Neuilly-sur-Seine CDI Publiée il y a plus d'un jour+5ans d'expérience demandéeRémunération :  50k à 65k Description Du PosteEn tant que Data Engineer F/H vous aurez pour mission au sein de l'équipe technique de : Analyser les données (par origine, contrats, criticités, ....) : fixer les priorités et analyser les différents cas d'usage Etablir des TBB de suivi (par branche/usage/Typologie de clients) : Donner un reporting de suivi & un niveau de risque Détecter des doublons (pour éviter de solliciter inutilement nos clients) : Baisser les couts, améliorer la performance Filtrer régulièrement les dataSets, de façon à isoler les contrats résiliés : Ne pas solliciter nos ex-clientsIl/elle est aussi à l'écoute de nos interlocuteurs business avec qui il interagit constamment.Description Du ProfilDiplômé(e) d'une École d'Ingénieur / Master Bac+5 en informatique, vous avez une expérience significative en Data engineering / Data Science.Vous avez 5 ans d'expérience minimum sur des projets en Data.CompétencesDataTBBAgilitéAssurancesCommunication
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer H/F,Devoteam Revolve,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-devoteam-revolve-3806790070?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=OXN3O1KwtZfFYKG30codmw%3D%3D&position=7&pageNum=5&trk=public_jobs_jserp-result_search-card,"About the jobEn constant mouvement, nous gravitons dans des écosystèmes hyper technologiques toujours en évolution.Notre projet concrétise les réflexions sur le sens que nous souhaitons donner à la technologie et notre volonté de lutter contre les raccourcis intellectuels et de proposer des alternatives.Et pour cela, nous avons besoin de vous !Si vous êtes intéressé·e d’intégrer une équipe qui challenge ses pratiques et révèle les singularités de chaque membre de notre collectif, alors cette annonce est faite pour vous !PROFIL RECHERCHÉ :Envie de rejoindre une équipe de “builders” qui travaillent sur de vrais projets de Data en production et à l’échelle ? Vous êtes au bon endroit !Vous avez au moins 2 ans d’expérience sur des problématiques de data engineering (construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données…) dans un context agileVous disposez de solides connaissances sur les architectures de données et les environnements cloud (GCP, Azure, AWS…)Vous disposez d’une expérience en visualisation de données (PowerBI, Tableau, QlikView, D3.js…)Vous maîtrisez au moins un langage de programmation spécifique (Spark, Scala, Python, Java, SQL)Vous maîtrisez des systèmes d’exploitation (UNIX, Linux, Solaris ) avec une expertise dans le stockage de données et les outils ETL.Vous avez une bonne culture DevOps, une bonne communication opérationnelle et une forte capacité d’adaptation.Vous êtes conscient·e de la valeur que peut apporter l'automatisation.Vous êtes convaincue par la culture Data, Cloud, tech et souhaitez affirmer vos convictions.Vous cultivez votre savoir faire, et cherchez constamment de meilleures manières de faire et votre volonté de la partager avec les autres n’a pas de limite.L’organisation, la rigueur, l’autonomie font partie de vos qualités tout comme l’écoute et le partage.Vous maîtrisez également l’anglais à l’oral comme à l’écrit.DESCRIPTIFVoici une liste non exhaustive de vos missions au quotidien, nous vous faisons confiance pour les prendre en main et les enrichir à votre façon :Participer à des projets Cloud AWS (EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB, etc.) ou autres solutions hébergées sur une architecture AWS (Snowflake, Databricks, etc.)Développer et automatiser des pipelines d’ingestion de données avec des layers de traitement dans les technologies adéquates ( Python,, Spark, Kafka)Industrialiser des algorithmes de Data ScienceConcevoir des schémas de données extensibles et génériques pour répondre à des besoins de reporting ou autre (SQL)Développer des applications custom sur la base de composants génériques existants pour répondre à des besoins client (scénarisation, suivi d'entraînement de modèles prédictifs et d’IA, reporting, etc.Encadrer et superviser les consultant(es) juniors i.e., peer code review, application des best practices.Accompagner notre équipe commerciale sur la rédaction de propositions et des réunions d’avant-vente.Participer au développement de notre communauté interne (REX, workshops, articles, hackerspace.Participer au recrutement de nos futurs talents.Compétences techniques requises :La liste des technos sur lesquelles vous seriez amené à travailler est la suivante :Python, PySpark ou Scala Spark. Scikit-learn, MLlib, Tensorflow, Keras, PyTorch ,LightGBM, XGBoost, Scikit-Learn et Spark (pour ne citer qu’eux)Les architectures Data et les environnements Hadoop, ElasticSearch, Kafka notamment.La stack AWS Big Data (Step Function, Lambda, ECR, S3, EC2, Code Build, Glue, outils d’automatisation et Devops, EMR, Redshift, Athena)Mise en place des environnements DevOps et Infra As CodeUne bonne partie des outils Git, GitLab CI, Jenkins, Ansible, Terraform, Docker, Kubernetes, ML Flow, Airflow ou leurs équivalents dans les environnements Cloud.BON A SAVOIR :Revolve training est notre centre de formation permettant à toutes et tous de pouvoir suivre des formations et monter en compétence.Les Revolvers peuvent, au-delà de leurs missions, contribuer à Gravity, notre centre de recherche contributive qui explore les sujets liés à la sobriété numérique, l’éthique de la technologie, la souveraineté numérique, le machine learning au service de l’écologie, ou tout autre projet susceptible de faire progresser la communauté et ses pratiques.Flexibilité : Le télétravail fait partie du quotidien des collaboratrices et collaborateurs.Une mutuelle attractiveLa possibilité de choisir son matériel (mac, windows, linux, smartphone…).Une participation annuelle aux frais de transportsUne carte ticket restaurantOffre exclusive MeyclubCe qui fait la différence chez Devoteam Revolve, c'est notre façon de :Partager ouvertement, largement et délibérément les informations.Encourager les prises de décision autonomes de la part des collaborateurs et collaboratrices.Ne collaborer sur le long terme qu'avec des collaborateurs et collaboratrices hautement compétent·es et ayant un impact positif sur le collectif.Toujours rechercher une ""meilleure façon"" de faire les choses.Être ouvert·e d'esprit aux idées changeantes et aux approches nouvelles.Devoteam Revolve s’engage à promouvoir la diversité et est fier de favoriser l’égalité des chances au sein de l’entreprise. Chaque candidature est considérée sans tenir compte de l’origine, de la couleur de peau, de la religion, du genre, de l’identité de genre, de l’orientation sexuelle, du handicap, des caractéristiques génétiques ou de l’âge.Parce que nous voulons que le savoir soit utile au plus grand nombre, nous croyons à l’inclusion de toutes et tous.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'Keras', 'PyTorch', 'XGBoost', 'LightGBM'], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': ['Linux', 'Windows'], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer (H/F),METEOJOB by CleverConnect,"Nice, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3804860094?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=fpVpBgDE%2F3GV2bLUU30QsQ%3D%3D&position=8&pageNum=5&trk=public_jobs_jserp-result_search-card,"EntrepriseAdsearch vous propose des milliers d''opportunités de carrières dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Intérim et Freelance sur notre site internet !Description Du PosteEn bref : Nice- CDI - Data Engineer Talend (F/H) - Salaire selon expérience - TélétravailAdsearch, cabinet de recrutement basé à Nice vous accompagne dans votre carrière pour vous trouver LE poste idéal.Je recrute pour un client un Data Engineer Talend (F/H) basé à Nice.Vos MissionsCadre du besoin Implémentation des solutions BI - TalendRédaction des spécifications techniques et fonctionnellesModélisation des systèmes décisionnelsOptimisation et monitoringDescription Du ProfilVotre profil ;Vous êtes idéalement titulaire d'un Bac+5 dans l'informatique Vous avez une première expérience sur un poste similaire Talend n'a plus de secret pour vous ? Ce Que L'on Vous ProposeDes sujets challengeant Une super TeamLe Processus De RecrutementEtape 1 : Entretien de sélection avec Adsearch pour définir vos objectifs de carrière et votre correspondance avec le posteEtape 2 : Entretien technique avec le clientEt c'est tout ! Pas d'entretien inutile, nous allons directement au but.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,Micropole,"Villeurbanne, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-micropole-3789104218?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=5kGYknX61p3tNBJZkR%2FMXg%3D%3D&position=9&pageNum=5&trk=public_jobs_jserp-result_search-card,"Rejoignez le Groupe Micropole. Devenez un(e) #InnovativePeople ! Mission En RésuméPoste : Data Engineer F/H Secteur de l'entreprise : experts conseil dans les secteurs de la banque-assurance, le luxe-retail et l’IndustrieLocalité : LyonType de contrat : CDI Niveau d’expérience : au moins 3 ansVous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data driven et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/ services.Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !En Tant Que Data EngineerVous rejoignez notre entité Data Analytics basée à Lyon, où vous interviendrez sur l’intégralité de plusieurs projets avec une vision « Data 360° », mêlant Conseil, Architecture, Intégration et Data Science. En tant que Data Engineer, vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance. Vous serez rattaché(e) à l’équipe Data Analytics, composée de 50 #InnovativePeople.Dans Vos Missions Quotidiennes, Vous Serez AmenésA comprendre le besoin de nos clients au travers de missions de type : aide aux choix d’outils, cadrage des besoins, Proof Of Concept ;Accompagner les équipes commerciales sur des rendez-vous client et en phase d’avant-vente ;Recueillir et analyser les besoins et proposer une architecture technique adaptée aux cas d’usage des clients ;A réaliser nos projets de construction de Data Platform au travers des activités : refonte, migration ou développement de tableaux de bord dans le respect des exigences de qualité et sécurité ; Rédiger la documentation des livrables pour rendre les utilisateurs autonomes et les former ;Rédiger la documentation permettant à l'IT d'assurer la maintenance ;Accompagner les consultants moins expérimentés dans leur montée en compétence ;Capitaliser et partager les bonnes pratiques, connaissances et retours d’expérience ; Profil Vos Compétences TechniquesVous avez un minimum de 3 années d’expérience sur des projets Data sur les outils ETL (Talend, SQL Server) et Reporting (Power BI, Tableau Software).Idéalement au moins une première expérience sur des projets Cloud AWS ou Azure Vous maîtrisez au minimum un langage de programmation (Python, Spark, Scala, R) ; Vous avez une maitrise des théories et outils de modélisation de données, Vous maitrisez des concepts d’industrialisation, Ia C, CI/CD et/ou gestion de version, Vos AtoutsVéritable coéquipier, vous avez à cœur de contribuer à la montée en compétence de votre équipe,Vous recherchez la variété et l’excellence dans votre travail. Autonome et impliqué(e), vous avez le goût du challenge,Doté(e) d’un excellent relationnel et du sens du service, vous avez la capacité de gérer une relation client,Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud et des solutions DataEnfin, vous disposez d’un bon niveau de français et d’anglais, à l’oral comme à l’écrit.Devenir #INNOVATIVE PEOPLE C’est :Intégrer une communauté de 1100 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine.Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale.Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP.Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus.S’assurer d’une innovation continue grâce : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients ; anagement par les talents naturels (regarder le mot de la DRH)Processus De RecrutementChez Micropole, le processus de recrutement est réactif et transparent.Etape 1 – Si votre profil correspond à nos besoins, vous êtes recontactés dans les 72 heures qui suivent votre candidature par Justine ou Nathan nos Talent Specialist dédiés à l'agence de Lyon pour une qualification téléphonique ;Etape 2 - Un premier entretien est programmé avec Justine ou Nathan en physique ou visio ;Etape 3 – Vous rencontrez Matthieu, un manager technique avec l’un de nos experts Data AnalyticsEn fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique)LA VIE CHEZ MICROPOLE, C’estUne vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ;Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ;Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ;Participation à des projets internes sur la base du volontariat.À PROPOS DU GROUPE MICROPOLEGroupe international de conseil et technologies innovantes, MICROPOLE est spécialisé dans les domaines de la Data & Digital. Depuis ses 14 agences situées en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts métiers, ingénieurs, UX designers…) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil à leur réalisation, et sur la conduite du changement.MICROPOLE réalise 35% de son chiffre d’affaires à l’international et est coté sur le marché Eurolist compartiment C d’Euronext Paris, segment Next Economy.Pour en savoir plus :  https://www.linkedin.com/company/micropoleA PROPOS DE L'AGENCE MICROPOLE LYON L’agence Micropole Lyon s’appuie sur son implantation stratégique et son expertise technique pour porter et accompagner les ambitions de croissance du groupe Micropole. Sous l’impulsion de notre Directrice d’Agence, Armelle Descaillot, nous souhaitons créer une synergie entre la data et le digital afin d’apporter une réelle valeur ajoutée à nos clients et les accompagner sur les défis technologiques de demain.Les marques fortes du groupe telles que Wide (agence digitale intégrée au groupe Micropole) et Lucy in the Cloud (entité conseil du groupe Micropole dédiée à AWS) nous soutiennent et nous permettent de nous positionner comme acteur conseil de référence dans la région Centre-Est.Véritable agence à taille humaine où règnent esprit d’équipe et convivialité, nos talents allient savoir-faire et expertise pour répondre aux besoins de transformation des entreprises.Mot du Manager En rejoignant notre agence Lyonnaise, vous bénéficiez de la puissance d’un groupe pionnier des grandes innovations data et digitales tout en intégrant une équipe dynamique, bienveillante et à taille humaine dont les valeurs de partage, le sens du service et de la convivialité sont les maîtres mots. Qu’attendez-vous ?


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage - Data Engineer,Exotec,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-at-exotec-3764789933?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=xWF7OLR%2F73JXdpXS%2FcXHZw%3D%3D&position=10&pageNum=5&trk=public_jobs_jserp-result_search-card,"Chez Exotec, nous mettons l'excellence technologique au service de la redéfinition des relations entre humains et robots. A travers le monde, nos solutions révolutionnent la façon dont nos clients délivrent leurs produits aux consommateurs finaux. Nous contribuons au succès des plus grandes marques du commerce et de l'industrie, tout en améliorant les conditions de travail de leurs salariés.Par l'alliance de l'intelligence artificielle et d'un hardware performant, nos robots sont désormais déployés dans le monde entier et leur succès a fait de nous la première licorne industrielle française.Rejoindre Exotec, c'est l'opportunité de donner du sens à vos compétences. Grandissez avec plus de 800 ExoPeople dans le monde entier pour faire de vos idées des réalités.La révolution robotique portée par Exotec ne fait que commencer, vous en êtes ?Au sein du pôle Data, de la DSI d'Exotec, votre rôle sera de participer au développement de l'environnement et de l'infrastructure Data d'Exotec.Pour cela :Vous participez à la mise en œuvre des composants techniques de la plateforme de données d'ExotecVous travaillez sur la collecte dans la plateforme de données provenant de sources multiples : Salesforce, ERP, logiciels développés en interneVous nettoyez, mettez en qualité et préparez les données afin de les rendre disponibles pour les différents cas d'usage qui en ont besoinVous migrez des reportings existants vers la plateforme de données et mettez en œuvre de nouveaux cas d'usage pour répondre aux besoins de l'entrepriseVous travaillerez au sein de l'équipe data et en étroite collaboration avec la software factory, ainsi qu'avec les utilisateurs des métiers qui ont besoin de rendre intelligibles les données disponiblesRequirementsVous êtes étudiant(e) d'une école d'Ingénieur généraliste avec une spécialisation programmation ou informatiqueVous recherchez un stage de fin d'études d'une durée de 4 à 6 moisVous avez idéalement une première expérience en Data Engineering et le développement de pipeline de donnéesVous maitrisez Python, l'ETL et SQL,Curieux(se) et rigoureux(se), vous souhaitez rejoindre une équipe jeune et dynamique ainsi que vous investir dans des projets complexes et excitantsVous avez un niveau d'anglais courantChez Exotec, nous garantissons l'égalité des chances dans notre processus de recrutement. L'ensemble des candidatures reçues sont étudiées indépendamment de l'âge, du genre, de l'origine, de la religion, de la couleur de peau, de la nationalité, du sexe, du handicap, de l'orientation sexuelle ou de toute autre distinction protégée par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les différences. En rejoignant le Pacte Parité, Exotec s'engage pour un écosystème French Tech plus paritaire.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F (CDI ou Freelance),ATAWIZ,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-cdi-ou-freelance-at-atawiz-3807732290?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=EFQ0jRApwNKBUDDtFKiL6g%3D%3D&position=11&pageNum=5&trk=public_jobs_jserp-result_search-card,"Pour la petite histoire, Atawiz a été créé en 2016, pour devenir le cabinet d’expertise que l’on connaît aujourd’hui. Nous sommes Microsoft Solutions Partner dans plusieurs domaines de compétences et partenaire Databricks. Les domaines d’expertise d’Atawiz s’adaptent aux nouveaux enjeux des entreprises : Time to Market, agilité, data, digitalisation des processus, …Nos consultant·e·s combinent ainsi agilité, approche DevOps pour soutenir nos clients dans la réalisation de leurs objectifs, et ce, depuis 2016 !Au-delà d’un groupe d’expert·e·s, nous sommes des passionné·e·s qui collaborent dans différents domaines d’expertise :Le Cloud, spécialement AzureDevOpsLe Big DataLe développement d’application mobile et webLes architectures micro-servicesAlimenté·e par une forte culture d’entreprise, notre objectif est d’assurer la satisfaction de nos consultant·e·s autant que de celle de nos clients. Pour cela, nous sélectionnons avec attention nos projets pour que chacun de nos collaborateur·rice·s se sentent stimulé(e)s et progressent rapidement.📇 Descriptif du posteNous avons de fortes demandes client et par conséquent besoin de renforcer notre équipe.L’aventure Atawiz, c’est aussi intégrer une communauté d’une vingtaine d’expert·e·s tous passionné·e·s. À leurs côtés, tu pourras évoluer rapidement et développer de nouvelles compétences.🎯Mission proposée (longue durée), en régie chez notre client, grande entreprise du secteur de l’énergie (petite couronne – proche Paris) :Freelance accepté.En tant que Data Engineer H/F, tu seras rattaché(e) au Responsable Data.💡 Enjeux du PosteAssurer le lead technique sur l’ingestion, le chargement et la transformation des données dans la data plaform (Datalake, Datawarehouse)Modéliser et implémenter les différents flux de donnéesParticiper à l’urbanisation de l’architecture de la plateforme avec le Tech Lead👩‍💻 La répartition des tâches :Pipelines de données :Mise en place et optimisation des processus.Référent technique pour l'ingestion, le loading et la transformation de données.Définition technique du modèle de données.Développement :Préparation des environnements techniques.Développement sur les assets selon les normes.Collaboration avec le support de la plateforme pour des expos en API.Ingénierie de données :Compétences en modélisation et création de scripts.Réflexions sur l'échelle, la disponibilité et l'optimisation des opérations.💻 Stack technique sur le projet :Cloud : AWS (idéalement) ou AzureDEV : Python, API, Git, Docker,DevOps (Terraform, CI/CD),DATA (SQL, NoSQL, DBT), BIGDATA (HDFS, SPARK).Data Science (MLOPS),Notions : Scalabilité, Clustering, Data Mesh, Data Virt, Data Qualité, Analytique (Tableau, Dataiku).✨ Avantages de la mission :En acceptant cette mission, tu bénéficieras d’un environnement de travail motivant et coopératif, où tu auras l’occasion de t’impliquer dans des projets diversifiés et challengeants.De plus, vous aurez des possibilités d’évolution de carrière.🔎 Profil recherché :Passionné(e) de nouvelles technologies et proactif(ve), tu excelles en équipe dans un environnement dynamique. Ton engagement envers les meilleures pratiques et tes compétences en communication font de toi la personne idéale pour cette mission.Tu as minimum 5 ans d’expériences, une solide expérience dans le domaine du data engineering en environnement cloud.Une expérience sur le cloud AWS ou équivalent (Azure, GCP) est un plus.Ton esprit d'équipe, ta pro activité font de toi un(e) candidat(e) idéal(e) pour renforcer l’équipe. Rejoins-nous ! 🌟Avant d’être en mission chez le client, tu es avant tout un(e) salarié(e) d’Atawiz 😊✨ La vie interne chez Atawiz:Chez Atawiz, les opportunités sont nombreuses, nous valorisons ton expertise et ton savoir-faire. Tu auras la possibilité de :✅ Développer tes compétences et pour ça, tu bénéficieras d'une formation approfondie, de coaching managérial et technique, et d'un accompagnement pour obtenir des certifications. 📚✅ Participer activement à la vie interne de l'entreprise, en partageant tes connaissances et ton expertise au travers d'articles techniques publiés sur notre blog et à notre page LinkedIn.👉 notre blog : https://blog.atawiz.fr/👉 page LinkedIn : https://www.linkedin.com/company/atawiz/✅ Suivre en mission et être garant de l’évolution de carrière de consultants juniors.✅ Participer au process de recrutement, pour tester techniquement les candidats ou proposer des cooptations de personnes de ton réseau.✅ Profiter d'avantages attractifs, tels que des événements Microsoft, des bootcamps et des workshops & tech coffees réguliers, un matériel performant, et bien plus encore ! 🎉Benefits:Salaire fixe entre 60k € et 65k € en fonction du profil pour un CDI Pour Freelance TJM entre 600 et 650 € / jourStatut cadreRTTTitre de transport pris en charge à 100%Mutuelle Alan pris en charge à 60 %La prévoyance prise en charge à 100 %7 € de panier repas par jour travaillé2 jours de Télétravail /semaineBudget télétravailDe beaux locaux à Paris 9e, proche de la gare Saint-LazareRejoins-nous dès maintenant dans nos bureaux situés en plein cœur de Paris 💼 pour faire partie d'une équipe de passionnés, relever de nouveaux défis et booster ta carrière. 🚀Intéressé(e) ? Postule dès à présent et découvre notre processus de recrutement interactif. Tu auras l'occasion de rencontrer notre équipe, d'échanger avec nos expert·e·s techniques, et même de discuter avec notre CEO et notre Sales Director.🤝 Notre processus de recrutement :1 - Postulez en ligne ! L’équipe Recrutement étudie avec attention ta candidature et te répond dans les plus brefs délais.2 - Premier échange ! Tu échanges avec notre Talent Acquisition Manager sur ton parcours, tes aspirations professionnelles ainsi que sur Atawiz et les opportunités que nous proposons.3 - Un entretien technique avec l’un·e de nos expert·e·s pour te challenger techniquement. C’est également l’occasion pour toi d’avoir son retour d’expérience.4 - Dernier entretien : pour finir, tu rencontreras notre CEO. Tu pourras par ailleurs échanger avec notre Sales Director.Pendant tout le processus de recrutement, tu as la possibilité de participer à des événements organisés par Atawiz et d’échanger avec des collaborateurs afin d’en apprendre plus sur nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Stage - Data Engineer,Numberly,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-at-numberly-1000mercis-group-3800212725?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=Yi9RV2nuIE84TDXJ9oxlrQ%3D%3D&position=12&pageNum=5&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseNumberly est reconnu comme l’un des meilleurs spécialistes mondiaux du Data Marketing avec près de 500 collaborateurs et 8 bureaux dans le monde au service de clients de premier plan (LVMH, BNP Paribas, Hill’s, Beneteau, L'Oréal, Ipsen, Ouigo, Maje, HSBC...).En mettant la technologie au service des marques et des consommateurs, Numberly est au cœur de la croissance des entreprises et de l’aspiration de chacun à un marketing plus responsable et plus pertinent. Numberly s’appuie sur les avancées les plus récentes en matière de traitement, d’analyse et d’activation media et CRM des données, dans un contexte vertueux alliant compétitivité des entreprises et respect renforcé de la vie privée et de la protection des données.Nous analysons des sets de données comportementales, personnelles, contextuelles et transactionnelles, dans tous les environnements technologiques existants, et les articulons avec les enjeux business et digitaux de nos clients.Nous construisons chaque jour des stratégies data et marketing digital qui améliorent la pertinence et l’impact des interactions de nos clients avec leurs audiences, en alimentant nos recommandations stratégiques avec toute l’expertise technologique, data, et opérationnelle du groupe.Description du posteNumberly recherche un(e) Data Engineer en stage pour rejoindre son équipe dédiée aux problématiques Data. Vous participerez aux traitements, transformations et restitutions des données auprès des équipes internes afin d’améliorer les performances des campagnes et des stratégies marketing de nos clients.Vous :Aimez la donnée sous toutes ses formes : brute, travaillée et analysée ;Avez le désir de la comprendre et de la faire parler ;Possédez une formation axée sur la big data, la fouille de données ou plus généralement en software engineering;Appréciez le travail bien fait, avez le sens du détail et vous aimez comprendre les problématiques de vos clients ;Aspirez à travailler pour des clients variés et prestigieux sur des problématiques pointues ;Êtes à l’affût des nouveaux langages/technologies et des dernières tendances open source;Êtes spontané(e) et appréciez le travail en équipe en collaborant avec différents métiers de la data;Portez de l'intérêt au Marketing et souhaitez découvrir ce domaine.Stage de 6 mois débutant en février 2024.Rémunération : 1400 € brut mensuel en M1 et 1700 € brut mensuel en M2.QualificationsVous connaissez :ModélisationSQLPythonETLEncore mieux si vous connaissez :Workflows management platformsEnvironnement HadoopSystèmes et calculs distribuésAPI REST, Web ServicesRealtime / StreamingDockerCe que nous utilisons :UbuntuSuite Microsoft (SSMS, SSIS, SSRS, Power BI)HdfsSpark / HiveGit / CICDAirflowKafkaKubernetesInformations complémentaires Chez Numberly, nous partageons une passion pour la transmission à nos équipes comme à nos clients : des talks internes hebdomadaires, des rencontres avec des professionnels experts dans leur domaine, un apprentissage permanent.Un onboarding rapide et puissant, notamment grâce aux Vis ma vie dans des équipes différentes ; aux Happy Meetings (des rendez-vous mensuels internes pour se retrouver avec toutes nos équipes dans le monde et partager l’actualité du groupe).Nous cultivons la liberté de parole qui permet à tous de participer au développement du groupe.Nous agissons positivement sur notre écosystème à travers 1000mercis impacts et via nos activités qui créent de la valeur dans l’Open Internet et participent à l’enrichissement de l’Open Source : https://github.com/numberlyNumberly est acteur de la diversité et Gender Equal by design (certification WeConnect International et gender equity score de 97/100).Numberly propose un environnement international avec plus de 30 nationalités.Des bureaux à l’image de chacune des équipes, une bibliothèque généreuse, un grand studio de musique tout équipé, deux chats, du tri sélectif et du lombricompostage, la possibilité de venir avec votre animal de compagnie et de la place pour les vélos ! Dans chaque cuisine : café, thé, infusions à volonté et aussi des mystery lunchs.Un abonnement Gymlib, des cours de sport et des soirées (souvent déguisées).Pour ceux qui en auraient besoin, possibilité de travailler en remote pendant la période des Jeux Olympiques.Carte Swile (titres-restaurants).Numberly accueille les personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer (H/F),Extia,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3627654825?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=kaSFdbhd%2By4s1xdiHx8BYA%3D%3D&position=13&pageNum=5&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l’humain au cœur de ses préoccupations ? On vous attend chez Extia !Société de conseil spécialisée dans les métiers de l’IT, de l’ingénierie et du digital, Extia privilégie depuis sa création en 2007 une approche qui allie performance et bien-être au travail. Une vision de l’entreprise partagée aujourd’hui par plus de 2 500 Extiens en France et à l'international et récompensée depuis 2012 par le label Great Place to Work®.Chez Extia, c’est « D’abord qui, ensuite quoi » alors, allons-y !D'abord quiVous êtes habitué à travailler aussi bien avec des méta-données qu’avec des données non-structurées. A cet effet vous maitrisez un ou plusieurs des concepts comme l’ETL, le Data mining le Machine learning, les Big data ou encore la Théorie des graphes par exemple,Vous maitrisez les bases de l’analyse statistique,Vous êtes apte à rédiger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,Vous êtes familiarisé avec l’environnement Linux,Une expérience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps réel seront aussi de réels atouts.Ensuite quoiVous serez en charge de :Participer à la définition des besoins et à la rédaction des User Stories,Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,Concevoir et construire des architectures de données,Intégrer des sources de données,Vous assurez que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Ops Data Engineer,Anywr,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/cloud-ops-data-engineer-at-anywr-3798641032?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=j325C70W6JcUQHgoxerblQ%3D%3D&position=14&pageNum=5&trk=public_jobs_jserp-result_search-card,"Notre client, acteur majeur mondial dans l'industrie, recherche un Cloud Ops Data Engineer pour la création de leur Data Factory. Ce poste est basé à Marcq-en-Barœul. Télétravail 2 jours / semaine.Le Cloud Ops Data Engineer participera à la construction et à la maintenance d'une plateforme de services de données basée sur une approche de maillage de données. Ce poste fera partie de la Data & Tech Factory et sera rattaché au responsable de l'architecture et de l'ingénierie des données. Il/elle sera responsable de la conception, de l'architecture, du développement et de la maintenance de notre plateforme de services de données en mettant l'accent sur l'automatisation, l'infrastructure en tant que code et les pratiques DevOps.Votre quotidien :Concevoir, développer et maintenir une plateforme de services de données qui prend en charge une approche de maillage des données en utilisant les principes de l'infrastructure en tant que code.Collaborer avec les équipes de développement des données pour intégrer les services numériques et de données dans la plateforme.Concevoir et mettre en œuvre des solutions d'automatisation pour la configuration, l'approvisionnement et la surveillance de la plateforme à l'aide d'outils et de pratiques DevOps tels que Ansible, Terraform et GitOps.Mettre en œuvre des pipelines d'intégration et de déploiement continus (CI/CD) pour les services de données.Identifier et résoudre les problèmes de performance de la plateforme à l'aide d'une surveillance et d'alertes automatiséesMettre en place des processus pour surveiller l'état de la plateforme et avertir les équipes de support en cas de dysfonctionnementCollaborer avec les équipes de sécurité informatique pour s'assurer que la plateforme répond aux normes de sécurité et mettre en œuvre les principes de sécurité en tant que code.Créer et maintenir la documentation et les manuels d'exécution pour assurer la résilience de la plateforme et la reprise en cas de défaillance.Profil recherché :Baccalauréat ou maîtrise en informatique, en génie informatique, en science des données ou dans un domaine connexe.Au moins 4 ans d'expérience professionnelle dans un environnement de données distribuées et Cloud native avec un fort accent sur l'automatisation, l'infrastructure en tant que code, et les pratiques DevOps.Bon niveau d'anglais souhaité.Compétences techniques :Connaissance approfondie des architectures de données distribuéesSolide expérience dans la conception et le développement de solutions de données distribuées à grande échelle en utilisant l'infrastructure en tant que code et les principes DevOps.Connaissance approfondie des technologies de données basées sur le cloud (AWS est un plus).Expérience de travail avec des outils de gestion de conteneurs tels que Kubernetes et Docker (EKS, ECS).Connaissance des technologies de stockage de données (Snowflake, NoSQL, S3)Solides compétences en programmation dans un ou plusieurs langages de programmation, dont au moins Python.Expérience de travail avec des bases de données relationnelles et non relationnelles (Postgresql, Cassandra, MongoDB, RDS, DynamoDB).Connaissance des pratiques de sécurité des données et des normes de conformitéSolides compétences en matière de dépannage et de résolution de problèmesCe poste est un CDI chez un client final.Vous intégrerez une entreprise en croissance avec des projets ambitieux.Vous aurez l'occasion d'être force de proposition, de construire votre poste.De plus, l'environnement de travail sera propice à votre bien-être : salle de sport, restaurant d'entreprise, conciergerie, crècheSalaire fixe : 50 - 60K€Salaire variable : 5 à 10% sur objectif personnel + 20% de participation


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Senior Data/SW Engineer | Up to 65k | Paris | IA | ML,Talent-R,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-sw-engineer-up-to-65k-paris-ia-ml-at-talent-r-3797676756?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=AWpZHFQP9qOvSV85ipsGSQ%3D%3D&position=15&pageNum=5&trk=public_jobs_jserp-result_search-card,"📍Localisation: Paris (20ème) & Remote (2 jours sur site / semaine)🔍 Seniorité: Intermédiaire (+3 ans)💰 Salaire : Up to 65K€ fixe + Variable + BSPCEL'entreprise 💼 Startup française de 30 personnes qui propose un produit SASS pour aider les commercants à optimiser leur rentabilité en utilisant l’Intelligence Artificielle et le Machine LearningVotre profil 👉Entre le data engineer et le développeur, vous aimez développer en python et manipuler de la data, vous révez de faire partie d'une entreprise en pleine croissance !Expérience > 3 ans dans un environnement de haut niveauEnglish MandatoryPython (bibliothèques Pandas/Dask)Frameworks : FastAPIBases de données : PostgreSQL (base de données relationnelle)Containers et orchestration : Docker Les plus : Linux, AS3, bash, sparkLes avantages 😍Bureaux en plein de coeur de Paris (20ème)Remote : 3 jours par semaine au début puis féxibilité totale ensuiteSalaire jusqu’à 70k (+variable)BSPCEBien plus à découvrir...Si vous êtes interessé, je vous invite à postuler et à m'envoyer un message si vous avez des questions !Merci de ne pas postuler si vous avez -3 ans d'éxperience professionnelle et si vous n'avez pas cette double compétences Data / Software.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Bash'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Docker'], 'Os': ['Linux'], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Ingénieur Data H/F,LA BOITE IMMO,"Hyères, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-at-la-bo%C3%AEte-immo-3803477031?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=xuZLFuILcOiWWuVAu609qA%3D%3D&position=16&pageNum=5&trk=public_jobs_jserp-result_search-card,"À propos de nousLa Boite Immo - le 1er partenaire des agents immobiliers indépendants partout en France.Depuis 15 ans, nous développons des applications web (logiciels, sites internet, solutions de visites virtuelles...) innovantes et modernes utilisées par plus de 59000 utilisateurs. Pionné dans notre secteur nous sommes constamment en quête d'innovation pour garantir la satisfaction de nos clients.Notre équipe, composée de plus de 200 personnes réparties entre nos sites de Hyères et Paris, travaille ardemment pour stimuler notre croissance. De nouveaux projets naissent constamment, ce qui fait de notre entreprise un lieu d'opportunités et d'évolution continue.Nous recherchons des collaborateurs qui veulent donner un véritable sens à leur travail, intégrer une entreprise où l'aventure humaine est au cœur de ses préoccupations.En 2023, nous avons obtenu le label Happy Index, avec une note de 4,6/5, démontrant l'importance que nous accordons au bien-être de nos employés.Si vous êtes à la recherche d'une mission enrichissante et d'une entreprise qui favorise votre progression, nous vous invitons à découvrir l'opportunité ci-dessous.MissionAu sein de notre service R&D et rattaché(e) au Directeur de l'innovation, vous serez en charge du montage des architectures techniques sur nos données métier et marché.Vos missions si vous les acceptez seront les suivantes :Structurer, modéliser et organiser les données afin de répondre aux différents use-cases métiers : Vous mettez en œuvre les solutions techniques et les pipelines data nécessaires pour modéliser au mieux les données métier et marché de notre sociétéRéaliser les croisements, raffinages et structurations de données pour la construction et le maintien des data marts et et data warehouseParticiper avec l'équipe du data management à la mise en place d'ETLProduire des DataViz pertinentes donnant du sens aux données récoltéesRéaliser des études et des analyses ponctuelles sur des données silotées des différents pôles métiersProfilVous êtes issu(e) d'une formation Bac+5 spécialisé(e) en informatique ou en data engineering et vous justifiez d'une expérience de 5 ans sur un poste similaire.Vous êtes désireux de relever des défis multiples autour de l'architecture de données dans un contexte technologique riche et innovant.Pour réussir à ce poste, nous recherchons les compétences suivantes :Connaissances confirmées sur Azur, Python, Power Bi, Talend ETLExpérience significative dans la modélisation de données, des entrepôts de données et des processus ETLDes notions en PHP et S3 seront fortement appréciéesExcellentes compétences en communication et capacité à expliquer des concepts techniques complexes à des parties prenantes non techniquesEn nous rejoignant, voici concrètement ce que nous vous proposons : Une rémunération fixe comprise entre 40k€ et 50k€/an en fonction de votre expérienceUn contrat de 35h sur 4.5 joursUne prime de participationUne formation et une intégration qui vous permettront de réussirDes séminaires de dingue! des apéros, des soirées guinguettes, de la pétanque, du miel de nos abeilles, des fruits de producteurs locaux, la salle de sport ton allié pendant la saison des raclettes et tartiflettes.. etcLes inévitables tickets restaurants, mutuelle, CE..Terminé les process de recrutement à rallonge, nous proposons des échanges simples et efficaces :A réception de votre CV, Charlyne notre chargée de recrutement prendra contact avec vous pour discuter de votre projetVous êtes retenu(e) ? Un premier entretien visio avec Jull, Directeur du pole R&D est organiséL'échange est positif ? Un deuxième et dernier entretien vous est proposé dans nos locaux afin de rencontrer Arnaud DSI de la Boite Immo et Carine Responsable RHvous avez un retour rapide qu'il soit positif ou négatif dans les jours qui suivent l'entretien !Référence de l'offre : cdrwvujz9m
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Data Engineer (H/F),Believe,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-believe-3773594947?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=RXlw7c4uFupf9rhoAZSrHA%3D%3D&position=17&pageNum=5&trk=public_jobs_jserp-result_search-card,"Company DescriptionBelieve est l'un des leaders mondiaux du marché de la musique numérique. Believe a pour mission d’accompagner les artistes et les labels locaux dans l’écosystème digital en leur offrant des solutions à chaque étape de leur carrière et développementCe sont plus de 1700 salariés dans 50 pays qui accompagnent artistes avec expertise, respect, équité et transparence.Afin de soutenir notre forte croissance sur tous les continents, nous sommes constamment à l’affût de nouveaux Believers. Rejoignez-nous afin qu’ensemble, nous ayons un impact fort et plus positif sur l’industrie musicale !Believe est cotée sur le compartiment A du marché réglementé d’Euronext Paris (Ticker : BLV, ISIN : FR0014003FE9).www.believe.comReady to #setthetone with Believe?Job DescriptionContexte Le Tribe « Customer Finance » est composé de plusieurs Squad, parmi elles la squad Finance Ingestion qui a pour mission de développer des outils et des applications pour la collecte de royalties auprès des plateformes de streaming de musique ainsi que préparer les données afin de faire la distribution des royalties auprès des producteurs de musiques.En tant que Data Engineer, tu intégras une équipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette équipe est composée essentiellement de 5 Data Engineer et 1 Software Engineer. Nous avons un écosystème qui se composeune socle de gestion des données (Delta Lake) plus d’1.5 milliard de lignes /mois data engineering avec du Scala Spark utilisant le runtime de Databricks orchestration de nos data pipelines avec Airflow managé des APIs avec les Lambda AWS pour faire interagir les utilisateurs avec notre interface front (PHP) RDS pour hoster la base de données back-end sous PostgreSQL versionning du code sous GitLab avec un environnement de dev, staging et production infrastructures sous AWS Les missions du Data Engineer au sein de l’équipe :           Interagir avec le Product Owner, le métier pour comprendre les besoins          Interagir avec l’architecte, les équipes infrastructures et Cloud pour concevoir les solutions de data engineering          Développer des flux de données (data pipelines) avec du Apache Spark et du Scala          Faire de l’orchestration via Airflow avec du Python          Maintenir et améliorer les modules existants de l’application          Utiliser GitLab pour tester, builder et déployer son code sur les différents environnements          Effectuer des revues de codes des autres membres de l’équipe          Interagir avec les membres de l’équipe pour atteindre l’objectif du sprint          Faire du support applicatif et fonctionnel de l’application auprès des opérationnelQualificationsQualifications du Data Engineer  3-5 ans d’expérience dans la pratique de développement sous Scala une très bonne maitrise du framework Spark avec du Scala, nous ne faisons pas de PySpark une bonne maitrise de conception et développement des data pipelines Développer avec un état d’esprit Keep it Simple, Stupid (KISS) une bonne maitrise d’un outil de versionning de code tel que Gitlab une bonne maitrise des APIs avec du Lambda une expérience dans l’écosystème AWSAdditional InformationSet the tone with us Chez Believe, nous avons deux cœurs : nos collaborateurs et nos artistes.Nous croyons en la force de nos collaborateurs, qui s'épanouissent chaque jour en développant leur potentiel... Notre objectif est d'offrir à nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'épanouir.Rock the jobProgramme de formation et de coaching sur mesureUne politique de télétravailUn programme de bien-être ""Pauses"" avec de nombreuses activités et animations en interneAccès à Eutelmed, la plateforme numérique de santé mentale et de bien-être qui permet de parler à un psychologue expérimentéUn restaurant d'entreprise sain et éco-responsableUne assurance santé individuelle ou familialeAvantages CEUn rooftopUne salle de sport avec des cours gratuitsSing in harmonyDes groupes d'ambassadeurs pour s'engager sur la réduction de l'empreinte carbone et environnementale de Believe et l’équité professionnelle Femme/Homme.Mise en place du Forfait mobilité durable: remboursement jusqu’à 600€ des frais de transport en commun/avec une faible empreinte carbone.Congé 2nd parent de 5 jours calendaires rémunérés à 100% (en plus du congé légal paternité ou du congé d’adoption, nous ne l’attribuons pas au congé maternité)Believe s’engage à garantir l’égalité des chances en matière d’emploi, sans tenir compte de l’origine, du sexe, des mœurs, de l’orientation sexuelle, du genre, de l’âge, de la situation de famille, de l’état de grossesse, d’une prétendue race, des opinions politiques, des activités syndicales, des convictions religieuses, de l’apparence physique, du nom de famille, du lieu de résidence, de l’état de santé, ou en situation de handicap.Découvrez nos nouveaux locaux : bit.ly/believeoffice
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),METEOJOB by CleverConnect,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3805816901?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=JtSgG7DyhkyMe9nAiKb%2F0Q%3D%3D&position=18&pageNum=5&trk=public_jobs_jserp-result_search-card,"EntrepriseChez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L'intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d'une centaine de disciplines, de l'optique à la physique quantique, du traitement du signal à la connectivité et à l'intelligence artificielle. Rejoindre Thales, c'est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C'est donc être au cœur d'une formidable aventure technique. Une attention portée à l'équilibre des collaborateurs au service de leur réussite. C'est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d'accorder la flexibilité nécessaire à l'équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C'est aussi la possibilité d'évoluer, de changer de fonction ou d'activité, voire de pays.Description Du PosteQUI SOMMES-NOUS ?Thales propose des systèmes d'information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d'importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d'information critiques et cybersécurité, répondent aux besoins de marchés où l'utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l'activité Systèmes d'information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d'information afin de faire face aux ruptures technologiques et aux cybermenaces.QUI ETES-VOUS ?Intégré(e) au centre de compétences « Augmented Data » de Brest, vous interviendrez sur des projets de développement de systèmes d'information « Data oriented ».Au sein de ce centre, vous rejoindrez nos Data Engineers, Data Architects et Data Scientists.De formation Ingénieur ou Bac +5, Ecole d'ingénieur ou Université vous justifiez d'une expérience professionnelle en mise en place de solutions Big Data d'au moins 2 ans et idéalement d'une première expérience réussie en animation d'équipe et/ou pilotage de lots techniques.CompétencesPlusieurs des affirmations suivantes vous caractérisent : Vous êtes passionné(e) par le Digital, les données, les enjeux qu'elles représentent et les technologies Big Data avec lesquelles les manipuler (Hadoop, Nifi, Kafka, ElasticSearch, Spark, Storm, HBase, Cassandra, etc.). Vous êtes familiarisé(e) avec les différentes plateformes et outils qui y sont reliés. Vous savez et aimez coder avec des langages de programmation communément utilisés pour la manipulation de données (Python, Java, SQL) sur des architectures distribuées en production. Vous savez implémenter des chaînes de traitement optimisées. Vous êtes familiarisé(e) avec les concepts et technologies d'intégration continue (Git) et les outils de déploiement (Docker). Vous êtes familiarisé(e) avec les frameworks Agile tels que Scrum ou Kanban. Vous êtes motivé(e), appliqué(e), organisé(e) et curieux(se) dans votre travail au quotidien. Vous êtes titulaire d'un diplôme d'ingénieur ou Master, idéalement avec une spécialisation sur les métiers de la donnée et du Big Data. Vous parlez français et, idéalement, anglais (écrit et oral)Ce Que Nous Pouvons Faire EnsembleEn tant que Data Engineer, vos missions seront les suivantes : Comprendre les besoins et les enjeux du client autour de ses données. Concevoir des solutions innovantes de traitement de données répondant aux besoins, implémenter des chaînes de traitements Big Data et les déployer à l'échelle dans des environnements de production. Contribuer à la définition d'architecture de données et à l'opérationnalisation de plateformes de données. Présenter vos propositions de conception et résultats auprès du client et de votre équipe. Partager et échanger vos connaissances et expériences dans le Data Engineering avec votre équipe. Contribuer à la préparation et à l'animation d'ateliers avec les interlocuteurs requis. Effectuer un reporting régulier à votre manager sur l'avancement de vos activités ainsi que sur les risques potentiels identifiés.Nous Vous Offrons Une diversité de projets vous permettant de découvrir plusieurs environnements techniques et fonctionnels ainsi que l'ensemble de nos métiers au sein du groupe Thales, Des conditions de travail motivantes et un plan de carrière personnalisé offrant de réelles perspectives d'évolution, La possibilité de vous investir dans une entreprise dont la réputation est mondiale avec des ambitions constantes d'innovations techniques, Un cadre de travail privilégié dans des bureaux situés à un endroit dynamique du port de commerce de Brest, La possibilité de télé-travailler jusqu'à 10 jours par mois.Alors n'attendez plus, rejoignez-nous !Thales reconnaît tous les talents : la diversité est notre meilleur atout.Le poste pouvant nécessiter d'accéder à des informations relevant du secret de la défense nationale, la personne retenue fera l'objet d'une procédure d'habilitation, conformément aux dispositions des articles R.2311-1 et suivants du Code de la défense et de l'IGI 1300 SGDSN/PSE du 09 août 2021.Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd'hui.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer R&D (M/F),Atos,"Échirolles, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-r-d-m-f-at-atos-3765788780?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=9wTDUoWPWzdGez20p%2B4q%2Fg%3D%3D&position=19&pageNum=5&trk=public_jobs_jserp-result_search-card,"Eviden is an Atos Group business with an annual revenue of circa € 5 billion and a global leader in data-driven, trusted and sustainable digital transformation. As a next generation digital business with worldwide leading positions in digital, cloud, data, advanced computing and security, it brings deep expertise for all industries in more than 47 countries. By uniting unique high-end technologies across the full digital continuum with 55,000 world-class talents, Eviden expands the possibilities of data and technology, now and for generations to come.Our team is building Eviden CVP (https //atos.net/fr/solutions/bullsequana-edge-fr/atos-computer-vision-platform) , a real-time video analytics platform for different verticals (security, retail, …). We use AI technologies to design and develop the product, as well as Big Data software components to manage the related data. We currently recruit in our European AI lab in Grenoble a data engineer to complete our team on data governance, end-to-end data pipeline implementation and datalake operation.Key Responsibilities Contribute to data / model governance policies definition and implementation. Set up and develop our computer vision data management platform (implement full data pipeline including data collection, data proliferation, meta-data extraction leveraging AI models, integrate 3rd party tools such as labeling framework, …) Operate the data platform Follow our internal quality & security standards for code development. Automatize everything (devops, mlops). Work with an international team.Required Skills MS in data science or computer science. Experience in data engineering and big data project Hand on experience in SQL/NoSQL database (eg. Elastic) and communication frameworks. Strong coding skills (Python). Deployment of machine learning based project Practice of agile methodology Practice of software engineering (devops, mlops) Practice of Linux environment. Excellent communication skills and the desire to work in a dynamic and collaborative environment Must be eager and able to learn quickly and to improve.Desirable Skills Appetite for AI & computer vision Experience in AI Engineering tool eg kubeflow, MLFlow, FiftyOne, Cvat etc Experience in docker, Restful API Experience in cloud platform (eg GCP)Location  EchirollesLet’s grow together.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer,DAHER,"Bouguenais, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-at-daher-3798420301?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=1qcB9168wZVmxHun1Ubnuw%3D%3D&position=20&pageNum=5&trk=public_jobs_jserp-result_search-card,"Vous avez envie de FAIRE DECOLLER votre carrière ?Nous recherchons notre futur(e)Data EngineerType de contratCDIPrésentation de l'emploiPour accompagner notre développement et renforcer notre équipe, nous recherchons un(e) DATA ENGINEER, en CDI. Vous serez rattaché(e) au Responsable de Centre Informatique DATA, à Nantes sur le centre d'innovation Shap'IN. Vous serez garant de l’accès qualitatif aux sources de données.Présentation de DaherNous sommes avionneur et équipementier pour l'industrie et le service et nous affirmons notre leadership dans 3 principaux métiers - construction d'avions, équipements et systèmes aéronautiques, services logistiques et supply chain.Fiche de PostePlus précisément, vous vous assurez de la maîtrise de la donnée et êtes garant de la qualité de son utilisation (référencement, normalisation, et qualification) afin d’en faciliter l’exploitation par les équipes (Data Analysts et Data Scientists).Vous contribuez également à la définition de la politique de la donnée et à la structuration de son cycle de vie dans le respect des réglementations en vigueur, en collaboration avec l'Architecte Data. Votre périmètre d’intervention est axé sur les systèmes applicatifs autour de la gestion et traitement de la donnée sur les plateformes PAAS et on-premise (Azure, Snowflake, Databricks et SQL Server[SSIS])Enfin, vous assurez la supervision et l’intégration des données de diverse nature qui proviennent de ces sources multiples et vérifie la qualité des données qui entrent dans le Lakehouse.Pour résumer, votre rôle clé au sein de l’équipe sera de :Construire des solutions d'intégration des données (structurées et non structurées).Travailler dans des équipes pluridisciplinaires informatiques et opérationnellesStructurer la donnée (sémantique, etc.)Cartographier et documenter les solutionsMaintenir / superviser les solutions (incidents, doublons, flux bloqués...)Accompagner les key users dans l'exploitation de la plateformePoste ouvert à un profil junior ou post-doc, pas à l'alternance.Ce poste est pour vous l'opportunité de travailler au sein d'une équipe expérimentée en Data Engineering, avec des technologies de pointe (Snowflake, Databricks), sur des projets d'envergure et sur des thématiques diverses (Aircraft, Industrie aéronautique, Logistique et Service Industriel, transverses...), en recherche et développement ou pour la production.Titulaire d'un Bac+5 en école Informatique ou équivalent, vous justifiez d'une expérience probante en tant que Data Engineer, idéalement dans un environnement industriel.Vous maitrisez les technologies : SQL, ETL(s), développement reporting PowerBI, SSIS, Microsoft Azure, SQL Server, Databricks, Snowflake, PySpark, analyse et modélisation de données, méthodes de développement Agile...Motivé(e), dynamique et doté(e) d'un grand sens de l'adaptabilité et de l'écoute, vous vous intéressez autant au métier de l'utilisateur final qu'à la solution technique que vous devez lui produire. Vous maitrisez l'anglais (lu, parlé, écrit, nos documentations sont à produire en Anglais).Postulez et rejoignez-nous chez DAHER Shap'IN à proximité directe de Nantes, centre d'excellence et d'innovation Industrielle.Allez-vous OSER l'aventure avec nous ?Venez nous rejoindre et libérez votre potentiel !


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Extia,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3675382393?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=0%2Be%2BPhtjW3o%2FVQv%2F1qPtwQ%3D%3D&position=21&pageNum=5&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l’humain au cœur de ses préoccupations ? On vous attend chez Extia !Société de conseil spécialisée dans les métiers de l’IT, de l’ingénierie et du digital, Extia privilégie depuis sa création en 2007 une approche qui allie performance et bien-être au travail. Une vision de l’entreprise partagée aujourd’hui par plus de 2 500 Extiens en France et à l'international et récompensée depuis 2012 par le label Great Place to Work®.Chez Extia, c’est « D’abord qui, ensuite quoi » alors, allons-y !D'abord quiRigoureux, vous ne laissez rien au hasard,Efficace, vous ne remettez pas à demain ce qui peut être fait dès aujourd’hui,Autonome, vous savez mener vos missions à bien sans aide.Ensuite quoiVous aurez le rôle de support technique aux équipes d’analyse : structurer les données, réaliser des analyses « statistiques » ou « techniques » sur les données, développer des outils d’analyse…Vous mènerez des études afin d’évaluer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d’identifier les solutions les plus pertinentes.Vous serez en charge de :Participer à la définition des besoins et à la rédaction des User Stories,Collaborer avec les Data Scientists au développement des modules d’analyse de donnée,Concevoir et construire des architectures de données,Intégrer des sources de données,S'assurer que les données sont facilement accessibles et que leur exploitation fonctionne comme demandé, même dans des circonstances hautement évolutives,Exécuter des processus ETL (extraire / transformer / charger) à partir d'ensembles de données complexes et / ou volumineux.Profil recherché :Maitrise de l’écosystème Microsoft Azure Data Factory, Azure Data Lake est un plusMaitrise Technologie autour de la data : Power BI, Spark, Airflow, Python, Scala…Maitrise des bonnes pratiques de développement et méthodes agilesBase de données : SQL, Postgré SQL (Paas) et modélisation de la donnéeConnaissance des systèmes de gestionnaire de conteneur (Kubernetes,...)Connaissance des outils de déploiements : Jenkins, Git, maven, AnsibleQualités relationnelles et capacité à gérer nombreuses interactionsDynamisme, autonomie et envie de découvrir des manières différentes/innovantes de faire


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Hub Python Data Engineer H/F,Jobs via eFinancialCareers,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-hub-python-data-engineer-h-f-at-jobs-via-efinancialcareers-3799927545?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=263T2FSwO58rO61nQxGszA%3D%3D&position=22&pageNum=5&trk=public_jobs_jserp-result_search-card,"Métier :Production et infrastructureExpérience :2 ans minimumA propos...ADD UP est une ESN (Entreprise de Services Numériques). Elle est née en 2001 de la rencontre de jeunes entrepreneurs, issus de grandes écoles françaises, dont Polytechnique et HEC, et formés dans les grands cabinets de consulting. Née d'une passion pour les nouvelles technologies, l'équipe d'ADD UP propose des prestations de conseil à forte valeur ajoutée à ses clients. Ses domaines de compétence : les services informatiques et le consulting pour la finance de marché.Description :Au sein des équipes de notre client dans le secteur bancaire, vous devrez contribuer aux développements de workflows en python au sein de l'équipe DataHub Core Platform.vos missions seront : Participer à différents projets Data au sein de l'équipe Participation au projet DQF (Data Quality Framework) Participation au projet Data Lineage Développement des modules python communs qui seront utiles à tous les projetsProfil recherché :De formation Bac+5, vous avez une première expérience sur un poste similaire.Date de démarrage :Asap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Scientist - Machine Learning Engineer,Phealing,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-scientist-machine-learning-engineer-at-phealing-3802114905?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=j3nCSet%2FHWKxR1xyCAV%2F5Q%3D%3D&position=23&pageNum=5&trk=public_jobs_jserp-result_search-card,"Poste à pourvoir : Data Scientist / ML EngineerExpérience demandée : 3 ans et +📍 Lyon (Part Dieu)💬 Qui sommes-nous ?Créé en 2019, Phealing est le premier outil d’aide à la dispensation en officine capable de prévenir instantanément le pharmacien en cas de risque médicamenteux pour son patient.Notre IA médicale permet le croisement instantané des données de la dispensation avec le profil physiopathologique du patient et les informations du médicament.Notre mission : mettre l’innovation technologique au service du comptoir de l’officine pour sécuriser le pharmacien et son patient face au risque pharmacologique et réglementaire de la dispensation. ⚙️ Descriptif du poste : Au sein de l’équipe technique (5 – 10 personnes), vous interviendrez sur des missions variées depuis la conception de prototypes jusqu’à leur implémentation et suivi en production.Après plusieurs années de R&D, Phealing a construit et exploite en production des modèles à l’état de l’art pour l’extraction d’information à partir de documents médicaux. Vous bénéficierez ainsi de cette expertise et êtes amené(e) à la renforcer afin d’enrichir les modèles actuels et en créer de nouveaux.Fort(e) de votre maîtrise du langage PYTHON, vous travaillerez également sur l’amélioration ou la conception d’heuristiques.Pragmatique et armé(e) d’une solide connaissance en IA (NLP en particulier) vous serez capable d’expérimenter des nouvelles idées innovantes ! 🎯 Vos missions :Conception / amélioration des modèles de machine learning / deep learningContribution à l’élaboration des datasets, finetuning selon les besoinsImplémentation et déploiement des fonctionnalités liées à l’IA ou la data, implémentation Python dans le respect des bonnes pratiquesVérification des contraintes de mise en productionSuivi des indicateurs de performances, analyses des anomaliesPrototyping, études, ou collecte de donnéesContribution à la planification et la construction de la feuille de route ❓Informations complémentaires : > Poste basé à Lyon (proche Gare Part Dieu) ; possibilité de télétravail partiel> Compétences : NLP, Python, Prototyping> Expérience en ML/DS : > 3ans> Disponibilité poste : dès Mars 2024Vous pouvez également postuler à : candidature@phealing.fr


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer H/F,MERITIS,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3775391196?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=EEm%2BiBUYZNs4cvU8J2xMuQ%3D%3D&position=24&pageNum=5&trk=public_jobs_jserp-result_search-card,"Descriptif de l’entreprise et du poste :Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise. Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​Les missions qui vous attendent :Data Engineer pour la construction d’un entrepôt de données DatalakeLe DataHub est un centre d’expertises de la donnée qui a vocation à faciliter les usages de la donnée par les différentes fonctions métiers (pilotage commercial, marketing, actuariat, finance et risque, etc.). Il est composé de deux équipes :• Le DataLab regroupant les Data Scientists en charge des prototypes IA,• Les Feature Team Data animées par un Product Owner et regroupant les Data Analyst / Data Engineer travaillant en amont et en aval des prototypes sur la construction d’enablers data sur le Datalake et leur mise à disposition via des vues métiers. Il y a actuellement 2 FT et celles-ci travaillent en agile (Scrum).La prestation du Data Engineer contribuera à développer sur notre Datalake les modèles de transformation de la donnée ; en partant des données brutes déversées depuis nos silos de gestion il devra mettre en oeuvre l’ensemble des règles de transformation métier pour raffiner la donnée et la rendre exploitable, compréhensible, reconnaissable par les différentes directions métier.Ainsi, au sein de la FT, les principales activités du Data Engineer seront les suivantes :• Participe aux cérémonies de la FT (daily, affinage, sprint planning),• Assure les développements spécifiques pour contribuer à la production du Datamart et des vues utilisateurs• Réalise des tests unitaires et d’intégration• Garanti la maintenabilité et les performances des programmes développés• Maintien à jour la documentation• Apporte un regard critique sur la production du Datamart au regard du métier de l’assuranceCompétences techniques demandées :• Langage SQL : Expertise• Technologie HADOOP (Spark, Hive principalement) : Expertise• Développement objet (JAVA) : Expertise• Gestion de source (Git) : Expertise• Connaissance en modélisation de la donnéeCe poste est uniquement ouvert à du CDI.Devenir collaborateur Meritis c’est :​· Des parcours professionnels sur mesure (évolution de carrière, formations adaptées, mentoring…) ;​· Avoir le choix de sa mission et un accompagnement personnalisé tout au long de votre carrière ;​· Evoluer dans un environnement où l’apprentissage est favorisé : formations certifiantes, e-learning, meetUp, concours de code, parcours d’évolutions etc ;​· Faire partie de communautés d’experts qui partagent leurs savoirs et expériences au sein de nos centres de compétences ;​· Un environnement convivial avec de nombreux événements festifs (soirée annuelle, séminaires & teambuiding, déjeuners et afterworks…) ;​​Meritis est engagée dans la Responsabilité Sociétale des Entreprises. Nous valorisons notre impact positif sur la société et l'environnement. Notre démarche RSE guide chacune de nos actions pour promouvoir l'équité, la durabilité et le bien-être de nos collaborateurs. Rejoignez-nous pour être partie prenante de cette démarche responsable, où chacun de nos talents contribue à construire un avenir meilleur.Nos différences sont nos atouts. C’est pourquoi Meritis s'implique en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - DUNKERQUE (H/F),Capgemini Engineering,Greater Dunkerque Area,https://fr.linkedin.com/jobs/view/data-engineer-dunkerque-h-f-at-capgemini-engineering-3806443084?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=hUP79CnCrH02JDvbdWFbKA%3D%3D&position=25&pageNum=5&trk=public_jobs_jserp-result_search-card,"CAPGEMINICapgemini, qu'est-ce que cela évoque pour vous ? Pour nous, c'est une success story à la française ! Celle d'une startup devenue une référence mondiale en matière de conseil et de services informatiques.Leader de la convergence des mondes physique et virtuel, nous agissons en partenaire de nos clients industriels pour concevoir, mettre en œuvre, sécuriser et démanteler des produits et infrastructures complexes. Nous participons à la transformation et à l’optimisation des entreprises de demain.Capgemini Engineering est la marque du groupe Capgemini réunissant les services d’ingénierie et de R&D. On accompagne la convergence des mondes physique et numérique. Conjuguée avec l’ensemble des capacités du Groupe, elle aide les entreprises à accélérer leur transformation vers l’Intelligent Industry. Capgemini Engineering compte plus de 52 000 ingénieurs et scientifiques dans plus de 30 pays, dans des secteurs tels que l’aéronautique, l’automobile, le ferroviaire, les communications, l’énergie, les sciences de la vie, les semi-conducteurs, les logiciels et l’Internet, le spatial et la défense, et les biens de consommation.VOTRE MISSIONVous intégrez l’équipe Digital Engineering de Capgemini Engineering, en tant que Data Engineer, vous participez à un projet chez notre client dans le secteur de la sidérurgie. Vous êtes responsable de :Concevoir et développer des solutions pour la collecte, l'organisation, le stockage et la modélisation des donnéesGarantir l'accès aux différentes sources de données et de maintenir la qualité des données. Veiller à ce que les analystes de données et les data scientists de l'entreprise puissent accéder facilement aux données et les exploiter dans des conditions optimalesContribuer, sous la supervision opérationnelle de notre architecte, aux meilleures pratiques, aux normes, aux politiques, aux méthodes, aux outils et aux procédures liés au Cluster Big DataContribuer à la mise en place d'une politique de données conforme aux réglementations en vigueurAssurer une veille technologique, notamment sur les langages de programmation utilisés afin d’aider à l'avancement des projetsCE QUE NOUS RECHERCHONSVous êtes Ingénieur(e) ou titulaire d'un diplôme équivalent de niveau bac+5 en informatique ou en sciences des données. Vous voulez commencez votre carrière dans les technologies du Big Data.Vous possédez certaines de ces compétences suivantes : Hive, HDFS, Kafka, Talend, SQL Server, Framework Spark, Datalake – Cloudera. Vous avez une bonne compréhension des infrastructures et des outils nécessaires pour le traitement des données, ainsi qu'un esprit d'équipe associé à d'excellentes compétences en communication.Vous avez également la capacité à vous intégrer dans des projets et des équipes existantes dans un contexte de transformation.Alors, rejoignez Capgemini et choisissez le futur qui vous ressemble !CAPGEMINI, entreprise handi accueillante, conformément à la norme AFNOR NF X50-783, est également signataire de la charte de la diversité en entreprise


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer CDI H/F,Mediaperformances,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cdi-h-f-at-mediaperformances-3806468738?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=DuMN2HjZGEXvXkcznetB3Q%3D%3D&position=1&pageNum=6&trk=public_jobs_jserp-result_search-card,"Le leader de l’Activation shopper omnicanal. Le premier partenaire de monétisation de la data et des médias de tous les retailers alimentaires français.Depuis plus de 35 ans, nous aidons les marques de grande consommation à développer leurs ventes dans les enseignes de la grande distribution alimentaire. Nous mettons en place des campagnes publicitaires à destination des shoppers pour influencer leur comportement d’achat.Depuis plusieurs années, nous avons pris un réel virage sur le digital, à travers des médias shopper data centric et data driven. Nous avons un patrimoine data activable significatif sur ce marché avec une part considérable de cette data en propriétaire.Suite à différentes créations et acquisition, le groupe Médiaperformances, couvre des médias omnicanaux, aussi divers que la programmatic, les avis clients, l’activation mobile, le drive … et bien entendu l’in store.VOTRE MISSION : Au cœur de cette stratégie d’accélération digitale, le Data Engineer H/F aura un rôle central. Vos principales missions seront de : Participer à la conception et à la construction de notre plateforme de donnéesConstruire des pipelines de données en ayant recours à différentes technologies et langages (Python, Sql, Beam …)Assurer la qualité des données collectées, préparer et optimiser le stockage et le chargement,Travailler de pair avec nos data scientists pour optimiser la performance de nos projets et développer de nouveaux cas d’usageAssurer et améliorer le monitoring des différents flux déjà existants en mettant en place des processus d’automatisation et d’industrialisationDéfinir des KPIs et créer des tableaux de bord de coût et d’utilisation Vous serez amené à collaborer avec différents services dans l’entreprise : La DSI, les développeurs de nos filiales, le trading desk, ainsi que des partenaires extérieurs retailer et GAFAM…Vous serez sous la responsabilité du Data Engineer senior, direction Data & Etudes.   VENEZ RELEVER LE CHALLENGE D’ETRE LE PREMIER MAILLON D’UNE EQUIPE DATA EN DEVENIR ! Votre profil :  Vous êtes passionné(e) par le domaine de l’informatique et la data et avez déjà une première expérience sur des enjeux data engineering et big data sur un environnement cloud. Les problématiques retail, marketing client ne vous sont pas étrangères. Vous êtes diplômés d’un minimum BAC +5 d’une école d’ingénieur ou d’un master dans un domaine connexe à la big data & informatique.Vous êtes Automne et rigoureux.Vous savez vous adapter (notamment pour assurer la gestion multi projet) et faites preuve de curiosité.Votre expérience :Vous justifiez d’au moins 2 ans d’expérience sur des problématiques de data engineering (construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données…)Vous êtes certifié et/ou avez une première expérience sur l’environnement cloud GCP (Bigquery, GCS, GCE, Cloud run, data proc, Pub/Sub… )Vous avez de solides compétences en Python, SQLVous avez une bonne connaissance des processus et outils de développement modernes (DevOps, Git, CI/CD…) ;Vous pratiquez les méthodes agiles dont Scrum.Les plus : Vous maîtrisez Javascript, le développement d’API,Vous utilisez les outils DBT ou Dataform,Une première expérience en visualisation de données démontrée sur au moins un outil : Datastudio / Looker, PowerBI, Tableau…Vous avez travaillé dans des contextes à très forte volumétrieMédiaperformances s’engage dans l’insertion des personnes en situation de handicap et traite l’ensemble des candidatures dans le respect des grands principes de non-discrimination.Join the team !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer / GCP (H/F),Micropole,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-h-f-at-micropole-3706045967?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=i1HCgBjlH35yorj9iIf%2B7w%3D%3D&position=2&pageNum=6&trk=public_jobs_jserp-result_search-card,"Rejoignez le Groupe Micropole. Devenez un(e) #InnovativePeople ! Mission En RésuméPoste : Data Engineer / GCPLocalité : Levallois-PerretType de contrat : CDINiveau d’expérience : au moins 3 ansVous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !Au sein de notre agence basée à levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance.Dans vos  missions quotidiennes , vous serez amené(e) à :Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Cloud GCP. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; Participer au développement de notre centre d’excellence GCP.  Profil Vos Compétences TechniquesVous avez un minimum de 3 années d’expérience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou à défaut une certification GCP avec l’ambition de vous préparer à d’autres. Vous maîtrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R) ; Vous avez une maitrise des théories et outils de modélisation de données, Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, Vos AtoutsVous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud GCP et des solutions Data. Devenir #INNOVATIVE PEOPLE C’est :Intégrer une communauté de 1200 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine.Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale.Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP.Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus.S’assurer d’une innovation continue grâce à : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients ; notre management par les talents naturels.Processus De RecrutementChez Micropole, le processus de recrutement est réactif et transparent.Etape 1 – si votre profil correspond à nos besoins, vous êtes recontactés dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification téléphonique ou physique est organisée rapidement avec Dimitri ;Etape 2 - Un premier entretien est programmé avec Dimitri en physique ou visioEtape 3 – Vous rencontrez un manager technique avec l’un de nos experts.En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique)LA VIE CHEZ MICROPOLE, C’estUne vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ;Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ;Une politique de formation attractive et éclectique (certifications prises en charge) ;Un travail en équipe valorisé pour une meilleure cohésion ;Participation à des projets internes sur la base du volontariat.CompétencesGCP Big Query


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,Aix-Marseille University,"Marseille, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aix-marseille-universit%C3%A9-3784236181?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=Htc%2BBIsDTrNJO7CijPqZvQ%3D%3D&position=3&pageNum=6&trk=public_jobs_jserp-result_search-card,"Et si vous rejoigniez une structure en pleine mutation vers l’université de demain ?Au premier rang des universités françaises et francophones, Aix-Marseille Université (AMU) regroupe 78 000 étudiants, 8 000 personnels, 122 structures de recherche en lien avec les plus grands organismes dans ce domaine et un budget de 720 M€. 5 grands campus accueillent les étudiants et tous les champs universitaires qu’il est possible d’étudier en France. La diversité des sites permet de proposer aujourd’hui des opportunités de carrière uniques. Aix-Marseille Université fait partie de l'alliance CIVIS pour la création des ""Universités Européennes"". Aix-Marseille Université recrute et reconnait tous les talents, ses offres d'emplois sont handi-accessibles.AMU en vidéo : https://youtu.be/7-Hrtn-l2QkMissionLe data Engineer travaillera au sein de la Direction du Numérique (DirNum) sous la responsabilité du directeur du pôle « Logiciels de gestion ». Il fera équipe avec les data analysts du service de la Direction du Pilotage et du Contrôle de Gestion (DPCG) pour l'installation, la modélisation, la construction et la maintenance des entrepôts de données.En Tant Qu'Ingénieur De Bases De Données, Il Sera En Charge De La Mise En Place Et Du Développement D'un Entrepôt De Données (projet SIROCCO)Extraction, uniformisation et structuration des données clientsCollecter, sélectionner et valider les données pertinentes pour l'analyse en collaboration avec les data analysts et les experts métiers. Définir les solutions de stockage et la structuration des données.Convertir, coder et cartographier des données de consommation ou d'usage produit dans un format compréhensible par l'ensemble des utilisateurs.Déterminer les outils et méthodes d'acquisition de données depuis un ensemble de bases techniquement hétérogènes.Concevoir l'architecture d'un entrepôt de données décisionnels (Data Warehouse). Maîtriser la qualité des données tout au long de leur traitement.Développement d'outils de support aux clients internesParticiper à la mise en œuvre de la stratégie de pilotageParticiper au développement des indicateurs de performance de l'université.Animer les ateliers d'expression des besoins internes et rédiger les cahiers des charges. Écrire et rédiger les spécifications de besoinsFormer les utilisateurs aux outils informatiques et décisionnels.Veille technologique sur les outils de dataminingEffectuer une veille sur les nouvelles et solutions logicielles d'analyse des données. Rechercher et expérimenter de nouvelles méthodes de modélisation et d'analyse des donnéesSélectionner les nouveaux outils et techniques de data management.ProfilCompétences ClésMaîtrise des outils d'ETL et notamment TalendExcellente maîtrise des bases de données relationnelles (Oracle Database, Postgresql, Mariadb) et connaissance des bases de données no-SQL Maitrise du langage SQLTrès bonne connaissance de la conception d'entrepôts de donnéesVous avez l'esprit d'analyse, et faites preuve d'une grande rigueurVous avez le sens de la communication et du serviceLes Avantages AMU Participation aux frais de transports en commun sur l'ensemble du territoire départemental Télétravail possible jusqu'à 2 jours/semaine, selon les nécessités et l'organisation du service à partir de 6 mois d’ancienneté Une prime au-delà des 12 mois d’ancienneté pour les agents non titulaire Selon votre rythme de travail, bénéficiez jusqu’à 50 jours de congés dès la première année puis 58 jours au bout d’un an Participation Mutuelle à hauteur de 15€ /mois Des offres loisirs, sport et culture pour tous les agents L’établissement conventionné par le FIPHFP (Fonds pour l'Insertion des Personnes Handicapées dans la Fonction Publique) Possibilité d’accès à un emplacement parking à proximité Forfait mobilité durable pour l’utilisation d’un cycle sur les trajets domicile-travail Parcours d’accueil et d’intégration pour les nouveaux agents


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Analytics Data engineer - internship,Equativ,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/analytics-data-engineer-internship-at-equativ-3798611608?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=6IVyFmLVKnaNVsoROTv0uQ%3D%3D&position=4&pageNum=6&trk=public_jobs_jserp-result_search-card,"Your mission: Helping the company be fully data-driven is not just a buzzword, it is our mission at Equativ. We, the Data Analytics team at Equativ, maximize efficiency by enabling easy and permanent access to quality data, valuable insights & rigorous thinking. Our responsibility is to ensure our local and central teams, clients and partners, make informed business decisions. To do so, we leverage huge volumes of data (Equativ handles 150Bn Auctions per Day) in a state-of-the-art tech stack (AirFlow, Snowflake, Tableau…) in order to provide actionable insights to all teams at Equativ!What you'll do : Reporting to the manager of the Analytics team, your mission will be to maintain and upgrade our data pipeline.Day-to-day maintenance of our data pipeline: Ensure data pipeline ingestion accuracy in due timeFollow-up on data quality issues raised by internal customersImprovement of sourcing processes:Migrate from Talend data flows to Python scripts for our sourcing jobsDevelop resources to make Data Analysts autonomous in sourcing data in our Snowflake database (through ready-to-use scripts or small interfaces)Developing new projects on our main platforms (Tableau & Snowflake)Leverage new resources to make the most out of Snowflake (Streamlit, Snowpark…)Identify new ways to structure our data sources in Tableau while reducing the loading time for the userParticipate in the restructuring of our data marts (schemas, stages & permissions)Communication:Sync with Data Analysts to make sure that their requests are properly prioritizedSynchronize with other technical teams (Core-Data, Infra) to gather requirements of the migration and ensure a smooth transitionUnderstand business needs to suggest the most efficient technical solution.About you:Pragmatic & hands-on mindset is required: you’ll have latitude to explore different options, but you need to go for the most effective solutionTechnical knowledge of Python & SQL is a must.Knowledge of collaboration platforms (Gitlab) & Agile processes is a plus.You can demonstrate your ability to solve problems end to end.You are fluent in English.👋 About us Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus — four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times’ FT 1000: Europe’s Fastest-Growing Companies.Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.Come and lead the charge with us in building a transparent ecosystem based on quality!----------------------Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Capital Fund Management (CFM),"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-capital-fund-management-cfm-3796580585?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=dcDCJdiQuEnUro9OfuL0kg%3D%3D&position=5&pageNum=6&trk=public_jobs_jserp-result_search-card,"ABOUT CFMFounded in 1991, we are a global quantitative and systematic asset management firm applying a scientific approach to finance to develop alternative investment strategies that create value for our clients.We value innovation, dedication, collaboration and the ability to make an impact and together we create an environment for talented and passionate experts in research, technology and business to explore new ideas and challenge assumptions.ABOUT THE ROLEThe context :Data is the fuel that powers our investment strategies: intraday price dynamics are used to better our investment decisions; buy/sell intents of market participants help to trade at the best available price… CFM Data team is in charge of preparing the data to make quant research easier and trading more reliable.The positionAs a data engineer intern, you will build data pipelines to convert raw orderbook data into features.Those features are then used by our systems to improve the efficiency and the reliability of our trading processes. Examples of features: daily traded volume per security, imbalance of trading volume between opening & closing auctions, etc.Our data is both large and diverse, so we are looking for someone that has both an interest in technology and in understanding the data and the rules that govern it.The work will involve python coding as well as data exploration/visualization from the notebook.You will be able to leverage our proven technology & expertise as we have already taken care of the heavy lifting.SKILLSET REQUIREMENTS/QUALIFICATIONS- You are proficient in python; a real ability to work on Linux environments (C++ not required but is a plus),- You are curious, attentive to details,- You have an interest in Technology and Data.EQUAL OPPORTUNITIES STATEMENTWe are continuously striving to be an equal opportunity employer and we prohibit any discrimination based on sex, disability, origin, sexual orientation, gender identity, age, race, or religion. We believe that our diversity, breadth of experience, and multiple points of view are among the leading factors in our success.CFM is a signatory of the Women Empowerment PrinciplesFOLLOW USFollow us on Twitter and LinkedIn or visit our website to find out more about CFM.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800339372?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=ISck%2F3DVLmeDZO4GHQcVtw%3D%3D&position=6&pageNum=6&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence 🚀Anthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et décident de créer une solution SAAS ERP à destination des ESN & sociétés de conseil, afin de ""travailler autrement"".BoondManager est ainsi né 🦊Au cœur de BoondManager, il y a l'idée que chacun(e) devrait avoir la possibilité de se réaliser dans son travail et sa carrière, de pouvoir ""les"" concilier avec sa vie personnelle. 🫶Notre Mission ⭐⭐⭐⭐⭐Fédérer sur un même outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunités, facturation, CRA) !Notre ADN ❤️Nos 75 Boonders sont en full remote/100% télétravail dans toute la France.Le télétravail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'est🤝 1500 clients👥 70.000 utilisateurs🌍 21 pays💶 Rentable et autofinancée🥰 La Boondfamily est passée de 30 à 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? 👇Le PosteBoondManager ne cesse de grandir ! 🦊Afin de répondre à notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'équipe BI/Performance 🦊Tout ça, c'est magnifique, mais on reste un peu sur notre faim… nos plus grands rêves sont :Devenir le leader européen des ERP pour les sociétés de conseils (on a de l'ambition).Et pour ça, on a besoin de toi !Nos Grands Principes 👌✅ Mieux vaut s'excuser que de demander la permission. On encourage à 300 % la prise d'initiative !✅ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, écoute !La (super) Team 🏆L'équipe Performance est composée de talents pluridisciplinaires ! François s'occupe de la data (ton futur binôme) Guillaume des projets de refactoring Manu de la stack ELK Rémi côté DevOps. Florens, ton futur managerLa performance touche l'ensemble des équipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plutôt sympa donc !Tes activités : 👇On Te Propose Côté Dataviz Création dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Intégration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets nécessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de manière transverse Spécification et conception de dashboard de A à ZCôté Data Analyst Création de KPI via sql Challenger les perfs de nos Kpi (améliorer les temps de résultats) Réaliser les croisements de données pour la construction et le maintien du data warehouse Assurer la maintenance et l'évolution des KPI du produit BoondCôté Engineering Suivi de l'intégrité de la donnée (topologie, audit) Participer à l'alimentation du Datawarehouse Développement, maintien et l'évolution de l'architecture des données Recueillir les besoins des parties prenantes et spécifier les besoins en dataNotre Stack Technique 🌈 Backend/Frontend : Java, Python (à venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'équipe Perfs 🦊 On se retrouve tous les lundis matin avec l'ensemble de l'équipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton évolution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour échanger avec le reste de la team Weekly avec toute l'équipe tech (les BB pour les intimes) le mercredi à 14hTon Onboarding 🚀1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Montée en compétence sur notre solution au travers de notre Boondgame Montée en compétence sur le métier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des données qui permet de calculer cette valeur, résolution). Être capable de mettre les mains dans l'intégration à boond des KPI (manipulé le backend)6 Mois Capacité de créer des nouveaux KPI à partir des demandes de PO (requête sql permettant de le calculer) Capable d'intégrer de la dataviz. L'idée est que tu sois dans les meilleures dispositions en maîtrisant notre environnement 💪ProfilEt toi, Qui es-tu ? 🤩🍷 Tu adores pinot et je ne te parle pas de celui des charentes💪 Tu as déjà construit des tableaux de bords au travers d'un outil de Dataviz✍️ tu connais kafka et pas que l'écrivain😎 Tu es capable d'écrire des requêtes optimisés pour fabriquer la dataviz avec des exemples concrets en SQL🧠 Python : Tu dois savoir développer des nouvelles fonctionnalités, gestion des dépendances, challenger l'existant (qualité du code), compiler le projet.🚀 Le + : Tu maîtrises notre stack technique (on veut des projets significatifs)🦊 Le petit ++ : Tu connais le monde des ESN🙋‍♀️ Mesdames, autorisez-vous à candidater !Ce Qu'on T'offrira En Plus De Tout Ça 🎁💸 Un salaire entre 45k et 60K🏡 100% remote 🇫🇷 (plus de temps pour toi !)🌴 3 séminaires par an pour se retrouver et s'éclater !😎 9 jours de congés payés supplémentaires🏥 Une mutuelle familiale (pas de suppléments pour ta famille)💸 Une offre télétravail en plus de ton salaire !🎁 Une offre mensuelle dans le coworking de ton choix !🧘 Cours en ligne de méditation, fitness et yoga chaque semaine !🤝 Un plan d'épargne entreprise valorisé à hauteur de 300 %💻 Une mise à disposition d'un Macbook, 2 écrans, casque, etc.🦊 On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !Déroulement des entretiens💻 Un premier échange avec Jean-Florian, notre Head Of Talent🚀 Un entretien technique/culture fit avec François, ton futur binôme côté Data🤝 Un échange Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager 🤓Et si tu as réussi à me lire jusqu'ici,voici ma dernière phrase pour qu'on ne passe pas à côté de toi : si demain cette offre venait à être clôturée et que tu penses regretter de ne pas avoir postulé, c'est qu'elle t'a tapé dans l'œil.Ça serait dommage de démarrer 2024 avec un regret,Alors, n'hésite pas, POSTULE👇
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Equativ,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-equativ-3797587886?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=g%2B7s9qeVMd02B7CZwrS3%2Bw%3D%3D&position=7&pageNum=6&trk=public_jobs_jserp-result_search-card,"👫 About the teamAt Equativ, we’re on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 100 billions requests per day and above 40 Gbps of network traffic.Our innovation team based in Paris, Nantes, Limoges, Kraków and Berlin is composed of 90 straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.Our data engineering team is composed of 10 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 140+ engineers spread across Paris, Nantes, Limoges, Kraków and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.Our mission 👇Data Engineering team is central to Equativ’s data centric business and is responsible to ingest, transform, model and redistribute all data coming from our adtech platform.We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle massive log ingestion (tens of billions per day), short & long term data storage, complex data modelling, real-time and batch ELT as well as providing external access through dedicated APIs.Data Engineers serve Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science algorithms (clustering and optimization), customer reporting, invoicing and more.Equativ Data Engineering team is engaged in an ambitious migration of its main data stack (Hadoop on-premise) to GCP with the objective to increase reporting features, lower maintenance time, improve performances and simplify the access to our raw data.What you'll do ✏️ As a Big Data Engineer, you’ll primarily focus on maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIsDesign, develop, test, promote and industrialize all data components from data ingestion to datawarehouse delivery (ClickHouse, BigQuery):- Propose and develop innovative solutions to achieve the best levels of scalability and performance for our Big Data engines- Automate and streamline our real-time and batch data pipelines (on-premise and in the cloud) in order to simplify access to our data by other teams and lower amount of work spent by other teams on ETL processes- Perform end-to-end monitoring to ensure high availability of production data processing, data quality and reliability- Apply best in class Devops guidelines and secure deploymentsBrainstorm with other team members working on our data backend (datawarehouse modelling and data exposure through our reporting APIs) on optimizing our architecture and support them in the use of our pipelinesContribute to data roadmap definition in coordination with other R&D and product teams in order to build a best in class data infrastructure that will generate insights for Equativ’s analyticsTake part in improving and deploy data engineering standards, procedures, processes and operational guidelines around target data components at Equativ💪 About youMaster degree in Computer Science or similar technical field of study3+ years of software development with open source technologiesFluent in Java and/or in Scala. SQL masteryVery good understanding of Devops principles (Gitlab, Docker, Kubernetes, Gradle, ci/cd)Experience with large-scale data engineering technologies (ClickHouse, Flink, Kafka, Hadoop, Spark, Hbase)Experience on building data pipelines on Google Cloud Platform (BigQuery, Dataflow, GCS, Cloud Run, Airflow …) would be a big plusExperience in working with high QPS Rest APIs is a plusEntrepreneurial spirit and know-how to identify opportunities of improvementWorking proficiency and communication skills in verbal and written EnglishPassion for playing with large volume of data🚀 How you'll growWithin 1 month:You'll be just finishing your onboarding. You'll probably have tackled a few small tasks in peer-codingWithin 4 months:You'll have an overview of 50% of the stack, CI/CD and team’s main processes. You’ll be able to work on more complex developmentsYou'll now have enough knowledge to participate to deployments of chosen applicationsWithin 9 months:You'll be autonomous on most of our stack and will have participated to major projectsYou’ll be helping the team on production matters👋 About us Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus — four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times’ FT 1000: Europe’s Fastest-Growing Companies.Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.Come and lead the charge with us in building a transparent ecosystem based on quality!


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer Marseille H/F,Jems Group,"Marseille, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-marseille-h-f-at-jems-3802354030?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=acMkelMsh3%2FrteFOCUBHRg%3D%3D&position=8&pageNum=6&trk=public_jobs_jserp-result_search-card,"A propos de JEMSNous sommes le seul industriel de la donnée en Europe. Notre métier est de créer, manager et exploiter le patrimoine data de nos clients.Nous avons la conviction que chaque entreprise peut adopter une démarche innovante de gestion de la donnée et créer des cas d’usage disruptifs en réduisant l'impact écologique et en diminuant la dette technique.Nous comptons plus de 840 collaborateurs en mission chez nos clients grands comptes dans tout secteur d’activité : banque, assurance, santé, énergie, e-commerce, automobile, luxe, retail, transport, agritech…Vos missionsNous recherchons un(e) data engineer capable de trouver des solutions innovantes et robustes à l'ensemble des problématiques Data.Vous aurez la charge de :Participer à la conception et réalisation d'une solution Data depuis l'acquisition jusqu'à l'exploitation de la donnée en accompagnant la réflexion des directions métiersIdentifier, collecter et intégrer les données nécessaires à la résolution de problématiques métier et opérationnellesGarantir la qualité des données en mettant en place les outils de mesure et de suivi adéquats en appliquant les règles de Data Gouvernance et de Data ManagementTranscrire des besoins métier en règles de gestion dataIndustrialiser le déploiement de vos réalisations à travers l'implémentation de tests unitaires, d'intégration et de non-régressionVos compétencesEn tant que Data Engineer vous maîtrisez :Le langage SQLUn langage objet (Python, JAVA, Scala)Un framework de calcul distribué L'intégration continue (Git, JUnit, SonarQube, Jenkins)Un cloud provider (AWS, GCP, Azure) ou une distribution Big Data (Hortonworks, Cloudera, Datastax)Les concepts de la modélisation relationnelle et non-relationnelleVotre profilDiplômé(e) d'une école d'ingénieur ou d'une université, vous justifiez d'une expérience professionnelle dans un contexte projet Data. Rigoureux, proactif et autonome vous restez en veille technologique et êtes force de proposition. Vous êtes capable de prendre de la hauteur et vous adapter aux enjeux du projet.Avantages à travailler chez JEMSUne JEMS Académie au service de votre montée en compétences (formations et certifications sur les technologies de pointe)Un accompagnement personnalisé et un management de proximité pour vous proposer des évolutions de carrièreUne intégration dans des communautés techniques et de pratiques JEMS (encadrement par des experts, échanges sur les bonnes pratiques, favoriser l'innovation...) Une entreprise reconnue ""Great Place To Work""Des évènements et séminaires inoubliables, des soirées d'agence convivialesMobilitéUne mobilité nationale et internationale pour vous accompagner dans vos projets de vie.DiversitéLe Groupe JEMS porte fièrement sa valeur ""Diversité"" en se mobilisant pour l'inclusion et l'égalité des chances et en luttant contre toutes formes de discrimination.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,ANFSI - Agence du numérique des forces de sécurité intérieure,"Issy-les-Moulineaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-anfsi-agence-du-num%C3%A9rique-des-forces-de-s%C3%A9curit%C3%A9-int%C3%A9rieure-3792963686?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=O%2ByzyH%2B7zQkGfGYHLp9tYg%3D%3D&position=9&pageNum=6&trk=public_jobs_jserp-result_search-card,"Vos activités principales : ACHEMINEMENT DE LA DONNÉE :• Recueillir les besoins métiers des différentes unités demandeuses et utilisatrices de solutions de collecte et stockage de la donnée.• Développer les solutions techniques de collecte de la donnée via des API.• Développer des solutions techniques de stockage de la donnée• Réaliser les tests unitaires et d’intégration.• Mettre en place et maintenir les batchs, c’est-à-dire les automatisations d’une série de traitements.MISE À DISPOSITION DES DONNÉES AUX ÉQUIPES UTILISATRICES :• Industrialiser et automatiser le nettoyage de la donnée selon les spécifications retenues.• Gérer, maintenir et documenter de multiples bases de données (via l’importation de données externes en open data ou de données internes par exemple).• Gérer le cycle de vie de la donnée conformément aux directives inscrites dans le RGPD.• Assurer le suivi de production et la maintenance.SUIVI DES PROJETS DE DÉVELOPPEMENT :• Établir les spécifications techniques à partir de l’analyse des besoins.• Reporter l’activité auprès du chef de projet.ACTIVITÉS ÉVENTUELLES :• Automatiser la création de tableaux de bord aux équipes métiers (envoi de fichiers via des applications dédiées).• Assurer une veille technologique sur les outils big data.• Écrire la documentation relative aux bases de données (règles de gestion, dictionnaire des variables…).Votre environnement professionnel : Activités du service L’ANFSI (agence du numérique des forces de sécurité intérieure) est chargée de piloter et de conduire les projets de systèmes d’information, de communication, de commandement et des moyens technologiques connexes dédiés aux utilisateurs de la sécurité publique.Composition et effectifs du service L’ANFSI (agence du numérique des forces de sécurité intérieure) est composé de six directions :la Direction des Supports Opérationnels, la Direction de la sécurité et de l’architecture, la Direction de l’appui à l’investigation, la Direction des applications d’appui au commandement, la Direction des communications tactiques, et la Direction de la proximité et de l’appui à l’innovation.L'effectif est composé de personnels de la police et de la gendarmerie nationales ainsi que de contractuels.La section de mise à disposition des données, au sein de laquelle le poste est ouvert, est composée de 9 postes. Son activité principale consiste à récupérer les données métier des logiciels de rédaction de procédures des forces de sécurité intérieure et les mettre à disposition d’applications tierces, comme le fichier des personnes recherchées, le fichier des objets et véhicules volés, le traitement des antécédents judiciaires et ce au travers d’outils à moderniser.Liaisons hiérarchiques Chef de section et chef de département et adjoint.Liaisons fonctionnellesToutes directions DGPN-DGGN-DNUMVos compétences principales mises en œuvre :Connaissances techniquesAvoir des compétences en informatique - bureautique niveau maîtrise requisConnaître l'environnement professionnel niveau maîtrise à acquérir Savoir-faireSavoir analyser niveau expert requisSavoir manager niveau maîtrise requisSavoir rédiger niveau pratique requisAvoir l'esprit de synthèse niveau maîtrise requisSavoir s'organiser niveau maîtrise requisSavoir travailler en équipe niveau maîtrise requisSavoir-être avoir le sens des relations humaines niveau maîtrise requissavoir s'adapter niveau expert requissavoir communiquer niveau maîtrise à acquérirsavoir s'exprimer oralement niveau maîtrise à acquérirAutres : Conception des applications, Intégration des systèmes, Tests, Déploiement de solutions, Gestion de l’information et de la connaissance, Gestion des changements métiers, Développement d’une stratégie et gestion de la sécurité de l’information, Développement d’une stratégie et gestion de la qualité informatiqueVos perspectives :Dans un contexte d’accélération de l'évolution du numérique et des besoins de réactivité associés : Enrichissement du réseau professionnel, approfondissement des connaissances et expérience professionnelles, maîtrise des procédures et compétences « métier » de la GN/PN. Implication dans la mise en place de projets innovants (PN/GN) et transverses. S’ouvrir aux nouvelles méthodologies de conduite de projet. Durée attendue sur le poste : 3 ansSpécificités du poste / Contraintes / Sujétions : Régime hebdomadaire 39 h – 25 CA – 22 RTT Les candidat.e.s pourront être soumis à une enquête administrative de sécurité sur le fondement de l'article L.114-1 du code de la sécurité intérieure.Localisation géographique : 4, rue Claude Bernard - 92130 Issy-les-Moulineaux


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - IDF H/F,Expleo Group,"Yvelines, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-idf-h-f-at-expleo-group-3732218304?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=a9g1nf29X81CzBeouLPefw%3D%3D&position=10&pageNum=6&trk=public_jobs_jserp-result_search-card,"En savoir plus  Soyez vous-même.  Devenez qui vous voulez. Acteur mondial de l’ingénierie, de la technologie et du conseil, Expleo accompagne des entreprises reconnues dans leur innovation afin d’accélérer leur réussite.Nous nous appuyons sur plus de 40 ans d’expérience dans le développement de produits complexes, l’optimisation des processus de fabrication et la performance des systèmes d’information.Notre expérience sectorielle nous permet d’apporter à nos clients une expertise approfondie propre à stimuler l’innovation à chaque étape de la chaîne de valeur.Le groupe réalise un chiffre d’affaires annuel de plus d’un milliard d’euros. Expleo  est un groupe responsable qui s’engage à placer l’éthique et la diversité au centre de ses pratiques, ainsi qu’à œuvrer pour une société plus durable et plus sûre.Chez Expleo, épanouissez-vous au cœur d’une communauté de 19 000 collaborateurs hautement qualifiés qui fournissent des solutions à forte valeur ajoutée dans 30 pays.Nos postes sont accessibles aux personnes en situation de handicap.Pourquoi nous rejoindre ? Un accompagnement technique sur le terrain  Des formations continues via nos experts techniques  Des valeurs humaines entre nos collaborateurs  La diversité de nos équipes  Une montée en compétences tout au long de sa carrière  Travailler sur des projets de grandes ampleurs  Mission Notre offre ?Au sein du département Digital & Emerging Technologies, vous accompagnerez nos clients sur les enjeux liés à la Data et à la mise en production de solutions innovantes en travaillant en équipe selon la méthode Agile.Localisation ?L’opportunité se situe en Ile-de-France (75, 78, 92).Notre siège se trouve à Saint-Quentin-en-Yvelines (78).Votre rôle ?  Concevoir et optimiser des solutions de pipelines de données (On-Premise, Hybrid, Cloud)  Réaliser des audits d’architecture data et des préconisations d’évolution  Participer aux développements techniques  Répondre aux enjeux variés autour de la donnée (création/migration de datalakes, Move-to-cloud, industrialisation de produits de data science...)  Assurer le reporting technique du projet au client  Réaliser une veille technologique afin de proposer des solutions innovantes  Accompagner des ingénieurs Data juniors dans leur montée en compétences  Profil Qui êtes-vous ?Diplômé(e) d’une formation supérieure (Bac +5), vous avez une première expérience significative (3 ans exp hors études).Vos compétences ?  Expert(e) d'un ou de plusieurs langages suivants : Python, SQL, Java, Scala  Connaissance d'au moins un Cloud Provider : GCP, AWS, Azure, Snowflake, etc  Connaissance du management de bases de données (SQL, NoSQL) et de l'écosystème BigData  Connaissance des principes et des éléments de Hadoop (HDFS, Hive, HBase), d'Apache Spark et/ou de Kafka  Connaissance des principes du CI/CD (ex : Git)  Connaissances des outils de virtualisation, de conteneurisation (Docker) et d'orchestration (Kubernetes)  Intérêt pour les architectures microservices (REST API's)  Anglais courant Quels sont nos avantages ? Politique interne sur le télétravail  CSE  13 RTT  Tickets restaurant  Prévoyance Santé  Compte Epargne temps  Prime de vacances  Prime de cooptation Quel est notre process de recrutement ?Vous êtes contacté par un spécialiste du recrutement lors d’un échange téléphonique.À la suite de cela, nous organisons un entretien à la fois technique et RH.Une décision peut être prise dès cet entretien pour une embauche.Quoi qu’il arrive, vous aurez un retour de notre part.Vous souhaitez en savoir plus sur nos activités =>  EXPLEOLa localisation des postes n’est qu’indicative, une mobilité géographique sur le territoire national peut être requise si la mission client le nécessite ou si une nouvelle mission est proposée . A bientôt dans nos équipes !  😊


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer senior H/F,C2S,"Issy-les-Moulineaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-h-f-at-c2s-bouygues-3804562963?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=28okjDhxrC8uIaByIVCRyw%3D%3D&position=11&pageNum=6&trk=public_jobs_jserp-result_search-card,"MissionsAu sein de la Direction Digital & Data Factory, vous intègrerez le pôle Pilotage & Transformation. Vous aurez pour mission d’aider nos clients à venir à bout de leurs problèmes de qualité de données, de validation de la conformité de données aux règles de gestion définies par leurs directions métiers.  En tant que Data Engineer, vous aurez notamment pour responsabilités de :Construire des pipelines de données en ayant recours à des technologies et langages variés (TALEND, SnowFlake, Power BI, Python…),Participer à l’étude de nouvelles solutions Data, Mener des études de faisabilité, Travailler à l'amélioration continue des pipelines (Bonnes pratiques, optimisations,…), Challenger les équipes dans leurs réalisations et travailler à l'amélioration des abaques, Participer et encadrer les exercices de Code Review, Accompagner des projets d'industrialisations Data Science (Dataiku,,...), Piloter des projets en lien avec les MOA, nos prestataires ou nos centres de développement externes,Participer à l'animation de l'équipe autour de son delivery et sa montée en compétence. Déplacements ponctuels en régions à prévoir.Profil  Vous êtes diplômé(e) d’une école d’ingénieur ou d'un autre diplôme Bac+5 lié à l'informatique et la data et vous avez au moins 5 ans d’expérience sur des problématiques de data engineering (construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données…) ; • Anglais professionnel • Vous travaillez en ayant une culture projet en mode AGILE • Vous disposez de solides connaissances sur les architectures de données et le cloud. • Vous avez de l’expérience sur un ou plusieurs environnements cloud (Azure, AWS…) ; • Vous disposez de bonnes compétences en Python, SQL • Vous avez travaillé à l'industrialisation de projet Data et avez des connaissances Data OPS / QOS - QOD Toutes nos opportunités professionnelles sont accessibles aux personnes en situation de handicap. Si vous nécessitez des aménagements spécifiques, nous vous invitons à nous en informer durant le processus de recrutement.En devenant membre de C2S, vous intégrez également la Communauté Informatique du Groupe Bouygues, BYTECH.Cette communauté dynamique favorise l'innovation, l'apprentissage et encourage le partage. Elle regroupe 3 200 collaborateurs issus de divers métiers de l'informatique et du digital au sein du Groupe.🚀 Êtes-vous prêt à embarquer dans l'aventure C2S Bouygues ? Postulez dès maintenant !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Mailinblack,"Marseille, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mailinblack-3794178809?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=CRRgILD4unrvriC%2FQF%2Fm4A%3D%3D&position=12&pageNum=6&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?   Basée à Marseille, Mailinblack est une société française en pleine expansion, et la première en cybersécurité de la région Sud à intégrer le palmarès Great Place to Work® ☀️ ☀️ Nous développons et distribuons des solutions SaaS de cybersécurité pour les professionnels depuis 20 ans. Notre mission consiste à garantir la sécurité des organisations en les protégeant contre les risques d'attaques par email, tout en formant et sensibilisant activement leurs collaborateurs à la cybersécurité.  Nous recrutons un(e) Data Engineer ! 🚀   Ton rôle ? Rattaché(e) à l'équipe Lab R&D, tu travailleras en étroite collaboration avec les Data Scientists, les équipes de développement, infrastructure et produit. Ton rôle sera d'améliorer et de maintenir le socle de données Big Data aux sources de données variées : emails (5 milliards par an !), pages web et bases de données Produit/CRM, afin de permettre aux Data Scientists d’améliorer nos systèmes de détection des menaces. Tu apporteras aux Data Scientists et à l’équipe Produit ton expertise en traitement et en analyse à de la donnée à grande échelle.  Tes missions ?   Déterminer les structures de données nécessaires aux besoins de recherche du Lab en collaboration avec les Data Scientists et l’équipe infrastructure. Développer, déployer et maintenir les services et outils constituant le pipeline de collecte et d’enrichissement des données. Contribuer activement aux bonnes pratiques en matière de sécurité. Veiller au respect des règles de traitement des données à caractère personnel, en accord avec les normes et régulations en vigueur. Mettre en place, industrialiser et maintenir les processus liés à l'intégration de données, tels que l'orchestration, le monitoring, les API, ainsi que les tests unitaires et d'intégration.  Environnement technique : Python, Go, Spark, Databricks, Azure (VM, ADLS, Event Hubs, Service Bus, Synapse, Cosmos DB, DevOps pipeline), MySQL, Git, Jenkins, Docker, Kubernetes, ELK, API REST, SMTP.     Ton profil ?   ✅ Expérience de 2 ans minimum en Data Engineering sur de gros volumes de données et en développement de pipeline basées sur des micro-services ✅ Bonne connaissance des technologies de Big Data : stockage (Data lakes, stockage distribué, bases de données) et traitement distribué à grande échelle (Spark, Event Hubs, Service Bus, etc.) ✅ Maîtrise du développement en Python et PySpark ✅ Maîtrise des processus de mise en production des modèles de Machine Learning ✅ Connaissance des systèmes de bases de données SQL ✅ Connaissances des approches d'intégration et de déploiement continu (Jenkins, GitLab CI/CD, Azure DevOps Pipeline)  🌟 Bonus : Connaissances dans les domaines de la messagerie (protocole SMTP et méthodes de filtrage) et web. Connaissance des environnements de micro-services (Docker, Kubernetes) et une expérience sur Azure.  Déroulement des entretiens  📱 Premier échange de 20 minutes par téléphone avec Alexandre, notre Talent Acquisition 💬 Entretien en visio avec Achraf, Manager de l’équipe IA/Data, et Alexandre 💻 Test technique 👀 Rencontre avec l’équipe Data   Les + chez Mailinblack :  Des bureaux sympas en plein centre de Marseille, au soleil et à deux pas du Vieux Port et des Calanques ☀️ ☀️ 7 jours de congés payés supplémentaires Une partie de la semaine en télétravail Une culture d’entreprise qui prône l’autonomie, la responsabilité et la bienveillance Un plan de développement de compétences Et aussi : des chèques vacances, des paniers de fruits dans la cuisine, des repas d’équipes, des journées massage sur site et des événements canons ! Et bien sûr une bonne mutuelle (Malakoff), une épargne salariale, une participation aux transports en commun (50%) Impatient(e) d'intégrer une équipe soudée et une entreprise en pleine évolution ?


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
DATA Engineer (H/F),METEOJOB by CleverConnect,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3805867739?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=QyoNs9%2FfrZs4lNKAIznhFA%3D%3D&position=13&pageNum=6&trk=public_jobs_jserp-result_search-card,"EntrepriseAdsearch vous propose des milliers d''opportunités de carrières dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Intérim et Freelance sur notre site internet !Description Du PosteIntroduction !En Bref : CDI - DATA Engineer (H/F) - Nantes - 50K-55K - Télétravail partiel - Editeur de logicielSolenn dAdsearch, Consultante spécialisée IT (Infrastructure, Data, Sécurité), recrute pour lun de ses partenaires, Editeur de logiciel nantais, un DATA ENGINEER H/F.Vos missions à réaliser !Dans un contexte de remplacement, vous devenez le nouveau DATA Engineer de lentreprise et endossez les responsabilités suivantes : Construire des modèles et schémas pour répondre aux besoins Procéder à de lanalyse DATA pour les clients Intégrer un nouvel outil BI Création de rapports personnalisés et rédaction de documentation Cibler des opportunités de communication DATA Contribuer à lamélioration continue et les projets stratégiques à venirVotre process de recrutement (peut-être réalisé en 2 semaines!)! Entretien n°1 en visio avec votre Consultante Adsearch Entretien n°2 par téléphone avec le Service RH Entretien n°3 en présentiel avec le Responsable Technique Entretien n°4 en présentiel avec la Direction GénéraleDescription Du ProfilVotre profil attendu ! Vos connaissances techniques : Outil BI, ETL, outils modèles et statistiques.SQL, SGBD, Looker, Vues et NoSQL. Vos compétences acquises : Au minimum 2 ans d'expérience sur l'ingénierie DATA. Aisance de compréhension et d'expression en Anglais. Votre posture professionnelle : Curieux, force de proposition, esprit d'analyse et d'équipe, guidé par l'amélioration continue !Vos leviers de motivations !Poste en autonomie & responsabilité complèteCadre de travail convivialEntreprise à taille humaine, dynamique et réputéeTélétravail partiel De nombreux avantagesCe poste est peut-être LE VOTRE alors candidatez sans tarder pour vous positionner et échanger avec Solenn d'ADSEARCH !
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer débutant - Réalisation de use cases et évaluation de plateforme No/Low code F/H,TotalEnergies,"Saint-Martin-d’Hères, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9butant-r%C3%A9alisation-de-use-cases-et-%C3%A9valuation-de-plateforme-no-low-code-f-h-at-totalenergies-3801952917?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=hyR7zwqJZWyDmkSyDRKcGQ%3D%3D&position=14&pageNum=6&trk=public_jobs_jserp-result_search-card,"Profil du candidat Débutez votre carrière par une expérience stimulante au cœur d’équipes internationales, engagées dans la transition énergétique !Nous recherchons pour une durée de 12 mois au CSTJF à PAU (64), un(e) Data Engineer débutant(e) - Réalisation de use cases et évaluation de plateforme No/Low code F/HVous êtes récemment diplômé(e) d'un Master 2 ou d’un diplôme d'ingénieur avec une spécialisation en Data Engineering, et êtes à la recherche d'une opportunité dans un environnement international et innovant ?Vous avez des compétences en programmation informatique  et en  Data Science ?Vous êtes familier(e) avec l’environnement Linux ?Vous êtes compétent(e) en programmation Python et en langage SQL / BDD ?Vous avez de solides connaissances en Data processing, Distributed computing, Data ingestion et en intégration?Vous faites preuve d' autonomie , de rigueur , et êtes force de proposition  ?Vous maitrisez l’ anglais professionnel ?Nous vous proposons un Contrat de Professionnalisation Temps Plein qualifiant de 12 mois (100% en entreprise) incluant 15% de formation interne (métier, linguistique, outils…) dispensée par des organismes sélectionnés par TotalEnergies. Ce contrat vous permettra d’acquérir une année d’expérience professionnelle tout en étant formé aux spécificités de votre métier en lien avec les activités de la Compagnie. Un réel atout pour booster votre employabilité. Activités A cette attention, voici les principales missions de votre activité : Développer et industrialiser des solutions basées sur l'intelligence artificielle pour le traitement des documents et des illustrations. Cela implique le développement Python, le refactoring de code et la création de packages. Vous participerez également à la phase exploratoire au côté du Data Scientist et notamment à la collecte, au traitement et à l'analyse de données (principalement images et textes).  Accompagner les équipes du DataLab dans la réalisation de cas d'usage sur des plateforme de Data Science No/Low code et contribuer à l'évaluation de différentes plateformes. D'un point de vuetechnique, vous participerez à : La création et l'exécution de cas de test sur la plateforme  Des tests d'appels API externes permettant l'inférence de modèles IA  Tester la capacité à intégrer différentes sources de données dans la plateforme  Évaluer l'interopérabilité  Développer des cas d'usage en Data Science  La collecte et la préparation de données au côté de Data Scientists  Contribuer à l'industrialisation de nos solutions  Contexte et environnement TotalEnergies est un acteur majeur de l'énergie dans le monde. Dans ce contexte, l’objectif est de fournir une solution innovante sous la forme d'une plateforme de Data Science No/Low code, destinée à des ingénieurs ayant une bonne connaissance de leurs données mais une moindre appétence pour la programmation. Cette plateforme vise à faciliter et rendre autonomes les ingénieurs dans la réalisation de leurs propres cas d'usage et l'exploitation de leurs données, en offrant des fonctionnalités intuitives et conviviales.Le poste de Data Engineer s'inscrit également dans un contexte dynamique axé sur l'optimisation des processus de Data management et de contribution aux équipes en charge du développement de moteurs de recherche intelligents.En tant que Data Engineer, vous travaillerez au sein d'une équipe dynamique et multidisciplinaire (Data Managers, Chefs de projets systèmes d'information, Spécialistes IT, Product Owners, Data Scientists et Data Engineers expérimentés), collaborant étroitement avec les utilisateurs finaux pour évaluer les capacités de la plateforme et réaliser des cas d'usage. Vous évoluerez dans un environnement stimulant et axé sur l'innovation, contribuant ainsi à renforcer les capacités d'analyse de données au sein de la Compagnie, et serez invité(e) aux différents points de rencontres des équipes : avancements, arbitrages, partenaires...En conséquence, vous apporterez une véritable valeur ajoutée par votre analyse et vos réalisations. Vous bénéficierez de toute l'expérience et l'accompagnement d'une équipe dynamique en mode ""start-up"", AGILE et flexible dans sa méthodologie.Alors, n'attendez plus... Postulez pour rejoindre les équipes TotalEnergies à Pau ! Informations supplémentaires Pour postuler à cette offre, vous devez impérativement posséder, à la date d’embauche, un titre de séjour valide pour la période couverte par cette offre (minimum 13 mois). Attention, la conclusion de ce contrat de professionnalisation ne permet pas la délivrance d’un titre de séjour (article R.52221-6 du Code du travail). Ce poste ne s'adresse pas aux personnes recherchant une alternance avec une école ou une formation diplômante, mais aux personnes récemment diplômées à la recherche d'un première expérience.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software engineer (x/f/m),Doctolib,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-x-f-m-at-doctolib-3788675399?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=UH6Zp%2FcvP0yPMh%2BynL1qRg%3D%3D&position=15&pageNum=6&trk=public_jobs_jserp-result_search-card,"What We DoJoin a team of passionate and hard working entrepreneurs to transform healthcare!Working in the tech team at Doctolib involves building innovative products and features to improve the daily lives of care teams and patients. We work in feature teams in an agile environment, while collaborating with product , design, and business teams.What You’ll DoWe are looking for a Software Engineer to join the Patient Identity Management team in the Patient Health Platform domain.As a Software Engineer, your mission will be to help Doctolib provide seamless access to healthcare for everyone. You will be working in a product team that develops foundational capabilities and services that enable patients and their relatives to access secure accounts at any time to manage their health, administrative and personal information.Your responsibilities include but are not limited to:Collaboratively design, implement and maintain high quality solutions delivering value to our users.Contribute to the modularization of the team’s domain enabling Doctolib to scale.Handle the day to day team operations (Improve monitoring, Fix bugs and security issues)Provide thoughtful and constructive feedback during pair programming sessions.Who You AreIf you don’t meet all the requirements below but believe this opportunity matches your expectations and experience, we still encourage you to apply!You have in-depth knowledge of Ruby on Rails.You have experience with React or similar Javascript frameworks.You have experience navigating technical debt, comfortably balancing between consciously incurring legacy and actively reducing it.You are product-oriented and can suggest tradeoffs to balance business needs with technical constraints.You have experience in monitoring the health of the system you are building and actively contribute to its improvement.We’ll like you even more if:You are familiar with Domain Driven Design.You are an advocate for pair and mob programming.What We OfferA stock-option program for each DoctoliberA competitive health insurance paid 100% by the company A dedicated onboarding program - the Doctolib AcademyMental health and wellbeing offer in partnership with moka.careThe Doctolib Parent Care Program, including extended parental leave, meet-ups and inspiring conferencesA subsidy from the work council to refund part of the membership to a sport club or a creative class Subsidy for lunch and various food offers in our offices A flexible workplace policy offering both hybrid and office-based mode Flexibility days allowing to work in EU countries and the UK 10 days per year The interview process Recruiter InterviewFeature Building Interview System Design InterviewBehavioral InterviewOffer!If you would like to find out more about tech life at Doctolib, feel free to read our latest Medium blog articles!At Doctolib, we believe in improving access to healthcare for everyone - regardless of where you come from, what you look like. This translates into our recruitment process: Doctolib is an equal opportunity employer. We don't just accept diversity at Doctolib, we respect and celebrate it!The more diverse ideas are heard, the more our product will truly improve healthcare for all. You are welcome to apply to Doctolib, regardless of your gender, religion, age, sexual orientation, ethnicity, disability, or place of origin. If you have a disability, let us know if there's any way we can make the interview process smoother for you! All the information transmitted via this form is processed by Doctolib for the purpose of managing applications. For more information on how Doctolib processes your application data, click here.If you wish to exercise your rights or if you have any questions about the processing of your data, you can write to us at hr.dataprivacy@doctolib.com.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F/NB) - Paris,Keyrus,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-nb-paris-at-keyrus-3799373891?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=8FRBBXs%2BXfqxHQcmpJ9NTg%3D%3D&position=16&pageNum=6&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ? Une success story dans la Data et le Digital !Notre mission ? Des projets à forte valeur ajoutée pour accroître la performance et la compétitivité des entreprises, faciliter et accélérer leur transformation.Notre Expertise Depuis Plus De 20 Ans ? Le Conseil Et L'intégration De Solutions Innovantes Autour De Trois DomainesData IntelligenceBusiness Intelligence, Big Data & Analytics, Intelligence ArtificielleDigital ExperienceConseil, Stratégie & Performance DigitalesConseil en Management & TransformationStratégie & Innovation, Pilotage de la Performance & Accompagnement des ProjetsNous sommes plus de 3000 talents sur plus de 20 pays et 4 continents. Notre ADN ? Innover et entreprendre.Le JobLes principales missions qui vous seront confiées seront les suivantes:Mettre en œuvre divers outils de développement, de test, d'automatisation et d'infrastructure informatique.Définir et paramétrer les processus de développement, de test, de publication, de mise à jour et de support pour les opérations DevOps.Avoir les compétences techniques pour examiner, vérifier et valider le code logiciel développé dans le cadre du projet.Surveiller les processus tout au long du cycle de vie pour leur adhésion et mettre à jour ou créer de nouveaux processus pour l'amélioration et la minimisation du gaspillage.Encourager et créer des processus automatisés dans la mesure du possible.Identifier et déployer des mesures de cybersécurité en effectuant en permanence une évaluation des vulnérabilités et une gestion des risques.S'efforcer d'améliorer continuellement et de construire une intégration continue, un développement continu et un pipeline de déploiement constant (CI/CD Pipeline)Gestion des rapports périodiques sur les progrès à la direction et au client.Le ProfilVous avez 5 ans d'expérience.Vous parlez anglais couramment.Pourquoi nous rejoindre ? Pour intégrer une communauté d’experts curieux et passionnés et évoluer dans un environnement multiculturel, formateur et favorisant la mobilité internationale.Parce que vous êtes #DataGeek, #DigitalAddict, #InnovationLover !#KeyrusRocks #YouRockKeyrus est une entreprise où il fait bon vivre et travailler !DécouvrezLa vie chez Keyrus en 60 secKeyrus en 3 motsNos animations pour nos collaborateurs sur Facebook et sur Instagram.Notre vidéo par Welcome To The Jungle
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Onepoint,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-onepoint-3619446219?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=aI1C0TiXMmjXol9eCz2oAQ%3D%3D&position=17&pageNum=6&trk=public_jobs_jserp-result_search-card,"Rejoignez notre communauté TechStud.io qui représente un collectif passionné de technologies proposant la création de solutions efficientes à un monde en quête de nouvelles expériences et de services innovants.Nous apportons notre vision technique pour aider nos clients à réaliser leur transformation numérique informatique vers des applications critiques à grande échelle.Votre rôleVous avez au moins 2 ans sur la conception et la mise en œuvre de solutions Data, vous avez une spécialisation sur l’une des stacks technologiques (Azure, AWS, GCP, Informatica, Talend, Spark, Databricks, Kakfa, ELK …) et souhaitez continuer à la développer, venez nous rejoindre dans le rôle de Data Engineer.Vous interviendrez sur nos projets de transformation en accompagnant des équipes de développeurs, vous serez le garant de la bonne qualité du code et de l’efficacité des solutions choisies, le tout dans un environnement Agile.Vous contribuerez également activement au développement ambitieux de notre équipe Data.Notre accompagnementAu sein de onepoint, vous continuerez à développer votre expertise technique grâce aux formations certifiantes que nous vous proposons tout au long de votre carrière, vous bénéficierez d'un écosystème de partenaires technologiques de premier plan et partagerez continuellement avec nos communautés d’experts au travers des nombreux événements que nous organisons régulièrement autour de la Data.Processus de recrutementOnepoint a mis en place un processus de recrutement établi en fonction de vos compétences, vos expériences et votre séniorité.Selon votre expérience, onepoint vous demandera de démontrer concrètement vos savoir-faire au cours des entretiens qu’il soit méthodologique, métier, tech ou créa.#TechInformations complémentairesNous proposons :   Des missions et projets passionnants ; Une communauté de consultants active ; Un cabinet de conseil différent (« Startup spirit »), très qualitatif et à taille moyenne ; Une opportunité unique de développement et d’évolution dans un esprit communautaire ; Des formations adaptées ainsi qu’une bonne dose de partage de connaissances, afin d’apprendre au quotidien ; Faire partie d’une communauté de technophiles souhaitant partager leurs connaissances via des événements internes et externes.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Développeur de big data/Développeuse de big data,GROUPE ALLIANCE,"Île-de-France, France",https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-de-big-data-d%C3%A9veloppeuse-de-big-data-at-groupe-alliance-3772574265?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=ewHKhEXnrcA9tIXZdVLXyQ%3D%3D&position=18&pageNum=6&trk=public_jobs_jserp-result_search-card,"Ce que tu recherches :Evoluer au sein d’une équipe dynamiqueParticiper à des projets innovants d’envergureRelever des défisDonner un nouveau souffle à ta carrièreAlors nous avons la mission idéale pour toi.Au sein d’acteurs majeurs du secteur Banque, Assurance, Retail ou Energie, tu participeras à des projets d’envergure, de refonte, de migration, et / ou à des évolutions majeures du SI du client : Analyse des besoins, tu ferasSpécifications techniques, tu rédigerasL’architecture et/ou socle technique, tu définirasBonnes pratiques, tu instaurerasDe nouvelles fonctionnalités, tu développerasZéro bug, tu laisserasTon équipe, tu accompagnerasAux instances de pilotage, tu participerasQui tu es :Diplômé(e) de la formation qui va bienSurdoué(e) ou dôté(e) d’une expérience de 7 ans minimumExpert(e) sur des solutions BI : MS BI, Power BiHabile avec les outils de DatavizAu-delà des compétences techniques, tu es / as :Dynamique : tu n’aimes pas rester les deux pieds dans le même sabotAutonome : un guide du Routard te suffiraEsprit de synthèse : tu sais aller à l’essentielCapacité d’adaptation : tu es un vrai caméléonSens de la communication : les mots n’ont pas de secret pour toiForce de proposition : tu es l’Aladdin de l’informatiqueEsprit d’équipe : un pour tous et tous pour un !


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER H/F,FRG Technology Consulting,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-frg-technology-consulting-3809885372?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=hC2WEzI0R3dRWbzNm2OUnA%3D%3D&position=19&pageNum=6&trk=public_jobs_jserp-result_search-card,"FRG Consulting recrute pour l'un de ses clients, un acteur majeur du secteur immobilier basé au cœur de Lyon, un Data Engineer H/D compétent pour renforcer son équipe dynamique. L'entreprise offre un environnement de travail stimulant, des opportunités de croissance professionnelle et la possibilité de contribuer à des projets innovants dans le domaine de l'immobilier.Responsabilités: En tant que Data Engineer, vous jouerez un rôle clé dans la conception, le développement et la maintenance des infrastructures de données. Vous collaborerez étroitement avec les équipes métier pour comprendre leurs besoins, et utiliserez les technologies suivantes :Concevoir, développer et maintenir des pipelines de données performants à l'aide de process engines tels que Spark, Hadoop et Apache Airflow.Mettre en œuvre des solutions ETL avec un outil tel que Talend pour assurer la fiabilité des flux de données.Utiliser les langages de programmation SQL et Python pour le traitement et l'analyse des données.Exploiter les bases de données SQL/NoSQL, notamment PostGreSQL, et déployer des solutions ELK (Elasticsearch, Logstash, Kibana) pour l'analyse des logs.Travailler avec des technologies Big Data telles que Hadoop, Spark et Hive pour gérer et analyser de grandes quantités de données.Collaborer avec les services Cloud, en particulier Azure, AWS ou Cloud Souverain (OVH Cloud), en mettant en œuvre des notions de FinOps pour optimiser les coûts.Mettre en place la conteneurisation et l'orchestration avec Docker et Kubernetes.Utiliser des outils de développement tels que Jupyter pour la création et le partage de notebooks interactifs.Participer à l'intégration continue avec Git et Jenkins.Travailler selon les méthodes agiles, notamment Scrum et Kanban, pour assurer une collaboration efficace au sein de l'équipe.Qualifications RequisesDiplôme en informatique, génie logiciel, sciences des données ou domaine connexe.Expérience pratique avec les technologies mentionnées ci-dessus.Compétences approfondies en SQL, Python, DBT, et expérience avec un ETL tel que Talend.Connaissance des bases de données SQL/NoSQL, des outils ELK, et des technologies Big Data (Hadoop, Spark, Hive).Expérience dans le déploiement sur des fournisseurs de cloud tels que Azure, AWS ou Cloud Souverain (OVH Cloud), avec des notions de FinOps.Maîtrise de la conteneurisation et de l'orchestration avec Docker et Kubernetes.Utilisation d'outils de développement tels que Jupyter.Expérience de l'intégration continue avec Git et Jenkins.Familiarité avec les méthodologies agiles, notamment Scrum et Kanban.AvantagesEnvironnement de travail collaboratif et dynamique.Opportunités de formation continue.Possibilité de contribuer à des projets innovants dans le secteur de l'immobilier.Croissance professionnelle au sein d'une entreprise en pleine expansion.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Apache Airflow'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Senior Data Engineer,Vestiaire Collective,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-vestiaire-collective-3809825947?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=E8V4DQMHTlLwro6LUp5xOg%3D%3D&position=20&pageNum=6&trk=public_jobs_jserp-result_search-card,"Vestiaire Collective is the leading global online marketplace for desirable pre-loved fashion. Our mission is to transform the fashion industry for a more sustainable future by empowering our community to promote the circular fashion movement. Vestiaire was founded in 2009 and is headquartered in Paris with offices in London, Berlin, New York, Singapore and Hong Kong and warehouses in Tourcoing (France), Crawley (UK), Hong Kong and New York.We currently have a diverse global team of 1000 employees representing over 50 nationalities. Our values are community, activism, transparency, dedication and greatness. We are proud to be a BCorp.About The RoleVestiaire Collective is hiring a Senior Data Engineer on our data platform team, to play a crucial role in developing and enhancing our data infrastructure, driving Vestiaire Collective's mission towards a sustainable fashion industry.What You'll Do Data Platform Architecture:Design and evolve our data platform's architecture for scalable, efficient data processing and analytics. Participate in strategic planning for long-term alignment with business goalsData Integration and ModelingImplement robust, scalable data integration strategies. Optimize data models for efficient storage, retrieval, and analytics. Building ML Platform EcosystemCollaboratively develop a scalable, reliable ML platform, focusing on model serving, training, and essential MLOps features. Prioritize efficiency, automation, and best practices in MLOps. Workflow AutomationDevelop automated solutions to enhance data operations. Utilize Apache Airflow for effective data workflow management. Real-Time Data ProcessingCreate real-time data processing applications, leveraging Kafka for timely data availability. Ensure high throughput and low latency in data processing/serv. Continuous Learning and ImprovementStay abreast of the latest data engineering trends and technologies. Foster a culture of continuous learning and knowledge sharing. Required Skills PythonExpert in clean, efficient Python coding; proficient with data libraries and web frameworksSkilled in asynchronous programming. SQL: Strong in SQL syntax and query optimization. Kafka:Proficient in Kafka architecture and stream processing. ML Deployment / Optimization: Experienced in ML model deployment and MLOps principles. Required ToolingsApache Airflow: Expertise in workflow management. FastAPI/Robyn: Skilled in FastAPI/Robyn development and features. Git:Advanced knowledge in version control and CI/CD integration. Cloud Services: AWS or similar cloud experience. Data Visualization Tools: Proficient in tools like Tableau and Streamlit. Monitoring and Logging Tools: Experienced with tools like DataDog, Prometheus, and Grafana. Nice To Have SkillsTerraform/Ansible: Skills in infrastructure automation. Golang: Experience in Go programming and its ecosystem. DBT: Proficient in DBT for data warehousing. Spark/Flin: Experienced in distributed data processing. What We OfferA meaningful job with an impact on the way people consume fashion and promote sustainabilityFlexible work possibilitiesThe opportunity to do career-defining work in a fast-growing French-born scale upThe possibility to work as part of a globally diverse team with more than 50 nationalities Two days to help Project - reinforcing your activist journey and volunteer for an associationSignificant investment in your learning and growthCompetitive compensation and benefits packageAs full member of our entrepreneurial project, you will be eligible to free sharesVestiaire Collective is an equal opportunities employer


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Apache Airflow'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Atos,"Clermont-Ferrand, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-atos-3799329300?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=YEAZjnku7q2XAfSBWYJj4g%3D%3D&position=21&pageNum=6&trk=public_jobs_jserp-result_search-card,"Bienvenue chez Atos, où nous imaginons le futur de la tech.Leader international du numérique sécurisé et décarboné, Atos contribue à façonner les nouvelles technologies avec ses clients.Dans un environnement multiculturel, collaboratif et agile, nous offrons des parcours de carrière valorisants basés sur des programmes de formation, de certification et de mobilité.C’est pourquoi chez Atos, la diversité des compétences et des expériences de nos équipes nous permet, ensemble, de faire les bons choix avec nos clients, pour l’avenir de notre entreprise et de la société.LA MISSION QUE L’ON VOUS CONFIE Vous maintenir au top des nouvelles technologies les plus modernes, c’est essentiel pour vous ?Nous avons les projets ambitieux et les clients qui veulent prendre un temps d’avance.Vous aimez partager vos convictions en matière de technos pour nous faire tous progresser ? Nous sommes preneurs !Au sein d'équipes dynamiques, vous aurez pour missions principalesConseiller en architecture en gouvernance de la donnée.Intervenir dans les aspects Data Ingestion, Data Analytiques et Data Science / IA.Mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud pour les projets stratégiques de nos clients.VOTRE PROFIL POUR RÉUSSIR De formation supérieure BAC +5 en Informatique d’une Ecole d’Ingénieur ou d’un Mastère universitaire dans le domaine des sciences informatiques que vous avez complété par une expérience significative en Data Science / Data Engineering.Votre stack technique  Requis Connaissance des écosystèmes Data (NoSQL/DW/Hadoop) ELK (ElasticSearch, Logstash, Kibana), MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS…Expertise en développement Python ou Java Spring Boot.Expertise sur un des framework suivants Spark, Kafka Connect & Streams, Apache Beam.Connaissance des architectures conteneurs Docker, Kubernetes. Apprécié Connaissance d’un des services managés BigData de Google Cloud Platform / AWS / Microsoft Azure.Connaissance des approches Agile & DevOps.Compétences obligatoires Docker, KubernetesSoft SkillsPassionné(e) d’informatique en progressant et en vous tenant à jour sur toutes les technologies et architectures, vous êtes créatif(ve), autonome, rigoureux(se), curieux(se), motivé(e) et avez le sens du travail en équipe et du relationnel alors rejoignez-nous !Niveau de langue Anglais niveau intermédiaire minimum recommandé et Français exigé.Chez Atos, la diversité, l'inclusion et l’accessibilité numérique font partie intégrante de notre ADN. Découvrez nos engagements en faveur d'un environnement de travail équitable pour toutes et tous. Atos est un leader reconnu dans son secteur pour les critères environnementaux, sociaux et de gouvernance (ESG). Pour en savoir plus sur notre engagement en matière de RSE.Chez Atos, la diversité, l'inclusion et l’accessibilité numérique font partie intégrante de notre ADN. Découvrez nos engagements en faveur d'un environnement de travail équitable pour toutes et tous.   Atos est un leader reconnu dans son secteur pour les critères environnementaux, sociaux et de gouvernance (ESG). Pour en savoir plus sur notre engagement en matière de RSE, cliquez ici.Choose your future. Choose Atos.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer,Mailinblack,"Marseille, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mailinblack-3794774027?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=r9jqop%2FZPOedibvTllD7fQ%3D%3D&position=22&pageNum=6&trk=public_jobs_jserp-result_search-card,"À propos de nousQui sommes-nous ? Basée à Marseille, Mailinblack est une société française en pleine expansion, et la première en cybersécurité de la région Sud à intégrer le palmarès Great Place to Work® ☀️ ☀️Nous développons et distribuons des solutions SaaS de cybersécurité pour les professionnels depuis 20 ans. Notre mission consiste à garantir la sécurité des organisations en les protégeant contre les risques d'attaques par email, tout en formant et sensibilisant activement leurs collaborateurs à la cybersécurité.En pleine croissance, nous recrutons un(e) Data Engineer ! 🚀MissionTon rôle ?Rattaché(e) à l'équipe Lab R&D, tu travailleras en étroite collaboration avec les Data Scientists, les équipes de développement, infrastructure et produit. Ton rôle sera d'améliorer et de maintenir le socle de données Big Data aux sources de données variées : emails (5 milliards par an !), pages web et bases de données Produit/CRM, afin de permettre aux Data Scientists d’améliorer nos systèmes de détection des menaces. Tu apporteras aux Data Scientists et à l’équipe Produit ton expertise en traitement et en analyse à de la donnée à grande échelle.Tes missions ? Déterminer les structures de données nécessaires aux besoins de recherche du Lab en collaboration avec les Data Scientists et l’équipe infrastructure. Développer, déployer et maintenir les services et outils constituant le pipeline de collecte et d’enrichissement des données. Contribuer activement aux bonnes pratiques en matière de sécurité. Veiller au respect des règles de traitement des données à caractère personnel, en accord avec les normes et régulations en vigueur. Mettre en place, industrialiser et maintenir les processus liés à l'intégration de données, tels que l'orchestration, le monitoring, les API, ainsi que les tests unitaires et d'intégration. Environnement technique : Python, Go, Spark, Databricks, Azure (VM, ADLS, Event Hubs, Service Bus, Synapse, Cosmos DB, DevOps pipeline), MySQL, Git, Jenkins, Docker, Kubernetes, ELK, API REST, SMTP.ProfilTon profil ? ✅ Expérience de 2 ans minimum en Data Engineering sur de gros volumes de données et en développement de pipeline basées sur des micro-services✅ Bonne connaissance des technologies de Big Data : stockage (Data lakes, stockage distribué, bases de données) et traitement distribué à grande échelle (Spark, Event Hubs, Service Bus, etc.)✅ Maîtrise du développement en Python et PySpark✅ Maîtrise des processus de mise en production des modèles de Machine Learning✅ Connaissance des systèmes de bases de données SQL✅ Connaissances des approches d'intégration et de déploiement continu (Jenkins, GitLab CI/CD, Azure DevOps Pipeline)🌟 Bonus : Connaissances dans les domaines de la messagerie (protocole SMTP et méthodes de filtrage) et web. Connaissance des environnements de micro-services (Docker, Kubernetes) et une expérience sur Azure. Déroulement des entretiens  📱 Premier échange de 20 minutes par téléphone avec Alexandre, notre Talent Acquisition💬 Entretien en visio avec Achraf, Manager de l’équipe IA/Data, et Alexandre 💻 Test technique  👀 Rencontre avec l’équipe DataLes + chez Mailinblack : Des bureaux sympas en plein centre de Marseille, au soleil et à deux pas du Vieux Port et des Calanques ☀️ ☀️ 7 jours de congés payés supplémentaires Une partie de la semaine en télétravail Une culture d’entreprise qui prône l’autonomie, la responsabilité et la bienveillanceUn plan de développement de compétences Et aussi : des chèques vacances, des paniers de fruits dans la cuisine, des repas d’équipes, des journées massage sur site et des événements canons !Et bien sûr une bonne mutuelle (Malakoff), une épargne salariale, une participation aux transports en commun (50%)Impatient(e) d'intégrer une équipe soudée et une entreprise en pleine évolution ?
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
(Senior) Data Engineer,Mirakl,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3698388646?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=RVVb%2B9npHdunN59bjkEkdg%3D%3D&position=23&pageNum=6&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l'économie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'accélérer de façon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avancée, sécurisée et évolutive leur permettant de digitaliser leur activité et d'élargir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacité, offrir une expérience d'achat personnalisée à leurs clients, et augmenter leurs profits grâce au retail media. Basée à Paris et Boston, Mirakl est certifiée Great Place to Work.A propos de Mirakl LabsNos équipes techniques et produits, nommées Mirakl Labs, sont principalement réparties entre nos 2 hubs situés à Paris et à Bordeaux. Elles collaborent au quotidien afin d'adresser les problématiques de nos clients et utilisateurs en répondant à différents challenges liés aux nouvelles fonctionnalités, à la scalabilité, la sécurité et l'ergonomie…Elles opèrent en mode agile et s'organisent en Squads composées d'un Squad Lead, de 5 développeurs, d'un Product Manager et d'un QA. Chaque Squad est spécialisée sur un scope fonctionnel afin de concevoir et réaliser de nouvelles features, leurs évolutions et des APIs (avec un découpage en micro-services). Nos équipes Infrastructure, Architecture, Sécurité, Documentation, Product Design, Data et Support opèrent en transverse en apportant leur expertise et de la cohérence sur l'ensemble des produits.Toutes les équipes sont responsables de leur périmètre et chacun des collaborateurs apporte son expérience et ses idées. Innovation, feedback et implication dans les prises de décision sont au cœur de notre philosophie.Et pour favoriser ce partage avec d'autres passionnés, nous sommes sponsors, speakers, et hôtes de différents événements, meetups, et associations de la scène Tech en France. Au cours des dernières années, nous avons participé à des événements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commerçants à travers le monde. Cette solution gère et produit de gros volumes de données qui présentent des challenges extrêmement intéressants pour les spécialistes de la donnée (produits, commandes, clients, niveaux de stock, prix, messages, appels API, données de navigation, séries temporelles, données géolocalisées etc.).En tant que (Senior) Data Engineer au sein de l'équipe Data Mirakl, vos principales missions seront de :contribuer à l'enrichissement de la Data Platform (ETL)améliorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inférence real time etc.)Intégré(e) dans une équipe de spécialistes de la donnée (data engineers, machine learning engineers, data scientists, data analysts), vous êtes un des acteurs clés pour garantir la place de Mirakl comme solution dominante sur son marché.Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, AnsibleAu quotidien, vous allez :Participer à la définition et à l'implémentation d'une architecture performante, robuste, scalable et aux coûts maîtrisés pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (évaluation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et améliorer la CI/CD de l'équipe en collaboration avec l'équipe SREAssurer la montée en compétence des membres de l'équipe sur les sujets de MLOps et Data EngineeringRéfléchir à la meilleure façon d'intégrer les données Google Analytics dans la data platformPartager ses connaissances et présenter les travaux devant toutes les équipes LabsCe qu'on peut vous apporter :Des projets data driven, divers et variés (traitements massifs d'images, de textes, time series etc.) pour des produits différents de MiraklUne culture orientée sur la veille technologiqueDes projets qui ont un vrai impact business devant être déployés sur des centaines de clients dans un contexte multilingueQuelques exemples de sujets en cours :Enrichissement des données produit à partir des images et des descriptionsModération automatique des produitsMapping automatique des données produitIdentification des produits à fort potentielsDétection de comportements frauduleuxSentiment analysis sur les messages échangés entre clients et vendeurs et dans les évaluationsDétermination de prix optimauxMonitoring de la qualité de service des vendeursDes applications d'inférence en synchrone de nos modèles de MLVous aimerez ce job si :Vous êtes passionné(e) par la data et les technologies modernes permettant d'en tirer partieVous vous intéressez à la data science et avez des connaissances générales sur les algorithmes de Machine LearningVous avez un background en développement et avez évolué dans un environnement DataVous avez a minima 4 ans d'expérience en environnement Machine Learning et/ou DataVous avez mis en production avec succès des applications Big Data faisant appel à du Machine Learning, du NLP, du traitement d'images dans des projets d'envergure, à fort volume de donnéesVotre maîtrisez Python, êtes un pro des frameworks data de la fondation Apache et êtes à l'aise dans un environnement AWSVous maîtrisez au moins un outil d'orchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous présentez vos travaux de manière simple et accessibleVous faîtes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et françaisLes plus pour le poste :Vous avez une expérience significative dans le domaine du e-commerceVous avez déjà mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez déployé des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de données avec une approche CDC à l'aide de Debezium ou autreVous maîtrisez Java/ScalaMirakl est engagée en faveur de la diversité, de l'égalité des chances et de l'inclusion. Nous célébrons nos différences car nous sommes convaincus que les qualités visibles et invisibles de chaque Mirakl Worker sont une source de force et d'innovation. Dans le cadre de cet engagement, nous étudions toutes les candidatures sans distinction de : genre, ethnicité, religion, orientation sexuelle, handicap, âge ou toute autre caractéristique protégée par la loi.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
"Data Engineer | Python, Airflow, Sql | Start up dans la medtech",Octopus IT - Expert du recrutement tech,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-airflow-sql-start-up-dans-la-medtech-at-octopus-it-expert-du-recrutement-tech-3664564642?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=yVcjTHbUQf6pScB4pYVDOg%3D%3D&position=24&pageNum=6&trk=public_jobs_jserp-result_search-card,"La sociétéCette startup de la MedTech est dédiée à la valorisation de la donnée de santé basée à Paris. Spin-off d'un célèbre institut de recherche en maladies génétiques, ils ont développé différentes solutions pour l'hôpital (entrepôt de données de santé intégrant du NLP, algorithmes d'anonymisation, ou encore une plateforme sécurisée de recueil des consentements).Leurs solutions sont aujourd'hui déployées dans plusieurs hôpitaux permettant defaciliter la recherche clinique, guider les décideurs avec de la donnée dans leurpilotage médico-économique, mais aussi d'identifier des patients en errancediagnostique.Depuis Leur création fin 2017, leur produit-phare (Dr. Warehouse) a été cité dansplus de 70 publications scientifiques comme solution clé pour le data miningpermettant de transformer les données de vie réelle (RWD) en preuves (RWE).Ils s'attachent particulièrement au développement de solutions innovantesqui sont réellement utiles pour les chercheurs ainsi que le personnel soignant. Etrendre utile la donnée pour le soin est une quête pour chaque personne de l’équipe.Le posteAfin d'accompagner cette start up dans le déploiement de la solution Dr. Warehouse dans les hôpitaux pour accélérer la recherche clinique et aider les praticiens à mieux soigner leurs patients, nous recherchons un Data Engineer. Ses missions seront de : Participer au développement (mapping des données, développement des connecteurs) et au maintien (validation de l’exhaustivité et de l’intégrité des données) des ETLs pour intégrer les données médicales dans un entrepôt de données Dr Warehouse  Améliorer les performances, la maintenabilité et le monitoring des ETLs existants Créer des dashboards (missions ponctuelles en fonction de la demande)  Définir et développer notre architecture data en liaison avec les autres équipes Participer à l’amélioration du traitement automatique du langage des compte-rendus médicaux poursuivant les objectifs suivants:Extraction automatique d'informations présente dans les textes Enrichissement sémantique pour extraction de contexte automatique et similarité de corpusLa société est sans silo ! Les équipes développement, commerciales, marketing et produit s’entraident pour mettre en place une gestion plus efficace et humaine des données de santé et accélérer les progrès médicaux !La stack actuelleVotre profil2 ans d’expérience en tant que Data Engineer alternance inclueDiplôme d’ingénieur ou école d’Informatique BAC+5 (idéalement) Avoir déjà travaillé sur des pipelines de données complexes (ETLs, mapping,...) Tu as conçu, déployé et maintenu une architecture complexe en production : spécifications, conception, monitoring, alerting, gestion des incidents etc. Gestion de projet en Agile (sprint planning, rétrospective) Gitlab/GitHub workflow (branch feature, developpement, master) (Bonus) Sensibilité aux problématiques de la données de santéVos compétences: Requises:PythonAirflowETLPandasSQLImportantesDjango RESTOracle / PostgreSQLLe salaire & avantages39-45 K€ selon expérienceRTTCarte Swile (ex-Lunchr) créditée mensuellementMutuelle et transport3 jours de télétravail par semaineIncentives organisés par la directionCe poste a été soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d’Experts en Recrutement Tech (CDI et clients finaux uniquement) – Visitez nous pour plus d’opportunités : www.octopusit.fr


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800339373?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=C%2BLACoqk65VitIqJxsgV6g%3D%3D&position=1&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence 🚀Anthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et décident de créer une solution SAAS ERP à destination des ESN & sociétés de conseil, afin de ""travailler autrement"".BoondManager est ainsi né 🦊Au cœur de BoondManager, il y a l'idée que chacun(e) devrait avoir la possibilité de se réaliser dans son travail et sa carrière, de pouvoir ""les"" concilier avec sa vie personnelle. 🫶Notre Mission ⭐⭐⭐⭐⭐Fédérer sur un même outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunités, facturation, CRA) !Notre ADN ❤️Nos 75 Boonders sont en full remote/100% télétravail dans toute la France.Le télétravail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'est🤝 1500 clients👥 70.000 utilisateurs🌍 21 pays💶 Rentable et autofinancée🥰 La Boondfamily est passée de 30 à 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? 👇Le PosteBoondManager ne cesse de grandir ! 🦊Afin de répondre à notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'équipe BI/Performance 🦊Tout ça, c'est magnifique, mais on reste un peu sur notre faim… nos plus grands rêves sont :Devenir le leader européen des ERP pour les sociétés de conseils (on a de l'ambition).Et pour ça, on a besoin de toi !Nos Grands Principes 👌✅ Mieux vaut s'excuser que de demander la permission. On encourage à 300 % la prise d'initiative !✅ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, écoute !La (super) Team 🏆L'équipe Performance est composée de talents pluridisciplinaires ! François s'occupe de la data (ton futur binôme) Guillaume des projets de refactoring Manu de la stack ELK Rémi côté DevOps. Florens, ton futur managerLa performance touche l'ensemble des équipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plutôt sympa donc !Tes activités : 👇On Te Propose Côté Dataviz Création dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Intégration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets nécessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de manière transverse Spécification et conception de dashboard de A à ZCôté Data Analyst Création de KPI via sql Challenger les perfs de nos Kpi (améliorer les temps de résultats) Réaliser les croisements de données pour la construction et le maintien du data warehouse Assurer la maintenance et l'évolution des KPI du produit BoondCôté Engineering Suivi de l'intégrité de la donnée (topologie, audit) Participer à l'alimentation du Datawarehouse Développement, maintien et l'évolution de l'architecture des données Recueillir les besoins des parties prenantes et spécifier les besoins en dataNotre Stack Technique 🌈 Backend/Frontend : Java, Python (à venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'équipe Perfs 🦊 On se retrouve tous les lundis matin avec l'ensemble de l'équipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton évolution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour échanger avec le reste de la team Weekly avec toute l'équipe tech (les BB pour les intimes) le mercredi à 14hTon Onboarding 🚀1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Montée en compétence sur notre solution au travers de notre Boondgame Montée en compétence sur le métier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des données qui permet de calculer cette valeur, résolution). Être capable de mettre les mains dans l'intégration à boond des KPI (manipulé le backend)6 Mois Capacité de créer des nouveaux KPI à partir des demandes de PO (requête sql permettant de le calculer) Capable d'intégrer de la dataviz. L'idée est que tu sois dans les meilleures dispositions en maîtrisant notre environnement 💪ProfilEt toi, Qui es-tu ? 🤩🍷 Tu adores pinot et je ne te parle pas de celui des charentes💪 Tu as déjà construit des tableaux de bords au travers d'un outil de Dataviz✍️ tu connais kafka et pas que l'écrivain😎 Tu es capable d'écrire des requêtes optimisés pour fabriquer la dataviz avec des exemples concrets en SQL🧠 Python : Tu dois savoir développer des nouvelles fonctionnalités, gestion des dépendances, challenger l'existant (qualité du code), compiler le projet.🚀 Le + : Tu maîtrises notre stack technique (on veut des projets significatifs)🦊 Le petit ++ : Tu connais le monde des ESN🙋‍♀️ Mesdames, autorisez-vous à candidater !Ce Qu'on T'offrira En Plus De Tout Ça 🎁💸 Un salaire entre 45k et 60K🏡 100% remote 🇫🇷 (plus de temps pour toi !)🌴 3 séminaires par an pour se retrouver et s'éclater !😎 9 jours de congés payés supplémentaires🏥 Une mutuelle familiale (pas de suppléments pour ta famille)💸 Une offre télétravail en plus de ton salaire !🎁 Une offre mensuelle dans le coworking de ton choix !🧘 Cours en ligne de méditation, fitness et yoga chaque semaine !🤝 Un plan d'épargne entreprise valorisé à hauteur de 300 %💻 Une mise à disposition d'un Macbook, 2 écrans, casque, etc.🦊 On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !Déroulement des entretiens💻 Un premier échange avec Jean-Florian, notre Head Of Talent🚀 Un entretien technique/culture fit avec François, ton futur binôme côté Data🤝 Un échange Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager 🤓Et si tu as réussi à me lire jusqu'ici,voici ma dernière phrase pour qu'on ne passe pas à côté de toi : si demain cette offre venait à être clôturée et que tu penses regretter de ne pas avoir postulé, c'est qu'elle t'a tapé dans l'œil.Ça serait dommage de démarrer 2024 avec un regret,Alors, n'hésite pas, POSTULE👇
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Embedded System Engineer,Le Bureau des Talents,"Royan, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/embedded-system-engineer-at-le-bureau-des-talents-3798663587?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=in3wjbvWjCsKm%2FPNXaf%2BbA%3D%3D&position=2&pageNum=7&trk=public_jobs_jserp-result_search-card,"Le Bureau des Talents est un cabinet de recrutement spécialisé dans la chasse, l’accompagnement et le coaching des talents pour les startups, les scale-ups et les entreprises à impact.🚀Notre client est une scale up développant des avions hybrides électriques de pointe qui recherche un ingénieur systèmes pour rejoindre son bureau d'études systèmes basé à Royan. Si vous souhaitez contribuer à la réduction des émissions de carbone dans le secteur de l'aviation et façonner l'avenir de l'aviation durable, postulez ici 👉⚒️MissionsDéfinir l’architecture de système aéronautique, les modes opératoires et les fonctions selon les exigences internes et externesGérer les exigences provenant des documents Métiers, Standards, Sécurité, et cahier des charges client durant toute la vie des systèmesDimensionner les systèmes et équipements pour assurer l’atteinte des performances.Rédiger les spécifications des sous-systèmes et équipements développés en interne ou externe.Coordonner, assurer et garantir la cohérence et compatibilité des systèmes entre les fournisseurs, les métiers interne pour les interfaces, et les performances attendues.Collaborer avec les spécialistes des disciplines transverses (certification, safety).Maintenir et garantir les référentiels et configurations techniques applicables.Rédiger la documentation à destination du client ou des sous-traitants et, sur demande, participer aux revues techniques avec le clientRédiger les rapports de tests de niveau systèmes et assurer la mise au point et l’intégration des fonctionsDéfinir et réaliser les vérifications fonctionnelles et de performances en collaboration avec les métiers et l’équipe flight testRésoudre les anomalies et problèmes techniques.Reporting technique auprès de la Direction Technique.Assurer et piloter le bon avancement du développement technique et supporter le projet sur la gestion des risques et optimisation.👩🏻👨🏽ProfilFormation Ingénieur Systèmes Embarqués (ou généraliste) – Niveau Master 25 à 10 ans d’expérience professionnelle dans le domaine des systèmesExpérience CS25/CS23 fortement appréciéeBonne connaissance des normes DO-178C, DO-254 et DO-160Expérience pratique souhaitée en matière de conception, d'intégration et de testBonne capacité à travailler en équipe sur des projets complexes avec des contraintes calendaires fortesRigueur, force de proposition et aisance relationnelleEsprit d'analyse et de synthèseForte autonomie, réactivité, bon esprit d’équipeAdaptation à un environnement start-up.Maîtrise parfaite du Français et de l’Anglais, écrit et oralBrevet ULM/Licence pilote privé avion/hélicoptère apprécié


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800338540?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=LrlRSaMO5hk4llRUlffiTA%3D%3D&position=3&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence 🚀Anthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et décident de créer une solution SAAS ERP à destination des ESN & sociétés de conseil, afin de ""travailler autrement"".BoondManager est ainsi né 🦊Au cœur de BoondManager, il y a l'idée que chacun(e) devrait avoir la possibilité de se réaliser dans son travail et sa carrière, de pouvoir ""les"" concilier avec sa vie personnelle. 🫶Notre Mission ⭐⭐⭐⭐⭐Fédérer sur un même outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunités, facturation, CRA) !Notre ADN ❤️Nos 75 Boonders sont en full remote/100% télétravail dans toute la France.Le télétravail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'est🤝 1500 clients👥 70.000 utilisateurs🌍 21 pays💶 Rentable et autofinancée🥰 La Boondfamily est passée de 30 à 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? 👇Le PosteBoondManager ne cesse de grandir ! 🦊Afin de répondre à notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'équipe BI/Performance 🦊Tout ça, c'est magnifique, mais on reste un peu sur notre faim… nos plus grands rêves sont :Devenir le leader européen des ERP pour les sociétés de conseils (on a de l'ambition).Et pour ça, on a besoin de toi !Nos Grands Principes 👌✅ Mieux vaut s'excuser que de demander la permission. On encourage à 300 % la prise d'initiative !✅ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, écoute !La (super) Team 🏆L'équipe Performance est composée de talents pluridisciplinaires ! François s'occupe de la data (ton futur binôme) Guillaume des projets de refactoring Manu de la stack ELK Rémi côté DevOps. Florens, ton futur managerLa performance touche l'ensemble des équipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plutôt sympa donc !Tes activités : 👇On Te Propose Côté Dataviz Création dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Intégration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets nécessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de manière transverse Spécification et conception de dashboard de A à ZCôté Data Analyst Création de KPI via sql Challenger les perfs de nos Kpi (améliorer les temps de résultats) Réaliser les croisements de données pour la construction et le maintien du data warehouse Assurer la maintenance et l'évolution des KPI du produit BoondCôté Engineering Suivi de l'intégrité de la donnée (topologie, audit) Participer à l'alimentation du Datawarehouse Développement, maintien et l'évolution de l'architecture des données Recueillir les besoins des parties prenantes et spécifier les besoins en dataNotre Stack Technique 🌈 Backend/Frontend : Java, Python (à venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'équipe Perfs 🦊 On se retrouve tous les lundis matin avec l'ensemble de l'équipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton évolution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour échanger avec le reste de la team Weekly avec toute l'équipe tech (les BB pour les intimes) le mercredi à 14hTon Onboarding 🚀1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Montée en compétence sur notre solution au travers de notre Boondgame Montée en compétence sur le métier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des données qui permet de calculer cette valeur, résolution). Être capable de mettre les mains dans l'intégration à boond des KPI (manipulé le backend)6 Mois Capacité de créer des nouveaux KPI à partir des demandes de PO (requête sql permettant de le calculer) Capable d'intégrer de la dataviz. L'idée est que tu sois dans les meilleures dispositions en maîtrisant notre environnement 💪ProfilEt toi, Qui es-tu ? 🤩🍷 Tu adores pinot et je ne te parle pas de celui des charentes💪 Tu as déjà construit des tableaux de bords au travers d'un outil de Dataviz✍️ tu connais kafka et pas que l'écrivain😎 Tu es capable d'écrire des requêtes optimisés pour fabriquer la dataviz avec des exemples concrets en SQL🧠 Python : Tu dois savoir développer des nouvelles fonctionnalités, gestion des dépendances, challenger l'existant (qualité du code), compiler le projet.🚀 Le + : Tu maîtrises notre stack technique (on veut des projets significatifs)🦊 Le petit ++ : Tu connais le monde des ESN🙋‍♀️ Mesdames, autorisez-vous à candidater !Ce Qu'on T'offrira En Plus De Tout Ça 🎁💸 Un salaire entre 45k et 60K🏡 100% remote 🇫🇷 (plus de temps pour toi !)🌴 3 séminaires par an pour se retrouver et s'éclater !😎 9 jours de congés payés supplémentaires🏥 Une mutuelle familiale (pas de suppléments pour ta famille)💸 Une offre télétravail en plus de ton salaire !🎁 Une offre mensuelle dans le coworking de ton choix !🧘 Cours en ligne de méditation, fitness et yoga chaque semaine !🤝 Un plan d'épargne entreprise valorisé à hauteur de 300 %💻 Une mise à disposition d'un Macbook, 2 écrans, casque, etc.🦊 On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !Déroulement des entretiens💻 Un premier échange avec Jean-Florian, notre Head Of Talent🚀 Un entretien technique/culture fit avec François, ton futur binôme côté Data🤝 Un échange Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager 🤓Et si tu as réussi à me lire jusqu'ici,voici ma dernière phrase pour qu'on ne passe pas à côté de toi : si demain cette offre venait à être clôturée et que tu penses regretter de ne pas avoir postulé, c'est qu'elle t'a tapé dans l'œil.Ça serait dommage de démarrer 2024 avec un regret,Alors, n'hésite pas, POSTULE👇
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Groupe Karavel - Promovacances,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-karavel-promovacances-3802118837?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=JwBhIW28J%2Fe%2BCbrw3FcOMw%3D%3D&position=4&pageNum=7&trk=public_jobs_jserp-result_search-card,"Lancé en 2000, le Groupe KARAVEL est aujourd’hui le leader français dans la vente de séjours sur Internet via ses deux marques phares, PROMOVACANCES, le spécialiste des bons plans implantés au cœur de Paris, et FRAM, fleuron toulousain du tourisme hexagonal réputé pour ses labels Framissima et Jumbo.Avec plus de 5 millions de visiteurs uniques par mois sur ses différents sites, le Groupe développe également un réseau de 143 agences en France. KARAVEL s'appuie également sur une équipe de plus de 900 collaborateurs dont plus de 100 dédiés à la recherche et la fabrication de voyages et 30 au seul service Qualité. Sa relation-client est assurée quant à elle, outre ses agences, par une centaine de Conseillers en centre d'appels basés à Paris et Nice.En tant que Data Engineer, vous interviendrez sur la totalité de la chaine décisionnelle au sein du pôle DATA, et serez chargé, entre autres de : La participation au projet d’implémentation de notre nouvelle plateforme BI AZURE / SnowFlake / Power BI,Analyse de l’existant et des nouveaux besoins métiers,Réalisation des spécifications fonctionnelles et techniques,Modélisation,Création de package sous SSIS,Implémentation des chargements de données vers SnowFlake,Développement sous cube Tabulaire (service AS Azure),Réalisation de rapports sous Excel, et modèles de données Power BI,Recette et mise en production. Profil :Vous disposez de : De 3 à 5 années d’expérience sur la suite Microsoft BI (SSIS, SQLSERVER, SSAS, SSRS) avec une solide compétence en SQL,De compétences sur Snowflake (architecture, développement, administration),D’une expérience sur Power BI (jusqu’à la conception du modèle de données, hors visualisations). Vous avez démontré un forte capacité d’adaptation et d’autonomie à travailler au sein d’environnements complexes et hétérogènes en termes de systèmes d’information et de domaines fonctionnels couverts. Vous êtes doté d'une forte culture de l'engagement et du résultat, vous êtes autonome, réactif et aimez relever les challenges. Vous avez déjà une expérience dans le secteur du digital et vous avez été confrontés aux problèmes de qualité de données et de volumétries.A vos claviers !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800341290?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=v7v8nORRdaVgEdTjDdbMAQ%3D%3D&position=5&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence 🚀Anthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et décident de créer une solution SAAS ERP à destination des ESN & sociétés de conseil, afin de ""travailler autrement"".BoondManager est ainsi né 🦊Au cœur de BoondManager, il y a l'idée que chacun(e) devrait avoir la possibilité de se réaliser dans son travail et sa carrière, de pouvoir ""les"" concilier avec sa vie personnelle. 🫶Notre Mission ⭐⭐⭐⭐⭐Fédérer sur un même outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunités, facturation, CRA) !Notre ADN ❤️Nos 75 Boonders sont en full remote/100% télétravail dans toute la France.Le télétravail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'est🤝 1500 clients👥 70.000 utilisateurs🌍 21 pays💶 Rentable et autofinancée🥰 La Boondfamily est passée de 30 à 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? 👇Le PosteBoondManager ne cesse de grandir ! 🦊Afin de répondre à notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'équipe BI/Performance 🦊Tout ça, c'est magnifique, mais on reste un peu sur notre faim… nos plus grands rêves sont :Devenir le leader européen des ERP pour les sociétés de conseils (on a de l'ambition).Et pour ça, on a besoin de toi !Nos Grands Principes 👌✅ Mieux vaut s'excuser que de demander la permission. On encourage à 300 % la prise d'initiative !✅ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, écoute !La (super) Team 🏆L'équipe Performance est composée de talents pluridisciplinaires ! François s'occupe de la data (ton futur binôme) Guillaume des projets de refactoring Manu de la stack ELK Rémi côté DevOps. Florens, ton futur managerLa performance touche l'ensemble des équipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plutôt sympa donc !Tes activités : 👇On Te Propose Côté Dataviz Création dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Intégration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets nécessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de manière transverse Spécification et conception de dashboard de A à ZCôté Data Analyst Création de KPI via sql Challenger les perfs de nos Kpi (améliorer les temps de résultats) Réaliser les croisements de données pour la construction et le maintien du data warehouse Assurer la maintenance et l'évolution des KPI du produit BoondCôté Engineering Suivi de l'intégrité de la donnée (topologie, audit) Participer à l'alimentation du Datawarehouse Développement, maintien et l'évolution de l'architecture des données Recueillir les besoins des parties prenantes et spécifier les besoins en dataNotre Stack Technique 🌈 Backend/Frontend : Java, Python (à venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'équipe Perfs 🦊 On se retrouve tous les lundis matin avec l'ensemble de l'équipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton évolution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour échanger avec le reste de la team Weekly avec toute l'équipe tech (les BB pour les intimes) le mercredi à 14hTon Onboarding 🚀1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Montée en compétence sur notre solution au travers de notre Boondgame Montée en compétence sur le métier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des données qui permet de calculer cette valeur, résolution). Être capable de mettre les mains dans l'intégration à boond des KPI (manipulé le backend)6 Mois Capacité de créer des nouveaux KPI à partir des demandes de PO (requête sql permettant de le calculer) Capable d'intégrer de la dataviz. L'idée est que tu sois dans les meilleures dispositions en maîtrisant notre environnement 💪ProfilEt toi, Qui es-tu ? 🤩🍷 Tu adores pinot et je ne te parle pas de celui des charentes💪 Tu as déjà construit des tableaux de bords au travers d'un outil de Dataviz✍️ tu connais kafka et pas que l'écrivain😎 Tu es capable d'écrire des requêtes optimisés pour fabriquer la dataviz avec des exemples concrets en SQL🧠 Python : Tu dois savoir développer des nouvelles fonctionnalités, gestion des dépendances, challenger l'existant (qualité du code), compiler le projet.🚀 Le + : Tu maîtrises notre stack technique (on veut des projets significatifs)🦊 Le petit ++ : Tu connais le monde des ESN🙋‍♀️ Mesdames, autorisez-vous à candidater !Ce Qu'on T'offrira En Plus De Tout Ça 🎁💸 Un salaire entre 45k et 60K🏡 100% remote 🇫🇷 (plus de temps pour toi !)🌴 3 séminaires par an pour se retrouver et s'éclater !😎 9 jours de congés payés supplémentaires🏥 Une mutuelle familiale (pas de suppléments pour ta famille)💸 Une offre télétravail en plus de ton salaire !🎁 Une offre mensuelle dans le coworking de ton choix !🧘 Cours en ligne de méditation, fitness et yoga chaque semaine !🤝 Un plan d'épargne entreprise valorisé à hauteur de 300 %💻 Une mise à disposition d'un Macbook, 2 écrans, casque, etc.🦊 On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !Déroulement des entretiens💻 Un premier échange avec Jean-Florian, notre Head Of Talent🚀 Un entretien technique/culture fit avec François, ton futur binôme côté Data🤝 Un échange Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager 🤓Et si tu as réussi à me lire jusqu'ici,voici ma dernière phrase pour qu'on ne passe pas à côté de toi : si demain cette offre venait à être clôturée et que tu penses regretter de ne pas avoir postulé, c'est qu'elle t'a tapé dans l'œil.Ça serait dommage de démarrer 2024 avec un regret,Alors, n'hésite pas, POSTULE👇
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Analytics Engineer,MYM,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/analytics-engineer-at-mym-3799459109?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=NHLu4y0GD4mPAuVx9NCHDA%3D%3D&position=6&pageNum=7&trk=public_jobs_jserp-result_search-card,"Poste :Tu intégreras la Team DATA et tu seras sous la responsabilité de notre super Data Expert 🚀.Il s’agit d’une création de poste pour lequel, tu vas exprimer toute ta créativité en analyse DATA !Ton rôle consistera à contribuer à développer les usages DATA de nos 50 employés répartis dans les différentes Team : Product, Customer, Growth, Finance,…..La data platform est en pleine construction et tu participeras à sa création, tant sur l’analyse et la compréhension de MYM que sur la construction d’un Datawarehouse efficace et pertinent.Tes principales tâches day-to-day 💼:En étroite collaboration avec Pierre, notre Head of Data au sein de l'équipe, tes responsabilités incluent de :Construire des modèles de données efficaces et robustes depuis de nombreuses sourcesParticiper au déploiement de nouvelles solutions (tracking, self service analytics, real time analytics)Mettre en œuvre des solutions pour améliorer la qualité des données.Travailler sur des projets end to end : ingestion, transformation, usage (visualisation et reverse ETL)Profil 🏗:Expérience de l'utilisation de SQL (toute expérience avec des moteurs SQL est appréciée )Une forte appétence pour le DATA ModelingUne première expérience réussie en tant que Data Analyst, avec la maîtrise d’un langage de programmation type PythonConnaissance de base d'UNIX et de GIT.Expérience avec un fournisseur de cloud (nous utilisons AWS).Tu as un 1 à 3 ans d’expérience en DATAIdéalement, tu as une expérience d’au moins 3 ans en tant qu'Analytics Engineer.Maîtrise de l'anglaisNotre Stack technique 🛠️:Datawarehouse : AWS Redshift / SpectrumIngestion : Airbyte / RudderstackData Transformation : DBTOrchestration : DagsterCDP / Reverse ETL : RudderstackSi tu te retrouves dans cette annonce, alors rejoins la Team MYM!Les avantages à travailler chez MYM :Travailler chez MYM, c’est rejoindre une entreprise qui comprend les enjeux des salariés d’aujourd’hui :Une Work-Life BalanceTu disposes d’un pass Gymlib 🚴 🤺2 jours de Télétravail possible par semaine 👩🏻‍💻👨🏾‍💻Des bureaux design et moderne en plein coeur de la Silicon IXème à ParisUn équipement informatique dernier criBien évidemment, nous disposons de :Tickets Restaurant SwileMutuelle BenefizNous proposons également:Des moments partagés entre collègues, en visio et en présentiel 🍻Un management à l’écoute et ouvert aux suggestions et propositions salariés 🦸🏾‍♂️🦸‍♀️Process de recrutement : Entretien avec Omar, notre Chief People (45 minutes)Entretien avec Pierre, notre Head of DATA (60 minutes)Echange avec Gauthier et Quentin, respectivement, le COO et le CTO.Rencontre avec Gaspard et Pierre, les fondateurs de MYM (30 minutes)


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer média,MP DATA,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-m%C3%A9dia-at-mp-data-3806329502?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=CmDtQw%2Fp4lqZfnOfNo3uUg%3D%3D&position=7&pageNum=7&trk=public_jobs_jserp-result_search-card,"MP DATA est une société spécialisée dans l’acquisition, le traitement, et la valorisation des données. Depuis sa création en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l’exploitation de leurs données.MP DATA accompagne ses clients sur toute la chaine au travers de 3 pôles d’expertise : Conseil et Stratégie, Infrastructure & CloudOPS, Data Science.Rejoindre MP DATA, c’est la garantie de travailler sur des sujets passionnants avec un cadre technique fort. MP DATA, recrute un Data Engineer afin de travailler pour notre client dans le secteur des Médias :Vos missions seront les suivantes :Renforcer notre connaissance 360 de nos clients/utilisateurs (segmentation, enrichissement, activation de la donnée…),Superviser les alimentations de production grâce aux outils (AirFlow…),Développer l'offre de ciblage publicitaire en TV segmentée,Gestion et maintenance de l'offre,⁠Apport d'une expertise sur l'offre de ciblage afin d'améliorer les recommandations,annonceurs/agences,Travailler avec les Data Scientists à la mise en œuvre des modèles statistiques et algorithmiques,Profil recherché :De formation Bac+5 (ou plus) en développement informatique / Data Engineering, vous justifiez d’une expérience professionnelle significative dans le secteur de la Publicité au cours de laquelle vous avez pu développer les compétences techniques suivantes :PythonSQLPysparkStreaming Process de recrutement :Pré-qualification téléphonique de 30 minEntretien techniqueÉchange avec l'équipe


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - ILM - F/H,Niji,"Issy-les-Moulineaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-ilm-f-h-at-niji-3804561156?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=vsvuELSodBwGR1%2BVEmeITA%3D%3D&position=8&pageNum=7&trk=public_jobs_jserp-result_search-card,"Nous sommes plus qu’un simple cabinet de conseil, qu'une agence de design et qu'une société de mise en œuvre technologique. Nous sommes le partenaire de la transformation digitale de nos clients grands-comptes et ETI, que nous accompagnons de l’idée à la réalité.Nous associons, dans une même chaîne de valeur, conseil en stratégie, design de service et design émotionnel, management et valorisation de la donnée, ingénierie et conseil technologique, réalisation logicielle et expertise en cybersécurité.Notre singularité repose sur les talents pluriels de nos équipes, au service de la satisfaction et de la performance de nos clients.Le Pôle Data De Niji C'est Avant Tout Une Équipe à Taille Humaine Et Pluridisciplinaire, Composée De Consultants Et Experts Qui Conseillent Et Appuient Nos Clients Sur Toutes Les Étapes Du Cycle Des Donnéesde la collecte à la valorisation dans des services innovants,en passant par les architectures de stockage et de services.Nos consultants sont basés en Ile-de-France et en régions (Nantes, Rennes, Lille, Lyon et Bordeaux).Nos 3 directeurs : experts confirmés de la gouvernance des données, de la data science de l'IA et des méthodologies d'industrialisation de l'IA (MLOps, DataOps), recherchent de nouveaux talents tous complémentaires avec plusieurs niveaux de qualification et séniorité, qui travailleront en synergie avec la large palette de compétences de Niji en développement, communication, cybersécurité et en conseil.Intégrer le Pôle Data de Niji c'est avoir l'assurance d'être accompagné dans sa progression et le développement rapide de ses compétences ,vous suivez un parcours de formation riche et diversifié, visant à vous faire rapidement monter en expertise et à vous certifier.En tant que Data Engineer, vos principales missions seront les suivantes : Développer et maintenir une architecture de données robuste, évolutive et sécurisée, en tenant compte des besoins spécifiques des clients.  Gérer et optimiser les pipelines de données, en assurant la collecte, le stockage, le traitement et la mise à disposition des données de manière fiable et performante.  Assurer la qualité des données en mettant en place des contrôles de qualité, des tests et des processus de validation, conformément aux exigences des clients.  Participer au maintien de la documentation technique, les bonnes pratiques et les standards de développement au sein de l'équipe.Profil recherchéSi VousAvez obtenu un diplôme en université, école de commerce ou équivalent type bac +5 Maîtrisez l'anglais à l'écrit comme à l'oral Avez de solides connaissances en architecture et en modélisation des données Maîtrisez des technologies et des outils liés au Big Data (Hadoop, Spark, Hive, etc.) Maîtrisez les outils d’industrialisation des pipelines data tel que Docker, Kubernetes, Dataiku, Jenkins… Avez une expérience avec les langages de programmation utilisés dans le domaine des données, tels que : Python,R, Scala, SQL, etc. Avez une expérience dans la conception et la mise en œuvre de pipelines de donnéesAlors… Venez participer au dynamisme de notre site en rejoignant notre Team Data Niji !L'aventure NijiProcess de recrutement : premier contact RH puis rencontre avec nos opérationnels.Rejoindre l'expérience Niji c'est avoir l'assurance de participer à une aventure humaine dans un environnement de travail motivant, challengeant et innovant.NijiU: notre plateforme de formation digital learning contenant près de 3 000 modules en accès libre.Nos valeurs : Audace - Bienveillance - Performance – Talent. Si ces mots vous parlent, venez faire la différence chez Niji !En rejoignant Niji, vous intégrez une entreprise dont la politique RSE contribue à la promotion de la diversité et de l’égalité des chances, notamment pour les personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
"Software Engineer, Android",amo,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-android-at-amo-3802326561?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=B15khhCzRgqhNvOyNaFfXQ%3D%3D&position=9&pageNum=7&trk=public_jobs_jserp-result_search-card,"Looking for someone to join us as one of the first members of the Android team. This means participating in all design and product decisions of the early days of product centric company.In the initial months, you'll be working closely with the founding team, gradually taking ownership of central components and features. Given our early stage, we're seeking a versatile engineers comfortable contributing to various aspects of the company's foundation.We value team members who delve deep into their respective domains, aiming to cultivate a team of subject matter experts. This commitment to expertise is an expectation for every team member.As an Android engineer, your day-to-day will include:Feature DevelopmentYou’ll be responsible for delivering unique, high-quality UI and features in a fast-moving environment. We like to push the push the limits of what’s possible, so be ready to use low-level APIs and go beyond what’s provide by the Android frameworks: building shaders to create dynamic effects in various media, writing a custom 2D scrolling rendering system with almost infinite zooming, etc.Platform DevelopmentYou’ll participate in the creation and improvements of the platform, in order to increase the velocity and quality of the work of the whole development team. That will include things like synchronizing a code-generated library for reading/writing config settings between the server and the client (like feature configuration, feature flags, etc.) or implementing a cross-platform realtime type-safe analytics system.Roadmap Creation and IdeationYou’ll also be an active participant of a the roadmap creation and ideation. You’ll be expected to help identify the right tradeoffs and bring ideas from a product and engineering perspective.Knowledge SharingWe love learning from each other, so we push ourselves to stay up to date with the latest trends and best practices in backend engineering. So we’ll be highly encouraging you to attend conferences, participate in online communities, and share your learnings internally.Your Skills & Experience5+ years of overall developer experience, with ideally at least 2 years of professional experience in native Android development using Kotlin or Java. Good understanding of computer systems fundamentals (Program execution, Linking, Multithreading, etc.). Professional or academic experience in low-level languages like C, C++ or Rust is a plus!Experience in Graphics Programming using APIs such as OpenGL, Vulkan or Metal. Passion and experience building consumer-facing products - we’d love to hear about apps you've made!Life at amoTo ensure that everyone is set up for success within our way of working, we work together onsite 5 days a week.We wanted to make sure coming to the office is as comfortable as possible for you:We chose a location in central Paris, near Opera (Metro lines 3,8,9 and RER A). We have a beautiful Parisian-style office with high ceilings, balconies, and huge windows. So a lot of natural light!We reimburse your commuting expenses 100%. Because life outside of work should also be stress-free, we cover:Health care (100% coverage). Maternity Leave, Paternity Leave, Second Parent Leave (salary maintained at 100%). We shut down entirely twice a year — two weeks in the summer and one week in the winter to allow everyone to truly recharge and to avoid prolonged slowdowns (especially in the summer). This enables everyone to actually disconnect and enjoy their vacation. No Slack, no email, no FOMO. Per French standard, we also offer another 4 weeks to allow team members to choose when they want to take time off. We love the diverse perspectives we get from having people from all over the world join us, and so we of course support relocation to Paris with:Help and sponsored visa process. 1 month of Airbnb 100% covered by amo upon arrival. Assistance from Settlesweet to find your permanent home. Help with french paperwork like opening a french social security account, tax forms and more. French lessons to be fully set with your new Parisian life.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'C++', 'R', 'Go', 'Kotlin'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Slack']}"
Data Engineer / Développeur BI BigData # H/F,Air France,"Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-bi-bigdata-%23-h-f-at-air-france-3728524792?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=BBoGFA9lsmQrGxDm%2BqCVcg%3D%3D&position=10&pageNum=7&trk=public_jobs_jserp-result_search-card,"Description du poste Intitulé du poste Data Engineer / Développeur BI BigData # H/F Métier Systèmes d'informations - Développement Catégorie socio-professionnelle Cadre Présentation du contexte Vous avez peut-être déjà voyagé avec nous, mais que connaissez-vous de nos métiers et de la richesse des données qu’ils génèrent au quotidien ? Comment le traitement et l’exploitation de ces données peut contribuer à notre stratégie de Revenue Management, ou encore aux multiples opérations à réaliser pour permettre à un vol de partir à l’heure ?Air France-KLM fait rêver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, grâce à une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunités sont vastes pour mettre à profit ses compétences, apprendre et se développer !Le département de développement DATA, OR & AI d’Air France, au sein de la direction des Systèmes d’Information, intervient dans toute la chaîne de captation et de traitement des données du groupe pour délivrer à nos métiers des solutions applicatives clés en main.Le département est également en charge de l’ensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du développement des talents et compétences de Data Engineering.Notre mission ? Transformer la donnée brute en décision intelligente, pour mieux optimiser les métiers d’Air France – KLM !Pour cela, nous avons chacun un rôle essentiel à jouer, pourquoi le vôtre ne serait pas celui de Data Engineer ?Description De La MissionAu sein de notre département, vous travaillerez main dans la main avec d’autres Data Engineers ainsi qu’avec des spécialistes des métiers.Intégré au sein d’une product team agile passionnée et dynamique : Vous participez à l’analyse des besoins métiers du commercial, des opérations aériennes, de l’exploitation sol en aéroport, de la maintenance aéronautique ou encore du Cargo. Vous contribuez à la définition, au développement, à l’industrialisation et à la maintenance d’applications Big Data ou en Business Intelligence Vous présentez la restitution de vos travaux et accompagnez les utilisateurs d’un point de vue fonctionnel ou méthodologiqueVous serez en contact avec les directions métier du groupe Air France KLM.Nous attachons beaucoup d'importance au développement des compétences de nos collaborateurs ainsi qu’à leur offrir des conditions de travail favorables à l’autonomie et aux missions à forte valeur ajoutée. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines portées par l'entreprise. Profil recherché Vous êtes diplômé de niveau Master ou Ingénieur dans les domaines informatiques, vous avez acquis une expérience professionnelle dans le développement d’applications. Vous disposez d’une expérience du développement indispensable en Backend / Java Vous maîtrisez les bases de données relationnelles et le langage SQLEn Complément, Vous Avez Une Connaissance Ou Une Expérience Dans Tout Ou Partie Des Concepts Ou Outils Suivants Base de données noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata Environnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...) Outil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana) Solutions de Cloud hybride(Ces compétences complémentaires ou manquantes pouvant aussi s'acquérir à travers un parcours de reskilling et de formations aux outils du data engineering dispensé en interne).Vous avez participé à des projets organisés en Scrum ou Kanban, et avez peut-être même œuvré comme Scrum-Master, ce qui vous permettra de vous intégrer aisément au sein d’une Product Team. Votre esprit de synthèse, votre force de conviction et votre maîtrise de la communication facilitent les décisions avec l’ensemble des collaborateurs de l’équipe, éventuellement en langue anglaise, à l’écrit comme à l’oral.Vous êtes autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en équipe. Vous possédez de bonnes capacités d'écoute, d'analyse, de synthèse et de communication.Et bien sûr, vous êtes passionné(e), enthousiaste et ingénieux(se)Ce que nous vous offrons De la création de valeur pour l’ensemble des métiers d’Air France KLM Des challenges et problématiques complexes à résoudre L’opportunité de déployer des solutions Data industrielles à l’échelle ! Une grande part de responsabilité dans une structure hiérarchique horizontale Un important degré de liberté pour apprendre et développer son expertise au sein de l’équipeOn vous attend le plus rapidement possible ! Et pour une durée indéterminée ;) Type de contrat CDI Date de prise de poste souhaitée 02/11/2023 Temps partiel possible Non Type d'horaires AdministratifProfil candidat Niveau d'études min. requis Bac + 5 et plus / 3ème année grande école Langue Anglais (4 - Confirmé / C1)Localisation du poste Localisation du poste France, Provence-Alpes-Côte d'Azur, Alpes Maritimes (06) Site Valbonne
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800335850?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=Kn2p9pqhoyVwFDryPfAbOA%3D%3D&position=11&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence 🚀Anthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et décident de créer une solution SAAS ERP à destination des ESN & sociétés de conseil, afin de ""travailler autrement"".BoondManager est ainsi né 🦊Au cœur de BoondManager, il y a l'idée que chacun(e) devrait avoir la possibilité de se réaliser dans son travail et sa carrière, de pouvoir ""les"" concilier avec sa vie personnelle. 🫶Notre Mission ⭐⭐⭐⭐⭐Fédérer sur un même outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunités, facturation, CRA) !Notre ADN ❤️Nos 75 Boonders sont en full remote/100% télétravail dans toute la France.Le télétravail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'est🤝 1500 clients👥 70.000 utilisateurs🌍 21 pays💶 Rentable et autofinancée🥰 La Boondfamily est passée de 30 à 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? 👇Le PosteBoondManager ne cesse de grandir ! 🦊Afin de répondre à notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'équipe BI/Performance 🦊Tout ça, c'est magnifique, mais on reste un peu sur notre faim… nos plus grands rêves sont :Devenir le leader européen des ERP pour les sociétés de conseils (on a de l'ambition).Et pour ça, on a besoin de toi !Nos Grands Principes 👌✅ Mieux vaut s'excuser que de demander la permission. On encourage à 300 % la prise d'initiative !✅ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, écoute !La (super) Team 🏆L'équipe Performance est composée de talents pluridisciplinaires ! François s'occupe de la data (ton futur binôme) Guillaume des projets de refactoring Manu de la stack ELK Rémi côté DevOps. Florens, ton futur managerLa performance touche l'ensemble des équipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plutôt sympa donc !Tes activités : 👇On Te Propose Côté Dataviz Création dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Intégration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets nécessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de manière transverse Spécification et conception de dashboard de A à ZCôté Data Analyst Création de KPI via sql Challenger les perfs de nos Kpi (améliorer les temps de résultats) Réaliser les croisements de données pour la construction et le maintien du data warehouse Assurer la maintenance et l'évolution des KPI du produit BoondCôté Engineering Suivi de l'intégrité de la donnée (topologie, audit) Participer à l'alimentation du Datawarehouse Développement, maintien et l'évolution de l'architecture des données Recueillir les besoins des parties prenantes et spécifier les besoins en dataNotre Stack Technique 🌈 Backend/Frontend : Java, Python (à venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'équipe Perfs 🦊 On se retrouve tous les lundis matin avec l'ensemble de l'équipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton évolution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour échanger avec le reste de la team Weekly avec toute l'équipe tech (les BB pour les intimes) le mercredi à 14hTon Onboarding 🚀1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Montée en compétence sur notre solution au travers de notre Boondgame Montée en compétence sur le métier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des données qui permet de calculer cette valeur, résolution). Être capable de mettre les mains dans l'intégration à boond des KPI (manipulé le backend)6 Mois Capacité de créer des nouveaux KPI à partir des demandes de PO (requête sql permettant de le calculer) Capable d'intégrer de la dataviz. L'idée est que tu sois dans les meilleures dispositions en maîtrisant notre environnement 💪ProfilEt toi, Qui es-tu ? 🤩🍷 Tu adores pinot et je ne te parle pas de celui des charentes💪 Tu as déjà construit des tableaux de bords au travers d'un outil de Dataviz✍️ tu connais kafka et pas que l'écrivain😎 Tu es capable d'écrire des requêtes optimisés pour fabriquer la dataviz avec des exemples concrets en SQL🧠 Python : Tu dois savoir développer des nouvelles fonctionnalités, gestion des dépendances, challenger l'existant (qualité du code), compiler le projet.🚀 Le + : Tu maîtrises notre stack technique (on veut des projets significatifs)🦊 Le petit ++ : Tu connais le monde des ESN🙋‍♀️ Mesdames, autorisez-vous à candidater !Ce Qu'on T'offrira En Plus De Tout Ça 🎁💸 Un salaire entre 45k et 60K🏡 100% remote 🇫🇷 (plus de temps pour toi !)🌴 3 séminaires par an pour se retrouver et s'éclater !😎 9 jours de congés payés supplémentaires🏥 Une mutuelle familiale (pas de suppléments pour ta famille)💸 Une offre télétravail en plus de ton salaire !🎁 Une offre mensuelle dans le coworking de ton choix !🧘 Cours en ligne de méditation, fitness et yoga chaque semaine !🤝 Un plan d'épargne entreprise valorisé à hauteur de 300 %💻 Une mise à disposition d'un Macbook, 2 écrans, casque, etc.🦊 On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !Déroulement des entretiens💻 Un premier échange avec Jean-Florian, notre Head Of Talent🚀 Un entretien technique/culture fit avec François, ton futur binôme côté Data🤝 Un échange Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager 🤓Et si tu as réussi à me lire jusqu'ici,voici ma dernière phrase pour qu'on ne passe pas à côté de toi : si demain cette offre venait à être clôturée et que tu penses regretter de ne pas avoir postulé, c'est qu'elle t'a tapé dans l'œil.Ça serait dommage de démarrer 2024 avec un regret,Alors, n'hésite pas, POSTULE👇
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Madonne Core (H/F),Natixis Corporate & Investment Banking,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-madonne-core-h-f-at-natixis-corporate-investment-banking-3794007401?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=49FelUpEzMM66BeHGNHnsg%3D%3D&position=12&pageNum=7&trk=public_jobs_jserp-result_search-card,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met à disposition des entreprises, institutions financières, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les marchés de capitaux.  Ses équipes d'experts, présentes dans 30 pays, conseillent les clients sur leur développement stratégique en les accompagnant dans la croissance et la transformation de leurs activités tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engagée à soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 °C d'ici à 2050.  Natixis Corporate & Investment Banking fait partie du pôle Global Financial Services du Groupe BPCE, 5e établissement financier européen et 2e acteur bancaire en France à travers ses réseaux Banque Populaire et Caisse d'Epargne.  Si vous êtes enthousiaste à l'idée de relever des défis passionnants, d'avoir un impact et de contribuer à la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job.Vous rejoignez l'équipe Core en charge de la maintenance évolutive des applications Madonne (Récolte, Explication et Validation du PnL) et BOP (Base transactionnelle unifiée au coeur de l'IT Risque). Au quotidien vous avez pour missions de :Participer à l'adaptation de nos applications en adéquation avec les besoins métiers (nouveaux produits, nouvelles règlementations, nouveaux SI Front) ;Participer activement à la modernisation de nos outils, modernisation de notre chaîne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;Monter en compétences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous développerez une compréhension globale des chaînes de traitements ;Participer à tous les travaux de modernisation de notre SI, et être donc engagé dans la migration de nombreux process vers le DataLake Risk. #TransformativeFinanceCe poste est basé à Paris avec la possibilité de télétravailler.En tant que Top Employer, nous plaçons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilité interne, développement de carrière et de formation vous permettent de grandir et de vous épanouir tout au long de votre parcours.Vous évoluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.Vous avez également la possibilité de vous engager en faveur de la société et de causes qui vous tiennent à cœur via notre fondation d'entreprise.  A propos du processus de recrutementVous serez contacté par l'un de nos recruteurs avant de rencontrer nos experts métier (manager, membre de l'équipe ou de la filière métier).Qui êtes-vous ? Si vous vous reconnaissez dans la description suivante vous êtes fait pour travailler avec nous :  Vous souhaitez bénéficier d'une première expérience significative en développement Spark et Scala.  Vous maitrisez : * Les méthodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une appétence pour la manipulation de la data.  Vous êtes : * Reconnu par votre esprit d'équipe ; * Capable de communiquer avec des publics différents, notamment avec le métier ; * Autonome et ntéressé par l'environnement finance de marché.  Vous maitrisez l'anglais avec un niveau B1.  Dites-nous que vous êtes intéressé en répondant à cette annonce.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst,Web Transition,"Marcq-en-Barœul, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-at-web-transition-3798106460?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=0WGSeAkrGK40s2dO7uyUAQ%3D%3D&position=13&pageNum=7&trk=public_jobs_jserp-result_search-card,"Web Transition, c’est qui ?   Fondée en 2011, Web transition est une entreprise de services numériques opérant sur le marché de l’IT/Digital !  Constituant une part essentielle de MoOngy Digital Lab, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et également en Data !  Notre objectif : nous implanter comme un acteur principal sur le marché de la Transformation Digitale en accompagnant et valorisant les compétences de nos collaborateurs ! Nous sommes convaincus que le succès de MoOngy Digital Lab réside dans la somme des potentiels de nos équipes 🤝  Ton équipe : La tribu Data  Parce qu’il est indispensable que tu puisses partager tes connaissances mais aussi en acquérir de nouvelles, tu feras partie de l’une de nos tribus : celle de la Data. De plus, cela te permettra d’être acteur dans le développement et la stratégie de Web Transition. Ce système de co-réflexion et co-construction est un fondement essentiel chez nous !  Dans cette aventure, tu : Optimises les requêtes SQL ;Construis les modèles de régression ;Analyses la rentabilité des actions marketing ;Réalises des études ad hoc sur les comportements clients ;Produits et automatise le reporting. Rejoins-nous si tu as : Un BAC+5 en école de commerce ou web,ainsi que d'une expérience de 3 à 5 ans dans l’animation digitale retail, avec une connaissance des spécificités du digital. Une connaissance approfondie des écosystèmes web et E-Commerce.Une aisance avec les indicateurs et tu as une bonne capacité d'analyse.Maitrises POWER BI.  Ton savoir-être : · Ouvert d’esprit · Respectueux des différences de chacun · Curieux · Proactif  Par où on commence ? · Un premier entretien RH d’1h pour comprendre ton parcours et tes aspirations · Un second entretien de 45 minutes avec l’un de nos Business Manager afin de valider tes compétences et qu’il se projette sur l’une des missions qu’il pourrait te proposer · Un troisième entretien de quelques minutes avec notre responsable d’agence pour te proposer d’intégrer notre superbe Team Web ! · 3 entretiens en peu de temps, si ton profil correspond tu intègreras très vite nos équipes 😉  Prêt pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant à cette offre ! Voici les avantages qui t’attendent en tant que Weber :  🤩 Des collègues incroyables 🏆 Certifiée Great Place to Work  🎮 Des bureaux sympas (où vous serez toujours les bienvenus)  🎉 Des teambuilding et évents tous les mois💻 Des tributs métiers pour échanger entre Weber du même métier Des missions chez le client qui sont accompagnées et coachées par ton manager Un accompagnement dans ton plan de carrière et tes envies de re skilling 🤓 Un catalogue de formations certifiantes ouvert à tous les salariés 🍽️ Une carte tickets restaurant MyEdenred   ❤️ Une mutuelle GrasSavoye   🚎 Une prise en charge des frais de transport à 100%


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Software Engineer - Branding Team,Teads,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-software-engineer-branding-team-at-teads-3776629218?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=Tfa7daI7dMRYR%2B9zQi9ipQ%3D%3D&position=14&pageNum=7&trk=public_jobs_jserp-result_search-card,"Teads has an engineering team that brings together 200+ talented individuals in 3 main locations (Montpellier, Paris, and Bucharest). We are organized in agile and autonomous feature teams and share technical knowledge within several communities of practice.We promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.Our organization gives the possibility to work remotely part of the time and more flexibility is open to discussion. We also offer relocation packages if you prefer to settle down in one of our engineering offices.👉 Join a team of passionate people who build quality and responsible advertising, at scale!Our Branding TeamThe Branding team is responsible for developing components and features that empower advertisers and agencies to craft compelling Branding campaigns, within an omnichannel framework (spanning in-article, in-stream, and CTV mediums).Our team works across the whole chain of campaign setup and delivery, covering both backend and frontend aspects. Our primary contribution is directed towards enhancing the usability of Teads Ad Manager, our campaign management system, while improving the code base.Our main Engineering challenges at TeadsWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).Rich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.Management of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).Build efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.A fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.Bring a wide diversity of profiles to the same level of quality and knowledge.What will you do?As a Senior Software Engineer, your mission will be to:Collaborate with a variety of teams to develop complex services.Create, design, develop, test, and monitor your code in production autonomously and reliably.Work with the Engineering Manager to frame projects and be accountable for their execution.Obtain a good understanding of the business to provide relevant solutions to clients.Be a work facilitator and help communication inside and outside Teads.Stay up-to-date on new technologies and architectures. If they can solve a problem Teads has, propose ways to implement them into our current software engineering process.What will you bring to the team?Good programming abilities. Testing your code is second nature to you. You are very mindful of your application’s architecture, performance, maintainability, and overall quality.Good communication skills and ability to work collaboratively within a team. You are an active listener and a dialogue facilitator, you know how to explain your decision and like sharing your knowledge.Multiple shipped projects in Software Engineering.Strong problem-solving skills.Why work at Teads?At Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to scale our business while continuing to create new and exciting products.We value team spirit, pragmatism, listening and we encourage initiatives.We promote end-to-end development: “You build it, you run it, you monitor it”.We share knowledge and support with each other beyond any organizational boundary.We fix issues during a blameless postmortem and learn from it so that it doesn’t happen twice.We are working together to create great engineering, but we are also supportive to promote a great work-life balance.We Care About YouSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).Career Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).Life Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.Wellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).Discover more about our culture and benefits on our Engineering website.What are our recruitment process steps?We want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!About TeadsTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.As an end-to-end solution, Teads’ modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world’s best publishers and content providers.Through exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.Teads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.We're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Data Engineer,Ryte,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-ryte-3727247165?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=j7uZCwrTWoptoadkkxHOog%3D%3D&position=15&pageNum=7&trk=public_jobs_jserp-result_search-card,"DescriptionAbout Us:We're a team of physicians, healthcare executives, data scientists and Tech experts committed to empowering anyone, anywhere with the insights they need to make well-informed healthcare decisions. Through the combined power of AI and big data, we have created the first all-in-one solution that provides our users with everything they need to know about medical professionals and facilities. RYTE transforms the comprehensive data we collect on millions of healthcare providers and medical experts worldwide into knowledge that helps individuals and organizations navigate healthcare systems. Headquartered in Toronto (Canada) and having operations in Canada, USA, France, Kazakhstan, and the Philippines, you will join a truly international, multicultural, and dynamic workforce driven toward building something unique that affects Life and Healthcare on a global scale. For more information about us, please contact us at www.ryte.ai.The Position: Senior Data EngineerWe are looking for a Senior level Data Engineer (Azure) who will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for use across existing products. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing and designing data systems. The Data Engineer will work alongside our international team of data stewards, data scientists, business and data analysts on data and integration initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. He/she must be self-directed and comfortable supporting multiple systems, products and data flows.This is a full-time position, working at Paris office (or Nice with frequent travel to Paris) | France. You will be working full-time for the Ryte team under the supervision of the Ryte Solution Architect.This is a CDI (Full time) position.The Role:As a successful candidate, you will bring extensive expertise in the design, framework & methodology of data warehousing, and possess experience in the full data life cycle. Additionally, you must possess a unique blend of healthcare business and industry savvy; a big-picture vision, and the drive to make that vision a reality. You must enjoy spending time in all healthcare SAAS business areas to understand their problems and find innovative solutions for the organization.Responsibilities:Understand complex Healthcare business requirements and provide solutions to business problems. Defining data engineering best practice and sharing across the organization. Understand modern data architecture approach including event-driven, data streaming and data mesh. Understand HealthCare compliance requirements (HIPAA, GDPR) and its applicability to Data Engineering. Create and maintain optimal data pipeline architecture. Set technical direction by designing solutions to complex problems. Improve the performance, observability, and reliability of our data pipelines. Implement data governance best practices in term of data cataloguing, lineage and metadata management. Work with large, complex financial data sets that require sophisticated processing and transformation. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build resilient and maintainable infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources. Work as part of an Agile development team with stakeholders to develop new features to support their data infrastructure needs. Work with data and analytics experts to strive for greater functionality in our data systems. Mentor less experienced team members by providing counsel and constructive oversight. Requirements Bachelor's degree in Engineering/Computer ScienceStrong experience using modern Data Warehousing solutions, preferably cloud solutionsAgile methodology experience essentialExperience applying modern data management frameworks and methodsExcellent documentation skillsTechnical project/change managementStrong understanding of RDBMS and NoSQL databasesExperience working with Graph databases is a plusOne or more in each of these categories:ETL: Spark, Azure Data Factory, DBT, pandas, Kafka StreamsQueues and Stream processing: Spark Streaming; Event Hub; Kafka. NoSQL: Cassandra, Azure Cosmos, Elasticsearch, MongoDBProgramming Languages: Python, SQL, Spark (Scala/PySpark)API Development: GraphQL, Rest, Thrift3+ years of experience as a Senior Data Engineer with Azure data components eg: Spark/Databricks, Data Lake, Data Factory, Synapse Analytics3+ years of data architecture, data analysis, ETL and/or data modeling experience3+ years current and deep experience with implementing large engagements. Proven experience managing projects through the entire project lifecycle. This includes managing multi-phase/multi-dimensional/multi-resource projects to conclusion while maintaining high customer satisfaction2+ years of experience and advanced domain knowledge in one or more vertical industries: manufacturing, financial services, government, legal, healthcare, property managementHighly proficient in spoken and written EnglishWe would like to thank all Applicants for their interest in this position. Please note that only Applicants selected for an interview will be contacted. Ryte Corp. is an equal opportunity employer. If selected for an interview, please advise our Human Resources team if you require accommodation during the interview and assessment process. We will work with Applicants to accommodate all accessibility needs.BenefitsFeatured Benefits:We provide Medical, Dental & Vision Insurance. Flexible Personal Time off (PTO). Fix + BonusFlexible remote work policy.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'Elasticsearch'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,RSight®,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-rsight%C2%AE-3801029508?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=5slywsiBSfT4hpDs5OO5kQ%3D%3D&position=16&pageNum=7&trk=public_jobs_jserp-result_search-card,"Nous recherchons pour notre client, un leader mondial des services et conseils en technologies, un ingénieur Databricks et Data Factory qui rejoindra une équipe qui combine des compétences métiers avec une forte expertise data, analytique et d’intelligence artificielle pour mettre en œuvre des solutions qui visent à améliorer la gestion et la valorisation des données.Descriptif des missions:Vous êtes intéressé à travailler sur une solution ayant un impact direct sur les ambitions de notre client en matière de data (datadriven, data démocratisation) ? Alors devenez membre de l’équipe Corporate Data Lake de notre client ! Comme tout autre membre de l'équipe, vous :Participer à la définition des composants informatiques supportant la fourniture de servicesDévelopper, tester, industrialiser et déployer des composants en minimisant les impacts sur les utilisateurs (automatisation, 0 temps d'arrêt,...)Documenter la bonne utilisation des servicesDéployer et supporter nos fonctionnalités sur la plateformeApporter assistance et conseils aux utilisateurs métiersOpérer la solution en opération courante (incluant le suivi de la qualité des services) et intervenir dans la résolution des incidentsParticiper activement à l'amélioration continue des activités de l'équipeExpliquer aux collaborateurs ce que le Corporate Data Lake peut faire pour euxConfigurer des espaces de travail pour euxFournir du coaching et de l'expertise lors de réunions en face à face ou sur les canaux communautairesParticiper à l'effort de support de la plateforme dans une approche ""vous la construisez, vous l'exécutez""Contribuer aux premières phases de conception définissant l'avenir du Corporate Data LakeCompétences:1er expérience Azure (PaaS et IaaS)Connaissance de Databricks et Data FactoryMaîtrise d'un ou plusieurs langages parmi : Python, Scala, Spark, PowerShellIntégration et livraison continues (Jenkins, Azure Devops, GIT Lab CI, …)Pratique des fondamentaux du génie logiciel (Gestion de Configuration, Tests,...)Anglais : à l'aise pour assister à une réunion et rédiger de la documentation techniqueBonne capacité d'écoute, orientation client/utilisateurExpression orale et écrite adaptée à l'interlocuteurCuriosité et adaptation aux changements technologiquesBénéfices:Un processus de recrutement court, un accompagnement personnalisé, une évolution qui s'adapte à votre trajectoire de carrière.En plus de votre quotidien lié à votre mission, vous pourrez entreprendre, être formé, passer des certifications.Plan d'épargne pour la retraite collectif, mutuelle, tickets restaurant, des congés d'ancienneté, un catalogue CE, des accords d’entreprise relatifs au télétravail et à la parentalité et autres avantages.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer (F/H),ACENSI,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-acensi-3747766862?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=sqezcwiQVfRess182ed3Ew%3D%3D&position=17&pageNum=7&trk=public_jobs_jserp-result_search-card,"Description de l'offre   LE POSTE ACENSI SUD-OUEST et ses équipes, ouvrent actuellement un poste de Data Engineer pour le bureau de Bordeaux !Contexte : Rattaché(e) à une équipe Data & IT, vous aiderez à concevoir, développer, exploiter les données et solutions Data à destination d’utilisateurs internes de pôles Supply Chain, Finance, Performance, RH et Marketing. LES MISSIONS Les Activités Qui Animeront Vos JournéesConcevoir et développer des solutions Data/IA à des fins analytics & dashboardingAccompagner les Métiers dans la compréhension des AnalyticsMettre en œuvre des solutions ""data driven""Mettre en œuvre des solutions industrielles exploitables, mesurables et opérablesCommuniquer et traduire les résultats aux parties prenantes de l'entrepriseCapitaliser sur les solutions pour créer de nouveaux produits, de nouveaux services et de nouvelles opportunités de digitalisation, de valorisation de la donnéeParticiper activement à la communauté de Data Scientist et de Data EngineerGérer un écosystème de partenaires data science et assurer un haut niveau d'expertiseAssurer un rôle de veille technologique sur tous les outils autour de la Data, IA et BISecteurs possibles : Telecom, Banque, E-Commerce, Assurances, …Un dernier point pour vous convaincre ?Un salaire positionné sur la fourchette haute du marché du numérique, avec un déroulé de carrière individualisé et le plus intéressant possible.Fini la « grille de salaires à respecter », et si on l'enjambait ensemble ?Vous pensez mériter ce salaire, avec votre niveau de compétences ? On peut se le permettre ? Et bien, allons-y !Fourchette de Salaire négociable : 45K à 60kDes Avantages Sociaux Personnalisés🎂 Acensi Sud-Ouest souhaite vous remercier chaque année pour votre engagement et votre fidélité. De nombreuses surprises et cadeaux vous attendent pour vos anniversaires au sein de la société, mais aussi lorsque vos retours de missions sont positifs sur la durée.🎨 Besoin de vous aérer l’esprit : loisir, art, sport ? C'est le moment de vous accompagner financièrement dans votre équilibre vie privée-vie pro !🤸‍♀️ On ne réinvente pas la roue, mais vous aurez le droit bien évidemment aux : ticket restaurant, 50% sur les transports en commun, 50% prise en charge de la mutuelle, chèques cadeaux, primes vacances, RTT …🏠 2/3 jours de télétravail🤝 Cooptation : 2000 à 3000 € brut / personne cooptée (selon conditions)Une entreprise où vous serez toujours bienvenupour partager un moment convivial (afterworks, soirées d’intégration…). LE PROFILPlus que des compétences, qui s’acquièrent avec de la motivation, du temps et de la formation, nous recherchons une personne avec un état d’esprit et qui sera capable d'être ambassadeur d'ACENSI !Pas de panique si vous ne cochez pas toutes les cases ! Nous échangerons ensemble sur vos compétences et nous mettrons en place un plan de formation adapté.De formation Bac+2 à Bac+5 en école d’ingénieur/université, vous avez au minimum 2 ans d’expérience dans le métier de l’ingénierie DATA ?Vous êtes à l’aise sur l’utilisation de la technologie Spark ?Vous connaissez des langages informatiques (Sql, Scala, Python, Java, Shell, …) vous permettant d'être autonome sur la manipulation des données ?Vous avez acquis une expérience dans les outils BI et data visualisation ?Vous avez des compétences statistiques et maîtrisez les modèles prédictifs ?Alors n'attendez plus pour nous envoyer une candidature !Recruteur en charge de l'offre: Florian AWANA
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer/BI (H/F),Eurécia,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-h-f-at-eur%C3%A9cia-3806360580?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=Nkl%2BxVrVTY6u1%2FQM7C%2FhAw%3D%3D&position=18&pageNum=7&trk=public_jobs_jserp-result_search-card,"À propos d'EuréciaEnvie de vivre une expérience différente ?Envie de retrouver du bon sens, de la simplicité, de l’efficacité ?Eurécia , c’est une solution RH made in Toulouse, 190 collaborateurs passionnés, 300 000 clients-utilisateurs, une présence dans 66 pays et des chocolatines (…Ô Toulouse) tous les matins ! Eurécia c’est aussi du management bienveillant, de l’épanouissement, de la confiance…Notre moteur ? Oser et Grandir ensemble en Confiance. Être Simple et Efficace !Si vous aussi vous voulez contribuer à construire un monde meilleur (ouais, on assume !), alors faites-nous un signe !Le poste🎯 Vos Missions, Votre QuotidienPour accompagner notre croissance, nous souhaitons renforcer le pôle data transverse qui soutient toutes les équipes. Dans ce cadre, nous cherchons notre nouveau Data Engineer/BI.Son rôle ? Participer à la mise en œuvre d’une plateforme data fiable et évolutive permettant de répondre aux différents besoins de KPI et de dashboard métiers.Concrètement, Vous Serez Amené(e) àMettre en œuvre et maintenir la plateforme data (airbyte, dataform, airflow, GCP)Concevoir, développer et maintenir des pipelines de données fiablesAnalyser les besoins des métiers en termes de data et mettre en œuvre les solutionsProposer et tester de nouvelles technos/outils pouvant améliorer la plateforme dataGérer la documentation technique et fonctionnelle des outilsGérer les problèmes techniquesProfil recherché🤓 On Est Fait Pour Travailler Ensemble SiVous disposez d'au moins 4 ans d'expérience dans un poste similaireVous avez une solide connaissance en Python, SQLVous avez une expérience en conception et mise en œuvre de pipelines de donnéesVous maîtrisez les concepts de BI traditionnels (datawarehouse, historisation…)Vous maîtriser un outil de data visualisation (Metabase, Tableau, power BI...)Vous êtes curieux(se) et pugnace pour trouver les solutions les plus efficaces et vous cherchez à progresser continuellementVous aimez relever des défis au quotidien, vous savez travailler en autonomie (et en équipe !) et être force de proposition afin d’apporter une valeur ajoutée à vos projetsVous avez une appétence pour la satisfaction clientVous êtes agile et capable de travailler sur plusieurs projets en même temps🚀 Pourquoi nous rejoindre ?Si nos valeurs vous font écho : «Oser et grandir ensemble en confiance. Être simple et efficace.»Pour s’épanouir et performer, Eurécia offre un cadre de travail de qualité à tous ses collaborateurs :Une team bienveillante, et un management de proximitéDes opportunités d’apprendre des uns et des autres : il n’y a pas d’échec, seulement des itérations et des occasions d’apprendreUne formation au cours de laquelle vous serez amené(e) à découvrir l’ensemble des équipes internes, nos offres, notre marché et nos process de développement produitsUn Campus de 1300m2 et 20 500m2 de parc au bord du canal du midi, pensé et réalisé pour répondre au bien-être quotidien des équipes, tout en préservant le patrimoine et l’âme du lieu☀️ Les Autres Avantages7 semaines de congés payés : soit 2 semaines supplémentaires par an !Des jours de congés supplémentaires : ancienneté, journée pour le mécénat et la journée de solidarité est offerte !Un accord de participation, qui peut être placé sur une épargne salarialeDes moments fun et gourmands : Euréciades, Stand up, gouter ou apéro 😉Un Kit Télétravail pour être bien installé(e) chez soi + une prime annuelle de 150€ netUne mutuelle prise en charge à 60%Des titres restaurants (dématérialisés) d’une valeur de 9.5€Une prise en charge de 50% des frais de transports en communUne prime mobilité annuelle de 400€ netDes fruits frais, massages, cours de sport et yoga…Notre Process De RecrutementUn premier échange avec Célia, Talent Acquisition Manager.Un second entretien, sera organisé avec Vincent, Data Manager.Si vous êtes retenu(e) parmi les candidats finaux, vous aurez l'occasion de faire connaissance avec toute l'équipe autour d’un moment convivial et gourmand ! 🍬🍫🍵Chez Eurécia nous croyons que la diversité est une chance et nous nous engageons à traiter les candidatures sans considération de sexe, d’âge, d’origine, de handicap ou de conviction.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer H/F,LesJeudis,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3788256076?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=mRmeZG7HM%2FVsk0xkOH594g%3D%3D&position=19&pageNum=7&trk=public_jobs_jserp-result_search-card,"MissionDans le cadre de son développement, Inetum recrute un Data Engineer (H/F) pour sa branche Applications Services.Vous interviendrez chez l'un de nos clients sur des projets BI et/ou Big Data en méthode agile.Le Data Engineer Sera En Charge DeApporter une expertise en Data permettant la manipulation de donnéesAccompagner nos clients dans la réalisation de projets dans un contexte Big Data et CloudParticiper à réunions permettant de valider les principes techniques et algorithmiques pour des projetsProfilDe formation Bac +5, vous justifiez d'une expérience d'au moins 4 ans dans le domaine de la Data. Vous avez évolué dans le monde du développement (Python, Spark, Aws...)Vous êtes capable de prendre des initiatives, autonome, rigoureux(se) et vous savez vous adaptez à de nouveaux environnements.Vous appréciez le travail en équipe dans un contexte agile, et aimez relever des défis.La maîtrise de l'anglais est un vrai plusOrganisationNous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer / Développeur·euse Big Data F/H,Onepoint,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur%C2%B7euse-big-data-f-h-at-onepoint-3612029460?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=xPfVnZG7Rehg1IxS4ymEdg%3D%3D&position=20&pageNum=7&trk=public_jobs_jserp-result_search-card,"Un·e data engineer est en charge de concevoir et de construire des pipelines de traitement de données. Curieux·se, il / elle est à l’aise avec du batch et du temps réel, de l’on premise et du cloud, des datalakes ou des data warehouses modernes. Ses traitements sont robustes, sécurisés, et performants, et il / elle n’hésite pas à les factoriser et les automatiser.Vos Missions Seront Les SuivantesÉtudier les systèmes sources ; Choisir et implémenter les solutions de stockage et les modèles de données adéquats ; Extraire et charger les données des systèmes sources ; Uniformiser, structurer et transformer les données ; Exposer ces données (API, Web services …) ; Planifier et orchestrer ces traitements ; Industrialiser selon les pratiques CI/CD ; Mettre en place des solutions de monitoring ; Documenter le code ; Expérimenter, évaluer, faire de la veille technologique. #techVous êtes diplômé·e d'une Grande École d'Ingénieur généraliste, informatique ou d’un Master spécialisé en Big Data, et avez une expérience minimum de 3 ans dans ce domaine.Vous Maitrisez Une Ou Plusieurs Des Solutions SuivantesL’écosystème Hadoop : Spark, HDFS, Hive, HBase, … Les distributions Cloudera (Hortonworks), MapR SQL, Scala, Java, Python, … Les services Data des principaux fournisseurs Cloud (AWS, Azure, GCP, …) Airflow, Luigi, … Kafka, RabbitMQ, … ElasticSearch (et la Suite ELK), Cassandra, MongoDB, Neo4J, … Docker, Kubernetes … Vous avez une ou plusieurs certifications en cours de validité sur l’une des technologies citées ci-dessus,Vous disposez d’un très bon relationnel, d’un bon sens de l’écoute et d’empathie,Vous faites preuve d’initiative, vous êtes naturellement force de propositions, vous avez envie de partager tes connaissances et savoir-faire et d’apprendre de vos pairs.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB', 'Cassandra', 'Neo4j', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer  H/F,Groupe INGENA,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-ingena-3788281977?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=zCiwalD0PwPEQAAW4VLAAQ%3D%3D&position=21&pageNum=7&trk=public_jobs_jserp-result_search-card,"Le groupe INGENA promeut la transition numérique en étant acteur d’un monde souhaitable.Votre mission :Concevoir, développer et tester des algorithmes de collecte et de traitement de gros volumes de données sous Scala, Python ou JavaAutomatiser et optimiser les flux de données et leurs visualisations en dashboardsIndustrialiser les traitements, la qualité et l’intégrité des donnéesParticiper à la Modélisation et à la Gouvernance des données (process, normalisation, référentiel,…)Contribuer à la scalabilité, la sécurité, la stabilité et la disponibilité des données de la plateformeAnalyser les données pour répondre aux questions métiers et participer à l’évolution de l’architecture Big DataConcevoir, Développer et Industrialiser des modèles de Machine Learning, Deep Learning, en collaboration avec les Data ScientistsAppliquer une démarche CI/CD (Git, Jira, Jenkins)Les compétences techniques nécessaires sont :Expérience de 5 ans minimum en développements Scala, Python ou JavaExpérience de 2 ans minimum sur SPARK et sur le traitement des flux en streamingExpertise sur Hadoop (Hive, HBase, HDFS) sous distributions MapR ou HortonworksExpérience souhaitée sur ELK, Terraform, NoSQL,…Fort background en Modélisation de données ou ETLMaîtrise des briques analytiques des clouds AWS, GCP ou AzureSensibilisation à la démarche CI/CD tools (Git, Jenkins)La connaissance de Docker, Kubernetes et Ansible est un plusMise en œuvre des méthodes Agile (Scrum, Kanban,…)Anglais souhaitéGroupe INGENA :Le Groupe INGENA est spécialisé en Conseil Métier et en Intégration pour les marchés de l’assurance, de la banque et de la Finance. INGENA intervient notamment sur les projets associés à la Data, aux Risques et à la Distribution.Le groupe comprend également la société DRiMS spécialisée en Finance de Marché.Nos valeurs : Engagement, Intégrité et Bienveillance.La mise en pratique du monde souhaitable, c’est pour nous une entreprise éco-responsable, éthique, inclusive, sociale, soucieuse du bien-être, de l’évolution et de l’épanouissement de ses équipes. Ce sont aussi des offres pour un monde durable comme la maîtrise des risques ou l’ESG.Dans un esprit convivial et engagé, nous faisons en sorte que chacun puisse être acteur de l’INGENA souhaitable.Bureau à Paris 9ème (Métro Le Peletier). Clients à Paris ou très proche banlieue.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['JIRA']}"
Data Analyst - 100% remote,BoondManager,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800335849?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=wGyR8mNsCDLVGMhKqfpaLA%3D%3D&position=22&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence 🚀Anthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et décident de créer une solution SAAS ERP à destination des ESN & sociétés de conseil, afin de ""travailler autrement"".BoondManager est ainsi né 🦊Au cœur de BoondManager, il y a l'idée que chacun(e) devrait avoir la possibilité de se réaliser dans son travail et sa carrière, de pouvoir ""les"" concilier avec sa vie personnelle. 🫶Notre Mission ⭐⭐⭐⭐⭐Fédérer sur un même outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunités, facturation, CRA) !Notre ADN ❤️Nos 75 Boonders sont en full remote/100% télétravail dans toute la France.Le télétravail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'est🤝 1500 clients👥 70.000 utilisateurs🌍 21 pays💶 Rentable et autofinancée🥰 La Boondfamily est passée de 30 à 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? 👇Le PosteBoondManager ne cesse de grandir ! 🦊Afin de répondre à notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'équipe BI/Performance 🦊Tout ça, c'est magnifique, mais on reste un peu sur notre faim… nos plus grands rêves sont :Devenir le leader européen des ERP pour les sociétés de conseils (on a de l'ambition).Et pour ça, on a besoin de toi !Nos Grands Principes 👌✅ Mieux vaut s'excuser que de demander la permission. On encourage à 300 % la prise d'initiative !✅ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, écoute !La (super) Team 🏆L'équipe Performance est composée de talents pluridisciplinaires ! François s'occupe de la data (ton futur binôme) Guillaume des projets de refactoring Manu de la stack ELK Rémi côté DevOps. Florens, ton futur managerLa performance touche l'ensemble des équipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plutôt sympa donc !Tes activités : 👇On Te Propose Côté Dataviz Création dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Intégration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets nécessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de manière transverse Spécification et conception de dashboard de A à ZCôté Data Analyst Création de KPI via sql Challenger les perfs de nos Kpi (améliorer les temps de résultats) Réaliser les croisements de données pour la construction et le maintien du data warehouse Assurer la maintenance et l'évolution des KPI du produit BoondCôté Engineering Suivi de l'intégrité de la donnée (topologie, audit) Participer à l'alimentation du Datawarehouse Développement, maintien et l'évolution de l'architecture des données Recueillir les besoins des parties prenantes et spécifier les besoins en dataNotre Stack Technique 🌈 Backend/Frontend : Java, Python (à venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'équipe Perfs 🦊 On se retrouve tous les lundis matin avec l'ensemble de l'équipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton évolution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour échanger avec le reste de la team Weekly avec toute l'équipe tech (les BB pour les intimes) le mercredi à 14hTon Onboarding 🚀1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Montée en compétence sur notre solution au travers de notre Boondgame Montée en compétence sur le métier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des données qui permet de calculer cette valeur, résolution). Être capable de mettre les mains dans l'intégration à boond des KPI (manipulé le backend)6 Mois Capacité de créer des nouveaux KPI à partir des demandes de PO (requête sql permettant de le calculer) Capable d'intégrer de la dataviz. L'idée est que tu sois dans les meilleures dispositions en maîtrisant notre environnement 💪ProfilEt toi, Qui es-tu ? 🤩🍷 Tu adores pinot et je ne te parle pas de celui des charentes💪 Tu as déjà construit des tableaux de bords au travers d'un outil de Dataviz✍️ tu connais kafka et pas que l'écrivain😎 Tu es capable d'écrire des requêtes optimisés pour fabriquer la dataviz avec des exemples concrets en SQL🧠 Python : Tu dois savoir développer des nouvelles fonctionnalités, gestion des dépendances, challenger l'existant (qualité du code), compiler le projet.🚀 Le + : Tu maîtrises notre stack technique (on veut des projets significatifs)🦊 Le petit ++ : Tu connais le monde des ESN🙋‍♀️ Mesdames, autorisez-vous à candidater !Ce Qu'on T'offrira En Plus De Tout Ça 🎁💸 Un salaire entre 45k et 60K🏡 100% remote 🇫🇷 (plus de temps pour toi !)🌴 3 séminaires par an pour se retrouver et s'éclater !😎 9 jours de congés payés supplémentaires🏥 Une mutuelle familiale (pas de suppléments pour ta famille)💸 Une offre télétravail en plus de ton salaire !🎁 Une offre mensuelle dans le coworking de ton choix !🧘 Cours en ligne de méditation, fitness et yoga chaque semaine !🤝 Un plan d'épargne entreprise valorisé à hauteur de 300 %💻 Une mise à disposition d'un Macbook, 2 écrans, casque, etc.🦊 On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !Déroulement des entretiens💻 Un premier échange avec Jean-Florian, notre Head Of Talent🚀 Un entretien technique/culture fit avec François, ton futur binôme côté Data🤝 Un échange Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager 🤓Et si tu as réussi à me lire jusqu'ici,voici ma dernière phrase pour qu'on ne passe pas à côté de toi : si demain cette offre venait à être clôturée et que tu penses regretter de ne pas avoir postulé, c'est qu'elle t'a tapé dans l'œil.Ça serait dommage de démarrer 2024 avec un regret,Alors, n'hésite pas, POSTULE👇
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),MERITIS,"Marseille, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3805423899?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=vIJA%2Bn6XU11S%2BL1rtgoS6Q%3D%3D&position=23&pageNum=7&trk=public_jobs_jserp-result_search-card,"Descriptif de l'entrepriseMeritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise. Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​Descriptif du posteEn collaboration avec l’architecte data, les experts data et le gestionnaire/propriétaire produit, vous serez amené à participer aux opérations et à l’implémentation de la roadmap technique de la plateforme d’orchestration. Voici vos missions :Participer au cycle de développement du produit Airflow,Assurer l’implémentation/développement de l’outillage et des fonctionnalités de la plateforme nécessaires avec accord de l’Architecte Data et les experts Data du groupe,Contribuer au développement des graphes orientés acycliques (DAG) nécessaires à la bonne opérabilité des plateformes datalake et datamart (AWS et Snowflake),Assurer le rôle de support technique auprès des end-users lors de leur usage de la plateforme,Assurer les livraisons et déploiement du code,Assurer le mode run de la plateforme,Support niveau 2 expertise de la production et participation aux situations de crises,Reporter au gestionnaire de la plateforme Airflow, les performances IT, l’état de santé temps réel et principaux risques opérationnels de la plateforme,Contribuer à la communauté Data Orchestration,Produire la documentation nécessaire à ce passage de connaissance : tuto, document d’exploitation, etc…Assurer et animer les sessions de transfert de connaissances au travers de démos produit.QualificationsVous avez un diplôme d’ingénieur ou un Bac+5 équivalentVous avez 3 ans d'expérience en tant que Data EngineerVous avez une bonne conne connaissance de l'environnement cloud AWSVous avez une bonne maitrise de l'Orchestration des processus, notamment avec AirflowVous êtes familier avec les principes ETL/ELTVous avez déjà travaillé avec la méthodologie Agile Scrum/KanbanInformations complémentaires :Des parcours professionnels sur mesure (évolution de carrière, formations adaptées, mentoring…) ;​Avoir le choix de sa mission et un accompagnement personnalisé tout au long de votre carrière ;​Evoluer dans un environnement où l’apprentissage est favorisé : formations certifiantes, e-learning, meetUp, concours de code, parcours d’évolutions etc ;​Faire partie de communautés d’experts qui partagent leurs savoirs et expériences au sein de nos centres de compétences ;​Un environnement convivial avec de nombreux événements festifs (soirée annuelle, séminaires & teambuiding, déjeuners et afterworks…) ;​""Meritis est engagée dans la Responsabilité Sociétale des Entreprises. Nous valorisons notre impact positif sur la société et l'environnement. Notre démarche RSE guide chacune de nos actions pour promouvoir l'équité, la durabilité et le bien-être de nos collaborateurs. Rejoignez-nous pour être partie prenante de cette démarche responsable, où chacun de nos talents contribue à construire un avenir meilleur.Nos différences sont nos atouts. C’est pourquoi Meritis s'implique en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap.""


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (h/f),METEOJOB by CleverConnect,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3786129236?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=UZaP4Dasr%2BgVHJ9RAQpdlQ%3D%3D&position=24&pageNum=7&trk=public_jobs_jserp-result_search-card,"EntrepriseACTIVUS c'est un groupe fondé par des passionnés de l'innovation au service de ses clients et de ses équipes.Ecoute, proximité, réactivité et efficacité se retrouvent dans notre management quotidien : bénéficiez d'un accompagnement personnalisé tout au long de votre carrière.Parce que nous remportons en permanence de nouveaux projets, nous saurons vous trouver LE poste que vous recherchez.Description Du PosteNous recherchons un(e) Data Engineer (H/F) avec une expertise avérée dans la construction et le maintien des infrastructures de données, ainsi qu'une solide expérience en développement de logiciels dans un environnement Python (architecture orientée microservices et API).Le/la Data Engineer aura pour mission d'accompagner les équipes dans le choix des technologies nécessaires à cette infrastructure, ainsi que de participer activement à sa mise en œuvre et à son bon fonctionnement.A Ce Titre, Ses Missions Seront Les SuivantesConcevoir les Data Models et Data Pipelines Concevoir les processus Elaborer la stratégie de validation des solutionsEtudier collaborativement et concevoir, en fonction des domaines et exigences non fonctionnellesConcevoir et spécifier l infrastructure pour la mise en place de Data Pipelines Spécifier les solutions d acquisition en fonction des flux Spécifier les solutions de traitement adaptées aux modèles, basés sur Python Estimer les besoins et coûtsSpécifier les solutions de gestion des données pour la mise en place des processus et politiques de gestionAccompagner et guider les équipesPrésentations des études et solutionsAccompagnement dans les expertisesAccompagnement dans les parcours de formationPrésentation et formations internesRevue de conception des solutions sur l ensemble de la chaîne de valeurMettre en œuvre et maintenirParticiper activement à la mise en œuvre de l infrastructureDévelopper et maintenir, avec les équipes de développement, les services de traitement de données en Python Supervision / monitoring des infrastructuresLanguesDescription du profil :Français courantAnglais professionnelCapacité à travailler en équipeRigueur et organisationAccompagnement du changementCapacité de vulgarisation et de démonstrationMotivation pour les grands projets d infrastructure (moyen/long terme)Appétence pour la météorologie et le monde scientifique en généra
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
R&D Data Engineer,Exotec,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/r-d-data-engineer-at-exotec-3806138743?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=LSp1H0WzAR9Tel2%2B2jJi2A%3D%3D&position=25&pageNum=7&trk=public_jobs_jserp-result_search-card,"Exotec is at the forefront of technological excellence, redefining the relationship between humans and robots. Our solutions are contributing to the success of some of the largest brands in retail and e-Commerce by revolutionizing the way they fulfill their orders to the end consumers, all while mitigating labor constraints and increasing workplace safety.Through the unification of artificial intelligence and high-performance hardware, our robotic solutions are now deployed across the globe and our exponential growth has led us to become the first industrial unicorn in France.Working at Exotec is an exciting opportunity to give purpose to your skills. Learn and grow with over 600 ExoPeople around the world to help turn your ideas into a reality.The robotics revolution is just the beginning at Exotec. Will you be part of it?We are seeking a talented and experienced Data Engineer to join our team in the Product Department.As a Data Engineer at Exotec, you will play a key role in designing, developing and maintaining our data infrastructure.ResponsibilitiesCollaborate with cross-functional teams to understand data requirements and design scalable data solutions. Collect data coming from our different client sitesDesign and implement an event driven data lakeProvide the data to applications and end userRequirementsIT/Software Engineer or related field. Proven experience as a Data Engineer or similar roleStrong proficiency in PythonHands-on experience with Terraform for Infrastructure as CodeKnowledge of containerization and orchestration tools like Docker and KubernetesFamiliarity with AWSStrong problem-solving and analytical skillsExcellent communication and collaboration skillsNice to have:Familiarity with Kafka or other message queuing systemHands-on experience with Apache Airflow or DagsterFamiliarity with machine learning frameworks and concepts


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Consultant·e Cloud Data Engineer GCP/Azure,Saegus,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/consultant%C2%B7e-cloud-data-engineer-gcp-azure-at-saegus-3769067736?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=tjPtpGd6a8%2B%2BlOehVWdP5w%3D%3D&position=1&pageNum=8&trk=public_jobs_jserp-result_search-card,"Qui est Saegus ?Saegus est la ConsulTech qui accompagne ses clients (grands groupes du CAC 40 / SBF 120) dans leur transition vers l'entreprise intelligente et responsable de demain, le Smart Shift.Le Smart Shift représente bien plus qu'une simple transition numérique. C'est une vision stratégique complète qui intègre les technologies émergentes, telles que l'intelligence artificielle et l'utilisation performante et raisonnée de la Data, à des changements culturels, organisationnels et de gouvernance.Nous appliquons également l’approche Smart Shift pour offrir à nos consultants un environnement propice à leur développement professionnel et à leur épanouissement : The Best Place To Grow. Au-delà de pouvoir vivre l'expérience d'un Smart Consultant (par l'IA), en rejoignant notre équipe, vous bénéficierez d'une culture d'entreprise axée sur l'agilité, l'innovation et l'adaptabilité. Nous accompagnons nos Saegusien·ne·s à développer de nouvelles compétences, à explorer les nouvelles technologies et à cultiver un esprit entrepreneurial, le tout accompagné par une école du conseil (parcours de formation propre à Saegus), un catalogue de formations et de certifications et un coach interne.Smart Shift. For Real.Saegus est incarné par ses quatre départements :Shift Acceleration, pour accélérer le passage d’une idée en un produit ou service au sein de grandes entreprises grâce à des outils et méthodologies agiles ;Smart Data, pour rendre compréhensibles, exploitables et valorisables les données des entreprises ;Smart Workplace, pour créer un environnement humain, physique et technologique optimal pour l’ensemble des collaborateur·rice·s ;Smart Experience Factory, pour designer et développer des applications sur-mesure grâce à une méthode centrée utilisateurs.Ainsi, nous recrutons un.e Consultant·e Cloud Data Engineer.Concrètement, quelle sera la mission et les réalisations attendues ❓En tant que Consultant·e Data Engineer, tu seras intégré·e à l’équipe Smart Data dont la mission est d’aider ses clients à tirer profit des technologies les plus innovantes pour valoriser leurs données. De l’acquisition à la restitution, tu interviens sur chaque étape du processus d’aide à la décision.Tu participeras aux missions de conseil et d’expertise afin de contribuer à l’atteinte des objectifs majeurs de nos clients et contribueras à la réalisation de projets tels que :⚡️ Le design d’une plateforme Azure Cloud et la mise en place de pipeline d’ingestion et exposition de données pour la mise à disposition de données métiers, rafraîchies toutes les 30mn⚡️ La mise en place des bonnes pratiques et l’initialisation du Datalab pour un grand groupe d’assurance, et l’accompagnement à l’industrialisation des algorithmes pour les usages métiers⚡️ L’ensemble des traitements d’ingestion et préparation des datasets afin d’alimenter des Dashboard de monitoring de l’activité digitale Worldwide d’un grand groupe cosmétique afin de mesurer l’empreinte des marques sur les médias et réseaux sociaux⚡️ L’accompagnement à la création et l’activité d’une Data Factory pour traiter l’ensemble des données d’un grand groupe de distribution et mettre à disposition des données qualifiées pour les différents use cases métiersNous recherchons un.e passionné.e possédant une envie de de fédérer et faire monter en valeur les consultants autour des thématiques Data Engineering recouvrant la mise en place de Plateforme de données, des bonnes pratiques de développements et des process DataOps, l’industrialisation de pipeline de traitements de données pouvant aller jusqu’à la Data Visualisation.➜ Dans quel environnement ?En fonction de tes missions et réalisations projet, tu seras amené·e à intégrer des équipes composées de Data Engineer, Data Scientist, Data Architects, organisées en mode agile. Tes activités s’appuieront sur les méthodes et savoir-faire de Saegus et sur son catalogue d’outils et technologies sur lesquels tu as une maîtrise sur plusieurs d’entre eux :✅ Bonnes connaissances sur les architectures data et cloud (connaissance d’un environnement Cloud) :Azure (Data Factory, Synapse, ADLS, Databricks)Google GCP (BigQuery, Composer, Data Studio)✅ SQL, Python✅ Spark, PySpark✅ Airflow, Kafka, Jenkins✅ Solides connaissances des processus collaboratifs et outils de développement (DevOps, Git, CI/CD…)Les connaissances suivantes seraient un plus ⤵️OpenShift, Docker, KubernetesData visualisationBases NoSQLCertification Data Engineer (Azure Data Engineer, Google Professional Data Engineer ou Snowflake SnowPro)Ce que nous t’apportons💫 FORMATIONS ET DÉVELOPPEMENT DE CARRIÈREUne journée de formation incluse dans ton parcours d’onboarding lors de ton premier mois d’arrivée pour partager sur les fondamentaux et répondre à tes questionsAccès à un coach interne et consultant comme toi pour t’accompagner dans ton quotidien (questions en particulier, aide, montée en compétences)Un plan de formations et de certifications ambitieux (minimum 1 certification offerte par an)⭐️ AVANTAGESRemboursement de tes frais de transports (remboursement à 100% de ton pass navigo ou forfait mobilité durable jusqu’à 700€ par an pour l’utilisation et l’aide à l’achat de matériel de mobilité douce)Titres restaurant à hauteur de 216€/mois pris en charge à 60% par Saegus (Carte Swile)Prime vacances (versée en juin)Prime téléphone 25€/moisPrime d’intéressement aux résultats de l’entreprisePrise en charge par Saegus de la mutuelle à la hauteur de 75%👋 COHÉSION ET CONVIVIALITÉOrganisation de deux activités par mois (fun, solidaire ou excellence) par notre Team AnimUn séminaire annuel pour favoriser la cohésion entre SaegusiensAccès aux locaux de Saegus, très accueillants dans le centre de Paris notamment lors de nos SaegUp mensuelProfil recherché🎯 Idéalement, en termes de compétences, nous recherchons :Un profil de formation supérieure (Bac + 5 minimum), ingénieur ou équivalent, avec une expérience d’au moins 3 ou 4 ans minimum dans le domaine du Big Data.Tu as déjà mené avec succès plusieurs projets Big Data avec des références significatives dans la mise en place de flux de données et de traitement de l’information.Tu interviens en autonomie sur tes projets et as une première expérience d’encadrement technique.Tu es motivé.e pour intégrer une structure alliant l’exigence d’un cabinet de conseil et le dynamisme et l’agilité d’une start-up.Tu es un·e très bon·ne communiquant·e et as un fort esprit d’initiative, un goût prononcé pour les nouvelles technologies et un bon esprit de synthèse.Ton sens du service et ton écoute client te permettront de t’inscrire parfaitement dans la culture de notre cabinet de conseil.La maîtrise de l’anglais et du français à l’écrit et à l’oral est indispensable.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes', 'OpenShift'], 'Collaboration': []}"
Data Quant Developer / Python - Hedge Fund - CDI - 100/180K€ - Paris,MR SEARCH,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-quant-developer-python-hedge-fund-cdi-100-180k%E2%82%AC-paris-at-mr-search-3804058753?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=yLkQC4BhDP2xnvt7uRg%2F8w%3D%3D&position=2&pageNum=8&trk=public_jobs_jserp-result_search-card,"Data Quant Developer Python – Hedge Fund – CDI – 75 – 100/180 K€ La société : Fond gérant plus 10 milliards dollars. Les 450 collaborateurs sont répartis dans les bureaux en plein centre de Paris ainsi qu’à Londres, Hong Kong et New York.En croissance permanente, la société prône des valeurs fortes tels que l’investissement et l’engagement. Le poste : Vous rejoignez les équipes Tech avec pour objectifs d’évaluer les nouvelles sources de données à intégrer dans la plateforme en lien avec les équipes de chercheurs quantitatifs :Analyser les sources de donnéesMettre en place des solutions de Machine Learning pour extraire les données cibléesGérer les différentes phases de traitement de la donnée : exploration, acquisition, engineeringValider les choix technologiquesAssurer la mise en production et la maintenabilité des flux de donnéesProfil recherché : Ecole d’ingénieurPlus de 3 ans d’expérience dans le domaine de la Data : Data Engineer, Data Quant ou Data ScientistExpert Python, Python ML, numpy, pandasConnaissance du NLPUne première expérience en banque d’investissement ou en Hedge Fund est appréciéeAnglais : courantVous avez la volonté et les capacités pour travailler dans un environnement exigeantPackage : Salaire fixe : selon expérience et supérieure à la moyenne du marchéBonus discrétionnaire : il peut dépasser 100% du fixeParticipation : élevée Si ce poste vous intéresse, envoyez-moi votre CV.Matthieu RicourMR Search


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Viz Engineer (H/F),Thales,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-viz-engineer-h-f-at-thales-3808500017?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=10g76wnsvYBx4yPXJpnh1Q%3D%3D&position=3&pageNum=8&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales propose des systèmes d'information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d'importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d'information critiques et cybersécurité, répondent aux besoins de marchés où l'utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l'activité Systèmes d'information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d'information afin de faire face aux ruptures technologiques et aux cybermenacesL’équipe de la BI Factory recherche un(e) Data Viz Engineer (H/F)QUI ETES-VOUS ?De formation Ingénieur ou Bac +5 (école d’ingénieur ou Université), vous justifiez d'une expérience professionnelle dans le monde de la DataViz / BI d’au moins 3 ans autour des solutions Qlik ou Power BI.Vous souhaitez mettre à disposition votre expertise dans le monde de la Data et continuer à développer vos compétences dans les aspects : Big Data, Data valorisation, Data Vizualisation, Data engineering et/ou Data Science et êtes doté d’un bon relationnel.Vous êtes pragmatique, curieux et organisé et aimez le travail bien fait.Vous êtes autonome, capable de travailler dans un environnement en évolution permanente et avez le sens du service (engagement et livraison)Vous êtes familier avec les pratiques agiles.Votre niveau d'anglais vous permet de rédiger des documents ou d'animer des réunions en anglais par téléphone/visio dans un contexte international.Vous vous reconnaissez ?CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :Le domaine de la Data est devenu aujourd'hui un enjeu majeur dans la stratégie des entreprises et leur transformation digitale. C’est pourquoi nous répondons aux besoins de nos client en leur offrant des solutions high-tech reposant d’une part sur notre connaissance des métiers, et d’autre part sur notre capacité d’innovation et notre savoir-faire autour de la Data (collecte, traitement, analyse, valorisation).Vous serez intégré(e) dans le centre de compétences « Augmented Data » de Brest, au sein de l’équipe BI Factory.La BI Factory, c’est une équipe dédiée agile à taille humaine qui adresse les besoins Data Vizualisation & Business Intelligence au sein du Groupe Thales et également pour nos clients hors Groupe.Vous interviendrez sur une diversité de projets de développement de systèmes d’information de nos clients locaux, mais aussi nationaux (domaines Défense, Banque, Assurance, Energie).Au sein de ce centre, vous rejoindrez notre équipe de Data Engineers, Data Architects et Data Scientistes installée à Brest. Data Viz Engineer, vous vous verrez confier les missions principales suivante :- Mener des ateliers de cadrage avec les utilisateurs finaux afin de recueillir tout d’abord leurs besoins puis ensuite leur présenter votre travail,- Participer à la conception de l’architecture générale des systèmes décisionnels de nos clients,- Être force de proposition et orienter les choix techniques en fonction de votre expérience et de la politique technique du groupe,- Implémenter les solutions validées par nos clients,- Etre le garant de la qualité technique des solutions produites et du respect de l'architecture initiale,- Contribuer au sein du département à l'effort d'animation technique, de veille technologique et d'innovation au sein des groupes de travail mis en place,- Partager vos connaissances au sein de la communauté BI Thales en présentant vos expériences sur vos travaux récents et approches innovantes.NOUS VOUS OFFRONS:- Une diversité de projets vous permettant de découvrir plusieurs environnements techniques et fonctionnels ainsi que l’ensemble de nos métiers au sein du groupe Thales,- Des conditions de travail motivantes et un plan de carrière personnalisé offrant de réelles perspectives d’évolution,- La possibilité de vous investir dans une entreprise dont la réputation est mondiale avec des ambitions constantes d’innovations techniques,- Un cadre de travail privilégié dans des bureaux situés à un endroit dynamique du port de commerce de Brest,- La possibilité de télé-travailler jusqu’à 10 jours par mois. Alors n'attendez plus, rejoignez-nous ! Thales reconnaît tous les talents : la diversité est notre meilleur atout. Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd'hui


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Paris H/F,Inventiv IT,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-paris-h-f-at-inventiv-it-3802092413?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=1OaelfvzhoupYpjj9Bc3bQ%3D%3D&position=4&pageNum=8&trk=public_jobs_jserp-result_search-card,"Imaginez comment vos compétences et votre vision pourraient enrichir notre dynamisme 🚀Votre énergie entrepreneuriale est le moteur de vos ambitions : vous visez toujours plus haut, désireux(se) de porter l'entreprise vers des sommets inexplorés. Réunir et inspirer les équipes fait naturellement partie de qui vous êtes, tout comme votre inébranlable expertise et votre passion pour chaque projet.La porte est ouverte pour discuter de l'impact que vous pourriez avoir ici⬇️Et si vous découvriez une entreprise créée en 2008 autour de l’humain et l’envie d’accompagner différemment ses clients :➡️ Nous sommes une tribu de 100 esprits dynamiques et passionnés, une entreprise à taille humaine où chaque voix compte. Notre cabinet de conseil en constante évolution incarne l'agilité et une flexibilité qui nous permet d'explorer des approches nouvelles et innovantes, centré sur le collaborateur..Nos consultants ont des responsabilités au sein de nos  4 pôles centraux : DIGITAL, DATA, CLOUD et FACTORY.Dans le cadre de son développement, Inventiv IT recrute un DATA Engineer avec une expérience de 4 ans au minimum.Le Poste est basé à Paris. Rythme de Travail Hybride🎯Inventifs Wanted Vous participerez au développement des projets ou des services data en développant une chaîne de traitement de données robuste et automatisée :Spécifications techniquesRelease plan des différents livrablesIngestion et mise en qualité des données selon les bonnes pratiques de la FactoryTraitement, agrégation et sauvegarde des donnéesIntégration continue (versioning, packaging, tests et déploiement)Étroite collaboration avec le chef de projet, OPS et architectesParticipation aux activités d’architecture, conception et développementRecette et mise en productionContribuer pro activement à la veille scientifique et technique, aux projets R&D, et à la construction d’assets et de services techniques orientés data ;Participer aux autres activités du pôle Data Science & Engineering (reporting d’activité, communication interne et externe, collaboration avec les universités et laboratoires associés)En mode agile : ScrumCompétences :Maitrise de Microsoft Azure Data Lake StorageMaitrise de Spark / ScalaConnaissances Git / Azure DevOpsConnaissances Airflow / DataDog / NifiPour vous aider à affronter nos défis,  vous disposez d’au moins 5 ans d’expérience dans les Big Data.Vous avez un esprit entrepreneurial et souhaitez vous investir pour faire grandir l’entreprise dans laquelle vous travaillez. Vous savez fédérer les équipes autour de vous et avez une réelle expertise et rigueur dans ce domaine.Vous possédez un bon niveau d’anglais.🤩 Inventiv OffersOn comprend bien que pour vous, un job ne se limite pas à être ""juste"" un job. On aimerait vous dévoiler ces petits détails qui font battre le cœur et font toute la différence:Vous êtes au cœur de nos priorités, nos actions en sont le reflet : Culture d'entreprise : partage des connaissances et esprit novateur Equilibre vie professionnelle / Perso: une flexibilité d’horaires et du télétravailOpportunités de développement professionnel : des défis stimulants pour grandirDes séminaires et événements mémorables, accompagnés de soirées d'entreprise chaleureuses.Rémunération : 52 000 - 58 000 €Sans négliger les avantages essentiels :Matériel au choix : ordinateur (PC ou Mac) recyclé ou neuf12 Jours de RTT / an - Et des jours en plus pour les moments de vie : mariage, naissance, paternitéTélétravail friendly (2 jours TT)Et bien sûr: Pass Navigo (100%) , carte Swile (10 € /Jour), Forfait téléphonique, Mutuelle Axa, primes diverses (participation, vacances, cooptation)Processus de recrutement :Entretien RH  avec une personne de notre Team RH : Discussion approfondie sur les motivations et l'adéquation avec la culture d'entreprise.Entretien Manager : Évaluation approfondie des compétences spécifiques au poste avec l'un de nos managersÉchanger avec vos pairs : opportunité de sentir l'ambiance, et l'environnement de travail.Envoi de la proposition : Bienvenue chez Inventiv-IT 🤸‍♀️Chez nous, chaque voix, chaque talent compte, sans aucun préjugé. Que vous soyez jeune ou plus expérimenté(e), peu importe votre origine, identité, religion ou orientation, nous valorisons chaque candidature. Nous nous engageons à répondre à toutes les candidatures dans les 72 heures.De plus, nous nous engageons fermement à l'inclusion, ouvrant tous nos postes aux personnes en situation de handicap.Rejoignez nous pour faire partie d'une équipe où l'égalité des chances est une réalité, où votre collaboration sera votre plus grand atout !


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer  H/F,Amiltone,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-amiltone-3701770014?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=PBUx5bmhjgIPHKJpw%2BaNIQ%3D%3D&position=5&pageNum=8&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?Nous sommes passionnés par les nouvelles technologies, et vous ?Rejoindre Amiltone, c’est intégrer des équipes dynamiques et soudées dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.Pourquoi choisir Amiltone ?Amiltone, plus qu’une entreprise, un état d’esprit !Notre objectif ? Votre épanouissement professionnel !Nous Avons à Cœur DeVous accompagner au mieux au travers d’un suivi personnalisé Vous faire monter en compétences en vous proposant des formations tout au long de votre carrière Comprendre vos besoins et respecter nos engagements Vous proposer des missions de qualité avec des technologies innovantes Cultivervotre potentiel grâce à notre programme de développement personnel Addvise Votre bien-être passe aussi par des activités extraprofessionnelles, c’est pourquoi nous vous proposons des séances sportives animées par nos coachs, soirées pour se retrouver et animations (à l'agence ou en visio), Gaming nights…Les Missions D'un AmiltonienEn tant que Data Engineer (H/F), vous serez en charge des missions suivantes :– Concevoir et développer les futures fonctionnalités de la plateforme Big Data sous Google Cloud Platform.– Concevoir les flux d'alimentation et les tables (structure de donnée).– Automatiser et industrialiser les flux.– Assurer le run applicatif, le cas échéant.La Stack TechniqueMaîtrise des langages suivants : SQL, Talend, BigQueryConnaissances de Google (GCP)Notion de programmation fonctionnelleLe Profil D’un AmiltonienDiplômé Bac+4/5 (Ecole d'ingénieur/Master), vous disposez de 2 années d'expérience dans le développement de data.Toujours sur le qui-vive des nouveautés technologiques, vous êtes force de proposition sur des technos, des outils ou des process qui permettent d'améliorer la qualité du code et la stabilité de nos applications.Outre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.Nos postes sont ouverts aux personnes en situation de handicap.Postuler
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,ALFI : Financial Markets Consultancy Services,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-alfi-financial-markets-consultancy-services-3799072485?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=i4jqJ9fH4MDGgq%2BZzgCMYQ%3D%3D&position=6&pageNum=8&trk=public_jobs_jserp-result_search-card,"ALFI est une société de conseil et services spécialisée en systèmes d’information. Depuis plus de 20 ans, ALFI est un acteur unique qui mêle technologie et humain pour accompagner les transformations numériques sur les marchés de l’Asset Management, la banque d’Investissement et les Services aux Investisseurs.Avec plus de 46 référencements de rang un, ALFI est reconnu comme incontournable sur le secteur BFA. Nous avons plus de 35 clients grands comptes actifs tels que HSBC, Société Générale, BNP Paribas, Crédit Agricole, Axa…Depuis 2015, ALFI a intégré le groupe MoOngy, qui compte plus de 6000 salariés dans toute l’EuropeMissions : Pour l'un de nos clients grands comptes, nous vous proposons d'intervenir sur une fonction de Consultant Data engineer.Les principales missions sont :Comprendre les besoins des utilisateurs et les traduire de manière analytiqueDéveloppement de solutions permettant de traiter des volumes importants de donnéesConception, collection et fabrication des données brutesDévelopper des algorithmes permettant de répondre aux problèmes posés et veiller à leur industrialisationSécurisation des Pipelines données pour les Data Scientists et les Data AnalystsConstruire des bases de données robustesOrganisation de l’architecture du cloudProfil recherché :Vous êtes issu d'une formation Bac +5 Ecole scientifique ou informatique.Vous disposez d'une première expérience en développement et dans la data.Vous disposez d'un niveau d'anglais opérationnel.Java, Python, C++SQLDevops (Jenkins, Kubernetes, Docker)Conformément à la règlementation, et à notre politique d’égalité professionnelle, tous nos postes sont ouverts aux personnes en situation de handicap;


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Stage Data Engineer (F/H),Capgemini,"Aix-en-Provence, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-f-h-at-capgemini-3806599442?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=Cd3gmcdXcYTUe3VupkcEiA%3D%3D&position=7&pageNum=8&trk=public_jobs_jserp-result_search-card,"DESCRIPTION DU POSTE Vous serez intégré au sein de notre Service Line Data Value et vous interviendrez sur les différentes phases d'un projet BI/Big Data: •Acquisition des données •Stockage optimisé •Traitements et analyses •Mise en forme et développement de rapports/dashboards Vous proposerez des nouvelles lectures de données via un travail de fouille sur les gisements d’information, notamment client. Dans votre quotidien, vous contribuerez au partage et à la capitalisation des savoirs et des pratiques au sein de la communauté data de Capgemini. Environnement techniqueETL (Talend, Informatica, SSIS), Spark, Python, Scala, Qlik, Tableau, Power BIBase de donnéesOracle, SQL Server, PostgresVotre profil : En dernière année d’école d’ingénieur ou de M2, vous cherchez un stage de fin d’études en vue d’intégrer durablement une entreprise de services du numérique. Dynamique, vous avez l’esprit d’équipe et de fortes appétences pour le domaine de la Data. Vous disposez d’un premier stage dans la data. Motivé, vous souhaitez vous investir dans une société qui vous offrira de belles perspectives de carrière, un accompagnement sur mesure managérial et RH et de beaux projets techniques. Bon niveau d’anglais (équivalent B2+ minimum)


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Betclic Group,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-betclic-group-3193434928?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=ORxSM5zs%2BtN%2BxhEDd1bQ1Q%3D%3D&position=8&pageNum=8&trk=public_jobs_jserp-result_search-card,"WE ARE BETCLICBetclic est une société tech de jeu en ligne et leader du pari sportif dans plusieurs pays Européens. Tous les jours Betclic s’engage à satisfaire la passion du sport en fournissant la meilleure expérience de divertissement à ses joueurs grâce à des technologies de pointe innovantes qui leur assurent un environnement de jeu sûr et sain.Betclic, dont le siège français est à Bordeaux, est une entreprise multiculturelle et internationale comptant près de 950 collaborateurs répartis dans 5 pays d’Europe : France, Italie, Malte, Pologne, et Portugal.L’univers du sport et du jeu te fait vibrer ? Tu aimes les défis, tu es passionné par la tech et participer à l’effort collectif ? Rejoins l’aventure !NO TECH NO GAME Betclic place la performance technologique au cœur de ses activités :Des applications entièrement développées en interne pour une maîtrise optimale de la chaîne de valeur : segmentation en temps réel, sensibilisation et intégration de règles pour protéger les joueurs, détection des risques … Des interfaces conçues pour une expérience joueur immersive : hautement sécurisées, capables de gérer de forts pics de connexion et d’intégrer les événements sportifs en streaming. Des équipes Tech organisées en squads et tribus autonomes, chacune responsable d'un domaine fonctionnel et technique qui permettent de gérer des projets de A à Z : développement, test de charge, livraison, suivi de production (monitoring, alerting). ENTER THE GAMEEn tant que Data Engineer, tu intégreras une équipe agile IT afin de construire les pipelines de transformation data. Dans ce cadre, tu travailleras étroitement avec les développeurs et le PO de l'équipe ainsi que les Data Architect sur la partie modélisation.YOUR ROLE WITHIN BETCLICAu sein d’une tribe Betclic et accompagné par une guild de data engineers DBT, tes missions principales seront de :Participer aux phases de conception et de développement des projets de transformation data Développer l’ensemble de la chaîne de transformation (Extract Load Transform / Extract Transform Load) au sein du Data Lake (Snowflake). Construction du Lake House et des couches Silver/Gold à partir de la couche Bronze du Lake. Automatiser le déploiement des pipelines data (DBT cloud, CICD Jenkins) Gérer l’évolution des solutions proposées, et en assurer la maintenance Rédiger la documentation relative aux projets TECHNICAL ENVIRONMENTSnowflakeDBT Core / DBT Cloud AWSJenkins GithubWHO WE ARE LOOKING FOR?Des collaborateurs avec une bonne dose d’humour, du respect et de la bienveillance, un amour pour la tech, un peu de zèle et une réelle passion pour leur métier !Ce job est fait pour toi si :Tu es diplômé(e) d’une école d’ingénieur, école informatique, MIAGETu disposes d’une expérience professionnelle réussie de 3 ans minimum en tant que Data Engineer / Data Ops / ML Ops dans un environnement Cloud PublicTu es doté(e) de fortes compétences en développement, d’une appétence pour l’automatisation (CI/CD) et le scripting et tu souhaites rejoindre un environnement professionnel challengeant. Tu es sensible à la performance, la fiabilité, la maintenabilité et la scalabilité de votre code et des architectures que tu conçoisTu maîtrises impérativement un des langages de développement Python, Scala, Java et tu as une expérience réussie avec l’Infrastructure As CodeEt enfin, tu parles anglais courammentWHAT ARE THE RECRUITMENT STEPS?Si ta candidature est sélectionnée, tu seras contacté par Maxime sous une semaine pour une préqualification RH (30 minutes) Nous te demanderons ensuite de réaliser le Test AssessFirst (personnalité, motivations et réflexion) Tu rencontreras ensuite ton futur manager puis Laurent le manager de la Data Platform qui t'évaluera techniquement.Enfin, Maxime te recevra en entretien final RH et vous débrieferez ensemble ton Test AssessFirst Afin d’offrir une expérience candidat idéale, le processus de recrutement Betclic dure, en moyenne, 4 à 6 semaines.WHAT CAN YOU EXPECT?25 jours de congés payés et 10 jours de « RTT » Une carte Ticket Restaurant® créditée de 10€ par jour (financée à hauteur de 50%) Une mutuelle prise en charge à 100% pour toi et tes enfants Un abonnement de transport pris en charge à hauteur de 50% ou une prime annuelle de mobilité durable (200€ pour les trajets domicile – travail en transport durable) Un accord de télétravail avantageux Un programme de formation annuel personnalisé Des locaux hors du commun avec un rooftop pour profiter de pauses et de déjeuners au soleil face à la Cité du Vin Des animations internes pour pimenter ton quotidien Des cours de sports gratuits dans nos locaux Et surtout, l’opportunité de travailler dans une atmosphère jeune, conviviale et fun !Poste en CDI à pourvoir dès que possible à BordeauxBetclic Group - 117 quai de Bacalan 33300 BORDEAUXTous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F/X,Verisure,"Antony, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-x-at-verisure-3798322567?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=yT4XSOMq52p3W4OXPuQXrQ%3D%3D&position=9&pageNum=8&trk=public_jobs_jserp-result_search-card,"Verisure c’est l’alarme de votre voisin mais c’est aussi le N°1 en France et en Europe ! Depuis plus de 30 ans, les équipes de Verisure partagent la même mission : « Nous sommes des personnes qui protégeons des personnes ».Les femmes et les hommes de Verisure ont toutes et tous un parcours de vie unique. Nos différences sont notre force et nous offrent une énergie singulière. Entreprise handi-accueillante et handi-bienveillante, nos postes sont évidemment ouverts aux personnes en situation de handicap.En recherche permanente de nouveaux talents, nous avons besoin de VOUS en qualité de Data Engineer !Rattaché(e) au Responsable Data, le/la Data Engineer sera le trait d’union entre les équipes internationales du groupe Verisure et la France.Sa capacité à apporter une connaissance et compréhension technique solide, nous permettra d’accroitre nos expertises croisées.Enthousiaste et passionné(e), vous êtes très êtes à l'aise avec les outils d’acquisition et de transformation de la donnée et avez une appétence toute particulière pour toutes les problématiques de flux temps réels et événementiels.Vous faites preuve d’une grande compréhension des flux de données et intervenez en tant que maîtrise d’œuvre afin de garantir la bonne implémentation des solutions informatiques décisionnelles de l’entreprise. Vous êtes rigoureux(se), structuré(e) et vous savez vous adapter selon vos interlocuteurs. Vous avez également le souci du détail ainsi qu’un esprit d'analyse.Vos principales missions seront les suivantes :Créer, maintenir et migrer les flux d’intégration de la plateforme internationaleImplémenter toutes les solutions techniques et/ou logicielles permettant d’améliorer la fiabilité.Administrer et monitorer les solutions communes multi-country (Data Viz – Sharing).Développer la connaissance technique de nos Data Engineer sur les technologies groupe.Accompagner le/la Product Owner dans le suivi des solutions Data multi-country.Collaborer avec notre Data Owner sur les travaux de normalisation de données.Maintenir nos référentiels techniques (cartographies, spécifications) et dictionnaire de KPIs à jour.Êtes-vous prêt à rejoindre nos équipes Data & Analytics engagées et passionnées ?Vous justifiez d’une première expérience de 2 année sur un poste de Data EngineerVotre appétence et curiosité autour des solutions Data ne fait aucun douteVous maitrisez le datamining, le SQL n’a aucun secret pour vousVous comprenez les flux informatiques anciens (BI classique) et modernes (temps réel et événementiel)Vous appréciez partager votre savoir-faire et faire grandir ceux qui vous entourentVotre niveau d’anglais est très avancé.Et votre savoir être s’inscrit dans l’ADN de nos Data Lovers(euses), humilité, simplicité et bienveillance.A nos côtés vous pourrez :Bénéficier d’un accompagnement personnalisé tout au long de votre parcours ;Profiter d’un tremplin de carrière grâce à notre parcours d’évolution ;Contribuer à la croissance d’une entreprise qui s’engage au quotidien pour un monde plus sûr, plus juste et plus durable ;Evoluer dans un environnement de travail innovant grâce à nos développements technologiques et à des projets ambitieux ;Travailler aux côtés d’équipes engagées et passionnées ;Profiter des avantages suivants :Un dispositif d’épargne salariale adapté selon votre éligibilité et les accords en vigueur dans l’entreprise (intéressement et participation aux résultats de l’entreprise) ;une pack mutuelle pour toute votre famille et une prévoyance ;prise en charge de votre déjeuner, adaptée selon le poste occupé et votre lieu de travail ;une plateforme de formation 100 % digitale et gratuite ;une offre collaborateur sur nos produits ;une plateforme sportive en ligne gratuite, proposant plus de 300 activités.Postulez dès aujourd’hui et embarquez au sein d’une aventure humaine aussi enrichissante que passionnante. Nous avons hâte de vous rencontrer !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Sancare,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-sancare-3751911956?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=J5XnRIu8EDZ2irZBSZIDyw%3D%3D&position=10&pageNum=8&trk=public_jobs_jserp-result_search-card,"Qui sont-ils ?Les hôpitaux recueillent de multiples données de santé lors de l’hospitalisation d’un patient : comptes rendus médicaux, observations du personnel soignant, résultats d’examens, etc.À l’échelle de l’hôpital, cela représente une quantité massive de données, qui sont largement sous-exploitées. Sancare propose des outils prédictifs utilisant les dernières avancées en intelligence artificielle pour mettre ces données au service des hôpitaux et de la santé.Notre premier produit est déjà utilisé par une quarantaine de groupement hospitalier. Il permet la détection automatique de diagnostics à partir de documents en texte libre et autres données contenus dans les dossiers patients, visualisables dans une interface web intuitive et ergonomique, et fait gagner du temps aux médecins et à leurs assistants administratifs. Nous développons en parallèle un nouvel outil facilitant la conduite d’études en vie réelle pour évaluer des médicaments et dispositifs médicaux. Vu le fort impact potentiel de ce projet sur la recherche clinique, l’attente de la part de différents acteurs de la santé (notamment, hôpitaux et laboratoires pharmaceutiques) est considérable.L'équipe de Sancare est composée de presque 50 collaborateurs spécialisées dans le développement informatique, le machine learning et la santé. Nous avons de plus la chance d’être accompagnés par des chercheurs reconnus dans le domaine du machine learning, ainsi que par des médecins et experts du monde de la santé. Nous recherchons un(e) Data Engineer avec de solides compétences opérationnelles et souhaitant rejoindre une équipe dynamique, expérimentée et motivée, afin d’accélérer l'arrivée de nos solutions en rupture dans le monde de la santé. Descriptif du posteLa gestion et le traitement de la donnée sont au coeur des problématiques de Sancare. Comme chaque hôpital dispose de son propre système d’information, des connecteurs doivent être implémentés pour chacun, afin de nourrir les algorithmes de machine learning. Les moyens d’accès et le format des données contenues dans les dossiers patients sont très variés et diffèrent d’un établissement à un autre.De plus, de nombreuses mesures sont à respecter afin de garantir la sécurité et la confidentialité des données.Missions :Développement de connecteurs permettant la transmission des données hospitalières entre les SI hospitaliers et les logiciels de SancareDéveloppement d’outils de standardisation et de traitement des données hospitalières en vue de leur utilisation par les algorithmes de machine learningAmélioration et maintenance des fonctionnalités existantes de traitement de donnéesGestion opérationnelle des différents services de traitement de données, etc. Les avantages  Sancare :Des superbes locaux en plein centre de Paris (Châtelet)Une organisation du travail flexible (109 jours de télétravail par année civile pour les salariés en forfait jour: soit deux jours de télétravail possibles par semaine et ce forfait pourra être porté à 131 jours de télétravail si les salariés au forfait jour justifient d’un temps de déplacement domicile-bureau supérieur à 3h par jour: soit trois à quatre jours de télétravail possibles par semaines pour les personnes à plus d’1h30 du bureau)Tickets restaurantÉligibilité BSPCEMutuelle AlanHello CSE, etc.Chez Sancare on n’est jamais à l’abri d’un apéro ou d’un cours de street-art ! Des retours d’expérience réguliers dans des formats variés (afterworks, séminaires, …) pour valoriser le partage d’idées et la connaissance commune. Profil recherchéExpérience significative dans le développement en Python orienté objet (3ans à 5ans)Expérience de développement sous LinuxExpérience dans la manipulation de données avec le langage SQLPratique avancée des outils d’intégration continue avec Git et tests unitairesDes qualités d’autonomie, de flexibilité et de responsabilitéL’esprit d’équipe et la volonté de prendre part à une aventure collectiveUn intérêt pour le monde de la santéSont un plus :Familiarité avec Docker et RabbitMqExpérience avec les données de santé dans le secteur hospitalierN’hésitez pas à partager vos projets personnels de développement (sur GitHub ou ailleurs). Déroulement des entretiensEntretien RHTest Technique puis Entretien Technique de pair programing avec l'équipe Entretien avec notre CEO


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
"Data Engineer - Scientific Engine (Airflow, DVC)",Descartes Underwriting,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-scientific-engine-airflow-dvc-at-descartes-underwriting-3699925454?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=yQs8ePVldRp7Yvc3GWtKfg%3D%3D&position=11&pageNum=8&trk=public_jobs_jserp-result_search-card,"ABOUT DESCARTES UNDERWRITINGDescartes was born out of the conviction that climate change calls for a revolutionary approach in insurance to better protect corporations, governments, and vulnerable communities. We offer a new generation of parametric insurance that builds resilience against the full spectrum of climate and emerging risks. Utilizing Machine Learning and real-time monitoring from satellite imagery & IoT, our state-of-the-art climate tech provides innovative coverage for all trade sectors in all regions of the world. After a successful Series B raise of $120M USD, Descartes Underwriting is proud to be recognized among the French Tech Next40 and launched Descartes Insurance, a ‘full stack’ insurer licensed to underwrite risk by the French Regulator (ACPR). With a growing corporate client base (350+ and counting) - our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. ABOUT YOUR ROLEDue to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenario to make a climate risk assessment. You will have to take initiative and assess the viability of proof of concept projects.You will have to work with data scientists and software engineers to run and develop our models. You will be working along DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events.🔔 KEY MISSIONS 🔔Setup, automate, maintain and update:Connections to external and internal APIsData preparation processModel training and inference processData storage processAssociated CI/CD pipelinesAssociated package versioning and releasing pipelineModularization of code baseNotification tools to inform the team of the status of the operationsSetup data storage, data processing and data visualizing tools, by :Assessing the pains and needs of the teamsBenchmarking the open source and private solutionsAssessing the security, price and reliability of data architectureFollowing the development the evolution of technologies on the topicForecasting the usage of the toolsTracking the cost of the toolsParticipate in:Tech stack selectionDiscussions with tech partnersTraining of software and underwriting teamsSupport and debug of internal usersTECH STACK 🖥️Cloud provider: GCPCode versioning tool: Git + GitlabOS: LinuxContainer: DockerContainer orchestrator: KubernetesWebsite architecture: LAMPCode base: PythonNotification tool: SlackDATA STACK 🗄️Types: images, timeseries,Storage: GCP bucketVersion: DVC (roll out in progress)Pipeline: Airflow (PoC stage)Data base: to be setup depending on the use casesIn our project, data is collected by sensors (satellite, weather station, IoT). We don’t work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation …).EQUIPMENT 🖱️Laptop: Dell Latitude 7530OS: you decideABOUT YOU EXPERIENCE & QUALIFICATIONS 👩‍💻👨‍💻[Hard skills]Knowledge of the tech stack or equivalent toolsExperience converting python code to efficient data engineering tools (eg: spark)Experience with DockerExperience with a cloud provider (GCP, AWS or azure)Experience automating a CI/CD pipelineGood knowledge in English and fluency in French[Soft skills]Desire to train junior developers and explain CI/CD and cloud toolsDesire to suggest improvements to the architecture[Nice-to-have]Experience working data science project or scientific codeExperience with KubernetesExperience in HPCContribution to an open source projectMINDSET 💥Strong interest with climate issue (it’s not a hoax, many people suffer from it)Being comfortable to work alongside corporate insurers (some still wear suits 👔)You enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline)Strong team spirit and ability to work (you’ll have to review code and have your code reviewed)Rigorous, creative and meticulous mind (we handle large insurance, we take our time)Strong desire to learn (there’s no limitation to the tech used, we’re happy to test and learn new tools)Eagerness to work in a multi-cultural environment (policies and teams are from all around the world 🗺️)WHY JOIN DESCARTES UNDERWRITING?Join a company with a true purpose – help us help our clients be more resilient towards climate risks;A competitive salary, bonus and benefits (Premium Alan health insurance, Swile restaurant vouchers, Navigo reimbursement etc.);The opportunity to grow in your role, as the company does;Commitment from Descartes to it’s staff of continued learning and development (think annual seminars, training etc.);Be part of a collaborative, diverse team where your ideas are heard;A paid referral scheme for successfully referring peers;Frequent team events.OUR COMMUNITYAt Descartes Underwriting, we are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences.With equal skills, all our positions are open to people with disabilities.HOW TO APPLY?If you want to develop your skills and work in a friendly start-up atmosphere, don't hesitate and send us your application! https://www.descartesunderwriting.com/careers/If you don’t check all the requirements in the description, don’t worry. We can try to make some room for you within the company if you’re motivated to work on climate risk.RECRUITMENT PROCESSStep 1: Call and HR Interview with our Talent RecruiterStep 2: Technical project submitted via GitHubStep 3: Technical interviewStep 4: Manager interviewStep 5: Final round interview with the team(Candidates can opt to have the manager interview before the technical project and interview)


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['Slack']}"
Senior Data Engineer (H/F),Believe,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-believe-3726297642?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=9fA50GJsLAI4XDNhpNAcDg%3D%3D&position=12&pageNum=8&trk=public_jobs_jserp-result_search-card,"Description De L'entrepriseBelieve est l'un des leaders mondiaux du marché de la musique numérique. Believe a pour mission d’accompagner les artistes et les labels locaux dans l’écosystème digital en leur offrant des solutions à chaque étape de leur carrière et développementCe sont plus de 1900 salariés dans 50 pays qui accompagnent artistes avec expertise, respect, équité et transparence.Afin de soutenir notre forte croissance sur tous les continents, nous sommes constamment à l’affût de nouveaux Believers. Rejoignez-nous afin qu’ensemble, nous ayons un impact fort et plus positif sur l’industrie musicale !Believe est cotée sur le compartiment A du marché réglementé d’Euronext Paris (Ticker : BLV, ISIN : FR0014003FE9).www.believe.comReady to #setthetone with Believe?Description Du PosteContexteLe Tribe « Customer Finance » est composé de plusieurs Squad, parmi elles la squad Finance Ingestion qui a pour mission de développer des outils et des applications pour la collecte de royalties auprès des plateformes de streaming de musique ainsi que préparer les données afin de faire la distribution des royalties auprès des producteurs de musiques.En tant que Senior Data Engineer, tu intégras une équipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette équipe est composée essentiellement de 5 Data Engineer et 1 Software Engineer.Nous Avons Un Écosystème Composé DeUn socle de gestion des données (Delta Lake) plus d’1.5 milliard de lignes /mois Data processing avec Scala et Spark utilisant le runtime de Databricks Orchestration de nos data pipelines avec Airflow managé Des APIs déployées avec AWS Lambda et API Gateway pour faire interagir les utilisateurs avec notre interface front (PHP) AWS RDS pour hoster la base de données back-end sous PostgreSQL Versionning du code sous GitLab avec un environnement de dev, staging et production Infrastructure sous AWS Les missions du Senior Data Engineer au sein de l’équipe : Accompagner les développeurs à écrire du code propre, qualitatif et conforme aux standards de l’équipe          Interagir avec l’architecte, les équipes infrastructures Cloud pour concevoir les solutions de data engineering Proposer des améliorations continues et être garant de réduire les dettes techniques          Développer des flux de données (data pipelines) avec de l’Apache Spark et du Scala          Faire de l’orchestration via Airflow avec du Python          Maintenir le workflow GitLab afin de garantir une bonne productivité de l’équipe de développement          Effectuer des revues de codes des autres membres de l’équipe          Collaborer les membres de l’équipe dev pour atteindre l’objectif du sprint          Faire du support applicatif et fonctionnel de l’application auprès des opérationnelQualificationsQualifications du Data Engineer  5-8 ans d’expérience en Scala  Une maitrise horizontale de tous les composants d’une plateforme de data Expérience en programmation fonctionnel Connaissance d’un effect system en Scala (ZIO ou cats) Excellente maîtrise de l’API Spark en Scala avec pour but de guider l’équipe sur les bonnes pratiques Expérience en développement backend Une bonne maitrise des services AWS (API Gateway, Lambda, SNS, SQS, S3, Cloudwatch, VPC) Développer avec un état d’esprit Keep it Simple, Stupid (KISS) Excellente compétence dans la gestion de relation avec une équipe en remote Bonne communication pour gérer les différents points de vue et expliquer les contraintes aux utilisateursOptionnel Expérience en PHP (framewok Symfony ou Laravel) Informations supplémentairesSet the tone with us Chez Believe, nous avons deux cœurs : nos collaborateurs et nos artistes.Nous croyons en la force de nos collaborateurs, qui s'épanouissent chaque jour en développant leur potentiel... Notre objectif est d'offrir à nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'épanouir.Rock the jobProgramme de formation et de coaching sur mesureUne politique de télétravailUn programme de bien-être ""Pauses"" avec de nombreuses activités et animations en interneAccès à Eutelmed, la plateforme numérique de santé mentale et de bien-être qui permet de parler à un psychologue expérimentéUn restaurant d'entreprise sain et éco-responsableUne assurance santé individuelle ou familialeAvantages CEUn rooftopUne salle de sport avec des cours gratuitsSing in harmonyDes groupes d'ambassadeurs pour s'engager sur la réduction de l'empreinte carbone et environnementale de Believe et l’équité professionnelle Femme/Homme.Mise en place du Forfait mobilité durable: remboursement jusqu’à 600€ des frais de transport en commun/avec une faible empreinte carbone.Congé 2nd parent de 5 jours calendaires rémunérés à 100% (en plus du congé légal paternité ou du congé d’adoption, nous ne l’attribuons pas au congé maternité)Believe s’engage à garantir l’égalité des chances en matière d’emploi, sans tenir compte de l’origine, du sexe, des mœurs, de l’orientation sexuelle, du genre, de l’âge, de la situation de famille, de l’état de grossesse, d’une prétendue race, des opinions politiques, des activités syndicales, des convictions religieuses, de l’apparence physique, du nom de famille, du lieu de résidence, de l’état de santé, ou en situation de handicap.Découvrez nos nouveaux locaux : bit.ly/believeoffice
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Big Data Engineer Databricks H/F,Talan,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-h-f-at-talan-3810332102?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=V0N1zdgOhxOUlVGsK2Cziw%3D%3D&position=13&pageNum=8&trk=public_jobs_jserp-result_search-card,"Talan est un cabinet de conseil en innovation et transformation par la technologie.Depuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en œuvre leurs projets de transformation et d’innovation en France et à l'international. Présent sur cinq continents, le groupe prévoit de réaliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant·e·s et vise à dépasser la barre du milliard d’€ de CA à horizon 2024.Le Groupe met l'innovation au cœur de son développement et intervient dans les domaines liés aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.Présent dans les événements incontournables du secteur, comme Viva Technology, Talan prend régulièrement la parole sur les enjeux de ces technologies révolutionnaires aux côtés d'acteurs majeurs du secteur et de parlementaires (Syntec Numérique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny…).Talan est une entreprise responsable, attachée à la diversité. Des aménagements de poste peuvent être organisés pour tenir compte des personnes en situation de handicap.Retrouvez nos engagementsRSEiciet nos actions en faveur de la diversitéiciJob DescriptionNous sommes à la recherche d’un Big Data Engineer Databricks confirmé qui sera en charge de l’intégration des données: acquisition, préparation, modélisation et stockage, exposition, . Vous devrez faire preuve d’un état d’esprit à la fois innovant, méthodique, orienté solution (et non problème!), et communiquant.ResponsabilitésAnalyse des besoins techniques métiers, définition de l’architecture solution et logiciel, référent technique, développement et optimisation, code review, maintenir les pratiques Devops “You build IT, You run IT”, support à recette et mise en production, documentation, et parfois assumer le rôle de Scrum Master,…Partager techniquement les membres de l’équipe: solutions et code reviews, recommandations, certifications à réaliser, …Participation à des meet-up, coding dogo,…Communication: écriture d’articles, retours d’expérience…QualificationsIssu d’une formation supérieure (école d’ingénieur, master,…)Vous disposez d’au moins 3 années d’expérience dans le domaine du Big Data et particulièrement sur le framework Spark (idéalement Databricks)Maîtrise du développement logiciel (Scala, Python,…) et vous disposez de solides expériences dans la mise en place de pipeline de donnéesExpérience sur une plateforme Cloud serait un plus et idéalement AWSExpérience sur des flux temps réelserait un plus : Kafka + Spark StreamingMaitrise du langage SQLExpérience sur des méthodes de stockage: HDFS, S3, ,…Bonnes connaissances en devOps : Jenkins, Gitlab, Maven, …Connaissance de l’AgilitéAutonomie, organisation, sens du partageBonne communicationOrientation produit et solutionAdditional InformationAVANTAGES :Top 5 du Palmarès Great Place to WorkManagement de proximité par des expertsOrganisation sous forme decommunautésUn parcours excellence Agile devopsFinancement de plusieurs certifications officielles à l’année grâce à nos partenaires éditeursUn accès à la plateforme CampusTalan avec plus de 1000 formations disponibles dès votre arrivéeUne mobilité interne facilitéeUn engagement auprès des travailleurs en situation de handicapDes événements et afterworks réguliersSiège parisien situé à Porte MaillotTickets restaurants digitalisésMutuelle d’entreprise prise en charge à 100%Prime vacancesPrimes de cooptationActionnariat1% logementPartenaire de l'organisme Mobility dans le cadre de l'accompagnement à la mobilité et à la recherche de logementRTT


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer / DBA MySQL / MariaDB (H/F),euRHasi,"Puteaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-dba-mysql-mariadb-h-f-at-eurhasi-3795382260?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=jYL8idRogd5iH%2FXhyx%2Fpmw%3D%3D&position=14&pageNum=8&trk=public_jobs_jserp-result_search-card,"Description Du PosteLe cabinet EURHASI recrute pour son client un Data Engineer / DBA MySQL / MariaDB (H/F)Notre client est un des un des leaders de la connectivité cellulaire pour l’Internet des Objets. Parallèlement, notre client est un leader européen en tant que MVNE (société apportant des solutions technologiques complètes aux MVNO).La mission Le rôle du DBA est de concevoir, maintenir, superviser et développer l’infrastructure des bases de données pour la plateforme Transatel afin de répondre aux exigences de services pour les clients externes et les usages internes. Transatel propose ses services à l’international pour des grands comptes ayant une haute exigence de disponibilité et d’efficacité. Cette activité permet aux DBA d’avoir des responsabilités variées et stimulantes avec de belles opportunités d’évolution.Au sein de la DTSI, rattaché(e) au Responsable Infrastructure et Devops, vous intégrez une équipe de 12 personnes dans les périmètres SysAdmins, DBA, Monitoring.Vos principales missions :Assurer le maintien en conditions optimales des bases de données (performances, disponibilité) Optimiser les performances des traitements SQL effectués par les plateformes Transatel Améliorer l’automatisation des tâches récurrentes et des tests de supervision Participer aux mises en production des composants développés et opérés par Transatel Rafraîchir les environnements de développement/test avec des données à jour et désensibilisées Superviser et analyser l’activité DB, Surveiller les jobs, Traiter les incidents Appliquer la politique de sécurité, Gérer les utilisateurs Conserver un environnement propre en assurant l’archivage des données et le nettoyage des structures de données Maintenir la qualité des données maitres et données de références, en relation avec les chefs de projets Apporter son expertise aux développeurs pour la conception des structures de données et le développement SQL Profil Profil recherchéCapacité d’analyse (investigation) méthodique et sens relationnel, Bonne gestion du stress, Bonne gestion des priorités et respect des délais, Travail collaboratif dans une direction technique avec des chefs de projets, développeurs, sysadmin, réseau et télécom, BDD, Support, Capacité rédactionnelle, esprit synthétique afin de rendre compte des actions et des réalisations entreprises, Capacité à transmettre son savoir et son savoir-faire, Expérience de 3 ans minimum (hors stage) en tant que DBA MySQL & Le monde des Telecom ne vous est pas inconnu Anglais technique Votre univers technologique :MySQL/MariaDB, Percona, ColumStore, Galera Cluster, ElasticSearch 6.X Etc. Linux Debian, Centos, Redhat Bash, Python, Ansible Compétences minimum attenduesExpérience de plus de 5 ans MySQL  MariaDB Informations contractuelles Les avantagesIntéressement Participation Télétravail Mutuelle dentreprise Autresremboursement pass Navigo à 50% avantages du CE 2 jours de télétravail par semaine La charte prévoit 2 jours de télétravail par semaine maximum après 2 mois d’ancienneté.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,illi&co,"Croix, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-illi-co-3752842280?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=3XCe3a0RyiDpMYsas906Nw%3D%3D&position=15&pageNum=8&trk=public_jobs_jserp-result_search-card,"Leader Français sur le marché de la carte cadeau multi-enseignes depuis plus de 15 ans, illicado est LA marque emblématique du groupe illi&co !Nous avons pour mission de simplifier le quotidien de tous et agir collectivement pour le mieux-être de demain !Nous pensons fièrement que chaque jour est une opportunité ! Alors, saisissez la VOTRE en répondant à cette annonce !MISSION :En cohérence avec la stratégie d’entreprise et la roadmap data, vous aurez pour principales missions de :- En lien avec l’équipe DevOps, construire, maintenir et faire évoluer la plateforme de données;- Définir et piloter la cohérence de la collecte, la gestion et l’alimentation des données internes et externes, en différents modes : batch, streaming, API (architecture micro-services);- Préparer et mettre en qualité les données pour les rendre disponibles dans les différents environnement de travail (datalake, datawarehouse, datamart);- Vérifier la qualité des données, de leur bonne et régulière exécution ainsi que de leur utilisation adéquate (gestion des coûts);- Travailler en étroite collaboration avec les data analysts, scientists et data stewards et business de l’entreprise ;- En lien avec l’IT et la sécurité, veiller aux règles d'intégrité et de sécurité des données;- Veille technologique.LES OUTILS :Plateforme data : Google Cloud Platform (Big Query, Airflow)Développement : Github/GitLab, Docker, Terraform, PythonAnalytiques : QlikOutils gestion de projets: Jira, Confluence, Miro, Drive, Docs, Sheets, SlidesPROFIL RECHERCHE :Expérience d’au moins 2 ans (après études) indispensable en data ingénierie (flux, modélisation, run)A l’aise avec l’environnement Cloud et les infrastructures digitalesCommuniquant, pédagogue et fortes capacités relationnellesAnglais (à l’écrit)Pourquoi rejoindre l’aventure humaine et professionnelle illi&co ?Nous voulons interagir avec toutes nos parties prenantes avec les valeurs qui nous animent, notre BASE :#Bienveillance - Prendre soin de soi et des autres#Audace - Chacun est libre d’avoir l’envie et le courage d’oser#Simplicité - Nous sommes une entreprise où on agit avec naturel, clarté et humilité#Enthousiasme - Un collectif d’hommes et de femmes optimistes et passionnésPour avoir un impact positif sur votre environnement #RSEAvantages : Fixe sur 12 mois + variable individuelParticipation/intéressement (environ 1,5 mois de salaire) + Actionnariat entrepriseTitres restaurants (sans part salariale)Statut Cadre (+RTT)Forfait mutuelle selon situation prise en charge à 50% (solo, duo, famille)2,5 jours de télétravail flexibleIndemnité kilométrique si vous venez au bureau en véloDes bureaux modernes et super lumineux


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence']}"
Data Engineer - Big data H/F CDI,Amanora Technologies,"Metz, Grand Est, France",https://fr.linkedin.com/jobs/view/data-engineer-big-data-h-f-cdi-at-amanora-technologies-3798913326?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=UU%2BsvM0BEPONK49gwCcGSA%3D%3D&position=16&pageNum=8&trk=public_jobs_jserp-result_search-card,"Fondé en 2013 par un ancien dirigeant industriel mondial, AMANORA démontre un savoir-faire en combinant l'expertise d'un cabinet de recrutement et d'ingénierie. Actif à l'échelle nationale en France,AMANORA se positionne dans divers secteurs tels que la métallurgie, la pharmacie, la pétrochimie, le nucléaire, l'aéronautique, l'agroalimentaire, ou encore le béton.Amanora Technologies est une société d'ingénierie et de recrutement fondée en 2013 par un ancien dirigeant de l'industrie. Amanora Technologies intervient partout en France dans des secteurs tels que la métallurgie, la pharmacie, la pétrochimie, le nucléaire, l'aéronautique, l'agroalimentaire ou le béton.Jeune talent, ingénieur ou manager expérimenté, rejoindre Amanora c'est faire le choix d'intégrer une entreprise à taille humaine qui place le plaisir au travail au coeur de ses préoccupations.Nous recrutons un(e) Data Engineer - Big data qui sera en délégation auprès de notre client, groupe international leader sur le secteur de l'industrie lourde, Dans le cadre des travaux menés avec l'équipe Data Intelligence de la DTD ,vous interviendrez au sein de l'équipe DigitalOps du département IT Transverse qui est en charge de l'opérationnel et contribue à certains projets du client.Vous êtes intéressé(e) par une mission variée et motivé(e) par le processus de transformation de l'industrie version 4.0 Ce poste est fait pour vous !Principales missions : Contribuer au suivi et pilotage en condition opérationnelle des traitements existants en production Vérifier et optimiser la disponibilité, la performance et l'efficacité des traitements Préparer le passage en opérationnel / maintenance pour l'intégration et l'automatisation des flux Concevoir et réaliser les développements en respectant l'architecture et les standards définis Chiffrer / Estimer la charge des travaux à réaliser Réaliser les tests (unitaire / intégration) et la recette et les automatiser si possible Rédiger les livrables documentaires associés (fonctionnel, technique, procédure opérationnelle...) Vous êtes de formation Ingénieur en développement informatique / informatique industrielle ou équivalent (Bac+5) Vous maitrisez Spark, PySpark, Python, Git (Branch, Merge, Pull, Fetch, Rebase), Hadoop (Cloudera) / Hive / HDFS, SQL / NoSQL, OS : Unix / Linux, Kafka, Suite Elastik (ELK) Vous avez une expérience de 3 ans minimum, idéalement au service de l'industrie lourde Vous disposez d'une bonne capacité d'analyse et de synthèse, Vous avez des compétences en gestion de projet, rédaction de documents et procédures, animation de réunion Vous êtes curieux, autonome, organisé et proactif, Vous savez communiquer avec des interlocuteurs variés et avez l'esprit d'équipeSi vous reconnaissez que cette opportunité correspond à votre profil, n'hésitez pas à postuler.Primes, environnement stimulant, accompagnement à la prise de poste, équilibre vie personnelle/vie professionnelle 19047535-55584
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Remote or Hybrid (Digital Assets),Turn Block Talent,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-remote-or-hybrid-digital-assets-at-turn-block-talent-3810820768?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=FROM%2FXEIBFkKU3%2Bc1ZQB%2Bg%3D%3D&position=17&pageNum=8&trk=public_jobs_jserp-result_search-card,"About The CompanyOur client is a global fintech company, with offices in NYC, London, Paris, andSingapore. Rapidly growing, they are the leading crypto market data provider for financialinstitutions and enterprises in the digital asset space.Our client is a team of +80 (and growing) passionate individuals with a deep interest in building datasolutions and supporting the growth of the digital finance economy.About The RoleThe Challenge:You will be joining a fast-paced engineering team made up of people with significant experienceworking with terabytes of data. They believe that everybody has something to bring to the table,and therefore put collaborative effort and team-work above all else (and not just from anengineering perspective).You will be able to work autonomously as an equally trusted member of the team, andParticipate In Efforts Such AsAddressing high availability problems: cross-region data replication, disaster recovery,etc.Addressing “big data” problems: 200+ millions of messages/day, 160B data points since2010Improving our development workflow, continuous integration, continuous delivery and ina broader sense our team practicesExpanding our platform’s observability through monitoring, logging, alerting and tracingWhat You’ll Be DoingDesign, develop and deploy scalable and observable backend microservicesReflect on our storage, querying and aggregation capabilities, as well as thetechnologies required to meet our objectivesWork hand-in-hand with the business team on developing new features, addressingissues and extending the platformTech StackGolang, Kafka, Redis, Clickhouse, Postgres, Nomad, Terraform and Vault.About YouSignificant experience as a Software/Data/DevOps EngineerKnowledgeable about data ingestion pipelines and massive data queryingWorked with, in no particular order: microservices architecture, infrastructure as a code, self-managed services (eg. deploy and maintain our own databases), distributed services, server-side development, etcThe most important skills for us revolve around two things:What we like to call “core” knowledge: what’s a software process, how does it interactwith a machine’s or the network’s resources, what kind of constraints can we expect forcertain workloads, etcHow fast you can adapt to a technology you didn’t know existed 10 minutes agoIn short, we are looking for someone able to spot early on that spending 10 days to migrate datato a more efficient schema is the better solution compared to scaling out a database cluster ina matter of minutes if we are looking to improve performance in the long term.Nice to haveExperience with data scraping over HTTP, WebSocket, and/or FIX ProtocolExperience developing financial product methodologies for indices, reference rates, andexchange ratesKnowledgeable about the technicalities of financial market data, such as the differencebetween: calls, puts, straddles, different types of bonds, swaps, CFD, CDS, options,futures, etcPersonal SkillsHonest: receiving and giving feedback is very important to youHumble: making new errors is an essential part of your journeyEmpathetic: you feel a sense of responsibility for all the team’s endeavors rather thanfocus on individual contributionsCommitted: as an equally important member of the team, you want to make yourselfheard while respecting everybody’s point of viewFluent in written and spoken EnglishYou have the utmost respect for legacy code and infrastructure, with some occasionaland perfectly understandable respectful complaintsWhat They OfferAn attractive compensation package, including equity and healthcare.An entrepreneurial environment with a lot of autonomy and responsibilities.Opportunity to work with an internationally diverse team.The hardware of your choice to help you deliver your best work.Good perks (remote-friendly, meal vouchers, multiple team events andstaff surprises).
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Ingénieur H/F,Alteca,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-h-f-at-alteca-3798371488?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=gCE3vDni9sp7FXYJD8iNQA%3D%3D&position=18&pageNum=8&trk=public_jobs_jserp-result_search-card,"TRAVAILLER CHEZ ALTECAChez Alteca le management de proximité, le bien-être et l'évolution de nos collaborateurs sont des priorités qui nous permettent, chaque jour, de proposer la meilleure expertise possible à nos clients.Et c'est grâce à ces convictions, que nous sommes aujourd'hui référencés auprès de partenaires grands comptes dans les secteurs de la Banque, de l'Assurance ou encore de la Distribution (Si vous souhaitez en savoir plus sur Alteca, RDV sur l'onglet ""Qui sommes-nous ?"").________________________________> En tant que Data Ingénieur (H/F), tu seras rattaché(e) au Pôle Data de notre Agence toulousaine. Ton Manager sera Christian COT (Responsable du Pôle) ou l'un de ses Référent technique. Interlocuteur privilégié, il assurera ton intégration durant tes trois premiers mois dans l'entreprise, ta montée en compétences, tes points de suivi tout au long de tes missions et tes Entretiens Annuels.> Tu auras également accès à une communauté technique d'experts grâce aux nombreux Webinar organisés tout au long de l'année, tu pourras aussi participer aux projets de notre Centre de R&D ou encore assister aux MID'INNO (présentations de nos collaborateurs sur des thématiques données comme la Green Tech, l'IA...).> Rejoindre ALTECA c'est aussi rejoindre une entreprise engagée sur la RSE (labellisée Ecovadis Silver 2022), pour le bien-être de ses salariés (labellisée HappyAtWork pour la 5ème année consécutive), et dans la formation de ses stagiaires et alternants (labellisée HappyTrainees pour la 4ème année consécutive).TES MISSIONSEn coordination avec les équipes d'un de nos clients grands comptes, tes missions seront les suivantes :Concevoir les Data Models et Data Pipelines : cartographier et documenter les types de données et leur usage, concevoir les solutions, les processus, élaborer la stratégie de validation des solutionsConcevoir et spécifier l’infrastructure : spécifier les solutions d’acquisition en fonction des flux, les solutions de traitement adaptées aux modèles, estimer les besoins et coûts, spécifier les solutions de gestion des donnéesAccompagner et guider les équipes : présentation des études et solutions, accompagnement dans les expertises, les parcours de formation…Mettre en œuvre l’infrastructure, développer et maintenir les services de traitement de données, supervision / monitoring des infrastructuresLa majeure partie des projets de nos clients sont sur des environnements techniques récents : Python, FastAPI (ou Django / Flask) et des ORM type SQLAlchemy, Pandas, Numpy, Xarray, ETL, Airflow, BDD (timescaleDB, IngluxDB, MongoDB, Elastic, NoSQL Redis, PostgreSQL), Kafka, Prefect, Nifi, Pandas, Numpy, Xarray, Dask) Docker, Kubernetes, Gitlab et en méthodologie Agile Scrum.  Ton profil : diplômé(e) d'un Bac+5 dans le domaine de la Data (Université ou Ecole d'Ingénieur), tu as au moins 7 ans d'expérience sur un poste similaire et tu sais évoluer en environnement Agile. Tu possèdes également une expérience dans le développement de logiciel (Python) dans une architecture orientée microservices et APITa personnalité : tu es une personne organisée et rigoureuse. Tu disposes d'un bon relationnel et tu aimes le travail en équipe. Tu as la capacité de vulgarisation et de démonstration. Tu apprécies et contribues à développer un contexte de travail bienveillant et qui favorise le partage de connaissances, l’accompagnement au changement. Enfin, tu et motivé pour les grands projets d’infrastructure (moyen / long terme)Type de contrat proposé : temps plein | Niveau de poste : confirmé________________________________Process de recrutement :ν Malivanh te contactera pour un premier échange téléphonique, puis elle te recevra dans le cadre d'un entretien RH.ν Si cet entretien est validé, tu rencontreras alors Christophe, le Responsable du Pôle Digital, pour un entretien technique.________________________________ NOS AVANTAGESTransport pris en charge à 75% | Tickets resto pris en charge à 60% | Mutuelle prise en charge à 60%10 jours de RTT en plus des 25 jours de CP | Mode de travail : hybride | Accès au CSE (billetterie, voyages...)Des parcours de formations personnalisés (75% de nos collaborateurs ont suivis au moins 1 formation en 2022)En tant que signataire de la charte de diversité en entreprise, Alteca favorise un environnement de travail inclusif et respectueux de tous. A compétences égales, tous nos postes sont ouverts aux personnes en situation de handicap.Votre chance c'est votre talent, la nôtre c'est de le développer : rejoignez-nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer (H/F),Adsearch,"Nice, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-adsearch-3807376801?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=SAIIILLsSVvtiMhXE7OYZg%3D%3D&position=19&pageNum=8&trk=public_jobs_jserp-result_search-card,"Adsearch vous propose des milliers d''opportunités de carrières dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Intérim et Freelance sur notre site internet ! En bref : Nice- CDI - Data Engineer Talend (F/H) - Salaire selon expérience - TélétravailAdsearch, cabinet de recrutement basé à Nice vous accompagne dans votre carrière pour vous trouver LE poste idéal.Je recrute pour un client un Data Engineer Talend (F/H) basé à Nice.Vos MissionsCadre du besoinImplémentation des solutions BI - TalendRédaction des spécifications techniques et fonctionnellesModélisation des systèmes décisionnelsOptimisation et monitoringVotre profil ;Vous êtes idéalement titulaire d'un Bac+5 dans l'informatiqueVous avez une première expérience sur un poste similaireTalend n'a plus de secret pour vous ?Ce Que L'on Vous ProposeDes sujets challengeantUne super TeamLe Processus De RecrutementEtape 1 : Entretien de sélection avec Adsearch pour définir vos objectifs de carrière et votre correspondance avec le posteEtape 2 : Entretien technique avec le clientEt c'est tout ! Pas d'entretien inutile, nous allons directement au but.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst,Hoist Finance,"Marcq-en-Barœul, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-at-hoist-finance-3800215166?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=1TJfCe8iejJ%2F0MA30e%2Fj5g%3D%3D&position=20&pageNum=8&trk=public_jobs_jserp-result_search-card,"Vous êtes à l’écoute d’une nouvelle opportunité professionnelle dans le domaine de la Data ?Vous portez un vif intérêt au secteur financier ?Rejoignez-nous ! Hoist Finance est une société financière spécialisée dans le rachat et la gestion de portefeuilles de créances bancaires. Le groupe compte 1 500 collaborateurs dans 13 pays européens. Propriétaires des dossiers-clients que nous rachetons aux établissements bancaires, nous sommes 120 collaborateurs en France tournés vers le même objectif : aider nos clients à devenir libres de dettes.Data Analyst (H/F) Dans le cadre d'un renforcement d'activité, rattaché(e) à la Responsable Stratégies Clients et en collaboration avec la Responsable Analytique, votre principale mission consiste à fournir des outils d’aide à la décision. Il s'agit plus particulièrement d'identifier et de répondre aux besoins des différentes équipes en matière d’analyses, d’outils de reporting, de data visualisation et mise en œuvre. Grâce à la qualité de vos analyses, vous participez à l’identification de poches de valeur et contribuez à l’amélioration des performances. Vos missions plus en détails : Gestion des bases de données :Validation de la cohérence des données chargées en baseParticipation active à l’élaboration du nouveau datalake : test des variables, migration des requêtes actuelles… Maintien et développement des process/reporting actuelsAnalyse de performance : Mise en place d’analyses de performance de l’activité (ex : performance des portefeuilles de créances, productivité…)Préconisations (analyse des stratégies et proposition de leviers d’optimisation)Présentation aux directions opérationnellesRéalisation de scoring (clients à potentiel, web, canal de communication…)Affiner le ciblage des clients :Préconisations et sélection des clients pour enrichissement de données, campagnes de communication, clients web…Participation à la nouvelle stratégie d’enrichissement de données Environnement technique : Bases de données SQL, SAS, Tableau, R, MS Excel/VBA, Alteryx Profil recherché : Formation supérieure de niveau Bac +5 en Statistiques / Informatique décisionnelle (type Master MIASHS parcours statistique, Master SIAD...), Idéalement première expérience de 2 ans minimum (hors stages/alternance) sur une fonction analytique (statistiques, manipulation de données). Excellentes capacités à communiquer en transverse et à présenter des données complexes et détaillées dans un format facilitant la compréhension. Curiosité, rigueur, réactivité, souplesse et d’une capacité d’adaptation pour intervenir sur des projets variés et auprès d’interlocuteurs multiples Un bon niveau d’anglais écrit serait un plus.Les conditions contractuelles & avantages : Poste à pourvoir dans le cadre d’un CDI – statut Cadre. Localisation : Marcq en Baroeul (proximité immédiate du Tramway – Arrêt Château Rouge). Parking. Package (fixe + variable annuel) compris entre 32 K€ et 38 K€ brut annuel pour 39h / semaine. Tickets restaurant : 9,20 € / jour (participation employeur de 5€) Intéressement/participation (autour de 1 K€ par an) Télétravail : jusque 2 jours / semaine Mutuelle (prise en charge employeur avantageuse) Remboursements frais de transports à hauteur de 60% Avantages CSE…Ce que vous trouverez de plus en tant que Data Analyst chez Hoist Finance :  Une équipe à taille humaine, conviviale, qui s’entraide au quotidien et qui a à cœur de partager son expertise« Pas de silos ! » : un champ d’intervention large permettant une diversité de projets : différents départements (fonctions Supports, fonctions Opérationnelles/Métiers), données variées (économiques, financières, sociodémographiques, RH…), différents types de crédits (prêt personnel, crédit à la consommation, découvert bancaire…)Nous sommes dans un contexte en fort changement ! : métiers de la relation-clients en transformation, développement de l’omnicanal / digital pour une expérience clients sur-mesure, intervention sur de nouveaux marchés… Notre environnement bouillonne d’idées et de projets ! En tant qu'entreprise inclusive, Hoist Finance s’engage pour la diversité et accorde la même considération à toutes les candidatures, sans discrimination.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer,VEV,"Sophia Antipolis, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/software-engineer-at-vev-3805917872?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=rPPjrEm1azOiCiRo%2BiRQtw%3D%3D&position=21&pageNum=8&trk=public_jobs_jserp-result_search-card,"The ideal candidate will be responsible for developing high-quality applications. They will also be responsible for designing and implementing testable and scalable code.  ResponsibilitiesDevelop quality software and web applications Analyze and maintain existing software applications Design highly scalable, testable code Discover and fix programming bugsQualificationsBachelor's degree or equivalent experience in Computer Science or related field Development experience with programming languages SQL database or relational database skills


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),LittleBigCode,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-littlebigcode-3785355778?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=45ju7PdIAmpC7Eiw3BYtww%3D%3D&position=22&pageNum=8&trk=public_jobs_jserp-result_search-card,"LittleBigCode en quelques mots Notre mission aider les entreprises à réussir la révolution de l’IA ! LittleBigCode révolutionne le conseil dans l’IA en associant à ses équipes d’experts, ses propres solutions et méthodes permettant de délivrer les projets à l’échelle des organisations avec un très haut niveau de valeur dans un délai record. Depuis notre création fin 2018, nous avons réalisé 80 % de croissance annuelle moyenne, plus de 190 projets dont 88 % passés à l’échelle et obtenu pas moins de 93 % de satisfaction client. L’équipe LittleBigCode se compose de 80 collaborateurs venant d’horizons variés et ayant tous la même envie d’emmener la société le plus haut possible. Notre culture d’entreprise prône la prise d’initiative, de responsabilité, la valorisation de l’échec, la bienveillance, la transparence et le fun. Nous y sommes tous très attachés et nous faisons tout notre possible pour la préserver via un programme d’onboarding soutenu et des formations.Notre objectif est de devenir un acteur mondial de premier plan dans le conseil en IA d'ici les 5 prochaines années ce qui signifie de doubler notre taille annuellement.Le recrutement est la chose la plus importante pour la réussite d’une entreprise.Description du poste Nous cherchons à renforcer notre équipe technique grâce à un profil Data Engineer senior !Ta mission si tu l’acceptes : accompagner tes clients dans leurs projets data / IA mais également participer activement au développement et rayonnement de LittleBigCode.Quel sera ton rôle chez nous ?Conseil et expertise auprès de nos clients sur leurs projets stratégiques :ModélisationConceptionDeliveryFormation, accompagnement & animation :Formation et accompagnement des équipes dans leur montée en compétences (en tant que Senior Coach ou Senior Tech)Organisation & Animation des communautés et des Tech-Events (Workshops, Challenge interne, Hackhaton …)Contributions au développement de LittleBigCode :Participation au développement de nos solutions internesProposition et création de solutions innovantesParticipation aux appels d’offresTon profil Tu es diplômé.e d’une grande école d’ingénieur en mathématique, statistique ou informatique et tu as au moins 5 ans d’expérience sur cette fonction !Tu es très solide sur les concepts de modélisation et structuration de données.Tu maîtrises l’industrialisation de pipelines d’ingestion et la mise en production de modèles Data Sciences.Tu maîtrises parfaitement les langages : Python, SQL (si possible Scala) et tu sais délivrer un code propre facilement maintenable et industrialisable.Tu sais parfaitement utiliser l’une des plateformes suivantes : Azure, GCP, AWS et connais également très bien les différentes typologies de Base de données.Tu es robuste sur la mise en place et l’utilisation d’ETL.Si en plus tu as une expérience les environnements de données à haut volume …


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer confirmé (H/F),BforBank,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3799165477?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=N314ABCnMsFp8m4SzGXGHg%3D%3D&position=23&pageNum=8&trk=public_jobs_jserp-result_search-card,"Sur le modèle d'une ""Tech company"", BforBank place l'humain et le digital au cœur de sa transformation. Notre mission, offrir à nos clients une expérience bancaire incomparable pour répondre à leurs besoins et usages mobile. 🌟 📱Rejoindre BforBank c’est rejoindre une équipe engagée dans un grand projet de développement stratégique en France et en Europe. Nous sommes aujourd’hui 350 passionné(e)s et recherchons nos talents pour construire la banque de demain. 🚀Nous croyons en la force du collectif, chaque jour rassemblés autour de nos valeurs, de simplicité, d'optimisme et d’engagement, encourageant chacun à oser, essayer et accepter d’échouer.🎯 Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, définir, déployer et opérer les meilleures solutions technologiques répondant aux cas d’usage data et d’automatisations de processus de la banque au travers de plateformes. Également, la Data Factory contribue au développement des produits, à la cristallisation et à la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque. Tu rejoindras une squad en charge de résoudre des problématiques métiers en créant des solutions applicatives utilisant les données, des data products, avec pour finalités la prise de décision via des moteurs de calcul ou des dashboards, la création de flux réglementaires, la création de data layer ou de reportings. 🚀 Tes missions principales sont les suivantes : · Participer aux analyses, études d’impacts et cadrage techniques · Concevoir des solutions en respectant les bonnes pratiques d’architecture data et développement· Réaliser le développement de nouveaux data products et assurer la maintenance évolutive et corrective des data products existants· Rédiger la documentation technique des data products· Assurer un support aux testeurs· Reporter de ton activité à ta Squad et travailler dans une démarche d’efficacité collective Concrètement tu seras amené(e) à produire les livrables suivants :· Réaliser du code applicatif à l’état de l’art sur notre nouvelle Data Platform · Créer des data layer et des rapports sur notre outil de Data Visualisation· Rédiger les documentations techniques liées à ta solution, incluant le modèle de données, les procédures, l’ordonnancementCe que tu maîtrises :· Maitrise des services managés de GCP (BigQuery, dataproc, dataflow, CloudSQL …)· Maitrise du langage Python, Pandas, Spark · Maitrise de la modélisation de base de données et du langage SQL· Maitrise d’une chaine CI/CD (GitLab…) · Bonne connaissance de Kafka· Bonne connaissance d’un outil d’intégration de données type ETL (Informatica…)· Connaissance de l’infra as code (Terraform)· Connaissance d’un outil de reporting (Looker, BO…) 🤝 Ce poste est fait pour toi si :· Tu es passionné(e) par la Data et leurs usages· Tu es orienté résolution de problème, est curieux(se) et force de proposition· Tu apprécies le travail en équipe· Tu as un bon relationnel et est rigoureux(se)· Tu as une bonne capacité d’analyse et rédactionnelle· Tu t’adaptes rapidement aux changements🎓 Formation : Tu es diplômé(e) d’un master en école de commerce, école d’ingénieur ou équivalent.Chez BforBank nous recherchons avant tout des compétences. Tu ne disposes pas du diplôme requis mais as des expériences équivalentes ? N'hésite pas à postuler !💼 Expérience : Expérience confirmée de 3 ans en tant que Data Engineer.En rejoignant BforBank tu trouveras… · Un projet ambitieux de transformation digitale et culturelle à l’échelon européen, terrain d’innovation et d’ouverture d’esprit · Une organisation apprenante, proposant un large choix de formations toute l’année, et qui favorise l’échange avec les autres marques du Groupe· Une promo RSE multi-métiers qui fait évoluer en continu les actions de BforBank vers une banque plus responsable· Une organisation du travail en mode Agile, impliquant un degré élevé de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifiés.· Une Direction Technologie en pleine expansion, porteuse de nombreux défis stratégiques Mais aussi…De 2 jours à 5 jours de télétravail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)25 jours de congés + 16 jours de RTT80% du coût de la mutuelle d’entreprise pris en charge / couvertAvantages collaborateurs Crédit Agricole : taux et tarifs préférentielsDes frais de transports remboursés à 75%Un restaurant d’entrepriseDes douches pour les sportifs et un tarif avantageux auprès d’une salle de sport toute proche📍 Le poste est basé à La Défense, dans des locaux flambant neufs !BforBank s'engage à garantir l'égalité des chances aux candidats car nous sommes convaincus de la richesse apportée par la diversité et l'inclusion dans nos équipes. Rencontrons-nous ! Le processus de recrutement se déroule en 4 étapes : 🧑🏼‍💻Call de 30 minutes avec notre équipe Talent Acquisition Echange avec le Data Factory Manager et notre équipe Talent Acquisition (présentiel)Echange avec une personne de l’équipe avec qui tu seras amené à travailler (visio)Echange avec le CTO (visio ou présentiel) Notre processus de recrutement dure en moyenne 3 semaines et l’équipe Talent Acquisition se tiendra à ta disposition pour te donner un maximum de visibilité sur l’avancée du process.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer (H/F),Groupe SII,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-sii-3745315181?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=8bADCPIePWgli9RyyiHyqQ%3D%3D&position=24&pageNum=8&trk=public_jobs_jserp-result_search-card,"Devenez le prochain collaborateur d'SII Nord en tant que :Data Engineer (H/F)Intégré chez l'un de nos clients, vous intervenez en tant que Data Engineer au sein de l’équipe IT Data. Vous développez et gérez la maintenance de la plateforme Data et d’autres outils mais aussi des flux entre les différentes sources de données de l’entreprise.Vous Contribuez àConcevoir et développer les futures fonctionnalités de la plateforme Big Data sous Google Cloud Platform,Concevoir les flux d’alimentation et les tables (structure de donnée),Automatiser et industrialiser les flux,Assurer le run applicatif, le cas échéant.ProfilDans l'idéal (oui uniquement dans l’idéal, chez nous on ne cherche pas qu’un CV mais une collaboration durable), de formations supérieure en informatique, type Bac+3/5, vous justifiez d’une expérience significative en développement sur un environnement BI et Big Data.Compétences TechniquesMaitrise des langages suivants : SQL, Python (Java/Scala serait un plus)Connaissances de Google Cloud Dataflow (Python)Anglais nécessaire à l’écritNotion de programmation fonctionnelleAu-delà des compétences techniques, vous faîtes preuve de rigueur, de curiosité et aimez relever les challenges. Vous êtes doté(e) d’un bon sens du service client, êtes organisé et pragmatique. Ces qualités vous permettent de mener à bien le projet.Vous vous reconnaissez dans ces compétences et qualités ? Vous souhaitez bousculer les codes, sortir des sentiers battus et rendre votre dynamisme contagieux ? Alors, rejoignez le mouvement #Fungénieur de SII dans lequel la créativité et l’esprit d’équipe sont mis à l’honneur !Vous êtes les créateurs de demain, osez mettre en avant vos compétences, investissez-vous dans des projets innovants et venez relever de nouveaux défis technologiques. Expertise, Innovation et fun est le mix que nous vous proposons !Qui sommes-nous ?Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. En 2023, pour la 6ème année consécutive, SII France a obtenu le label Great Place To Work®. Nous avons été reconnus 3ème entreprise de « + de 2500 salariés» où il fait bon vivre. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés !Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos salariés un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la créativité, la proximité et l’esprit d’équipe sont mis à l’honneur.Le Groupe SII est une société handi-accueillante, signataire de la Charte de la diversité en entreprise.Alors si ces valeurs vous parlent, rejoignez-nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,MindPal,"Marseille, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3810930852?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=aH7RUdp8lLNvaiT0DAi4Ww%3D%3D&position=25&pageNum=8&trk=public_jobs_jserp-result_search-card,"We are looking for Data Engineer!ResponsibilitiesDesigning, creating, and maintaining data processing systems Analyzing and optimizing data processing workflows Collaborating with the team to ensure data quality and efficiency Testing and implementing new solutions RequirementsAt least 2 years of experience in designing and creating data processing systems Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python) Excellent knowledge of databases and SQL language Ability to work in a team and communicate effectively with other departments Communicative English skills Experience with AWS/AWS Glue is a plus We OfferB2B contract Full-time job Remote work and flexible hours


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Thales,"Valbonne, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3733768380?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=aRSz3pEABaX5NCtYHBpAgA%3D%3D&position=1&pageNum=9&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces.Le département IA & Big Data recherche plusieurs Data Engineers (H/F) basés à Sophia Antipolis (06).QUI ETES-VOUS ?De formation Bac+4 ou Bac +5 (type école d’ingénieur), vous possédez de bonnes connaissances dans le domaine de la donnée (Data Science, Data Engineering, Stockage), en ingénierie logicielle globalement.Une connaissance cloud serait un réel atout, qu’il soit public (AWS, GCP, AZURE) ou privé.Les principales activités que vous réaliserez sont les suivantes :Mise en place de pipelines de traitement de donnéesUtilisation de l’état de l’art des technologies actuelles dédiées à ces activités : Kafka / Spark / Spark Streaming / Flink / StormDéveloppement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie)Utilisation de tous les types de stockage actuels :SQL : Oracle, SQLServer, PostgreSQLNoSQL : Cassandra / MongoDB / HBaseObjet : S3 / MinIOVous avez de bonnes expériences en développement logiciel et/ou scripting (principalement Scala & Java).Vous êtes à l’aise en Anglais.Vous êtes curieux et rigoureux.Vous aimez travailler en équipe au quotidien, pour vous le succès n’est que collectif.Vous vous reconnaissez ? Alors parlons missions …CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :Le département IA & Big Data fédère et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers d’une structure permettant d’accélérer la transformation des enjeux Data de nos clients.Nos savoir-faire :Big Data, Intelligence Artificielle, Algorithmie, Expertise ImagerieProjets d’intégration systèmeNos domaines métier :Maintenance prédictive, Traitement d’image pour la santéArchivage certifiant, Gestion de contenu, Analyse risque et optimisation de réponseAerospace : Centre de Mission et de Contrôle, Dynamique du Vol, Qualité Image, Occupation des sols, Sondage AtmosphériqueNos partenaires :Recherche : INRIA, CNRS, 3IAExternes : Nvidia, MicrosoftEn collaboration avec les membres de notre département :Vous contribuerez au développement et à la scalabilité de nos plateformes au travers d’activités d’automatisation, de création de services managés et d’API.Vous accompagnerez nos clients dans leurs projets de valorisation de données en proposant des solutions techniques et fonctionnelles, évaluées, choisies et opportunes.Vous participerez à l’intégration des plateformes techniques sécurisées développées par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com)Vous collaborerez à nos publications, conférences et webinars.Vous serez partie prenante de la 3ème révolution industrielle impactant tous les secteurs d’activité, énergie, santé, industrie, …La perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant à cette offre.Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Ingénieur Data (H/F),CITECH,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-at-citech-3803400445?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=85Pa79zWENcZAf08kBjdQA%3D%3D&position=2&pageNum=9&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseCITECH recrute ! ✨ Si vous souhaitez apporter vos compétences dans la réalisation de différents projets, nous avons LA mission pour vous ! Nous recherchons en effet un(e) Ingénieur Data (H/F) ⚓️ Votre mission est pour un client présent dans plus de 160 pays et connu pour être l’un des principaux leaders mondiaux du secteur de la logistique et du transport maritime. L’innovation et la digitalisation sont au cœur du projet de développement du groupe. L’organisation est à la fois tournée sur l’humain et sur l’agilité ce qui permet de structurer le développement et ainsi, encourager les salariés à prendre des initiatives et innover.Vous intégrerez l'équipe Data Science afin d’intégrer différents modèles de machine learning et flux de transformation de données dans la plateforme de production de Dataiku.La mission sera liée à de nombreux aspects techniques en termes de développement, d'intégration, de tests continus, releases en environnement DEVOPS, contraintes de production.Description du posteVous aurez donc les missions principales suivantes :Transformer les projets POC/ML en environnement de productionDévelopper et optimiser les flux de donnéesSoutenir l'équipe pour l'optimisation de SparkMettre en place et maintenir un pipeline CI/CD adapté aux contraintes de l'équipeÉtudier et intégrer les nouvelles technologiesAccompagner l'équipe dans l'utilisation des outilsAnalyser, qualifier et résoudre ou transmettre les incidentsAmélioration continue, suivi de la mise en œuvreContribuer à une communauté d'intégrationQualifications⚙️ Les compétences attendues sont les suivantes :✔️ Vous êtes expert en troubleshooting, Continuous Deployment, Continuous Integration (Dataiku) et Continuous Testing.✔️ Vous êtes expert sur Python et Spark.✔️ Vous avez de très bonnes compétences en Monitoring et en Tests scenario.✔️ Vous avez une bonne maîtrise du Cloud (AWS), de Kubernetes, en Database (SQL / noSQL) et en Data Science.✔️ Vous êtes bilingue en anglais.☑️ Tous nos postes sont ouverts aux personnes possédant le statut RQTH.Informations supplémentairesPourquoi rejoindre Citech ? Une ambiance de travail conviviale avec des afterworks organisés régulièrement ! Des missions de longues durées.  Des formations adaptées à vos envies et vos aspirations.  Une mobilité que si vous le souhaitez Un accompagnement personnalisé avec un suivi régulier (autour d’un café ou un thé, c’est vous qui choisissez ) Une mutuelle avantageuse pour vous mais aussi pour les membres de votre famille Une flexibilité sur la gestion de vos repas Un statut Cadre et une convention collective SYNTEC.  Prime d’intéressement. Alors qu’attendez-vous pour nous rejoindre ?100% télétravail avec déplacements ponctuels sur Marseille ☀️Salaire : 50-55K€ Brut/anFreelance : 400-450€/jRéférence : 240111_IngénieurData_
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Engineer,Kaiko,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-kaiko-3802164696?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=XrBEpTeHKXDtGYLS39IjBQ%3D%3D&position=3&pageNum=9&trk=public_jobs_jserp-result_search-card,"Kaiko is the leading source of cryptocurrency market data, providing businesses with industrial-grade and regulatory-compliant data. Kaiko empowers market participants with global connectivity to real-time and historical data feeds across the world's leading centralized and decentralized cryptocurrency exchanges. Kaiko’s proprietary products are built to empower financial institutions and cryptocurrency businesses with solutions ranging from portfolio valuation to strategy backtesting, performance reporting, charting, analysis, indices, and pre-and post-trade.What We DoKaiko provides financial data products and solutions, across three main business units: Market Data: “CEX” Centralized Exchanges Market Data: we collect, structure and distribute market data from 100+ cryptocurrency trading venues; “DEX” Decentralized Protocols Market Data: we run blockchain infrastructure in order to read, collect, engineer and distribute venue-level market data from DeFI protocols. Analytics: proprietary quantitative models & data solutions to price and assess risk. Indices: suite of mono-assets rates and benchmarks, as well as cross-assets indices.Kaiko’s products are available worldwide on all networks and infrastructures: public APIs, private & on-premises networks; private & hybrid cloud set-ups; blockchain native (Kaiko oracles solution).Additionally, Kaiko’s Research publications are read by thousands of industry professionals and cited in the world’s leading media organizations. We provide original insights and in-depth analysis of crypto markets using Kaiko’s data and products.Who We AreWe’re a team of 80 (and growing) passionate individuals with a deep interest in building data solutions and supporting the growth of the digital finance economy. We’re proud of Kaiko’s talented team and are committed to our international representation and diversity. Our people and their values are the foundation of our continued success.About The RoleYou will be joining a fast-paced engineering team made up of people with significant experience working with terabytes of data. We believe that everybody has something to bring to the table, and therefore put collaborative effort and team-work above all else (and not just from an engineering perspective).You will be able to work autonomously as an equally trusted member of the team, and participate in efforts such as:Addressing high availability problems: cross-region data replication, disaster recovery, etc.Addressing “big data” problems: 200+ millions of messages/day, 160B data points since 2010Improving our development workflow, continuous integration, continuous delivery and in a broader sense our team practicesExpanding our platform’s observability through monitoring, logging, alerting and tracingWhat you’ll be doing:Design, develop and deploy scalable and observable backend microservicesReflect on our storage, querying and aggregation capabilities, as well as the technologies required to meet our objectivesWork hand-in-hand with the business team on developing new features, addressing issues and extending the platformOur tech stack:Monitoring: VictoriaMetrics, Grafana Alerting: Alert Manager, Karma, Pager DutyLogging: Vector, LokiCaching: FoundationDB, RedisSecrets management and PKI: Vault Configuration management and provisioning: Terraform, AnsibleService discovery: ConsulMessaging: KafkaProxying: HAProxy, TraefikService deployment: Terraform, Nomad (plugged in Consul and Vault), Kubernetes (to a lesser extent, used for non production critical workloads)Database systems: ClickHouse (main datastore), PostgreSQL (ACID workloads)Protocols: gRPC, HTTP (phasing out in favor of gRPC), WebSocket (phasing out in favor of gRPC)Platforms (packaged in containers): Golang, NodeJS (phasing out in favor of Golang), Ruby (phasing out in favor of Golang)About You:Significant experience as a Software/Data/DevOps EngineerKnowledgeable about data ingestion pipelines and massive data queryingWorked with, in no particular order: microservices architecture, infrastructure as a code, self-managed services (eg. deploy and maintain our own databases), distributed services, server-side development, etcNice to haveExperience with data scraping over HTTP, WebSocket, and/or FIX ProtocolExperience developing financial product methodologies for indices, reference rates, and exchange ratesKnowledgeable about the technicalities of financial market data, such as the difference between: calls, puts, straddles, different types of bonds, swaps, CFD, CDS, options, futures, etcLocation: Paris (hybrid)Type of contract: CDIWhat we offer25 paid holidays & RTTsThe hardware of your choiceGreat health insurance (Alan)Meal vouchers (Swile)Contribution to your monthly gym subscriptionContribution to daily commutingRemote-friendlyMultiple team events (annual retreat, casual drinks, etc.)An entrepreneurial environment with a lot of autonomy and responsibilitiesTalent Acquisition ProcessCall with the People team (20 min)Interview with the Hiring Manager (45 min)Technical test / Business Case (1h in meet)Cross team interviews with 2-3 team members (30 min)Offer, reference checkDiversity & InclusionAt Kaiko, we believe in the diversity of thought because we appreciate that this makes us stronger. Therefore, we encourage applications from everyone who can offer their unique experience to our collective achievements.
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Pilote Projets Data / Data Engineer H/F,Emotors,"Carrières-sous-Poissy, Île-de-France, France",https://fr.linkedin.com/jobs/view/pilote-projets-data-data-engineer-h-f-at-emotors-3809167161?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=xZFqwIQ8HSEO%2BG0BoG1m%2BQ%3D%3D&position=4&pageNum=9&trk=public_jobs_jserp-result_search-card,"Emotors est une joint-venture entre les Groupes STELLANTIS et NIDEC, destinée à assurer la conception et la fabrication des nouveaux moteurs électriques pour l’automobile. Moteurs électriques qui ont pour vocation à être intégrés dans des véhicules mild-hybride (MHEV), hybrides rechargeables (PHEV) et véhicules électriques (EV).Notre société est basée à Carrières-Sous-Poissy pour sa partie développement et à Trémery, pour son site de fabrication. Aujourd’hui, 450 collaborateurs travaillent conjointement sur ces 2 sites pour faire de cette co-entreprise un succès et contribuer au développement de nouvelles motorisations pour le secteur automobile.Intégré à l’équipe AIDA (Automation, It and Digital Accelerator), dont la mission est de gérer la digitalisation de tous les métiers Emotors ; vous avez en charge de :Mettre en place une architecture de collecte des données des différents systèmes : manufacturing, IoT, ERP, PLM, MoM, autres sources et formats variés.Piloter la mise en place d’une plateforme data au sein d’EmotorsVous jouerez un rôle clé dans la collecte, la transformation, le stockage et la gestion des données pour soutenir les besoins de l'entreprise. Vous travaillerez au sein de notre équipe data constituée de data analyst et scientist et en étroite collaboration avec les entités Emotors.Responsabilités Principales :Mise en place d’une architecture de collecte des données :Concevoir et développer des pipelines de traitement des données pour l'extraction, la transformation et le chargement (ETL) des données.Assurer la qualité et la cohérence des données en mettant en place des procédures de nettoyage et de normalisation des données.Gérer les bases de données et entrepôts de données pour garantir des performances optimales et une disponibilité constante.Mettre en place des systèmes de collecte de données en streaming et batch.Mettre en place des solutions de collecte et transformation de données au plus proche des ligne “Edge”Analyse et Modélisation :Collaborer avec les équipes métier pour comprendre leurs besoins en données et concevoir des modèles de données appropriés.Mettre en place des solutions d'analyse de données, y compris la création de rapports et de tableaux de bord.Pilotage de Projet :Rédiger la spécification et piloter la mise en place d’une plateforme data au sein d’EmotorsSuperviser et gérer des projets liés aux données, y compris la planification, la coordination des ressources, le suivi des délais et la gestion des risques.Assurer une communication efficace entre les parties prenantes du projet, y compris les équipes techniques et métier.Sécurité des Données :Mettre en place des mesures de sécurité des données pour garantir la confidentialité et l'intégrité des informations sensibles.Documentation :Documenter les processus, les pipelines de données, les modèles de données et les solutions mises en place.Vous êtes :Issu(e) d’une formation supérieure en école d’ingénieur ou école d’informatique.Vous avez de l’expérience en tant que Data Engineer, de préférence dans un environnement industriel.Curieux(se), organisé(e), rigoureux, autonome et force de propositionCompétences et/ou connaissances :Maitrise du langage Python et SQLSparkMQTT / OPC UADéploiement (APIs, CI/CD, Git, Docker, Kubernetes)Maîtrise d’une (ou plusieurs) des plateformes cloudBonne connaissance des métiers de conception produit/process, de fabrication industrielle et de la logistiqueOrganisation, esprit d’équipe, aisance relationnelle, curiosité, agilité, autonomie et esprit d’initiativeExcellentes compétences en communication orale et écriteConnaissance et intérêt pour l’industrie 4.0, les moyens de production et leur amélioration continue (dans le milieu automobile)Anglais courantDes déplacements réguliers sur notre site de Trémery (Metz) sont à prévoir.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Ingénieur Data Spark (F/H),Thales,"Vélizy-Villacoublay, Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-f-h-at-thales-3737307284?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=B3zi5cqTzrVSly31r89%2FRw%3D%3D&position=5&pageNum=9&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales est un leader mondial des hautes technologies comptant plus de 81 000collaborateurs présents sur tous les continents. Le Groupe investit dans lesinnovations du numérique et de la « deep tech » – big data, intelligenceartificielle, connectivité, cybersécurité et quantique – pour construire unavenir de confiance, essentiel au développement de nos sociétés, en plaçantl’humain au cœur des décisions.Thalespropose des solutions, services et produits qui aident ses clients –entreprises, organisations, Etats – dans cinq grands marchés vitaux pour lefonctionnement de nos sociétés : identité et sécurité numériques, défense,aéronautique, espace, et transport.QUI ETES-VOUS ?De formation Ingénieur ou Bac+5, Ecole d’ingénieur ou Université vous justifiez d'une expérience professionnelle en mise en place de solutions Spark / BI d’au moins 4 ans.CE QUE NOUS POUVONS ACCOMPLIRENSEMBLE :Nous recherchons un Développeur Power BI et Azure passionné et compétent pourrejoindre notre équipe technique. En tant que Développeur Power BI et Azure,vous jouerez un rôle essentiel dans la conception, le développement et lamaintenance de nos solutions d'intelligence d'affaires basées sur Power BI etAzure. Vous travaillerez en étroite collaboration avec les équipes métier pourcréer des visualisations de données percutantes et des tableaux de bordinteractifs, tout en exploitant les services cloud Azure pour assurer lascalabilité et la sécurité des données.Vous avez pu acquérir plusieurs des compétences suivantes :Solide expérience dans le développement de solutions Power BI, y compris laconception de tableaux de bord interactifs, la création de mesures et de KPI,et la transformation des données.Connaissance approfondie des services cloud Azure, tels que Azure Data Factory,Azure SQL Database, Azure Data Lake, etc.Maîtrise des langages de requête de données tels que SQL, DAX et M.Compréhension des principes de modélisation de données et d'architecture BI.Expérience dans l'intégration de différentes sources de données dans Power BI,y compris des bases de données relationnelles, des services web et des fichiersplats.Capacité à comprendre les besoins métier et à traduire les exigences ensolutions Power BI efficaces.Bonnes compétences en résolution de problèmes et en communication pourcollaborer avec les membres de l'équipe et les parties prenantes.En nous rejoignant, vous vous verrez confier les missions suivantes :Concevoir et développer des tableaux de bord interactifs et des rapportspersonnalisés en utilisant Power BI.Collecter et analyser les besoins des utilisateurs métier pour définir lesindicateurs clés de performance (KPI) et les exigences de visualisation desdonnées.Extraire, transformer et charger (ETL) les données à partir de différentessources dans les solutions Power BI et Azure.Optimiser les performances et la scalabilité des solutions Power BI enutilisant les fonctionnalités avancées d'Azure, telles que les entrepôts dedonnées Azure, Azure Data Factory, Azure SQL Database, etc.Assurer la sécurité des données en mettant en place des mécanismes d'accès etde confidentialité appropriés dans Power BI et Azure.Collaborer avec les équipes métier pour fournir des conseils et desrecommandations sur l'utilisation efficace de Power BI et Azure pour l'analysedes données.Maintenir et améliorer les solutions Power BI existantes en fonction desévolutions des besoins des utilisateurs.Effectuer des tests et des contrôles de qualité pour assurer l'exactitude et lacohérence des données.Nous vous offrons :· Une diversité de projets vous permettant de découvrir l’ensemble de nosmétiers,· Des conditions de travail motivantes et un plan de carrière personnaliséoffrant de réelles perspectives d’évolution,· La possibilité de vous investir dans une entreprise dont la réputation estmondiale avec des ambitions constantes d’innovations techniques.Innovation, passion, ambition :rejoignez Thales et créez le monde de demain, dès aujourd’hui.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Data Engineer - Rennes - I&D (H/F),Capgemini,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-rennes-i-d-h-f-at-capgemini-3803721636?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=9kRLMGjupMx3e2eTa7XCyQ%3D%3D&position=6&pageNum=9&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseCapgemini est un leader mondial, responsable et multiculturel, regroupant 270 000 personnes dans près de 50 pays.Partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie, le Groupe est guidé au quotidien par sa raison d’être : libérer les énergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d’expérience et d’une grande expertise des différents secteurs d’activité, Capgemini est reconnu par ses clients pour répondre à l’ensemble de leurs besoins, de la stratégie et du design jusqu’au management des opérations, en tirant parti des innovations dans les domaines en perpétuelle évolution du cloud, de la data, de l’Intelligence Artificielle, de la connectivité, des logiciels, de l’ingénierie digitale et des plateformes. Le Groupe a réalisé un chiffre d'affaires de 16 milliards d'euros en 2020.Dans ce contexte, notre practice Insights & Data (I&D) s’appuie sur une équipe de 1300 personnes qui supporte nos clients de tous les secteurs dans leur transformation data. Cette équipe combine des compétences métiers avec une forte expertise data, analytique et d’intelligence artificielle pour mettre en œuvre des solutions qui visent à améliorer la gestion et la valorisation des données.Description de la missionVous intégrez une communauté d’experts passionnés reconnus par nos clients sur des technologies de pointe (Google Cloud Platform, Azure, AWS)Vous interagissez au plus proche de nos clients, des partenaires pour concevoir et mettre en œuvre des solutions/projets innovants et compétitifsVous répondez aux problématiques de nos clients en proposant la meilleure plateforme data dans un environnement AgileVous avez acquis de l’expérience sur les cadres de référence et patterns d’architecture Data, DevOpsVous adaptez chaque architecture en fonction du contexte grâce à votre maitrise des caractéristiques fondamentales de chaque solution (catalogue des offres de services managés, performance, sécurité, déploiement des data centers …)Vous utilisez les solutions d’intégration associées et les solutions décisionnelles ainsi qu’analytiques qui viennent consommer les données manipuléesVous êtes en mesure d’encadrer les équipes dans la mise en place des architectures préconisées et/ ou des plateformes DataPourquoi nous rejoindre ?En plus de votre quotidien, vous pourrez entreprendre, être formé, utiliser nos incubateurs pour innover, et vous dessiner une trajectoire de carrière personnalisée.Vous intégrerez une équipe ambitieuse, fun et dynamique !Une culture forte et bienveillante, et une grande place laissée à la libertéDes clients variés, leaders de leur secteurUne approche pragmatique, qui répond aux vrais enjeux des entreprisesUn véritable accompagnement dans l’évolution de votre carrière Une équipe à taille humaine, en renouvellement et en hyper croissanceUne priorité accordée au développement des collaborateurs – un management qui aide les équipes à progresser, à réussirPas de profil type chez Capgemini, mais quelques ingrédients pour laisser la magie opérer ... !Diplômé(e) de Bac+5 en informatique, vous comptez au moins 6 ans d’expérience (au sein d’une ESN ou chez un intégrateur) en conseil clientèle et une solide culture technologique, un bon niveau d’anglais.Vous avez des qualités de pédagogue, et pour vous la transmission de compétences fait partie de votre quotidien actuel. La phase d’avant-vente vous intéresse.CAPGEMINI, Entreprise handi accueillante, conformément à la norme AFNOR NF X50-783, est également signataire de la charte de la diversité en entreprise


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer BI - Nantes F/H,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-f-h-at-capgemini-3803963477?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=NquEVr1od0A7rYUDH71%2Bvw%3D%3D&position=7&pageNum=9&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques mots Capgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans près de 50 pays. Partenaire stratégique des entreprises pour la transformation de leurs activités en tirant profit de toute la puissance de la technologie, le Groupe est guidé au quotidien par sa raison d’être : libérer les énergies humaines par la technologie pour un avenir inclusif et durable. Fort de plus de 50 ans d’expérience, Capgemini est reconnu par ses clients pour répondre à l’ensemble de leurs besoins, de la stratégie et du design jusqu’au management des opérations, en tirant parti des innovations dans les domaines en perpétuelle évolution. Insights & Data en quelques mots Dans ce contexte, notre practice Insights & Data (I&D) s’appuie sur une équipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette équipe combine des compétences métiers avec une forte expertise data, analytique et d’intelligence artificielle pour mettre en œuvre des solutions qui visent à améliorer la gestion et la valorisation des données. Pour renforcer les équipes d’I&D, nous recherchons actuellement un.e Data Engineer BI.  A propos du poste : Intégré au sein d’une équipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activités divers, vous serez notamment en charge des missions suivantes :Mener les analyses fonctionnelles destinées à traduire les besoins du client,Mener les travaux de conception et de modélisation,Diriger le développement de la solution / des traitements d'alimentation du DataWareHouse,Organiser et préparer les travaux de recette utilisateurs,Mettre en place les processus d'industrialisation et mener cette dernière.  Pourquoi nous rejoindre ?Une culture forte et bienveillante, et une grande place laissée à la libertéDes clients variés, leaders de leur secteurUne approche pragmatique, qui répond aux vrais enjeux des entreprises.Vous arrivez au bon moment pour prendre place dans une équipe à taille humaine, en renouvellement et en hyper croissance.  Pas de profil type chez Capgemini, mais quelques ingrédients pour laisser la magie opérer ... !  Diplômé d'un Bac + 5 en école d’ingénieur ou équivalent universitaire, vous avez au moins 3 ans d’expérience en BI ou en lien avec un ETLVous avez déjà encadré des équipesVous êtes un(e) passionné(e) de la Data, enthousiaste et curieux(se)Vous êtes prêt(e) à partager de façon accessible à une audience non « data expert »Vous maîtrisez une ou plusieurs des technologies suivantes :BI : SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB InitioDataviz : Microsoft Power BI, Tableau, QlikviewBig Data : Ecosystème Hadoop (HIVE, PIG, Mahout…), Cloudera, Pivotal, Spark, HNXAnalytics : R, SAS, IBM SPSSEnglish speaker, because we are French but also international  « Capgemini, Entreprise handi accueillante, conformément à la norme AFNOR NF X50-783, est également signataire de la charte de la diversité en entreprise ».


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,padoa,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-padoa-3806408425?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=UaSmaEBDQcQviluwEPnDKw%3D%3D&position=8&pageNum=9&trk=public_jobs_jserp-result_search-card,"Tu cherches à donner du sens à ton talent et à avoir un impact positif sur le monde ?Née en 2016, padoa c’est 240 collaborateurs passionnés autour d’un logiciel et une offre de services conçus pour moderniser les services de santé au travail. Sur notre logiciel SaaS, nous gérons les dossiers médicaux de 5,5 millions de salariés en France. Avec une nouvelle levée de fonds de 80M€ en 2022, nous sommes prêts à réaliser notre mission : Faire du monde du travail un univers de prévention afin d’améliorer la santé de millions de personnes ! Pour atteindre notre objectif, nous renforçons régulièrement nos équipes avec les meilleurs talents. Aujourd’hui, nous recherchons différentes compétences (stratégie, design, tech, data, médecine et vente) pour concevoir, améliorer, développer, promouvoir et déployer padoa. Tes missionsAu sein de l’équipe intégration, qui compte presque 20 Data Engineers, tu assureras la reprise complète et structurée des données des anciens logiciels métier de nos clients vers les solutions padoa. Pour ce faire, tu devras :Comprendre les besoins en termes de données de différents corps de métiers (professionnels de santé, ingénieurs de prévention, gestionnaires de facturation ...)Analyser et comprendre l’état et la structuration de la donnée de différents métiers (ex: professionnels de santé, gestionnaires de facturation... ) dans les anciennes bases de données des clientsParticiper à la prise de décision pour nettoyer et traduire ces données dans la solution padoaMettre en place un pipeline de données pour récupérer ces données et les injecter dans notre logiciel (grande diversité de données : + de 250 informations différentes, avec jusqu’à plusieurs millions de points de données pour certaines informations)Assurer que le pipeline soit robuste, testé et permettre un maximum de traçabilité sur les traitements subis par la donnée et les incohérences détectées (python + node.Js) Assurer la maintenance et l’évolution de la base de données du produit padoaDévelopper des fonctionnalités backend qui manipulent de grandes quantités de donnéesTravailler en collaboration avec les référents métiers ainsi qu’avec les clients des différents métiers (professionnels de santé, gestionnaires de facturation, etc.)Qualifications clésBAC + 5 en ingénierie informatique ou science des données ou diplômes d’école d’ingénieur ou équivalentDe très bonnes compétences interpersonnelles : tu sais adapter ton discours à différents profils, dont des profils non-techniques De la rigueur et un bon sens de l’organisationDe bonnes connaissances en Python et en SQL Bon à savoirCarte Swile (ticket de 10€/jour pris en charge à 60%). Abonnement transport remboursé à moitié évidemment ou IK vélo pour les plus sportifs avec un parking vélo au pied des bureaux. Des locaux bien desservis (place de l’étoile / Ternes). 2 jours de télétravail.Des événements d’entreprise nombreux par équipe et all-staff. De nombreuses initiatives internes (green team, club de jeux de société, événements sportifs et caritatifs…). Une bonne mutuelle et des petit-dejs à dispo tous les jours !padoa s'inscrit dans une démarche d'inclusion et s'engage à étudier toutes les candidatures aux regards des compétences et qualifications de chacun.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Analytics Engineer (x/f/m),Doctolib,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/analytics-engineer-x-f-m-at-doctolib-3788192686?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=eq51woOT3ApMNxDVB%2BeIyQ%3D%3D&position=9&pageNum=9&trk=public_jobs_jserp-result_search-card,"What You’ll DoWe are looking for an Analytics Engineer to join the team and help us transform the access to healthcare!Important point at Doctolib: the data is fully encrypted and anonymized.You will be part of the Analytics Engineering team which has different goals:Build, maintain, and evolve data products that provide insights and support decision-making across DoctolibCollaborate with stakeholders to understand their data needs Explore data to validate business rulesEvaluate complexityDefine specifications and develop themCommunicate with stakeholders to ensure alignment (constraints, business rules, timeline, project updates)Project management (project split, grooming, timeline)Monitor the product (test and measure)Continuous improvementDefine and implement high level reporting (KPI definitions, Dashboards creation and maintenance)Define roadmaps in collaboration with PMs and stakeholdersEnsure data products quality (monitoring), security (GDPR, legal, infrastructure security), and availability (code optimization, performance monitoring, architecture optimization)Stakeholders guidance, empower data self-service to your stakeholders (train and advice)Everyone in the team is able to develop full stack data skills (from the source to the publication).Your responsibilities within the team include but are not limited to:Work with Business/Engineering teams to challenge the needsBuild and maintain data pipelines (Python)Build and maintain datamarts in Redshift (SQL)Build dashboards for the high level reporting (Tableau)Ensure training on data to end users (Metabase and Tableau)Monitor the quality of the data providedBe a key player to improve our architectureThe team hosts quarterly Data Innovation Days, hackatons for trying new tools/architectures or developing applications you find useful for the team.Our stackETL : AirflowData Warehouse : AWS S3 / RedshiftBI / Reporting : Metabase / TableauGitHubAmazon Web ServicesWho You AreIf you don’t meet all the requirements below but believe this opportunity matches your expectations and experience, we still encourage you to apply!You could be our next team mate if you:Have at least 2 years of experience as a Analytics Engineer, BI Engineer, Data Engineer or a similar roleLove to use SQL Have some knowledge of PythonKnow Redshift and/or PostgreSQLHave a good understanding of functional aspects of data (Sales, Finance, Web Analytics, Product)Have already used BI tools such as Tableau, Metabase, Superset, Power BI…Have experience in code hosting platform (we are using GitHub)Have good communication skillsAre results-oriented and proactiveHave already worked with business teams and challenged their needsLove to learnSpeak both French & EnglishNow, it would be fantastic if you:Have experience with DBTHave experience with AWS environment (S3/Athena/Firehose...)Have experience with Apache Airflow and DockerAre familiar with the GDPR regulationsWhat We OfferA stock-option program for each DoctoliberQuarterly bonuses and a competitive packageA 6-month dedicated onboarding program - the Doctolib AcademyContinuous training programs on all key competencies (English, soft skills, expertise) Transparent internal mobility opportunities you're welcome to apply for2 days per year to help health charities and create a positive social impact - the Solidarity DaysMental health and wellbeing offer in partnership with moka.careThe Doctolib Parent Care Program, including extended parental leave, meet-ups and inspiring conferencesHigh-quality office spaces supporting collaboration, health and wellbeingA subsidy from the work council to refund part of the membership to a sport club or a creative classA competitive health insurance paid 100% by the company Subsidy for lunch and various food offers in our offices A flexible workplace policy offering both hybrid and office-based modeFlexibility days allowing to work in EU countries and the UK 10 days per year A support for relocation in case of international mobilities and new joiners arriving to France, Germany and Italy from another countryThe interview process HR ScreenTake home test + Case restitutionHiring Manager Interview Job detailsPermanent positionFull Time Workplace : Paris areaStart date: asapRemuneration : fix + bonus on objectives (according to your profile)A stock options plan for every DoctoliberAt Doctolib, we believe in improving access to healthcare for everyone - regardless of where you come from, what you look like. This translates into our recruitment process: Doctolib is an equal opportunity employer. We don't just accept diversity at Doctolib, we respect and celebrate it!The more diverse ideas are heard, the more our product will truly improve healthcare for all. You are welcome to apply to Doctolib, regardless of your gender, religion, age, sexual orientation, ethnicity, disability, or place of origin. If you have a disability, let us know if there's any way we can make the interview process smoother for you! All the information transmitted via this form is processed by Doctolib for the purpose of managing applications. For more information on how Doctolib processes your application data, click here.If you wish to exercise your rights or if you have any questions about the processing of your data, you can write to us at hr.dataprivacy@doctolib.com.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer,MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3805299937?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=uDBP%2Bmk5l1c3D73zBFfNfg%3D%3D&position=10&pageNum=9&trk=public_jobs_jserp-result_search-card,"We are looking for Data Engineer!ResponsibilitiesDesigning, creating, and maintaining data processing systems Analyzing and optimizing data processing workflows Collaborating with the team to ensure data quality and efficiency Testing and implementing new solutions RequirementsAt least 2 years of experience in designing and creating data processing systems Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python) Excellent knowledge of databases and SQL language Ability to work in a team and communicate effectively with other departments Communicative English skills Experience with AWS/AWS Glue is a plus We OfferB2B contract Full-time job Remote work and flexible hours


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER CLOUD (H/F/NB),TRIMANE | Expert BI et Big Data,"Puteaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-h-f-nb-at-trimane-the-data-intelligence-company-3793473491?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=66I96m3C4p%2FEkOa4bI7ZHg%3D%3D&position=11&pageNum=9&trk=public_jobs_jserp-result_search-card,"En tant que pure Player Data, depuis plus de 15 ans, nous avons pour mission de faciliter l'accès à l'information en proposant des prestations sur mesure et à forte valeur ajoutée. Nous utilisons les technologies de pointe pour créer de la valeur à partir des données disponibles, telles que la Data Intelligence, le Big Data, l'Intelligence Artificielle, le Machine Learning …« Identifier, gouverner, acquérir, traiter, visualiser, analyser et optimiser vos données pour créer un maximum de valeur ! »Nous proposons aux entreprises un accompagnement adapté dans leur projet de transformation Data en respectant la réglementation en vigueur telle que la RGPD.Société à taille humaine, nous recrutons, avant tout, des personnes passionnées désirant intégrer une vraie communauté et construire ensemble une relation durable et de confiance.Rejoindre Trimane C'est> Un triple suivi de carrière avec vos référents technique, RH et commercial,> Un accès en illimité à nos plateformes de formations via nos activités R&D, des certifications, des formations en interne autour en BI, Big Data, Machine Learning, Blockchain et logiciels software,> Des ateliers de veilles technologiques sur des sujets innovants,> Un CSE avec des afterworks, des escapes games, et autres activités d'équipe,> Participer à l'aventure The Blockchain Group, un groupe d'entrepreneurs, composé de différentes entités proposant des offres de services complémentaires (digital, blockchain, Data...) et des projets communs.Le PosteDans le cadre du développement de notre communauté Cloud, vous aurez pour principales missions d'accompagner nos clients dans leur transformation digitale par la mise en place de projets cloud.Votre Mission Sera De Concevoir et développer des outils de traitements et processing de données Déploiement, industrialisation et tests de solutions développées, Monitoring et analyse de flux de données. Rédiger les rapports d'analyse de données, et assurer la présentation au client Savoir utiliser les outils d'analyse et de visualisation de données Assurer une veille technologique soutenue en lien avec les éditeurs Intervenir en tant qu'expert pour conseiller, cadrer et transformer des infrastructures, afin que nos clients puissent garder le contrôle et tirer pleinement parti du cloudPoints Forts Du Poste  Rejoignez une équipe d'experts et de passionnés en Data Participez à des projets innovants d'envergure nationale et internationale avec de forts enjeux économiques, réglementaires, organisationnels et techniques Fonctions pluridisciplinaires : Conseil, gestion de projet, développement, formation, Recherche / Innovation, porteur d'offre Cloud… Participer et devenir un véritable pilier à la création et au développement des activités stratégiques de TRIMANE grâce à un management participatif (basé sur des bonus)Profil Formation ingénieur ou universitaire de niveau Bac+5 ou plus à dominante informatique et mathématiques Une première expérience réussie en data engineering Connaissance des techniques et outils de traitement de la donnée en python, Spark/Hadoop dans un environnement cloud Vous parlez très bien anglais et français vous permettant d'échanger avec des équipes internationales. Vous êtes curieux, force de proposition, avec une vraie culture du résultat, vous appréciez le travail en équipe. Vous aimez les défis et êtes passionné par les enjeux techniques à forte valeur ajoutée.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Bouygues Construction,"Guyancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-bouygues-construction-3802935645?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=swD4%2BNAL2b8o0JXxQA%2F%2F3Q%3D%3D&position=12&pageNum=9&trk=public_jobs_jserp-result_search-card,"Bouygues Construction IT est au service des structures du Groupe et répond aux besoins diversifiés des métiers de la Construction, de l'Energie et des Services. Nous les accompagnons dans la réalisation de leurs métiers, la digitalisation des processus et le développement à l'international. Nous sommes engagés en faveur de la diversité et ouverts à tous les talents.Prêt(e) à participer à des projets d'envergures ? Rejoignez la Direction DATA de Bouygues Construction IT !En tant que Data Engineer, vous aurez notamment pour responsabilités de : Construire des pipelines de données en ayant recours à des technologies et langages variés (TALEND, SnowFlake, Power BI, Python…) Participer à l’étude de nouvelles solutions Data Mener des études de faisabilité Travailler à l'amélioration continue des pipelines (Bonnes pratiques, optimisations,...) Challenger les équipes dans leurs réalisations et travailler à l'amélioration des abaques Participer et encadrer les exercices de Code Review Accompagner des projets d'industrialisations Data Science (Dataiku, Snowpark,...) Piloter des projets en lien avec les MOA, nos prestataires ou nos centres de développement externes. Participer à l'animation de l'équipe autour de son delivery et sa montée en compétenceVous êtes diplômé(e) d’une école d’ingénieur ou d'un autre diplome Bac+5 lié à l'informatique et la data et vous avez au moins 5 ans d’expérience sur des problématiques de data engineering (construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données…) ; Anglais professionnel Vous travaillez en ayant une culture projet en mode AGILE Vous disposez de solides connaissances sur les architectures de données et le cloud. Vous avez de l’expérience sur un ou plusieurs environnements cloud (Azure, AWS…) ; Vous disposez de bonnes compétences en Python, SQL Vous avez travaillé à l'industrialisation de projet Data et avez des connaissances Data OPS / QOS - QOD


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Ingénieur Data Analyst (F/H),Thales,"Vélizy-Villacoublay, Île-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-analyst-f-h-at-thales-3737181947?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=FyboRwMGKaiVYoENeUgsOw%3D%3D&position=13&pageNum=9&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales est un leader mondial des hautes technologies comptant plus de 81 000collaborateurs présents sur tous les continents. Le Groupe investit dans lesinnovations du numérique et de la « deep tech » – big data, intelligenceartificielle, connectivité, cybersécurité et quantique – pour construire unavenir de confiance, essentiel au développement de nos sociétés, en plaçantl’humain au cœur des décisions.Thalespropose des solutions, services et produits qui aident ses clients –entreprises, organisations, Etats – dans cinq grands marchés vitaux pour lefonctionnement de nos sociétés : identité et sécurité numériques, défense,aéronautique, espace, et transport.QUI ETES-VOUS ?De formation Ingénieur ou Bac+5, Ecole d’ingénieur ou Université vous justifiez d'une expérience professionnelle en mise en place de solutions DataViz / BI d’au moins 4 ans.CE QUE NOUS POUVONS ACCOMPLIRENSEMBLE :Nous recherchons un Développeur Power BI et Azure passionné et compétent pourrejoindre notre équipe technique. En tant que Développeur Power BI et Azure,vous jouerez un rôle essentiel dans la conception, le développement et lamaintenance de nos solutions d'intelligence d'affaires basées sur Power BI etAzure. Vous travaillerez en étroite collaboration avec les équipes métier pourcréer des visualisations de données percutantes et des tableaux de bordinteractifs, tout en exploitant les services cloud Azure pour assurer lascalabilité et la sécurité des données.Vous avez pu acquérir plusieursdes compétences suivantes :Solide expérience dans le développement de solutions Power BI, y compris laconception de tableaux de bord interactifs, la création de mesures et de KPI,et la transformation des données.Connaissance approfondie des services cloud Azure, tels que Azure Data Factory,Azure SQL Database, Azure Data Lake, etc.Maîtrise des langages de requête de données tels que SQL, DAX et M.Compréhension des principes de modélisation de données et d'architecture BI.Expérience dans l'intégration de différentes sources de données dans Power BI,y compris des bases de données relationnelles, des services web et des fichiersplats.Capacité à comprendre les besoins métier et à traduire les exigences ensolutions Power BI efficaces.Bonnes compétences en résolution de problèmes et en communication pourcollaborer avec les membres de l'équipe et les parties prenantes.En nous rejoignant, vous vousverrez confier les missions suivantesConcevoir et développer des tableaux de bord interactifs et des rapportspersonnalisés en utilisant Power BI.Collecter et analyser les besoins des utilisateurs métier pour définir lesindicateurs clés de performance (KPI) et les exigences de visualisation desdonnées.Extraire, transformer et charger (ETL) les données à partir de différentessources dans les solutions Power BI et Azure.Optimiser les performances et la scalabilité des solutions Power BI enutilisant les fonctionnalités avancées d'Azure, telles que les entrepôts dedonnées Azure, Azure Data Factory, Azure SQL Database, etc.Assurer la sécurité des données en mettant en place des mécanismes d'accès etde confidentialité appropriés dans Power BI et Azure.Collaborer avec les équipes métier pour fournir des conseils et desrecommandations sur l'utilisation efficace de Power BI et Azure pour l'analysedes données.Maintenir et améliorer les solutions Power BI existantes en fonction desévolutions des besoins des utilisateurs.Effectuer des tests et des contrôles de qualité pour assurer l'exactitude et lacohérence des données.Nous vous offrons :· Une diversité de projets vous permettant de découvrir l’ensemble de nosmétiers,· Des conditions de travail motivantes et un plan de carrière personnaliséoffrant de réelles perspectives d’évolution,· La possibilité de vous investir dans une entreprise dont la réputation estmondiale avec des ambitions constantes d’innovations techniques.Innovation, passion, ambition :rejoignez Thales et créez le monde de demain, dès aujourd’hui.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3803324889?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=kXapIGUzxzyD0EtYNwVacA%3D%3D&position=14&pageNum=9&trk=public_jobs_jserp-result_search-card,"We are looking for Data Engineer!ResponsibilitiesDesigning, creating, and maintaining data processing systems Analyzing and optimizing data processing workflows Collaborating with the team to ensure data quality and efficiency Testing and implementing new solutions RequirementsAt least 2 years of experience in designing and creating data processing systems Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python) Excellent knowledge of databases and SQL language Ability to work in a team and communicate effectively with other departments Communicative English skills Experience with AWS/AWS Glue is a plus We OfferB2B contract Full-time job Remote work and flexible hours


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA Engineer H/F,LesJeudis,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3788251741?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=faRHKkXSZWo3YWMOVpLXDQ%3D%3D&position=15&pageNum=9&trk=public_jobs_jserp-result_search-card,"MissionDans le cadre de la croissance de notre agence lilloise, nous développons notre Practice Data et recrutons des profils Data de divers horizons : Data Analyst, Data Engineer, Data Scientist et Data Gouv.Les besoins métiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversité de compétences.Vous pourriez être l'un d'eux et rejoindre Inetum.En tant que Data Engineer, vos principales missions consistent à :Analyser et retranscrire le besoin clientConcevoir et mettre en œuvre les solutions permettant de traiter des volumes de données important afin de les mettre à disposition des Data Analyst ou Data ScientistVous êtes le premier maillon de la chaîne garantissant l'intégrité et la qualité de la donnéeProfilPour mener à bien votre rôle, il vous faut :Une maîtrise de la conception des entrepôts de donnéesUne expertise dans le stockage de données et leurs manipulationsBase de données : parmi les SGBD MySQL, PostgreSQL, Oracle, Snowflake, BigQuery, etc...NoSQL : parmi MongoDB, Cassandra, HBase, Neo4J, etc...ETL : parmi Talend, Stambia, SSIS, etc...Une appétence pour la programmation : parmi Python, Scala, Java, NodeJS, etc..Et si en plus vous disposez des compétences : dans les environnements cloud et/ou dans les technologies BigData : Hadoop, Spark, Kafka, etc...un choix de missions encore plus large s'offre à vous.Vous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !Notre PlusRejoindre la région Nord-Est, c'est bénéficier des avantages d'un Grand Groupe tout en gardant la proximité régionale.Nous mettrons tout en œuvre pour vous apporter un équilibre vie perso / vie pro. C'est pourquoi nous vous proposons un rythme hybride (selon les contraintes clients).Inetum a d'ailleurs signé un accord de télétravail en 2021 pour que chaque collaborateur puisse adapter son rythme de travail.Une trajectoire de carrière personnalisée et adaptée à vos souhaits d'évolution grâce à une implantation à l'international (26 pays, 7 Fablab), des formations ciblées et des projets couvrant l'ensemble de la chaîne de valeur IT (+25 filières métiers).Intégrer un collectif d'experts partageant des valeurs de solidarité et d'excellence.OrganisationNous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'Neo4j', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['MySQL', 'PostgreSQL', 'Oracle', 'Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage Data Engineer H/F,ACENSI,"Montpouillan, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-h-f-at-acensi-3779681692?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=ODyoH1IuNR1U%2Bn1gB70qvQ%3D%3D&position=16&pageNum=9&trk=public_jobs_jserp-result_search-card,"Description De L'offre LE STAGE Rattaché au responsable du pôle Data d’ACENSI, vous interviendrez dans le cadre des projets groupe à la maintenance et à l’évolution du SIBI.Dans le cadre du stage, vous aurez notamment pour mission (liste non exhaustive et pouvant évoluer)De mettre en place une solution cloud (GCP/AWS/Azure) orientée dataDe mettre en place les bonnes pratiques de développement pour une data pipeline Code  Enchainement (landing, raw, redefined et takeoff)  Les couches de data lineage D’initialiser la chaine CI/CDDe réaliser des POC sur des sujets diverses et variés orienté DataDe réaliser des rapports via PowerBiDe réaliser les documentations afférentes aux tâchesTechnologiesCloud : AWS/GCP/AzureLangage : Python/Spark (scala/python)Restitution : PowerBiOptionnel : Jenkins, Github, Confluence, …Pas de panique ! Vous serez accompagné tout au long de votre stage pour monter en compétence !Grâce à notre centre de formation interne, vous pourrez également assister à toutes les formations nécessaires à la réalisation de votre stage et l’accompagnement vous permettant d’aboutir à un CDI.PROFILEtudiant(e) en dernière année d’école d’Ingénieur / de Management ou de Master Universitaire en Système d’Information, passionné(e) par le Big Data et/ou la Business Intelligence, vous souhaitez mettre vos connaissances et vos compétences au profit d’une entreprise dynamique.Vous êtes autonome et organisé.Vous êtes doté d'un excellent relationnel et d'une forte capacité d'intégration aux équipes projet.Vous avez le sens de l’écoute.Un bon niveau d'anglais est souhaitable.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Confluence']}"
Data engineer Pyspark / SAS H/F,MERITIS,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-pyspark-sas-h-f-at-meritis-3797402761?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=1qOU3a1U5wIWwu%2F3NXwDBQ%3D%3D&position=17&pageNum=9&trk=public_jobs_jserp-result_search-card,"Nous recherchons un développeur en capacité de lire et comprendre les programmes SAS sous environnements WPS afin de les réécrire en PySpark dans Databricks.Dans le cadre de sa stratégie de migration vers le Cloud, notre client travaille à moderniser ses outils de projection actuarielle et les installer dans un environnement Azure.  Afin d'opérer son modèle interne et réaliser ses projections, l'équipe souhaite moderniser les outils de son processus d'inventaire car ils ne répondent plus aux exigences du groupe. Cette modernisation passe par la réécriture de l'ensemble des programmes SAS en PySpark sous DataBricks.  La mission consistera à : - Analyser et comprendre l'existant (programmes SAS) - Prendre en charge les développements / migration de l'ensemble du processus d'inventaire sous PySpark - Élaborer les tests unitaires, tests automatiques, tests de non-régression pour contrôler les résultats (comparaison des résultats des programmes SAS avec les nouveaux programmes Python) - Gestion du processus de développements et de livraison entre les environnements DataLab et Usecase - Former les équipes métiers au codage Python/PySpark afin qu'ils puissent maintenir et faire évoluer l'ensemble du futur processus - Rédiger la documentation technique dans une haute démarche de qualité (spécifications, manuel d’utilisation, rapport de recette...)Expertise souhaitée- Vous êtes diplômé(e) d'un Bac +5 et justifiez d'au moins 7 ans d'expérience - Expertise dans le codage en langage Python, PysPark - Bon niveau dans le codage en langage SAS - Excellentes qualités relationnelles et volonté d'interagir avec les équipes métiers - Capacité de rédaction de documentations techniques - Des compétences dans la réalisation de rapports avec Power Bi seraient un plus  Descriptif de l’entreprise Meritis est un cabinet de conseil, pilotage et développement IT fondé en 2007 présent à Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bientôt sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d’avance.​ Nous accompagnons nos clients dans l’intégralité de leurs besoins en transformation numérique à travers de nombreux domaines d’expertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybersécurité ou encore Agilité.​ Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des Télécommunications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.​ Fort de nos valeurs d’exigence, d’humilité, de bienveillance et de proximité, nous comptons aujourd’hui plus de 900 collaborateurs.​ Nous mettons un point d’honneur à être proche de nos collaborateurs et à les accompagner de manière individualisée quelles que soient leurs fonctions dans l’entreprise. Certifiée Great Place To Work depuis 2013, notre conception du bien-être au travail va bien au-delà d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.​ Vos différences sont nos atouts. C’est pourquoi Meritis est engagée en faveur de la diversité et de la non-discrimination. Tous nos métiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez être victime ou témoin d’une discrimination, vous pouvez contacter ethiquegroup@meritis.fr. »


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer DevOps H/F,Inetum,"Courbevoie, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-inetum-3782176029?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=p2XriDapx6oi28pgKtMDuw%3D%3D&position=18&pageNum=9&trk=public_jobs_jserp-result_search-card,"Détail de l'offre  Informations générales  Entité de rattachement  Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste Métier Métier BS (Business Solutions) - DevOps BS Intitulé du poste Data Engineer DevOps H/F Contrat CDIDescription De La MissionQui sommes-nous ?Nous sommes une ESN agile et un groupe international. A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 27 000 collaborateurs puisse se renouveler perpétuellement, en vivant positivement son propre flow digital. Chacun d'entre eux peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde plus positif, innover localement dans 26 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Capital Market, entité Inetum en Finance de Marché. Nous accompagnons les acteurs majeurs du secteur de la finance en France et à l’International.Cultivant la double compétence technique et fonctionnelle, nous intervenons sur des projets innovants à haute valeur ajoutée.Quelles sont nos valeurs ?🏆 Excellence Notre culture de l’excellence naît de notre audace.🤝 Engagement S’associer et grandir ensemble !🛰 Innovation Nos FabLab au service de la transformation digitale de nos clients.Missions proposéesPour accompagner notre forte croissance, nous recherchons des Data Engineer DevOps pour le compte d’un acteur majeur de la finance de marché en Europe et dans le monde. Dans ce contexte international et exigeant, vous travaillez sur la conception de solutions Big Data afin de répondre aux besoins des opérationnels métiers.Pour mener à bien ce projet, vous aurez pour responsabilités de Comprendre les enjeux des équipes Data et les accompagner. Faire le lien entre les environnements (datalake, datawarehouse et environnement de déploiement du modèle) grâce à des pipelines sophistiqués Être référent et garant des bonnes pratiques pour le développement des langages utilisés par l'équipe. Accompagner les Data Scientists dans l'optimisation de leurs algorithmes Assurer la viabilité des solutions de datamining et de machine learning de l'équipe Data et les mettre en production.Construire et optimiser des pipelines de données complexes (ETL et ELT) Coordonner le développement et les opérations grâce à l’automatisation des flux de travail, la création de services Web prédictifs. Déployez ces modèles en utilisant les dernières techniques et pratiques (API REST, Docker, Tensorflow Serving, etc.) Analyser et résoudre les anomalies liées aux performances et à l’évolutivité des solutions Cloud BI et Big Data Profil Profil souhaité De formation Ingénieur Grande Ecole ou équivalent, vous possédez une première expérience réussite de trois ans minimum sur un poste équivalent idéalement en banque d’investissement ou asset management. Vous êtes familier avec l’environnement Big Data (data grids, compute grids, REST based architectures, SGBDR, No-SQL Databases, GPUs) Vous avez déjà travaillé avec la méthodologie Agile Une certaine aisance technique est également requise (Jenkins, Docker, Ansible, Git, Scala, Kubernetes, Python/Java, Maven) Une double compétence Cloud (AWS, Google Cloud, Azure) serait un véritable plus Evoluant dans un contexte international, la maîtrise de l'Anglais est nécessaire. L’aisance relationnelle, de l’autonomie, la gestion des priorités, des capacités d’analyse et de synthèse, … le savoir-être est une composante importante dans notre processus de recrutement. Tous nos postes sont ouverts aux personnes en situation de handicap.Et pourquoi Inetum Capital Market ?😄 Des missions intéressantes🤩 Des perspectives d'évolutions professionnelles et financières😎 Les avantages d'un grand groupe international😉 Un suivi régulier✈️ Une aide à la mobilité géographique que vous soyez localisé en France ou à l'étranger👨‍🎓 Des formations certifiantes🥳 Des moments de FUN !Localisation du poste Localisation du poste France, Ile-de-France, 75 Paris Ville CourbevoieCritères candidat Niveau d'études min. requis Bac+5 Niveau d'expérience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Big Data Engineer,OPEN,"Île-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-at-open-3808435963?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=uiJc9PYuSGamV1bJWTcWlw%3D%3D&position=19&pageNum=9&trk=public_jobs_jserp-result_search-card,"📋 Contexte de la mission :On s'aperçoit de plus en plus que l'usage du Big Data dans tous les secteurs est désormais incontournable.Ces usages permettent d’analyser et d’évaluer tout type de production humaine et feedbacks clients, afin d'améliorer la prise de décision.Si vous êtes passionné(e) par la valorisation de la donnée, à l’aise avec la manipulation, complexité et hétérogénéité d'un gros volumes de données.Vous êtes intéressés par les technologies de pointe et des projets innovants Big Data .Qu’attendez-vous pour nous rejoindre La Business Unit Open Data IA & Kynapse ?Nous travaillons en direct chez nos clients Grands Comptes, dans leurs locaux, dans nos centres de services, Hybride.Venez rejoindre notre équipe !Positionné sur les technologies émergentes #Data #BI #Cloud – notre BU accompagne au quotidien les entreprises et les organisations dans leurs enjeux de transformation industrielle et digitale. Nous vous attendons pour rejoindre l'équipe de Kais, notre Directeur des Opérations en tant que Consultant Data & IA.Vous aurez la possibilité d'intervenir sur des missions au forfait mais aussi chez nos clients en régie dans un contexte agile !📍 Ce qui vous attend :Étude des solutions techniques et fonctionnelles avec les équipes du projetPrise en charge des développements nécessaires (Spark, Hive, Scala, Hadoop, Python, Java)Concevoir un DatawarehouseTraitement et stockage des donnéesMettre en place les meilleures solutions big dataConstruction des bases de donnéesL'application des standards (Clean code, Craftmanshift, TDD, BDD...)Participation aux points de suivi de projet selon la méthodologie Agile Scrum🛠️ Vous êtes fait(e) pour ce poste si :Vous disposez de 5 ans d’expérience minimum dans le monde de la data, Vous maitrisez un ou plusieurs langage(s) technique(s) et l'environnement technique global d'un projet, vous avez déjà travaillé dans un environnement Agile ainsi que sur ses outils (Python /Java / Spark / Hadoop / Hive / Scala / HBase / Elasticsearch / MongoDB / Cassandra / Cloudera, Hortonwork / AWS / Azure…)Votre envie, votre bonne humeur, votre capacité relationnelle et votre rigueur sont à la hauteur de votre dynamisme . Vous souhaitez vous projeter dans une nouvelle aventure, au sein d'une structure forte, intégrer une équipe Data et référents techniques !Vous maitrisez l’Anglais aussi bien à l’écrit qu’à l’oral.🤝 Au-delà de la mission, vous pourrez : Intervenir sur différentes missions dans des secteurs d'activités variés (Secteur public, banque, assurance, télécoms…)Rejoindre nos Practices ! Notre programme interne de communautés d'experts sur des technologies émergentes (Data, Microsoft, Cloud…)Vous engagez à nos côtés et contribuer à augmenter l’impact positif de nos actions : faites de vos compétences des dons à destination d’associations, participez à des événements sportifs associatifs et faites-vous sponsoriser.Notre process de recrutement : un bref échange téléphonique, un premier échange RH d'environ 1h pour parler de vous, de vos aspirations professionnelles et de notre offre, un deuxième échange avec votre futur Manager et un dernier échange avec un de nos experts pour parler technique. Ce sont nos Ambassadeurs qui en parlent le mieux, découvrez leurs témoignages sans filtre : https://www.youtube.com/watch?v=C4w_dkkVq40 Et vous, qu’attendez-vous pour être Open ?


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [' MongoDB', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer EMEA (F/M/D),Flowdesk,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-emea-f-m-d-at-flowdesk-3805794445?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=0%2F5%2BVc5Tm7Af0%2FzEi9xHQg%3D%3D&position=20&pageNum=9&trk=public_jobs_jserp-result_search-card,"Flowdesk is seeking a highly motivated Data Engineer to join the team and managed by the Quentin, the Lead Data!The data engineer will be an integral part of the growing data team, working closely with our trading and quantitative departments to provide a platform and tools to answer their analytical needs. The data platform revolves around Dagster deployed on Kubernetes for the orchestration, and dbt on BigQuery for the transformations.The next challenge will be to add support for real-time ingestion and processing of terabytes of market data.ResponsibilitiesDesign, build, and maintain efficient, scalable, and reliable batch and streaming data pipelines to support Flowdesk's trading infrastructureDevelop and maintain data warehouses, data lakes, and other data management systems with a strong focus on logical and physical modelingContribute early on to the definition of the data team's data products in order to maximize ease of access, data quality, and related documentationCollaborate with the software engineering team to integrate data-related functionality into Flowdesk's trading infrastructure and other applicationsLeverage cutting-edge data engineering technologies to continually improve the speed, reliability, and scalability of Flowdesk's data processing capabilitiesDevelop and maintain strong processes and procedures for data quality control, data validation, data documentation and, data integrationCollaborate with cross-functional teams including traders, developers, and compliance officers to ensure that all data used by Flowdesk is accurate, timely, and compliant with relevant regulations and requirementsRequirementsBachelor's or Master's degree in Computer Science, Engineering, or related field3+ years of experience in data engineering or related fieldExperience working with distributed streaming systems (Kafka, Beam, Flink)Knowledge and understanding of the lake-house architecture (Trino, open table format)Experience optimizing modern data warehousing platforms (BigQuery is a plus)Strong communication skills and ability to work collaboratively in a fast-paced an international environmentKnowledge of the data engineering ecosystem (contribution to open source projects is a plus)Strong analytical and problem-solving skills with a keen attention to detailBenefits💸 BSPCE🌍 International environment (English is the main language)🚃 50% of transportation costs & a sustainable mobility agreement🍔 Swile lunch voucher (€9.25 per day, 60% covered)🏥 100% Alan Blue covered for you and your children💻 Top of the range equipment: Macbook, keyboard, laptop stand, 4K monitor & headphones🎉 Team events and offsites🔜 Coming soon : gym memberships, international mobility & lot of other cool benefits !Recruitment process👀 Are you interested in this job but feel you haven't ticked all the boxes? Don't hesitate to apply and tell us in the cover letter section why we should meet!📝 Here's what you can expect if you apply:HR interview (30')Technical testTechnical interview (60')Chat with the Head of People (30') and the Head of Department (30') On the agenda: discussions rather than trick questions! These moments of exchange will allow you to understand how Flowdesk works and its values. But they are also (and above all) an opportunity for you to present your career path and your expectations for your next job!
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
[CDI] Data Eng Fullstack (Airflow / DBT / sujets BI) - Full remote - 55/90K€ (H/F),Hirestone,France,https://fr.linkedin.com/jobs/view/cdi-data-eng-fullstack-airflow-dbt-sujets-bi-full-remote-55-90k%E2%82%AC-h-f-at-hirestone-3801932614?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=2x0w5JQu4B9CfJVabex3DA%3D%3D&position=21&pageNum=9&trk=public_jobs_jserp-result_search-card,"Cette société est initiatrice de la Ad-tech pour les apps TV de streaming sur le marché américain. Ils permettent notamment aux entreprises de plus petite taille, type PME, d’accéder à la publicité TV, de façon simplifiée, ciblée et à moindre coût.Le job :- Ils montent une équipe pour supporter les besoins data côté business, et cherchent donc un data ingénieur avec une appétence business et data analyse.- Le Data Warehouse est a créer, ils y a déjà de gros volumes qui vont impliquer des modèles de database Olap, donc l'utilisation de Druid, DuckDB ou ClickHouse.- Vous utiliserez Airflow pour intégrer de la donnée provenant de nombreuses sources et scheduler des pipelines.- Utilisation également de DBT pour construire des modèles de données qui scalent et qui vont inclure les besoins produit.- D'autres sujets seront à venir par la suite, notamment des sujets de straming.Pourquoi c’est cool ?- Une équipe très sénior et un challenge technique pas accessible dans toutes les entreprises ! (Très gros volumes de données dans la pub).- Salaire : 55-90k selon profil.- Full Remote, avec rencontre toutes les 6 semaines en région parisienne pour un event team building et un point sur les avancées.- BSPCE avec objectif revente en 2025-2026, et donc un beau chèque à ce moment là :)


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - H/F,Sia Partners,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sia-partners-3804524646?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=eDNswyR4rifYB2XKqcLkJg%3D%3D&position=22&pageNum=9&trk=public_jobs_jserp-result_search-card,"Sia Partners réinvente le métier du conseil et apporte un regard innovant et des résultats concrets à ses clients. Nous avons développé des solutions basées sur l’Intelligence Artificielle et le design pour augmenter l’impact de nos missions de conseil. Notre présence globale et notre expertise dans plus de 30 secteurs et services nous permettent d’accompagner nos clients dans le monde entier. A travers notre démarche ""Consulting for Good"", nous mettons notre expertise au service des objectifs RSE de nos clients et faisons du développement durable un levier de performance pour nos clients.Heka.ai est la marque indépendante de Sia Partners dédiée aux solutions d'IA. Nous hébergeons de nombreuses solutions SaaS alimentées par l'IA qui, associées à des services de conseil ou utilisées indépendamment, fournissent à nos clients des solutions à l'échelle.Description du posteSia Partners recrute un(e) Data Engineer pour accompagner le développement des activités de la Business Unit Data Science.Vous serez amené(e) à participer aux missions Data Science de Sia Partners chez nos clients, ainsi qu’au développement de nos produits Software-as-a-Service Heka.ai. Vous accompagnerez des Data Scientists, Software Engineers et DevOps Engineers dans des projets à forte composante Data, dans le but de répondre à des challenges techniques autour du stockage, flux et traitement de données. Vous contribuerez activement aux choix technologiques, architecturaux et de gouvernance pour faire face aux enjeux de la mise à l’échelle de projets Data.Les travaux couvriront les thèmes suivants :Pipelines de données : développement de scripts d’ETL dans des écosystèmes Big DataInfrastructures & Services adaptés au Machine Learning : veille technologique et mise en place de solutions utiles aux Data Scientists dans l’entraînement et la mise à disposition de leurs modèles de Machine LearningProgrammation en python : développement d'outils exécutés côté serveur (traitement de données en masse, exposition des données via des APIs, ...)Services Cloud: choix d'architecture, utilisation de services de stockage & calculQualificationsDiplômé(e) d'une formation en École d'Ingénieur ou d'une formation de haut niveau dans le domaine des technologies de l’information, vous justifiez d'une première expérience d'au moins 2 ans en Data, DevOps, Cloud ou Software Engineering.Vous disposez d'un bon niveau en Python, vous permettant de qualifier, enrichir, et traiter de la donnée.C’est un plus si vous maîtrisez un autre langage de programmationVous maîtrisez les bases de données relationnelles (PostgreSQL, SQLServer, …)C’est un plus si vous maîtrisez un autre paradigme de base de données (Wide-column, Key-value, …)Vous avez de l’expérience avec des outils de calcul distribué, tels que Hadoop ou Spark ou vous avez de l’expérience avec des outils de Machine Learning, tels que Tensorflow ou TorchC’est un plus si vous avez de l'expérience avec les services d’au moins une plateforme de services Cloud (GCP, AWS, Azure)Pour vous, il est essentiel…d’aller au fond des choses : Il est important pour vous de comprendre toutes les nuances de votre datasetd’avoir un état d’esprit “Do it yourself” : Monter en compétence sur une technologie en autonomie pour répondre à une problématique ne vous fait pas peurd’être curieux(se) : Le monde de la data avance vite, mais vos capacités de veille vous permettent de rester à jourVous êtes curieux(se) et aimez travailler en équipe ? Vous êtes reconnu(e) pour votre sens de l’analyse et du service client ?Vous souhaitez rejoindre un environnement professionnel dynamique et motivant ? Vous partagez nos valeurs que sont l'excellence, l'entrepreneuriat, l'innovation, le partage, la bienveillance et l'équilibre vie personnelle/vie professionnelle ?Vous parlez français et anglais couramment dans un contexte professionnel ?Alors rejoignez-nous !Informations supplémentairesPoste basé en plein cœur de Paris (métro George V).Pour plus d'information sur notre practice Data Science, consultez notre site https://heka.ai/Sia Partners est un employeur qui souscrit au principe de l’égalité d’accès à l’emploi. Tous les aspects de l’emploi, tels que le recrutement, les promotions, la rémunération, ou les sanctions sont basés uniquement sur les performances, les compétences, et le comportement des employés ou les besoins de l’entreprise.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
STAGE INGENIEUR DATA - H/F,"Testia, an Airbus Company","Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/stage-ingenieur-data-h-f-at-testia-an-airbus-company-3799408240?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=6xTuf6%2BzKy5zTyskNb1jcw%3D%3D&position=23&pageNum=9&trk=public_jobs_jserp-result_search-card,"TESTIA, filiale du groupe Airbus, est spécialisée dans le Contrôle de Structures pour l’industrie aéronautique et spatiale depuis plus de 30 ans.Nous intervenons auprès de nos clients à travers des contrats d'étude au forfait, des missions d'assistance technique ou des formations spécialisées pour les donneurs d’ordres et leurs fournisseurs ainsi que pour les compagnies aériennes et MRO.Contexte de la mission : Dans le cadre de la croissance de ses activités numériques, TESTIA recherche un(e) stagiaire informatique spécialisé en gestion de la donnée.Missions et objectifs du poste : Rattaché(e) aux services supports de l’entreprise, vos missions principales consisteront à:- Participer à la définition et la documentation des règles de gestion des données.- Industrialiser et automatiser le nettoyage de la donnée selon les spécifications retenues.- Gérer le cycle de vie de la donnée conformément aux directives inscrites dans le RGPD- Créer les tableaux de bord pour les équipes métiers- Participer à la mise en place d’un outil de Business intelligenceAu sein de l’équipe IT :- Assistance de niveau 1 sur les incidents génériques- Accompagnement des utilisateurs dans les changements opérés par l’équipe IT (migration sur google workspace, suivi des améliorations de l’ERP- Suivre les demandes dans l’outil de support GLPI- Avec l'aide de nos sous-traitants IT, garantir la maintenance en conditions opérationnelles (et cyber-sécurisé) de nos installations physiques (routeurs, switch...)​Compétences recherchées : De formation ingénieur Data (de données) ou généraliste, vous avez des compétences opérationnelles en IT et une première expérience réussie (personnelle ou professionnelle) en gestion de bases de données SQL ou sur l’utilisation d’un BI.Des notions en développement dans des langages modernes (ex : Python) seraient un plus. Savoir être :Curiosité et envie de découvrir de nouveaux outils et services informatiquesSens du service, dynamique, flexible, organisé(e), rigoureux (se), et autonomeAutres compétences :Bon niveau d'anglais oral et écritInformations de l’offre :  Stage (4 à 6 mois)Lieu : ToulouseMerci de bien vouloir faire parvenir CV et lettre de motivation par mail à : recrutement@testia.com


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirmé(e),SFEIR,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-e-at-sfeir-3498603998?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=D%2BLuwb2AmfNKwASsj0E3Ow%3D%3D&position=24&pageNum=9&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ? SFEIR, c’est avant tout une communauté de 800 techs, en France, en Belgique et au Luxembourg, unis par la passion, dont 90 à Lille.Nous aidons nos clients à :Donner de la valeur à leurs données, innover avec l’IA ;Être compatible avec le futur en développant leurs architectures SI, Cloud et Data ;Créer de la valeur grâce aux API & microservices ;Développer des applications web et mobiles pour améliorer leur expérience client et se connecter partout.Et Lille dans tout ça ? SFEIR Lille c'est :Une agence créée en 2014 par Nicolas Leroy ;Quatre-vingt consultant(e)s qui se connaissent toutes et tous ;Des managers techniques qui comprennent ton métier ;Une dizaine de clients actifs en local et une centaine au niveau du groupe ;Des événements en interne et organisés chaque mois (afterworks, Meetup, formations) ;Une communauté active : une cinquantaine de conférences externes données en 2022 (Devfest, Devoxx, Meetup…) ;Des locaux dans le centre de Lille, à 5 minutes des gares !.💪 Ce qui fait notre force ?1. Notre culture est Digital Native. L’agilité est au cœur de notre fonctionnement.On s’est inspiré des pratiques des entreprises Digital Natives pour construire notre succès : agilité, rapidité dans les prises de décision, organisation décentralisée, promotion et utilisation de l’Open Source, etc.2. Notre stratégie est co-construite par les Techs pour les Techs.La direction générale et la direction de chaque entité sont co-leadées par un directeur Engineering et un directeur Business.Individuellement, chaque sfeirienne et sfeirien reporte à un(e) Engineering Manager, lui(elle)-même consultant(e) et a du temps dédié pour manager. Il(Elle) travaille étroitement avec le Business pour proposer les missions les plus adaptées à chacun(e).3. Notre communauté est apprenante et dans le partage.Nous sommes partenaires officiels des trois principaux Cloud Provider (Google Cloud, AWS et Azure), de solutions de gestion de données (Databricks, dbt ou Snowflake) mais aussi de solutions infra (Linux Foundation, …).Nous avons nos propres dispositifs de formation (SFEIR Institute, SFEIR School, …). Ça nous permet de former officiellement nos clients, et tout au long de l’année, les sfeiriennes et les sfeiriens.Nous sommes présents à de nombreux évènements Techs tant au niveau national que régional : tu as sûrement croisé des sfeiriennes et sfeiriens si tu vas aux Meetup, aux DevFest,…👩‍💻 👨‍💻 Qui sont les sfeiriennes et les sfeiriens ? 100% des consultant(e)s sont des techs passionné(e)s par leur métier.Ce qui nous rassemble aussi, c’est notre envie de contribuer à la communauté et à l’entreprise.On a une hiérarchie plate : on croit que l’entreprise est plus performante quand elle favorise l’autonomie et l’intelligence collective.Tu t’attendais à ce qu’on te parle d’études, de diplômes ou d’expérience, dans cette section ?Chez SFEIR, on n’a qu’un seul critère : c’est ton niveau technique et ta culture tech. On en reparle un peu plus bas !Ce que tu feras, en tant que Data Engineer confirmé(e) chez SFEIR ?Dans un contexte retail, Thomas accompagne les équipes data dans la construction d’applications de pilotage d’activité, de performance commerciale et d’aide à la décision. Utilisés par les magasins ou les équipes marketplace, ces outils ont un véritable impact sur la performance des domaines. Dans cette mission, Thomas apporte son expertise sur les technologies suivantes : Google Cloud (BigQuery, Firestore, Cloud Run), Looker Studio, Terraform, Github Actions.Jonathan accompagne un grand compte dans la migration d’un stack data Hadoop vers Google Cloud. L’approche Lift and Shift permet de migrer l’ensemble des traitements Spark vers Dataproc. Les technologies suivantes sont au cœur de sa mission : Google Cloud (Dataproc, BigQuery, Cloud Storage), Apache Spark, Python, SQL.La mission de Florian est orientée domaine supply. Le projet a pour but l'optimisation du contrôle de marchandise lors de la livraison fournisseur. La solution mise en place est un algorithme de Machine Learning qui prend la décision de contrôle, en temps réel à partir du contenu de la commande. Il travaille avec les technologies suivantes : Google Cloud (Composer/Airflow, Dataflow/Apache Beam, Firestore, BigQuery, Cloud Monitoring, Vertex AI), Docker, Kafka, GKE, Datadog, FastApi, Github Actions.👌 Comment on va t’aider à progresser :Des points mensuels avec ton(a) manager, qui est un(e) tech comme toi ;Des formations et des certifications selon tes besoins ;La possibilité de choisir ta mission et d’en changer lorsque tu en auras fait le tour ;… Bref, on sera là pour t’accompagner dans toutes les situations.🚀 Et si tu souhaites évoluer ? Nous proposons des possibilités d'évolution verticales et horizontales. Nous pourrons t'accompagner pour te certifier ou évaluer sur une autre spécialité, ou encore devenir Data Architect.Tu auras également la possibilité de prendre des rôles en interne si tu le souhaites :Évaluateur(trice) dans le processus de recrutement ;Formateur(trice) SFEIR School ou SFEIR Institute ;Speaker(euse) lors de conférences, Meetup, talks internes, auprès des écoles ;Engineering Manager si tu veux manager une équipe tout en restant dans la technique ;Staff Engineer si tu veux devenir contributeur(trice) individuel(lle), en apportant ton expertise à tous les métiers de SFEIR et à nos clients.Et si tu as d'autres envies, on en discute, chacun(e) est différent(e) et on fait au cas par cas.💰 Combien tu vas gagner chez SFEIR ?A l’issue des PlayOffs, nos tests techniques, on sera en mesure de déterminer tes compétences, et surtout ton potentiel afin de te proposer une rémunération adaptée.Pour te donner une idée, la rémunération moyenne au sein de SFEIR Lille pour un(e) Data Engineer confirmé(e) avec ton expérience démarre à 44 000€ brut par an.Ton salaire sera ensuite revalorisé chaque année.Tes compétences, rien que tes compétences !💻 Présentiel ou télé-travail ?Les deux, capitaine !La plupart de nos clients sont en mode hybride. Le classique, c’est 3 jours / 2 jours. 👋 La suite des événements :Si tu réponds à cette annonce, un mail arrivera chez Agathe RITOUET, Lisa TOTI, Gaëlle SPREUX et Khadija YANOURI, les recruteuses de l’agence de Lille ;L’une de nous te recontactera sous 2 jours pour un échange téléphonique d’une quinzaine de minutes ;Parce que chacun(e) est unique, un entretien RH te sera proposé pour comprendre ton parcours et tes envies ;Si tout est ok, on te proposera de passer les PlayOffs. Ce sont nos tests de sélection. Tu vas échanger et faire du pair programming avec 3 sfeiriennes ou sfeiriens en :AlgorithmiqueLangage Python ou SQLConnaissances des outils, et architectures Data.Les évaluateurs(trices) pourront aussi te donner un aperçu de la culture d’entreprise et de la vie chez nous !Tu pourras aussi discuter avec l’équipe commerciale qui te présentera nos clients et projets.On revient vers toi au max 2 jours après les PlayOffs pour te débriefer, et :soit, on te dit sur quels aspects tu peux encore progresser et on te donne des billes pour que tu puisses grandir (et pourquoi pas revenir vers nous plus tard);soit, Nicolas Leroy te reçoit afin de faire ta connaissance, partager sa vision de SFEIR et te faire une proposition d’embauche.Si tu as encore des questions, contacte-nous sur LinkedIn !Chez Sfeir, la confiance, la bonne humeur et l'inclusion font partie de notre ADN.#L’inclusionEstUneForce: Notre process de recrutement inclusif assure une égalité de traitement et de chance aux candidats de tous horizons.Sinon, clique sur Postuler ✌️


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data engineer,KION Group,"Marne-la-Vallée, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-kion-group-3697456771?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=YmYFoi8zGgBKW1%2Bfn%2B6KbA%3D%3D&position=25&pageNum=9&trk=public_jobs_jserp-result_search-card,"For more than 100 years, STILL has been providing tailor-made intralogistics solutions worldwide. Joining us is an opportunity to evolve in a stimulating environment, where professionalism and rigor rhyme with friendliness and cooperation. Reference of technological innovation and pioneer of the electric trolley, it is together that we provide ever more efficient solutions, which perfectly meet the challenges of our customers.Want to play a key role in the ever-changing material handling industry?The STILL team is waiting for you!What we offer:As a Data Engineer ""princing and production"", what is our objective ?To extract and analyse data from the various IT systems in order to successfully implement new pricing strategies and processes.Working with technologies like SAP, SAP Business Warehouse, Power BI, AzureTranslate pricing and sales planning demands into technical requirements, architecture concepts and interface definitionsFind clever, automated and intelligent solutions and implement those in an independent mannerCreate advanced reports and analysis with Power BIDevelop scalable and robust data pipelinesData and analysis support in pricing and sales planning related projectsTasks and Qualifications:University degree with a focus on data analytics or a comparable qualificationPractical experience in dealing with mass dataExperience with SAP and SAP Business WarehouseExperience in a manufacturing companyStrong analytical and conceptual skillsGoal-oriented communication to describe problems and complex issuesLanguage skills English (B2)


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer (AWS),Accor,"Issy-les-Moulineaux, Île-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-aws-at-accor-3798445083?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=np7W4vwLGgaPc2t%2BEZf2BA%3D%3D&position=1&pageNum=10&trk=public_jobs_jserp-result_search-card,"Bienvenue chez ACCOR, groupe hôtelier, leader dans le secteur de l’hospitalité. Nous sommes un écosystème de 40 marques dans 110 pays, de talents et de solutions, prêts à s'engager dans les possibilités infinies de l'avenir. Accor vous propose une nouvelle façon de vivre, de travailler, de vous divertir et de développer votre activité professionnelle grâce à une expérience client personnalisée. Groupe engagé, nous veillons plus que jamais à évoluer dans le respect de notre patrimoine commun. Découvrez notre culture, nos valeurs et nos ambitions sur https://group.accor.com/ DescriptionLa Digital Business Factory a pour objectif de proposer des produits et des services digitaux différenciants de premier plan, tant aux clients qu’aux propriétaires de nos hôtels, afin d’accélérer la transformation du modèle d’exécution, de favoriser les méthodes de travail agiles, et de renforcer le programme d’innovation en misant sur les capacités technologiques. Notre organisation est composée de +600 talents (internes et externes) aux expertises product management, tech et data.  Domaine : Data  En 2021, Accor a regroupé au sein de la ""Digital Factory"" ses différentes équipes Data sous la responsabilité unique d'un Chief Data Officer. Notre mission première est de fournir à l'ensemble de l'entreprise - des Hotels à la Direction, en passant par les différents Métiers - des produits Data et Analytics servant de multiples usages. Avec un fort redémarrage post-COVID, nous sommes en pleine modernisation (passage au Cloud massif) et transformation/mise à l’échelle - env. 150 pers aujourd’hui organisées en Tribu/Squad & Chapter inspiré du modèle Spotify - et accompagnons les équipes pour inscrire cette double culture ""Tech"" & ""Produit"" dans la durée. La richesse de cet écosystème, l'esprit d'innovation et le sens du ""service"" caractéristique à la culture hotellière d'Accor sont les forces qui nous motivent au quotidien.  Aperçu du poste : Au sein de la Tribe Data Platform dans le département Data Engineering, nous recrutons des Cloud Data Platform Engineer pour renforcer les équipes en charge de créer et maintenir les briques et services technologiques qui composant notre plateforme Accor « Welcome Data ».  Vous participez à la définition, conception, développement et maintenance des produits qui composent l’offre de Service en accord avec la vision d’architecture du département DATA. Au quotidien, vous intégrez une Feature Team composée d'une dizaine de personnes maximum aux profils variés (PO, Cloud Data Engineer, QA, FlyingOps, Scrum Master), sous la supervision directe du ""Tech Lead"".  Missions et responsabilités : Au quotidien, vos missions au sein de la Feature Team sont : Développer les produits et services de la plateforme DATA utilisés par les équipes de Data Engineer d’Accor Travailler en équipe à l’élaboration et définitions des fonctionnalités produits Assurer la conformité, la maintenabilité et la qualité du code (TDD, Sonar, etc.) Détecter, analyser et résoudre les incidents ou anomalies survenant sur les produits de l'équipe. (Build it / run it) Contribuer aux chantiers transverses (usine logicielle-CI/CD, supervision, catalogue, etc.). Participer activement à la vie de la feature team rythmée par les cérémonies agiles. Assurer la cohérence des services proposés Respecter et promouvoir les patterns de développement. Participer à l'animation de la communauté ""Data Tech"" (diffusion bonnes pratiques, capitalisation code, veille techno, etc.) QualificationsProfil recherché Diplômé(e) en informatique, analyse de données & Big Data, MIAGE, conseils aux entreprises, ou équivalent. Au moins 3 années d’ancienneté en lien avec les domaines de la Data et le Cloud. Compétences Data & Cloud requises : Indispensable : DevOps sur AWS : infra as code avec terraform, CDK principalement sur composants « serverless » (Lambda, DynamoDB, SQS) Backend: Python, Java, Typescript Gitlab SQL Souhaitable : Splunk (SPL) Node js, docker Front end : React JSSnowflake  Compétences générales attendues : Culture de la sécurité en mode « least access policy » Culture du FINOPS, obsession de l’optimisation des couts Culture & techniques DevOps Connaissances et mise en œuvre des méthodologies Agile : Scrum & Kanban Collaboration et travail en équipe Bonne communication orale et écrite Autonomie et proactivité Gestion des priorités, risques et alertes Anglais opérationnel requis.  Mindset recherché : Encourage la transparence, un climat de confiance : travail & revue entre pairs. Culture du feedback, droit à l’erreur. Être force de proposition, recherché l’amélioration continue. Curiosité (veille techno, etc.) et innovation  Additional informationPourquoi travailler chez Accor ? Nous sommes bien plus qu’un leader mondial. Nous vous accueillons comme vous êtes et vous pouvez trouver le métier et la marque qui correspond à votre personnalité. Faites ce que vous aimez, prenez soin du monde qui vous entoure, osez challenger le status quo ! #BELIMITLESS Découvrez la vie qui vous attend chez Accor, https://careers.accor.com/.  Quels avantages Accor offre à ses collaborateurs ? Accor et plus particulièrement la DIGITAL FACTORY propose une expérience de travail unique à ses collaborateurs où l’excellence rime avec bienveillance : Télétravail étendu : présence sur site de minimum 4 jours /mois en fonction des rituels d'équipes. Prise en charge d’un forfait d’équipement et Indemnités journalières offertes. Amélioration continue : hackathons, partenariats technologiques d’exception, plateforme dédiée à la formation Digitech Academy & certifications, programme de formation pour l’ensemble de nos salariés à l’agilité, à la culture OKR, formations dédiées Product Management, AWS.  Les avantages collaborateurs Accor c’est aussi : un véritable équilibre de vie : Work Everywhere : accès personnel offert à plus de 500 espaces de Coworking dont beaucoup au sein de nos hôtels. Une opportunité également de partir à la rencontre de nos collaborateurs hôteliers ! Programme ALL Heartists : avantages, séjours et expériences inoubliables dans toutes nos adresses Accor, dans le monde entier. Plus de 70 partenaires répartis selon différents univers (Voyages, Gourmet, Bien-être et Sport, etc.) pour satisfaire toutes vos envies. Et sur notre site d’Issy les Moulineaux : café à volonté, restaurant d’entreprise avec des prestations gourmandes et de qualité, salle de fitness, conciergerie d’entreprise.  des avantages financiers attractifs : Une participation Groupe et un intéressement, avec abondements de l’entreprise si versements dans PEEG/PERCOL, Un Forfait Mobilité durable de 700€/an maximum versé aux collaborateurs utilisant des moyens de déplacements verts, une prise en charge du pass NAVIGO à hauteur de 75%, Un CSE qui vous accompagne dans le financement de vos activités : Culture, vacances, sport, Noël, événements familiaux…  Sans oublier, l’accompagnement tout au long de votre carrière au sein du Groupe : Learning & development : un Talent management au cœur de notre stratégie RH & un catalogue de formation d’excellence, ouvrant de nombreuses perspectives de mobilités intra filières et internationales Un programme de cooptation de 1500€ bruts, pour récompenser votre participation aux recrutements de profils qualifiés.   Nous sommes engagés pour la Diversité & l’Inclusion : « La diversité & l’Inclusion pour Accor, c’est accueillir chacun et chacune dans le respect de ses différences en donnant la priorité aux seules qualités et compétences. Notre ambition est de développer l’emploi, mieux accueillir, offrir d’excellentes conditions de travail et favoriser l’évolution de l’ensemble des collaborateurs et notamment des personnes en situation de handicap. N’hésitez pas à nous faire part de vos éventuels besoins spécifiques afin que nous puissions les prendre en considération. »


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Ingénieur / Engineer,EPIGONE,"Île-de-France, France",https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-engineer-at-epigone-3802056482?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=EqGcKlKUsjYJdWRAm3GFdg%3D%3D&position=2&pageNum=10&trk=public_jobs_jserp-result_search-card,"À propos d'Epigone :Epigone est une entreprise spécialisée dans le conseil, se concentrant principalement sur les secteurs de l'assurance, de la banque et de la finance. Fondée par un actuaire en 1999, l'entreprise bénéficie de plus de 20 ans d'expérience dans ces domaines spécifiques.Chiffres clés :50 collaborateurs5 millions de chiffre d'affaires2019 intégration au groupe MoOngy (8 000 collaborateurs)Domaines d'intervention :Epigone intervient à travers quatre principaux pôles métiers pour répondre aux besoins variés de ses clients :Opérationnel MétierMaîtrise d'Ouvrage (MOA)Maîtrise d'Œuvre (MOE)ProgicielProfil Souhaité :✓ Diplômé(e) d'une école d'ingénieurs ou équivalent Bac +5✓ Bonne maîtrise de l'anglais✓ Une expérience supérieur à 4 ans réussie (si possible en banque / finance / assurance)✓ Maîtrise de Databricks✓ Maîtrise PySparkVous êtes motivé(e) et avez envie de monter en compétences ? Postulez ! On vous attend !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Session Juin 2024 H/F,Fitec Formation,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-session-juin-2024-h-f-at-fitec-formation-3805573776?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=s%2FG7MDk7XfrhPVvuCNKV7g%3D%3D&position=3&pageNum=10&trk=public_jobs_jserp-result_search-card,"Fitec, organisme de formation dédié à la reconversion et l'évolution professionnelle des actifs dans les métiers du numérique, vous propose formation + CDI avant même de débuter une formation.Comment ça marcheFitec vous met en relation avec les principaux employeurs sur les métiers du digital. Dès qu'un match avec une entreprise fonctionne, cette dernière vous fera une proposition d'embauche conditionnée par le fait de suivre une formation.A l'issue de la formation, vous serez capable de : Définir et piloter le choix et la mise en place d'une solution informatique adaptée à une organisation Gérer et optimiser des bases de données pour de grandes échelles.  Implémenter des pipelines de données efficaces.  Assurer la sécurité et la conformité des systèmes de données.  Travailler avec des technologies de cloud computing.  Collaborer avec des équipes pour intégrer des solutions de donnéesLa formation démarrera le 19 juin et se terminera le 20 septembre 2024 Être titulaire d'une certification professionnelle ou d'un diplôme de niveau 6 (bac+3) dans le domaine du management de projets, de l'informatique ou du développement et justifiant d'au moins une année d'expérience professionnelle dans ce secteur.  ou être titulaire d'une certification professionnelle ou d'un diplôme de niveau 5 (bac+2) dans le domaine du management de projets, de l'informatique ou du développement et justifiant d'au moins trois ans d'expérience professionnelle dans ce secteur.  Rigoureux, créatif, vous avez un sens aigu du service client, Être mobile, dynamique et capable de vous adapter rapidement, Avoir des compétences dans le domaine de l'analyse de données (R, Matlab...), la modélisation et/ou le développement (Java, Python, C++, JavaScript, HTML...). 19162255-55584


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R', 'MATLAB'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer,Understanding Recruitment,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-at-understanding-recruitment-3798350920?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=ghbMo9qNi9llcTYcMX4gNA%3D%3D&position=4&pageNum=10&trk=public_jobs_jserp-result_search-card,"Software Engineer - Elixir 🚀 Tech: Elixir, Phoenix, Terraform, AWS🤝 Healthtech💷 €50,000 - €70,000 + Benefits including a 10% bonus📍 Paris - ideally you'll go into the office 2 days a week but they will look at every 2 weeks📈 Company Size – 40✅ Interview process: 4 stages – Intro chat with Talent Team, Chat with CTO, Technical Interview then final with CEOWhy apply? You'll join a Series A funded SaaS health tech that partners with leading clinical organisations.You’ll build the next generation of their products that offer real-time assistance to their partners.Reporting directly to the CTO you'll design products using Elixir & Phoenix, pushing to AWS.They are hiring multiple engineers due to growth You’ll have: 👍 Experience writing high quality code, ideally with Elixir or at least want to learn it👍 Experience creating distributed system architecture👍 Experience building concurrent, real-time systemsApply or drop me a DM for more info📱Mobile: +44 (0) 7791 141 227📧Email: agillard@understandingrecruitment.co.uk📆Book a call: https://calendly.com/agillardUnderstanding Recruitment is passionate about equity, diversity and inclusion.We seek individuals from the widest talent pool and encourage underrepresented talent to apply for vacancies with us.We are committed to recruitment processes that are fair for all, regardless of background and personal characteristics.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - FRANCE (H/F),Capgemini Engineering,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-france-h-f-at-capgemini-engineering-3806453709?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=h0seOluE%2Fw6jAc4LhMsOww%3D%3D&position=5&pageNum=10&trk=public_jobs_jserp-result_search-card,"CAPGEMINICapgemini, qu'est-ce que cela évoque pour vous ? Pour nous, c'est une success story à la française ! Celle d'une startup devenue une référence mondiale en matière de conseil et de services informatiques.Leader de la convergence des mondes physique et virtuel, nous agissons en partenaire de nos clients industriels pour concevoir, mettre en œuvre, sécuriser et démanteler des produits et infrastructures complexes. Nous participons à la transformation et à l’optimisation des entreprises de demain.Capgemini Engineering est la marque du groupe Capgemini réunissant les services d’ingénierie et de R&D. On accompagne la convergence des mondes physique et numérique. Conjuguée avec l’ensemble des capacités du Groupe, elle aide les entreprises à accélérer leur transformation vers l’Intelligent Industry. Capgemini Engineering compte plus de 52 000 ingénieurs et scientifiques dans plus de 30 pays, dans des secteurs tels que l’aéronautique, l’automobile, le ferroviaire, les communications, l’énergie, les sciences de la vie, les semi-conducteurs, les logiciels et l’Internet, le spatial et la défense, et les biens de consommation.VOTRE MISSIONVous êtes passionné(e) par le domaine de la Data et vous souhaitez prendre part à un projet d’envergure dans le secteur des telecom ? Rejoignez notre équipe Digital Engineering de Capgemini Engineering, en tant que Data Analyst. Vous êtes responsable de :Comprendre le besoin métier, évaluer les charges et concevoir les solutions techniques et fonctionnellesRédiger le cahier des charges et décrire sous forme de spécificationsAssurer le lien entre le besoin métier et les possibilités fonctionnelles et informatiquesFournir aux équipes techniques les documents projetsEcrire les cahiers de recette applicativeAssurer la coordination et le suivi de la recette fonctionnelle avec les experts métiersFormer et assurer le support aux experts métiers dans l’utilisation des outilsCE QUE NOUS RECHERCHONSVous êtes Ingénieur(e) ou titulaire d'un diplôme équivalent de niveau bac+5 en informatique spécialisé en business intelligence. Idéalement vous justifiez d’une expérience réussie dans le développement / intégration de solutions BI (Minimum 2 ans).Vous maîtrisez Power BI, le langage SQL, le requêtage de données. La connaissance d’un ETL est un réel plus.Enfin, vous avez le sens des priorités, vous êtes reconnu(e) pour votre capacité à créer du lien avec les équipes techniques et les équipes métiers.Vous avez également la capacité à vous intégrer dans des projets et des équipes existantes dans un contexte de transformation.Vous vous reconnaissez dans la description du profil et vous souhaitez en savoir plus ? Postulez dès maintenant !Alors, rejoignez Capgemini et choisissez le futur qui vous ressemble ! CAPGEMINI, entreprise handi accueillante, conformément à la norme AFNOR NF X50-783, est également signataire de la charte de la diversité en entreprise


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer (Graduated) (H/F),Alstom,"St.-Ouen, Île-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-graduated-h-f-at-alstom-3735951792?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=00Bz99ep0jE2DxetwnYPqg%3D%3D&position=6&pageNum=10&trk=public_jobs_jserp-result_search-card,"POURQUOI REJOINDRE L'AVENTURE ALSTOM ? À la tête des entreprises qui s’engagent vers un avenir plus vert, Alstom développe et commercialise des solutions de mobilité qui apportent les fondements durables pour l'avenir des transports. Notre portefeuille de produits s'étend des trains à grande vitesse, métros, monorails et tramways jusqu’aux systèmes intégrés, services sur mesure, infrastructures, signalisation et solutions de mobilité numérique. Nous rejoindre, c'est rejoindre une entreprise bienveillante, responsable et innovante où plus de 70 000 personnes ouvrent la voie à une mobilité plus verte et plus intelligente, dans le monde entier.Au sein de notre activité signalisation nous concevons les nouvelles solutions intelligentes permettant l’exploitation des réseaux de transports ferroviaires.Nos métiers en innovation, informatique, cybersécurité, électronique et en télécommunications construisent l’intelligence des trains de demain afin de répondre aux besoins de mobilité plus durable.Nous recherchons des personnes curieuses dotées d’un esprit novateurs et qui ont à cœur de réinventer la mobilité en la rendant plus intelligente et plus durable.Localisée à Saint-Ouen-sur-Seine, centre d’excellence mondial, plus de 1000 collaborateurs vous y attendent. CE QUE NOUS POUVONS REALISER ENSEMBLE : Dans le cadre de notre activité Alstom Digital & Integrated Systems, le Centre de Développement de Saint-Ouen est en charge de concevoir les principales Solutions de Signalisation CBTC Urbaines d'Alstom : Urbalis 400, Système déployé sur plus de 100 projets dans le Monde, et Urbalis Fluence, notre dernier et plus innovant Système de Signalisation urbain.Rattaché(e) au Software Leader au sein du Service Design Logiciel PA (Pilote automatique), vous intervenez en tant que Software Designer au sein d’une équipe de développement.Votre rôle est de :   Développer des fonctionnalités dans la descente du cycle en V logiciel selon le process issu de la Cenelec 50128-2011  Participer à l’analyse des besoins du client interne pour collaborer à l’élaboration de la spécification système, prenant en compte les contraintes de définition du produit (plateforme, niveau de sécurité, testabilité, ressources) et de process, en utilisant vos compétences en signalisation ferroviaire  Elaborer les spécifications logicielles correspondantes, en vue de leur développement dans le respect du process en vigueur, prenant en compte les contraintes d’architecture, de performance, de sécurité, de qualité, de coûts, de testabilité, et de maintenabilité. Assurer leur implémentation incluant le codage (en Ada95 ou en C selon le cas), et des tests designers associés  Contribuer aux actions d’amélioration continue du métier  QUEL EST VOTRE PROFIL ?  De formation minimum Bac 5, ingénieur ou diplôme universitaire en Génie Logiciel, vous avez une première expérience dans un contexte similaire sur des problématiques de spécification/conception de systèmes embarqués à forte contrainte sécuritaire.  Vous avez des compétences en programmation temps réel, et avez idéalement déjà développé des applications dans le domaine de la signalisation ferroviaire dans le respect des normes de la CENELEC 50128. Une expérience en programmation Ada95 et l’utilisation de la méthode B seraient appréciées.  Vous êtes intéressé(e) par le domaine des transports ferroviaires et vous êtes motivé(e) pour démontrer votre capacité à innover et travailler dans un contexte international. Forte sensibilité technique, rigueur, efficacité opérationnelle, esprit d’équipe, aisance relationnelle et sens de l’initiative sont vos atouts pour réussir dans ce poste.  Anglais indispensable.  Localisation : Vous serez basé dans nos locaux à Saint-OuenRejoindre Alstom vous permettra de développer votre carrière dans un environnement de travail diversifié et international.Vous contribuerez au succès d'un acteur mondial incontournable qui se positionne à la pointe de l'innovation et des modes de transports durables pour ses clients et les voyageurs. Notre culture d'entreprise est fondée sur l'innovation, la diversité, l'entrepreneuriat, la responsabilité sociale et l'éthique. Nous partageons des valeurs communes: l'esprit d'équipe, la confiance et le sens de l'action. Les perspectives d'évolution qu'offre Alstom en France et à l'international vous donneront l'opportunité d'être acteur de votre carrière professionnelle et de contribuer directement au développement de la mobilité durable dans le monde.Alstom garantit l'égalité des chances et s'engage en tant qu’employeur à créer un environnement de travail inclusif où tous sont encouragés à atteindre leur plein potentiel, et où les différences individuelles sont valorisées et respectées. Tous les candidats qualifiés sont considérés dans nos processus de recrutement sans tenir compte de l’origine, de la couleur de peau, de la religion, du sexe, de l'orientation sexuelle, de l'identité de genre, de l'âge, de la nationalité, de la nature du handicap ou de toute autre caractéristique protégée par la loi locale
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Analytics Data engineer - internship,Equativ,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/analytics-data-engineer-internship-at-equativ-3798660173?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=sHSgNkrxaOhRoT4wfKK2Pg%3D%3D&position=7&pageNum=10&trk=public_jobs_jserp-result_search-card,"Your missionHelping the company be fully data-driven is not just a buzzword, it is our mission at Equativ. We, the Data Analytics team at Equativ, maximize efficiency by enabling easy and permanent access to quality data, valuable insights & rigorous thinking. Our responsibility is to ensure our local and central teams, clients and partners, make informed business decisions. To do so, we leverage huge volumes of data (Equativ handles 150Bn Auctions per Day) in a state-of-the-art tech stack (AirFlow, Snowflake, Tableau…) in order to provide actionable insights to all teams at Equativ!What you'll doReporting to the manager of the Analytics team, your mission will be to maintain and upgrade our data pipelineDay-to-day maintenance of our data pipeline: Ensure data pipeline ingestion accuracy in due timeFollow-up on data quality issues raised by internal customersImprovement of sourcing processes:Migrate from Talend data flows to Python scripts for our sourcing jobsDevelop resources to make Data Analysts autonomous in sourcing data in our Snowflake database (through ready-to-use scripts or small interfaces)Developing new projects on our main platforms (Tableau & Snowflake)Leverage new resources to make the most out of Snowflake (Streamlit, Snowpark…)Identify new ways to structure our data sources in Tableau while reducing the loading time for the userParticipate in the restructuring of our data marts (schemas, stages & permissions)Communication:Sync with Data Analysts to make sure that their requests are properly prioritizedSynchronize with other technical teams (Core-Data, Infra) to gather requirements of the migration and ensure a smooth transitionUnderstand business needs to suggest the most efficient technical solution. About youPragmatic & hands-on mindset is required: you’ll have latitude to explore different options, but you need to go for the most effective solutionTechnical knowledge of Python & SQL is a mustKnowledge of collaboration platforms (Gitlab) & Agile processes is a plus.You can demonstrate your ability to solve problems end to endYou are fluent in English👋 About usEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus — four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times’ FT 1000: Europe’s Fastest-Growing Companies.Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.Come and lead the charge with us in building a transparent ecosystem based on quality!Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Junior Data Engineer,Constellium,"Voreppe, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/junior-data-engineer-at-constellium-3791294675?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=k7MlASqYOj4SJMhxYhO10Q%3D%3D&position=8&pageNum=10&trk=public_jobs_jserp-result_search-card,"C  -TEC RECRUTE  Junior Data Engineer (all genders) Constellium is a world leader in the development and manufacture of high value-added aluminium products and solutions for a wide range of markets and applications, focusing in particular on aerospace, automotive and packaging. Constellium also has nearly 12,000 employees worldwide.We are committed to minimizing the environmental impact of our operations and improving the life cycle footprint of aluminium throughout the value chain. In our company, safety is essential, it is one of our core values without compromise. Our Research and Technology Center, C-TEC Constellium Technology Center, based in Grenoble (Voreppe - 38), employs about 240 people.By joining our company, you will discover a multicultural company (more than 18 nationalities) which is committed to diversity and the well-being of its employees. You will also discover an R&D center rich by its expertise and by the benevolence of its employees.The Digital core team is deploying Industry 4.0 technologies everywhere in the group to create our future world-class manufacturing processes. In the context of a replacement, C-TEC is hiring a Junior Data Engineer.  Responsibilities: In the frame of our global digital strategy, the focus of this role is to set data solutions to bring value for our business.The job holder will have to: Design, build and maintain data flows  Manage SQL databases and support users on data access  Design and grow our data repository on the cloud  Watch, benchmark, test and implement solutions around data on Azure  Help our plants to structure and process their data  Support our developers on data transfer and modeling  Run basic data analysis and support data scientists on model industrialization The job holder will need good communication skills to share his results and achievements to non-IT / data specialists.Contribute to C-TEC's zero accident policy by enforcing all EHS rules, writing GTPs (General Work Permits) when necessary, conducting safety visits, reporting any accidents or near accidents and being mindful of the safety of others. Profile : A masters-level qualification in computer science linked to data management.A first experience in a data engineer position with achievements regarding the following fields: SQL / data modeling  Coding in Python  Software architecture  ETL (ideally Azure Data Factory)  Data Architecture / Datalake organization  Knowledge of Azure Cloud environment and GitHub would be a plus, but is not mandatory The ideal candidate will have: Strong interest in data and manufacturing topics.  Proven ability to learn and deliver.  Willingness to interact with various profiles (including non-IT).  Curiosity to evaluate innovative technologies from the digital world. Professional Working Proficiency in written and spoken in English and French are required to interact with team members and other plants. Job requirements: The position implies business trips to plants in Europe and in the USA. We offer:  Attractive Salary  Profit-sharing  Bonus  Annual working days system, with work time reduction  Staff canteen  Important benefits from the work council  Remote work


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - H/F - CDI,Polyconseil,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-cdi-at-polyconseil-3583593428?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=jCX%2FQjnp5rkfm2D7cXEGhA%3D%3D&position=9&pageNum=10&trk=public_jobs_jserp-result_search-card,"Expert de la transformation numérique depuis 1989, Polyconseil possède un positionnement atypique, alliant expertise en conseil et réalisation de produits digitaux. Nos équipes s'intègrent sur toute de la chaîne de valeur, afin d’avoir une vue d’ensemble d’un projet et d’en maîtriser chaque étape : cadrage des besoins, préconisations, conception, développement et déploiement de solutions innovantes et complexes.Nous accompagnons aussi bien des grands comptes, que des institutions publiques ou des start-ups, dans des secteurs variés tels que : Médias, Assurance, Mobilité, Aérospatial, Écologie, etc.Nous intervenons sur des projets à forte valeur ajoutée et apportons un accompagnement sur-mesure à nos clients, en constituant des équipes multidisciplinaires de Développeur(se)s, Product Managers, Digital Consultant(e)s, UI / UX Designers, Data Scientists et InfraOps.Polyconseil est fondé sur des valeurs d’excellence, de bienveillance et d’entraide favorisant la responsabilisation et la montée en compétence graduelle de tous nos collaborateurs.Pourquoi rejoindre Polyconseil ?Vous intervenez sur des missions à impact et voyez le résultat de vos actionsVous êtes responsabilisé(e) et évoluez dans un environnement propice à l’apprentissage et à la progression, au contact de talents qui se tirent vers le hautVous travaillez dans une ambiance à la fois détendue et stimulante, prônant esprit d’équipe et prise d’initiativesVous profitez d’une vie interne riche en événements (sportifs, culturels, culinaires…)Votre équilibre vie pro / vie perso est respecté et vous bénéficiez d’une politique de télétravail flexibleVous rejoignez nos locaux récents en plein Paris (Paris 9, métro Grands Boulevards, lignes 8-9)Vous avez accès à la participation, plan épargne entreprise avec abondement, tickets restaurant…Vos missionsIntégré(e) au sein de l’équipe Data, vous intervenez notamment sur :Le développement, déploiement et maintenance de pipelines d’ETL/ELTLa mise en place d’APIs et de backends applicatifsLa définition et mise en place de modèles de données, administration de base de donnéesL’utilisation de plateformes et outils CloudLa compréhension et application de principes d’architectureLa supervision et monitoring d’applicationsEntouré(e) de nos experts, vous montez rapidement en compétence sur les technologies suivantes : Python, Apache Spark, MongoDB, ElasticSearch, Airflow, et participez au développement de nouveaux produits innovants dans le cadre de notre Datalab.En fonction de vos appétences, vous aurez également la possibilité de vous impliquer sur des sujets transversaux pour accompagner notre croissance : recrutement, réponses aux AOs, organisation d’événements, chantiers internes (RSE…) etc.Principales technologies à utiliser ou à découvrirLangages : Python, SQL, DBT, SparkBases de données : PostgreSQL, base de données NoSQL (MongoDB, ELK…)Orchestration : Airflow, LuigiDevOps : Git, CI/CD, Docker, Kubernetes/Nomad, Ansible…Outils Cloud : AWS, GCP, Azure, Snowflake, Databricks…Autres : KafkaQuelques Exemples De MissionsDéveloppement et commercialisation en SaaS d’un système de gestion intelligente de la politique de stationnement pour une centaine de villes en FranceSolution d’optimisation du pricing des produits vendus via une plateforme de ventes aux enchères en ligneDéveloppement d’une plateforme de suivi et de prédiction des incidents sur un parc ITDéveloppement from scratch d’un feature store à destination des data scientists d’un acteur de la réassuranceAlgorithmes de détection de fraude auprès d’assureursConception d’une plateforme data temps réél sur AWSVos moyens pour réussirFormation : dès votre arrivée, vous avez accès à un large panel de formations et ressources documentaires pour approfondir vos connaissances sur vos sujets de prédilection ou bien découvrir des sujets nouveaux par simple curiosité. Nous finançons également des formations AWSManagement opérationnel : vous êtes accompagné(e) par un manager de mission et un Talent Manager tout au long de votre parcours chez nousContact constant avec d’autres métiers / équipes au sein de nos locauxVotre profilIssu(e) d'une école d'ingénieurs ou d’une école spécialisée en développement informatique, vous possédez minimum 2 années d’expérience en Data Engineering et maîtrisez Python et SQL. Une expérience ou une formation spécifique (ex : Udemy) avec le calcul distribué, le traitement des données temps réel ou les bases de données NoSQL est un plus. Avoir déjà travaillé avec un ou plusieurs fournisseurs de cloud (AWS, GCP, Azure notamment) est également apprécié.Nous recherchons avant tout un fit humain, et de futur(e)s collègues avec qui nous prendrons plaisir à travailler chaque jour.Alors, Si Comme Nous Vous PossédezUne curiosité naturelle pour le monde du numérique Un goût pour le challengeUne envie de progresser et d’apprendre Un esprit d’équipe à toute épreuveUne réelle volonté de transmettre vos connaissances et d’aider les autresUne très bonne maîtrise de la langue française …n’hésitez pas à nous envoyer votre candidature !Polyconseil est une entreprise engagée, handi-accueillante et inclusive


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer - Lyon - H/F,Lincoln France,Greater Lyon Area,https://fr.linkedin.com/jobs/view/data-engineer-lyon-h-f-at-lincoln-3697110169?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=3C2AVv9HeGzv1atgdt9P%2BA%3D%3D&position=10&pageNum=10&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre Lincoln pour mettre en œuvre des solutions Big Data adaptées aux enjeux de nos clients ?Ce que l'on vous proposeRejoindre LINCOLN, c’est rejoindre un cabinet de conseil reconnu pour son expertise data depuis plus de 30 ans, en proposant des prestations d’expertise, de conseil et d’accompagnement en Modern BI, Big Data et Science de la donnée.Vous progresserez au sein d’une équipe de 380 experts de l’ingénierie Vous évoluerez ainsi dans un environnement technique stimulant et en constante évolution : architectures distribuées ; sécurisation, configuration et optimisation de plateformes ; gouvernance QoD ; industrialisation de projets data science…Enfin, vous perfectionnerez vos compétences grâce à notre Lincoln Academy, véritable institut de formation interne et data-docké.Ce que l’on attend de vousEn intégrant nos équipes de consultants, vous participez à la mise en œuvre des solutions Big Data adaptées aux enjeux de nos clients.En tant que Data Engineer, vous aurez pour mission :Mettre en place et accompagner au déploiement d’architectures Big DataConcevoir, développer, superviser et optimiser les flux d’alimentation de données à forte volumétrieAccompagner techniquement les équipes de développementSuperviser et diagnostiquer des jobs en productionsVos atouts pour mener à bien cette mission Des fondamentaux théoriques acquis en cursus école d’ingénieurs informatique ou universitaire avec une spécialisation data, avec une expérience d’au minimum 3 ans d’expérience en développement Big Data (les profils juniors ne seront pas contactés)Une sensibilité à la méthodologie Agile (Definition of ready, definition of done, valeurs SCRUM)Une maîtrise de l’écosystème Hadoop (Hive, Spark,…)Connaissances des environnements Cloud (idéalement AWS et/ou Azure)La connaissance de Databricks est un véritable plusMaîtrise des langages de programmation (Python, Scala, SQL)Compréhension des documentations techniques en anglaisLa cerise sur le gâteau : doté(e) d’un bon relationnel, vous aimez travailler en équipe et êtes rigoureux. Votre dynamisme et votre curiosité vous permettent également d’être autonome.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Stage (F/H/X),iAdvize,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-stage-f-h-x-at-iadvize-3799307113?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=%2FOj7IZRhjJJ%2FWY1lyU8Olg%3D%3D&position=11&pageNum=10&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseEn associant le meilleur de l’humain et l’intelligence artificielle, la plateforme conversationnelle d’iAdvize permet aux marques d’offrir à grande échelle, à leurs clients, une expérience d’achat en ligne authentique et personnalisée.Les consommateurs ont massivement adopté le Messaging dans leur vie quotidienne. Ils sont 85% à vouloir interagir avec une marque comme ils le font avec leurs proches: via messaging. C’est simple, personnel et engageant.En tant que fournisseur d'une solution complète pour l’avant-vente et le service client, iAdvize n'a qu'une seule mission depuis sa création en 2010 : rendre les marques conversationnelles. Pour offrir cette expérience à grande échelle, nous déployons des copilotes virtuels propulsés par l’IA, fiables, connectés et en parfaite conformité :iAdvize Copilot™ for Shoppers : Boostez les ventes en ligne en 24/7 grâce à un assistant à l’achat propulsé par l’IA. Levez les freins à l'achat et augmentez les conversions. iAdvize Copilot™ for Agents : Augmentez la vitesse, l'efficacité et la qualité de service de vos conseillers grâce à des copilotes propulsés par l’IA générative de confiance. iAdvize c'est aussi plus de 200 talents présents à Nantes (notre siège social), Paris (FR), Düsseldorf (DE) et Boston (US) ; Nous sommes fiers d’être une Great Place to Work et un Lauréat FrenchTech Next 40 et 120.Le bien être de nos collaborateurs est essentiel pour nous et de nombreuses initiatives sont portées chaque année par nos équipes pour que nous puissions tous évoluer dans un contexte de travail propice à l'épanouissement personnel comme professionnel.Convaincus par l'atout majeur que représente la diversité dans nos équipes, nous sommes fiers de compter plus de 45% de femmes dans nos effectifs.Nous sommes également convaincus qu’une croissance durable n’est réalisable qu’en prenant en compte des objectifs ambitieux d’un point de vue sociétal & environnemental. Nous avons lancé depuis 2022 un groupe de travail pluridisciplinaire sur les enjeux RSE, afin de réduire nos émissions carbones, nouer des partenariats responsables et accompagner la transformation conversationnelle du e-commerce vers un modèle plus durable.Vous pouvez retrouver plus d'informations et des photos de nos locaux sur notre page Welcome to the jungle.Description du posteL'opportunité : Vous rejoindrez l'équipe Data au sein du département Product & Engineering. Vous serez sous la responsabilité du Senior Data Engineer et l'aiderez à concevoir, construire, améliorer et maintenir la stack data. Vous aurez l'opportunité de participer à une gamme étendue de tâches, allant de la surveillance de l'infrastructure de données à la mise en œuvre de changements critiques, ainsi que de la collecte de données pour répondre aux défis business. Votre travail implique des actions à plus long terme ainsi que des interventions opérationnelles quotidiennes, vous offrant ainsi une expérience réaliste du rôle de Data Engineer.Vous collaborez avec des Data Scientists et des Analystes, ainsi qu'avec l'équipe Engineering Platform et éventuellement avec des parties prenantes commerciales.Vous acquerrez de l'expérience dans un environnement technique riche : Google Big Query, Apache Airflow, Amazon Athena, Elasticsearch, Tableau.Les missions : Surveillance de l'exécution des pipelines de donnéesContribuer à la migration des processus ETLImplémenter des évolutions dans la stack d'ingénierie des données (par exemple, automatisations, systèmes d'alerte, traçabilité, documentation)Contribuer à la mise à jour ou à la configuration de nouveaux pipelines de collecteEffectuer des extractions ad hoc et/ou des corrections BI pour répondre aux besoins urgents de l'entrepriseQualificationsVous avez une expérience en programmation, des compétences en manipulation de données et des connaissances de base des environnements cloud. Vous êtes à l'aise avec la gestion de plusieurs tâches et des délais. Les compétences relationnelles, la motivation et le désir d'amélioration personnelle sont fondamentaux pour réussir dans ce rôle.Compétences techniquesBonne connaissance de Python (usage général, avec un accent sur la manipulation de structures de données)Bonne connaissance de SQLFamiliarité avec les environnements Linux et la ligne de commande (CLI)Compréhension des processus et de l'orchestration ELT/ETLBonus I : Expérience avec au moins un fournisseur de Cloud majeur (AWS, GCP, Azure, ...)Bonus II : Connaissance d'Airflow, Docker, Terraform, Big QueryBonus III : Connaissance de Tableau ou d'autres outils BICompétences relationnellesBonnes compétences en communication : Vous interagissez avec d'autres rôles liés à la Data, ainsi qu'avec des ingénieurs et des analystes commerciaux. Vous devrez adapter votre style de communication à différents publics. La connaissance de l'anglais et du français est obligatoireCapacité à s'adapter aux changements de priorités et à respecter des délais strictsProactivité et ouverture à assumer des tâches imprévues si la situation l'exigeInformations supplémentairesContrat : Stage Lieu de travail : poste à pourvoir à Nantes (siège social, proche gare Sud)Date de début : dès que possibleCharte de télétravail en place (3 jours par semaine, possible après l'onboarding). La société iAdvize est attachée à la diversité de ses équipes et pratique une stricte politique de non-discrimination au recrutement. Rejoindre iAdvize, c’est…Participer au développement d’une scale-up française ambitieuse, internationale et dynamique. Rejoindre une promotion de nouveaux, et participer à un programme d’onboarding d’une semaine qui vous formera sur notre produit, notre stratégie, notre marché, nos techniques de ventes. Travailler dans des conditions de travail agiles, où vous pourrez être force de proposition pour apporter vos idées.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
DATA ENGINEER H/F,METEOJOB by CleverConnect,"Olivet, Centre-Val de Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3804853067?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=Cu0b%2BoajFrhUFWO%2BGQb5VA%3D%3D&position=12&pageNum=10&trk=public_jobs_jserp-result_search-card,"EntrepriseAxéréal : un groupe coopératif agricole et agroalimentaire fier de ses racines locales et de son implantation mondiale.Rejoignez le groupe Axéréal et ses filiales pour prendre part à notre ambition collective : transformer durablement le modèle agricole et alimentaire dans un contexte dynamique et stimulant.Engagez-vous aux côtés de 11 000 agriculteurs collectivement associés et de 4 000 collaborateurs dans des projets innovants et ambitieux.Evoluez dans un groupe international - 18 pays - aux activités multiples - Malt, Meunerie et Alimentation animale - et qui réalise un chiffre d'affaires de 4,3 milliards d'euros.Rencontrez des managers qui vous feront confiance et vous permettront de vous épanouir dans un contexte de travail propice à l'esprit d'initiative et à l'autonomie.Convaincu ? Alors, apportez votre contribution en candidatant ci-dessous en quelques clics et décrochez un poste qui a du sens !Dans le cadre de sa politique diversité, Axéréal étudie, à compétences égales, toutes candidatures dont celles de personnes en situation de handicap.Description Du PosteRattaché à la Direction Systèmes d'Information (DSI), vous intégrez une équipe de 4 personnes. Votre rôle, consiste mettre en place la collecte et la mise à disposition des données au sein de l'entreprise, être en charge d'industrialiser et mettre en production des traitements sur les données (par exemple : mise à disposition de tableaux de bord, intégration de modèles statistiques) en lien avec les équipes métiers et les équipes qui les analysent.C'est un rôle central et très important, situé au coeur de notre développement ! Le Data Engineer est le maillon essentiel pour fournir les données fiables aux métiers leur permettant de créer leurs nouveaux produits et services.Les missions sont composées des actions suivantes ;Acheminement de la donnée ; Recueillir les besoins métiers des différentes unités demandeuses et utilisatrices de solutions de collecte et stockage de la donnée. Développer les solutions techniques de collecte de la donnée via des API. Développer des solutions techniques de stockage de la donnée (Hadoop). Réaliser les tests unitaires et d'intégration. Mettre en place et maintenir les batchs, c'est-à-dire les automatisations d'une série de traitements.Mise à disposition des données aux équipes utilisatrices ; Industrialiser et automatiser le nettoyage de la donnée selon les spécifications retenues. Gérer, maintenir et documenter de multiples bases de données (via l'importation de données externes en open data ou de données internes par exemple). Gérer le cycle de vie de la donnée conformément aux directives inscrites dans le RGPD. Assurer le suivi de production et la maintenance.Mise en production de modèles statistiques dans les applications ; Développer l'industrialisation de modèles statistiques ou de machine learning. Implémentation du suivi de la validité du modèle statistique. Assurer le suivi de production et la maintenance.Suivi des projets de développement ; Établir les spécifications techniques à partir de l'analyse des besoins. Reporter l'activité auprès du chef de projet. Autres activités éventuelles ; Automatiser la création de tableaux de bord aux équipes métiers (envoi de fichiers via des applications dédiées). Assurer une veille technologique sur les outils big data. Écrire la documentation relative aux bases de données (règles de gestion, dictionnaire des variables…).Dans le cadre de sa politique diversité, le groupe Axéréal étudie, à compétences égales, toutes candidatures dont celles de personnes en situation de handicap.Description Du ProfilDe formation Bac+5 école d'ingénieur orienté développement, ou master spécialisé en data, avec une spécialisation Big Data, vous êtes passionné par l'innovation et les technologies liées aux domaines Data Analytics & AI. Maîtrise de l'environnement technique du cloud provider (GCP ) Maîtrise des bases de données (BigQuery) Maîtrise de langages de programmation (Java, Python, Spark, Scala, Sql,…) Maîtrise des outils de gestion de flux et de manipulation de données ETL/ELT (Semarchy DI, Google DataFlow, Dataproc, etc …) Connaissance des méthodes de développement agile Maîtrise des systèmes d'exploitation (Unix, Windows…)Vous appréciez travailler en équipe et possédez un excellent relationnel ? C'est parfait, car le poste nécessite de travailler avec des interlocuteurs multiples et demande ainsi une grande adaptabilité.Aussi, vos capacités organisationnelles, votre autonomie, votre sens de l'initiative, votre rigueur et votre orientation résultat sont autant d'atouts qui vous permettront d'exceller dans la fonction.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3738615749?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=8W9XLa1kaOwFefUF3%2BafjQ%3D%3D&position=13&pageNum=10&trk=public_jobs_jserp-result_search-card,"Description de posteBig Data, Data Science, Data analyse, Data architecture, ... Ça n’a pas de secret pour vous ?Que vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l’une de ces disciplines, intégrer notre communauté Data, c’est l’assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.Si vous souhaitez intégrer nos équipes à Nantes et accompagner les plus grands acteurs de secteurs variés, cette annonce est susceptible de vous intéresser.Fonctions et responsabilitésSous la responsabilité d'un Chef de Projet / Scrum Master, vos principales missions sont : Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions techniques mises en place Recueillir les besoins métiers et des équipes data Assurer une veille technologique régulière Concevoir et mettre en place les traitements de données Tester et valider les développements réalisés Réaliser la documentation technique des développements réalisés Participer à l'élaboration et la révision de normes / documentation technique dans le cadre du projet Développer ses compétences et connaissances des architectures Data Etre garant de la mise en place, du suivi et de l'exploitation des outils déployésEn rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,...).Qualités requises pour réussir dans ce rôleDe formation Bac +5, vous disposez d'une expérience d'au moins deux ans dans la conception et le développement.Vous maîtrisez un ou plusieurs ETL.Véritable passionné, vous êtes rigoureux et doté d'un bon sens de la collaboration.CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l’évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d’accessibilité et de clarté, le point médian n’est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.Allier savoir et faireAlors que la technologie s’inscrit au cœur de la transformation numérique de nos clients, nous savons que les individus sont au cœur du succès en affaires.Lorsque vous rejoignez CGI, vous devenez un conseiller de confiance, collaborant avec vos collègues et clients pour proposer des idées exploitables qui produisent des résultats concrets et durables. Nous appelons nos employés ""membres"" parce qu’ils sont actionnaires et propriétaires de CGI. Ils ont du plaisir à travailler et à grandir ensemble pour bâtir une entreprise dont nous sommes fiers. C’est notre rêve depuis 1976. Il nous a menés là où nous sommes aujourd’hui – l’une des plus importantes entreprises indépendantes de conseil en technologie de l’information (TI) et en management au monde.Chez CGI, nous reconnaissons la richesse que la diversité nous apporte. Nous aspirons à créer une culture à laquelle nous appartenons tous et collaborons avec nos clients pour créer des communautés plus inclusives. En tant qu’employeur qui prône l’égalité des chances pour tous, nous voulons donner à tous nos membres les moyens de réussir et de s’épanouir. Si vous avez besoin d’un accompagnement spécifique durant le processus de recrutement et d’intégration, veuillez nous en informer. Nous serons heureux de vous aider.Prêt à faire partie d’une entreprise qui est gage d’excellence? Rejoignez CGI – où vos idées et vos actions changent la donne.
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst H/F,Inetum,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-inetum-3782175235?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=Qio%2FTBF9SulAe1ZAwsyypQ%3D%3D&position=14&pageNum=10&trk=public_jobs_jserp-result_search-card,"Détail de l'offre  Informations générales  Entité de rattachement  Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste Métier Métier AS (Application Services) - Technique AS Intitulé du poste Data Analyst H/F Contrat CDIDescription De La MissionDans le cadre de la croissance de notre agence lilloise, nous développons notre Practice Data et recrutons des profils Data de divers horizons Data Analyst, Data Engineer, Data Scientist et Data Gouv. Les besoins métiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversité de compétences. Vous pourriez être l’un d’eux et rejoindre Inetum.En tant que Data Analyst, vos principales missions consistent à Analyser et retranscrire le besoin client Identifier, extraire et exploiter les sources d'acquisition de données les plus pertinentes Valoriser de la donnée Développer l'outil de data visualisation pour accompagner les équipes métiers dans leurs aides à la décision Être le lien entre les équipes métier pour les accompagner dans la mise en œuvre des nouveaux outils Profil Pour mener à bien votre rôle, il vous faut parler SQL couramment un niveau avancé sur Excel et/ou Google Spreadsheet une maîtrise d'un outil décisionnel comme PowerBI, Qlik, Tableau ou encore Google Data StudioVous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !Notre plus Rejoindre la région Nord-Est, c’est bénéficier des avantages d’un Grand Groupe tout en gardant la proximité régionale. Nous mettrons tout en œuvre pour vous apporter un équilibre vie perso / vie pro. C’est pourquoi nous vous proposons un rythme hybride (selon les contraintes clients) Une trajectoire de carrière personnalisée et adaptée à vos souhaits d'évolution grâce à une implantation à l’international (26 pays, 7 Fablab), des formations ciblées et des projets couvrant l’ensemble de la chaîne de valeur IT (+25 filières métiers) Intégrer un collectif d’experts partageant des valeurs de solidarité et d’excellence Intégrer une entreprise ayant une stratégie affirmée de certifications de ses collaborateursLocalisation du poste Localisation du poste France, Nord, 59 Nord Ville LilleCritères candidat Niveau d'études min. requis Bac+5 Niveau d'expérience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
SOFTWARE ENGINEER / INGENIEUR INFORMATIQUE (H/F),Akkodis,"Gennevilliers, Île-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-ingenieur-informatique-h-f-at-akkodis-3788244655?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=z2h75vpEXOiGxnVmBegKWA%3D%3D&position=15&pageNum=10&trk=public_jobs_jserp-result_search-card,"La ligne de service Talent d’Akkodis France recrute un SOFTWARE ENGINEER/INGÉNIEUR INFORMATIQUE (H/F) en CDI à Gennevilliers. Notre client est une entreprise française spécialisée dans la conception et la fabrication d'équipements de haute technologie.Rattaché(e) au Responsable Bureau d’Études Informatique, vous prenez en charge l’interface de l’ensemble des composants électroniques d’un instrument de microanalyse de surface. Un programme qui propose des fonctions de réglage et d’acquisition ainsi qu’un programme graphique interactif.Vos principales missions :Prendre connaisse du cahier des charges fonctionnel du composant à développer, définir l’ergonomie et tests de validation.Analyser les spécifications techniques du composant à développer.Concevoir l’architecture logicielle, le découpage en modules, l’interface externe, les tests d’intégration du composant.Développer les modules, définir et réaliser les tests unitaires.Participer aux tests fonctionnels et à la validation du composant. Profil recherché :Titulaire d’une formation Bac+4/5 spécialisée en informatique industrielle ou mécatronique / généraliste.Vous disposez de 5 à 7 ans d'expérience dans un poste similaire, secteur de l’instrumentation. Idéalement : connaissance en physique des particules chargées.Vous êtes à l’aise avec le système d’exploitation Windows.Vos bases en programmation vous permettent de maitriser C/C++ et C#.La programmation d’IHM en WPF ne vous est pas inconnu ;Vous comprenez les principes de fonctionnement d’intégration de composants externes (widgets, graphes, images).Vous avez eu l’occasion de travailler en programmation temps réel (RTOS, VXWORKS, Nucleus ou VRTX) et/ou en programmation LABVIEW.Vous avez de bonnes capacités rédactionnelles et un bon esprit de synthèse,Vous êtes curieux et vous avez le goût de l’innovation.La maîtrise de l’anglais est indispensable pour ce poste (oral / écrit).Les déplacements professionnels sont occasionnels et peuvent représenter 5 % de l’activité.A propos de nousAkkodis, est un acteur mondial de l’ingénierie et de l’IT et un leader dans la smart industrie. Nous accompagnons nos clients dans leurs projets de transformation digitale via 4 lignes de service : Consulting, Solutions, Talent et Academy. Akkodis est un partenaire technologique de confiance pour ses clients à l’échelle internationale. Nous co-créons et nous imaginons des solutions de pointe pour répondre aux défis majeurs de notre société, qu'il s'agisse d'accélérer la transition énergétique et de développer la mobilité verte, ou encore de construire des approches centrées sur les utilisateurs.Dotés d’une forte culture de l’inclusion et de la diversité, nos 50 000 experts en IT et en ingénierie, présents dans 30 pays, allient les meilleures compétences technologiques à une connaissance transverse de toutes les industries pour façonner un futur plus durable. Nous sommes passionnés par l’idée d’inventer ensemble un avenir meilleur.Akkodis Talent est la ligne de service d’Akkodis en France qui combine tout le savoir-faire en termes de recrutement du groupe Adecco avec l’expertise technologique d’Akkodis. Les équipes d’Akkodis Talent répondent aux enjeux RH de leurs clients en les accompagnant sur leurs projets de recrutement temporaire via l’intérim ou CDD, ou permanents via des recrutements en CDI.Akkodis Talent est une marque du groupe Adecco


        Show more

        


        Show less","{'ProgLanguage': ['C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),FAB Group,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-fab-group-3796635086?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=C4DLw0FyWeoenFKoPDElrg%3D%3D&position=16&pageNum=10&trk=public_jobs_jserp-result_search-card,"FAB Group (www.fab-group.fr) est un cabinet de conseil en recrutement et management de transition. Notre rôle est de trouver les meilleurs talents pour nos clients et les plus belles opportunités professionnelles pour tous les candidats qui nous font confiance.Depuis 2007, nous accompagnons nos partenaires et talents avec une approche basée sur 3 piliers qui ont fait notre réputation : spécialisations sectorielles, rigueur et transparence.Nous plaçons l'humain au coeur de notre réflexion, en veillant à prendre en compte chaque projet individuellement et en mettant en place de véritables coachings de nos candidats et de nos clients. La construction de liens solides avec chacun d'entre eux est la force de notre cabinet. La disponibilité est un élément central de notre ADN.Sous la marque FAB IT & Digital, nos équipes de spécialistes accompagnent les Directions des Systèmes d'Information de tous secteurs d'activité dans leurs recrutements (gouvernance, MOA, études et développement, infrastructures, sécurité et digital).Aujourd'hui, nous recherchons pour l'un de nos clients, un acteur du secteur assurantiel, de premier plan, un Data Engineer F/H basé à Paris(75).Vos principales missions seront les suivantes : Administrer les usages SnowFlake et devenir le référent technique de la solution dans le projet de migration sur SnowPark nécessitant de bonnes compétences Spark Industrialiser les pipelines et applications (optimisation, supervision,...) Coordination avec les équipes projets IT ou métier la mise en exploitation Développement des automates en script shell Veiller à la qualité, à la performance, à la fiabilité et l'amélioration continue des traitements Data Suivi du RUN, support production, suivi des incidents, gestion des habilitations. Vous avez au moins 3 ans d'expérience dans le domaine du Big Data et si possible avec une expérience d'industrialisation et de supervision de Production:Technologies requises : Snowflake, Spark HadoopTechnologies souhaitées : Kubernetes, Daitaiku, PySpark, Apache Sqoop, pipelines CI/CD (Jenkins, Gitlab...)Vous êtes rigoureux et avez une aisance dans la communication avec les équipes fonctionnelles et techniques;Vous avez des bases en anglais technique pour collaborer efficacement avec les différents interlocuteurs internationaux; 18941510-55584
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Engineer / Talend Big Data (H/F),Micropole,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-talend-big-data-h-f-at-micropole-3706046900?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=T3oDS7wWM5gYvxSdv5b9YQ%3D%3D&position=17&pageNum=10&trk=public_jobs_jserp-result_search-card,"Rejoignez le Groupe Micropole. Devenez un(e) #InnovativePeople ! Mission En RésuméPoste : Data Engineer Talend Big DataLocalité : Levallois-PerretType de contrat : CDINiveau d’expérience : au moins 3 ansVous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !Au sein de notre agence basée à Levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer - Talend Big Data (F/H) , vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance.Dans vos  missions quotidiennes , vous serez amené(e) à :Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; Réaliser une veille technologique pour être à la pointe sur les solutions Cloud & Data ; Participer au développement de notre centre d’excellence.  Profil Vos Compétences TechniquesVous avez un minimum de 3 années d’expérience sur des projets Data avec Talend Spark ou SSIS. Vous maîtrisez au minimum un langage de programmation (Spark, Scala ou SQL) ; Vous avez une maitrise des théories et outils de modélisation de données, Vous maitrisez des outils et framework d’industrialisation, IaC, CI/CD et/ou gestion de version, Vos AtoutsVous êtes passionné(e), rigoureux(se), curieux(se) et à l’écoute ; Vous avez un bon niveau d’anglais qui vous permet d’intervenir sur des projets à dimension internationale ; Vous développerez votre créativité et votre curiosité grâce à une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le développement d’équipes et de communautés techniques autour du Cloud et des solutions Data. Devenir #INNOVATIVE PEOPLE C’est :Intégrer une communauté de 1200 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine.Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale.Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP.Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus.S’assurer d’une innovation continue grâce à : notre écosystème de partenaires technologiques ; notre accélérateur de start’up databoost’R ; nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients ; notre management par les talents naturels.Processus De RecrutementChez Micropole, le processus de recrutement est réactif et transparent.Etape 1 – si votre profil correspond à nos besoins, vous êtes recontactés dans les 72 heures qui suivent votre candidature par Lamia notre Talent Specialist. Une qualification téléphonique ou physique est organisée rapidement avec Dimitri ;Etape 2 - Un premier entretien est programmé avec Dimitri en physique ou visioEtape 3 – Vous rencontrez un manager technique avec l’un de nos experts.En fonction du poste, vous pouvez passer des étapes supplémentaires (entretien supplémentaire ou test technique)LA VIE CHEZ MICROPOLE, C’estUne vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ;Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ;Une politique de formation attractive et éclectique (certifications prises en charge) ;Un travail en équipe valorisé pour une meilleure cohésion ;Participation à des projets internes sur la base du volontariat.CompétencesSQLSCALASPARKTALENDSSIS


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA Engineer (H/F),Adsearch,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-adsearch-3801834663?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=qrTmGdaGtCbBu%2FC9KkGoAw%3D%3D&position=18&pageNum=10&trk=public_jobs_jserp-result_search-card,"Adsearch vous propose des milliers d''opportunités de carrières dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Intérim et Freelance sur notre site internet ! Introduction !En Bref : CDI - DATA Engineer (H/F) - Nantes - 50K-55K - Télétravail partiel - Editeur de logicielSolenn dAdsearch, Consultante spécialisée IT (Infrastructure, Data, Sécurité), recrute pour lun de ses partenaires, Editeur de logiciel nantais, un DATA ENGINEER H/F.Vos missions à réaliser !Dans un contexte de remplacement, vous devenez le nouveau DATA Engineer de lentreprise et endossez les responsabilités suivantes : Construire des modèles et schémas pour répondre aux besoins Procéder à de lanalyse DATA pour les clients Intégrer un nouvel outil BI Création de rapports personnalisés et rédaction de documentation Cibler des opportunités de communication DATA Contribuer à lamélioration continue et les projets stratégiques à venirVotre process de recrutement (peut-être réalisé en 2 semaines!)! Entretien n1 en visio avec votre Consultante Adsearch Entretien n2 par téléphone avec le Service RH Entretien n3 en présentiel avec le Responsable Technique Entretien n4 en présentiel avec la Direction GénéraleVotre profil attendu ! Vos connaissances techniques : Outil BI, ETL, outils modèles et statistiques.SQL, SGBD, Looker, Vues et NoSQL. Vos compétences acquises : Au minimum 2 ans d'expérience sur l'ingénierie DATA. Aisance de compréhension et d'expression en Anglais. Votre posture professionnelle : Curieux, force de proposition, esprit d'analyse et d'équipe, guidé par l'amélioration continue !Vos leviers de motivations !Poste en autonomie & responsabilité complèteCadre de travail convivialEntreprise à taille humaine, dynamique et réputéeTélétravail partielDe nombreux avantagesCe poste est peut-être LE VOTRE alors candidatez sans tarder pour vous positionner et échanger avec Solenn d'ADSEARCH !
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst,eXalt,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-at-exalt-3791770040?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=tipuW0PnYs3bHZ3COBC5fw%3D%3D&position=19&pageNum=10&trk=public_jobs_jserp-result_search-card,"Qui sont-ils ?Cabinet de conseil en Transformation Digitale, eXalt est avant tout une formidable aventure humaine, et une communauté de plus de 700 collaborateurs, basés à Paris (siège social), mais également à Lyon, Lille, Nantes, Bordeaux, Aix-en-Provence, Bogota et bientôt New-YorkFondée en juillet 2018 autour des valeurs d’intrapreneuriat, de co-apprentissage et de co-construction, eXalt inscrit son développement dans un engagement fort auprès de ses clients et de ses équipes. Multi-spécialiste, le groupe décline son modèle dans différents domaines à travers ses filiales dédiées :Le Product Management & la Gestion de Projet au sein d’eXalt P&PLa Finance de Marché au sein d’eXalt Fi,La Tech au sein d’eXalt IT,La Cybersécurité au sein d’eXalt ShieldLa Data au sein d’eXalt ValueDescriptif du posteeXalt Value, filiale du groupe spécialisée sur les métiers de la Data, et recherche son/ sa nouveau/elle Data Analyst pour aller à la conquête de nouveaux projets ! Vous évoluerez dans un contexte multi sociétés et challengeant.Vous serez rattaché(e) à notre bureau parisien.Vos principales missions seront de :Comprendre les problématiques métiers et les traduire de manières analytiquesExtraire les données nécessaires à l’analyse.Définir et réaliser le nettoyage de la base de données.S’assurer la qualité des données tout au long de leur traitementAnalyser et exploiter les donnéesCréer des dashboards via des outils de visualisationsEffectuer une veille sur les nouvelles technologies et solutions logicielles d’analyse des données.Profil recherchéNous recherchons avant tout une personne animée par l’esprit et l’ADN d’eXalt ☀️ ayant l’envie de prendre part à un superbe challenge et à notre aventure !Vous êtes diplômé(e) d’un Bac+5Vous bénéficiez d’une expérience d’au moins 4 ans en tant que Data AnalystVous avez une expertise en base de données et gestion de base de données (SQL/ NoSQL)Vous maitrisez des outils de data visualisation (Tableau, Qlikview, PowerBI) et/ou des outils de fouille et analyse de données (Dataiku)Vous avez une aisance rédactionnelle & relationnelleVous avez une passion pour les chiffres et le goût pour l’innovationVous êtes reconnu(e) pour votre rigueur, votre organisation et votre adaptabilité.L’anglais professionnel est requis


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer en alternance F/H,Treez Data Management 📊📈🖥️,"Villeneuve-d’Ascq, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-en-alternance-f-h-at-treez-data-management-%F0%9F%93%8A%F0%9F%93%88%F0%9F%96%A5%EF%B8%8F-3807132988?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=gznNvg%2B4XiqwluReNJ05Hw%3D%3D&position=20&pageNum=10&trk=public_jobs_jserp-result_search-card,"Ta mission ?Sous la responsabilité de l’un de nos consultants séniors et après une période de formation, tu interviendras dans des missions techniques notamment autour de l’outil POWER BI et concernant toute la chaîne décisionnelle depuis la collecte des données jusqu’à leur restitution :Alimentation d’entrepôts de données (datawarehouse)Développement de bases de données multidimensionnelles (Cubes)Développement de rapportsDéveloppement d’algorithmesModélisation prédictive.Au-delà de ces missions techniques, tu acquerras avec l’expérience des compétences de conseil et d’accompagnement du client pour atteindre un profil de consultant junior.En fonction de tes appétences, tu pourras également intégrer des équipes aux compétences spécifiques :Power Platform/Power Apps.Data Performance/XLCUBED.Qui es-tu ?Tu es en cours de cursus de formation ou de spécialisation en informatique décisionnelle / Data Sciences et recherches une mission pas planquée, dans laquelle tu continueras d'apprendre et seras rapidement impliqué.e dans des missions de production.Tu maîtrises le langage SQL pour des requêtes simples à complexes, voire pour la conception et la modélisation de bases de données. Idéalement, tu maîtrises également SQL Server.Si en plus, tu as déjà approché la BI Microsoft (Power BI) en cours ou lors d’une première expérience, c’est le top !Nous cherchons aussi (surtout !) une personnalité qui a envie de rejoindre une petite et conviviale équipe de passionné.e.s doté.e.s d'une volonté de toujours avancer.L’alternant que nous recrutons aujourd'hui pourra être le/la Consultant/e Treez de demain, donc tu recherches un stage puis Alternance ou Alternance directement pour ton master.Et nous ? Qui sommes-nous ?TREEZ a été créée en 2015 par 3 associés (Olivier, Arnaud & Rémi), passionnés de longue date par la BI. Aujourd’hui composée de 45 consultant.e.s spécialisé.es en Data Microsoft (BI, Data Sciences, Self-services BI, Machine Learning), l’équipe TREEZ conseille ses clients et met en pratique les nouveaux usages de la donnée, en aidant ses clients à exploiter leur potentiel insoupçonné. Intéressant, n’est-ce pas ?!Dans le cadre de notre croissance et de notre envie de transmettre, nous proposons chaque année un contrat d’alternance au sein de notre agence de Villeneuve d'Ascq.Aurais-tu envie de rejoindre la grande famille Treez ? L’aventure te tente ?Transmets-nous vite ta candidature ! :)


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer (H/F),Devoteam G Cloud,"Levallois-Perret, Île-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-h-f-at-devoteam-g-cloud-3163051864?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=YFSMAN%2FOZZgwhLCfzcsC%2FA%3D%3D&position=21&pageNum=10&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseDevoteam G Cloud a pour mission de conseiller et d'accompagner les sociétés dans leur transformation digitale avec les solutions Google Cloud.Avec plus de 1.300 clients et 1 000 000 d'utilisateurs déployés, Devoteam G Cloud s'impose depuis 10 ans comme 1er partenaire EMEA de Google Cloud sur l'intégration des nouvelles plateformes SaaS.En savoir plus : http://devoteamgcloud.com.Basée à Paris et Lyon, Devoteam G Cloud est le leader européen de la distribution de produits Google Cloud toute solution confondue.  Description du posteTu auras pour mission d’accompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l’écosystème solutions open source associé.Intégré(e) à une équipe d’experts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d’étudier et cadrer les besoins clientsPréconiser les solutions et architectures ciblesDéfinir les méthodologies de déploiement et plans de migrationRédiger les dossiers d’architecture et spécifications techniquesConstruire les architectures de donnéesConcevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels)Construire et déployer les pipelines de données (ETL)Assurer la migration des données vers les nouveaux environnementsAnalyser les donnéesAnalyser les données sources afin d’identifier et évaluer des cas d’usage métierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio…)Sélectionner, entraîner, évaluer et déployer des modèles prédictifs en s’appuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les équipes clients aux méthodes et concepts du cloudTu seras accompagné(e) en interne pour monter rapidement en compétences sur GCP dans l’objectif de devenir certifié Google sur ta practice.  Qualifications Diplômé(e) d'une école d'ingénieurs ou d'un Master 2 en Informatique, tu disposes d'une expérience significative au sein de projets Data : architecture, traitement ou analyse de données.Tu maîtrises au minimum un langage de programmation appliqué à l’analyse de données (Scala, R, Python, Java).Tu as de bonnes compétences dans de l’architecture des systèmes, bases de données, méthodologies d’analyseTu es passionné(e) par la Business Intelligence, le Big Data, l’Internet des objets (IoT) et le Machine LearningUne connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, …) est un plus.Tu as une solide compréhension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et à l’écoute, tu possèdes un réel esprit d’analyseTa maîtrise de l'anglais te permettra de gérer des projets en contexte international  Informations supplémentairesLe Groupe Devoteam oeuvre pour l'égalité des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au mérite et lutte activement contre toute forme de discrimination. Nous sommes persuadés que la diversité contribue à la créativité, au dynamisme et à l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,LesJeudis,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3788257066?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=m6ADYxk5L33oOS0dYtPhqQ%3D%3D&position=22&pageNum=10&trk=public_jobs_jserp-result_search-card,"MissionDans le cadre de son développement, Inetum recrute un Data Engineer (H/F) pour sa branche Applications Services.Le Data Engineer interviendra chez l'un de nos clients sur des projets BI et/ou Big Data avec une approche Data Driven et ce, en méthode agile.Le Data Engineer Sera En Charge De Apporter une expertise en Big Data permettant la manipulation de données Accompagner nos clients dans la réalisation de projets dans un contexte Big Data et Cloud Participer à des POCs (Proof Of Concept) permettant de valider les principes techniques et algorithmiques pour des projets Concevoir des plateformes permettant de traiter des volumes importants de données Développer des pipelines de données pour assembler les données en provenance de multiples systèmes Développer des applications d'injection et de traitements massifs sur des volumétries importantes Participer à l'industrialisation d'applications partiellement réalisées (optimisation du code, optimisation des performances, utilisation maximisée des possibilités des outils et du cluster disponible) Mettre en place des bases de données (SQL, NoSQL...)ProfilDe formation ingénieure en informatique (Bac+5), vous avez évolué dans le monde du développement (langages Java, Scala, python, R, Spark, Tensorflow) avec une culture Devops, une maîtrise des BDD, du Shell/Unix...Vous disposez d'une expérience significative dans le développement (2/3ans) et une expérience également sur une distribution Hadoop (Cloudera, Horthonworks ou MAP-R).Vous êtes à l'aise avec les principes du cloud, une première expérience avec l'un des cloud provider suivant : AWS, Azure, GCP serait un plus...Vous avez un esprit d'analyse, orienté sur la mise en place d'algorithmes de manipulation de données volumineuses, sur la manière de les rendre plus performantes (parallélisation, distribution de charge) et dans des conditions de hautes disponibilités.Vous appréciez le travail en équipe et les challenges.Vous possédez des qualités de communication qui vous amène naturellement à partager vos connaissances avec vos clients et vos collaborateurs.Si vous vous reconnaissez, n'hésitez pas à postuler !OrganisationNous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst H/F,IDKIDS.COMMUNITY,"Roubaix, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-idkids-3806035968?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=ft%2FO4u5aAeMBHc9%2FD%2FqdvQ%3D%3D&position=23&pageNum=10&trk=public_jobs_jserp-result_search-card,"Chez OKAIDI, nous sommes bien plus qu’un réseau de magasins. Nous sommes des acteurs au service du bien-être des enfants. Envie de prendre part à cette aventure ?En tant que Data Analyst, tu contribues par tes actions à la satisfaction de nos clients et à la performance de l'entreprise. Tu garantis la connaissance client omnicanal et multimarque, indispensable au pilotage de l'activité et à l'élaboration de nos stratégies de prospection et de fidélisation.Le programme de ton futur job !☑️ Comprendre précisément les problématiques marketing, e-commerce et retail et les traduire de manière analytique.☑️ Accompagner les marques dans l'analyse des performances, l'optimisation de leur action et l’alimentation de leur réflexion stratégique.☑️ Piloter et analyser les opérations marketing tel que l'A/B testing, la publicité en ligne, l'e-mailing.☑️ Explorer, qualifier et valoriser les données de navigations, de transactions et de produits, dans une dimension client.☑️ Développer et automatiser des dashboards en fonction des demandes internes.☑️ Utiliser des méthodes statistiques basiques et avancées pour améliorer la connaissance client.Le poste de Data Analyst H/F est à pourvoir en CDI, il est basé à Roubaix.Alors, cap ou pas cap ? Ce poste est fait pour toi si ✔️Tu as une expérience de minimum 3 ans en tant que Data Analyst / Business Analyst.✔️Tu as une capacité à aller facilement vers l’autre et à créer du lien avec les équipes.✔️Tu es reconnu pour tes capacités d’analyse et ton esprit de synthèse✔️Tu es câblé business afin de bien comprendre les problématiques digitales, marketing et commerciales.✔️Tu sais faire rimer curiosité, autonomie et rigueur dans l'accompagnement des sujets confiés.✔️Tu es au top 🤩 si tu maîtrises les outils d'analyse de données (SAS, RStudio, GCP) et le langage SQL.Ce que l’on peut t’offrir ?Les afterworks les plus convoités du groupe #BestTeamLa possibilité d’évoluer en interne au sein des nombreuses marques du groupeUn équilibre vie pro / vie perso respecté ⚖️Un management bienveillant et de proximitéLa possibilité de réaliser une journée solidaire chaque année avec ton équipeEt bien-sûr : le remboursement des frais de transport à 50%, carte tickets resto Swile, mutuelle, avantages du CSE, remise au personnel, et primes.Tu veux en savoir plus sur nous ? Intégrer IDKIDS, c’est prendre part à une formidable aventure humaine au sein d’une entreprise engagée !Chez nous, l’engagement c’est du solide 💪Acteur du développement émotionnel, moteur et intellectuel de l’enfant #WECARE+ de 52 000 enfants aidés dans le monde grâce à notre fonds de dotation.Le coton bio déjà utilisé depuis + de 15 ans dans nos collections OKAIDI / OBAIBI ! La mise au point d’un coton recyclé fabriqué à partir de vêtements usagés 1 tonne de plastique et 5 tonnes de carton économisés grâce à 98% de packagings OXYBUL éco-conçus 📦Précurseur de la seconde vie du produit avec nos ÏDTROC depuis + de 7 ans ♻️50 crèches animées par des projets de sens favorisant la mixité sociale, les liens intergénérationnels, l’inclusion d’enfants en situation de handicap 👶Et petit bonus, producteur de miel made in Roubaix #biodiversité 🐝 En bref, IDKIDS c’est bon pour les Enfants, essentiel pour les Parents et engagé pour la Planète !Cerise sur le gâteau, en rejoignant OXYBUL, vous intégrerez l’écosystème IDKIDS composé :Des marques produits : Okaïdi, Obaïbi, Jacadi, Oxybul Eveil et Jeux, Catimini et Absorba Des marques de services : Rigolo Comme La Vie, N’Joy, ConsoBabyDes marques médias : JoyVox, BubblemagUne fondation d’entreprise : We Act For Kids Fond’actions#63pays #1300magasins #6000collaborateurs #3millionsdeclients #WEACTFORKIDSEt si tu faisais sourire ton avenir chez ÏDKIDS ? :-)Dans le respect de ses engagements RSE et de sa charte diversité, IDKIDS étudie toutes les candidatures dont celles des personnes en situation de handicap.#RejoignezOKAIDI
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Thales,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3804599575?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=QRbum27rcAL60NQY7hl2HQ%3D%3D&position=24&pageNum=10&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces.QUI ETES-VOUS ?Intégré(e) au centre de compétences « Augmented Data » de Brest, vous interviendrez sur des projets de développement de systèmes d’information « Data oriented ».Au sein de ce centre, vous rejoindrez nos Data Engineers, Data Architects et Data Scientists.De formation Ingénieur ou Bac +5, Ecole d’ingénieur ou Université vous justifiez d'une expérience professionnelle en mise en place de solutions Big Data d’au moins 2 ans et idéalement d’une première expérience réussie en animation d’équipe et/ou pilotage de lots techniques.COMPÉTENCES :Plusieurs des affirmations suivantes vous caractérisent : Vous êtes passionné(e) par le Digital, les données, les enjeux qu’elles représentent et les technologies Big Data avec lesquelles les manipuler (Hadoop, Nifi, Kafka, ElasticSearch, Spark, Storm, HBase, Cassandra, etc.). Vous êtes familiarisé(e) avec les différentes plateformes et outils qui y sont reliés. Vous savez et aimez coder avec des langages de programmation communément utilisés pour la manipulation de données (Python, Java, SQL) sur des architectures distribuées en production. Vous savez implémenter des chaînes de traitement optimisées. Vous êtes familiarisé(e) avec les concepts et technologies d’intégration continue (Git) et les outils de déploiement (Docker). Vous êtes familiarisé(e) avec les frameworks Agile tels que Scrum ou Kanban. Vous êtes motivé(e), appliqué(e), organisé(e) et curieux(se) dans votre travail au quotidien. Vous êtes titulaire d’un diplôme d’ingénieur ou Master, idéalement avec une spécialisation sur les métiers de la donnée et du Big Data. Vous parlez français et, idéalement, anglais (écrit et oral)CE QUE NOUS POUVONS FAIRE ENSEMBLE:En tant que Data Engineer, vos missions seront les suivantes : Comprendre les besoins et les enjeux du client autour de ses données. Concevoir des solutions innovantes de traitement de données répondant aux besoins, implémenter des chaînes de traitements Big Data et les déployer à l’échelle dans des environnements de production. Contribuer à la définition d’architecture de données et à l’opérationnalisation de plateformes de données. Présenter vos propositions de conception et résultats auprès du client et de votre équipe. Partager et échanger vos connaissances et expériences dans le Data Engineering avec votre équipe. Contribuer à la préparation et à l’animation d’ateliers avec les interlocuteurs requis. Effectuer un reporting régulier à votre manager sur l’avancement de vos activités ainsi que sur les risques potentiels identifiés.Nous vous offrons : Une diversité de projets vous permettant de découvrir plusieurs environnements techniques et fonctionnels ainsi que l’ensemble de nos métiers au sein du groupe Thales, Des conditions de travail motivantes et un plan de carrière personnalisé offrant de réelles perspectives d’évolution, La possibilité de vous investir dans une entreprise dont la réputation est mondiale avec des ambitions constantes d’innovations techniques, Un cadre de travail privilégié dans des bureaux situés à un endroit dynamique du port de commerce de Brest, La possibilité de télé-travailler jusqu’à 10 jours par mois.Alors n'attendez plus, rejoignez-nous !Thales reconnaît tous les talents : la diversité est notre meilleur atout.Le poste pouvant nécessiter d'accéder à des informations relevant du secret de la défense nationale, la personne retenue fera l'objet d'une procédure d’habilitation, conformément aux dispositions des articles R.2311-1 et suivants du Code de la défense et de l’IGI 1300 SGDSN/PSE du 09 août 2021.Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd’hui.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Software Engineer,Lever Middleware Test Company 2,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-at-lever-middleware-test-company-2-3787335392?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=i3SA50Xm3er5oFgFfthD6Q%3D%3D&position=25&pageNum=10&trk=public_jobs_jserp-result_search-card,"This is a software engineer role.This is paragraph format.Responsibilities123Requirements123Please join us!Lever builds modern recruiting software for teams to source, interview, and hire top talent. Our team strives to set a new bar for enterprise software with modern, well-designed, real-time apps. We participated in Y Combinator in summer 2012, and since then have raised $73 million. As the applicant tracking system of choice for Netflix, Eventbrite, ClearSlide, change.org, and thousands more leading companies, Lever means you hire the best by hiring together.Lever is an equal opportunity employer. We are committed to providing reasonable accommodations and will work with you to meet your needs. If you are a person with a disability and require assistance during the application process, please don’t hesitate to reach out! We celebrate our inclusive work environment and welcome members of all backgrounds and perspectives. Learn more about our team culture and commitment to diversity and inclusion.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - MOE BI H/F,GRDF,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-moe-bi-h-f-at-grdf-3806857264?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=QVLkbE19RwhPhN%2F8OnTF0g%3D%3D&position=1&pageNum=11&trk=public_jobs_jserp-result_search-card,"Vous êtes motivé(e) :  pour mettre vos compétences au service d’un acteur majeur de la transition énergétique, expert et distributeur du gaz naturel ?  pour participer à l’avenir de la distribution du gaz naturel (compteur communicant, technologies du réseau intelligent, développement du biogaz et du GNV, …) ?  Vous souhaitez acquérir un véritable savoir-faire technique gazier dans une entreprise qui investit dans les innovations digitales ?  Rejoignez-nous à GRDF ! GRDF, filiale indépendante d’ENGIE, est le principal gestionnaire de réseau de distribution de gaz naturel en France.GRDF distribue le gaz naturel à plus de 11 millions de clients, pour qu’ils disposent du gaz quand ils en ont besoin, quel que soit leur fournisseur.Pour cela, et conformément à ses missions de service public, GRDF conçoit, construit, exploite, entretient le plus grand réseau de distribution d’Europe (198 886 km) et le développe dans plus de 9 500 communes, en garantissant la sécurité des personnes et des biens et la qualité de la distribution.Chaque jour, ce sont 11 431 femmes et hommes qui s'investissent dans leur mission. Partout en France, des équipes sont prêtes à intervenir 24h/24 et 7j/7 pour fournir le meilleur service possible.Au sein de la Région Ile de France, GRDF recrute : Un(e) Data Engineer – MOE BI H/F La Direction Système d'Information de GRDF, créatrice de valeur et partenaire des métiers, a pour mission d’assurer le fonctionnement, la création et l'adaptation du SI conformément aux besoins des utilisateurs tout en veillant à la maîtrise des coûts projet, ainsi qu’en MCO.Vous serez Data Engineer/MOE BI dans le pôle BI Management à la DSI et rejoindrez une stream métier, pour laquelle vous devrez assurer le MCO des applicatifs BI existant et conduire le(s) projet(s) BI dans un contexte de refonte de l’écosystème sur une nouvelle plateforme data analytics.Accompagné par le responsable MOA, vous serez en lien direct avec les équipes de développement et devez assurer le delivery des projets de votre stream. Vous assurez également le maintien en condition opérationnel des applicatifs de votre stream et êtes le garant technique de ces dernières. Dans ce contexte vous validez les conceptions techniques dans les normes et bonnes pratiques, vous assurez la recette technique et assistez la MOA SI et le métier dans leur recette, vous garantissez les mises en production et mises en service. Missions : Vous aurez en charge les missions suivantes : Piloter les projets Data, avec l'ensemble des parties prenantes, Métiers, MOA, AMOA, MOE, Administrateur technique, etc.  Garantir des solutions SI optimales et conformes à la stratégie de GRDF ainsi qu'aux besoins exprimés du métier, en termes de qualité, performances, coût et délai dans le respect des processus de gestion en vigueur à la DSI,  Valider la modélisation et la conception de la solution fonctionnelle et technique,  Planifier et suivre les développements,  Coordonner les recettes techniques et fonctionnelles et contrôler la conformité avec les engagements du projet,  Organiser et suivre la comitologie projet et MCO,  Conduire le changement,  Proposer les améliorations de process, ainsi qu'assurer une veille technologique.  Profil recherché : Vous êtes titulaire d’un diplôme Bac +5 en IT, avec une spécialité en système d’information et data.Vous connaissez la méthodologie de gestion de projets, disposez d’un solide bagage technique autour des technologies BI et de leur implémentation. Vous maitrisez les principes de modélisation des Datawares et Datamarts, et les bonnes pratiques autour de la conception des systèmes BI sur toute leur composante. Vous avez également des qualités requises : organisation,  rigueur,  esprit d’équipe,  pro-activité,  esprit de synthèse,  capacités d’écoute et de communication,  bonne expression écrite et orale,  très bonnes capacités relationnelles. Vous savez analyser les besoins exprimés par les métiers et définir la faisabilité technique (une bonne connaissance du SQL est requise) et en définissant les échanges et la modélisation BI.Vous travaillerez en étroite collaboration avec les développeurs et équipes de conduite technique ainsi que les MOA SI.Vous possédez une aptitude à comprendre et intégrer les problématiques métier et les contraintes d'urbanisme et d'architecture, pour une bonne insertion du projet dans les patterns Data Analytics définis.Une expérience significative en gestion de projets informatiques, dans le domaine Data Analytics/Décisionnel. Informations complémentaires L’emploi est régi par l’obligation de respect des engagements du code de bonne conduite de GRDF, lequel est constitué des principes d’indépendance, de non-discrimination, de protection des informations commercialement sensibles, d’objectivité et de transparence. En tant qu’Employeur responsable, GRDF valorise la diversité des profils de ses collaborateurs. Son engagement est reconnu par les Labels Diversité et Egalité professionnelle. Lieu de travail : 6 rue de Condorcet , 75009 PARIS (Déménagement prévu à Saint Denis en 2025)


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,LesJeudis,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3804516142?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=WpM7FAerVc9TLhHULXxtdA%3D%3D&position=2&pageNum=11&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…).Nous sommes experts du digital aussi bien sur de l'accompagnement stratégique qu'opérationnel.Fort du succès, NEXTON connaît aujourd'hui un développement significatif, autour de ses valeurs piliers : cohésion, confiance et performance.Et pour toi ? Notre politique de développement des compétences dynamique saura te séduire avec un programme de suivi de carrière sur-mesure.NEXTON recrute unDATA ENGINEER H/F, enCDI, àBordeaux !Qui sommes-nous ?NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS…).Nous sommes experts du digital aussi bien sur de l'accompagnement stratégique qu'opérationnel.Fort du succès, NEXTON connaît aujourd'hui un développement significatif, autour de ses valeurs piliers : cohésion, confiance et performance.Et pour toi ? Notre politique de développement des compétences dynamique saura te séduire avec un programme de suivi de carrière sur-mesure.Le ContexteTu es rattaché à l'équipe innovative Data& IT en qualité de data engineer de notre client. Son équipe conçoit, développe et exploite une grande partie des données et solutions Data à destination des utilisateurs internes pour la France et l'international.Les MissionsConcevoir et développer des solutions Data/IA à des fins analytics& dashboardingAccompagner les métiers dans la compréhension des Analytics et mise en oeuvre de solution""data driven""Mettre en oeuvre des solutions industrielles exploitables, mesurables et opérablesCommuniquer et traduire les résultats complexes et leur implications aux parties prenantes de l'entrepriseCapitaliser sur les solutions pour créer de nouveaux produits, de nouveaux services et de nouvelles opportunités de digitalisation, de valorisation de la donnéeCollaborer avec les data scientist et data ops dans la construction d'une culture axée sur les donnéesParticiper activement à la communauté de data scientists et de data ingénieursGérer un écosystème de partenaires data science et assurer un haut niveau d'expertiseAssurer un rôle de veille technologique sur tous les outils autours de la data, IA et BIContribuer au développement des membres de l'équipe BI et Big DataTu as étudié les systèmes d'informations, la Big Data ou le traitement de données lors d'un parcours supérieur de type école d'ingénieurs (BAC+5).Ta capacité à régler des problèmes techniques complexes et ton autonomie dans la recherche de solutions liées à la Big Data font partie de tes qualités professionnelles.Tu travailles de manière autonome dans un contexte agile, un minimum de quatre années d'expériences sur un poste de data engineer est attendu pour être opérationnel sur ce poste.NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'année : Des communautés : 2 Meet Up par mois pour partager et échanger avec des experts De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'année Des moments privilégiés avec ton managerPrêt à nous rejoindre ?Rencontrons-nous !


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Full-stack Software Engineer,Skeepers,"Marseille, Provence-Alpes-Côte d'Azur, France",https://fr.linkedin.com/jobs/view/full-stack-software-engineer-at-skeepers-3780879052?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=%2FdZvmfMGZeoc9gGNzrcLyg%3D%3D&position=3&pageNum=11&trk=public_jobs_jserp-result_search-card,"SKEEPERS is a group that is changing the world of customer experience. With a strong international ambition, SKEEPERS helps brands generate value by and for their customers.With its' one for all platform, SKEEPERS provides brands with a complete solution that allows them to prescriptively activate data collected from customer feedback for marketing purposes.Recognised as a high-growth group, SKEEPERS has already made it into the Next40 ranking of the forty most innovative French start-ups!To accompany our development, we are constantly looking for new talents who are ready to make a difference on an international scale!Created in 2019, SKEEPERS reached 450 employees internationally across 6 countries: France, Spain, Italy, Brazil, Canada, and also USA.SKEEPERS is the right place for you if you are a Go-Getter; someone who likes to deliver results, ready to roll up their sleeves to make things happen, and a positive challenger.About the role:You will join the R&D team of Skeepers (100 staff), a talented team working on the development of all Skeepers Solutions. In a SaaS company like SKEEPERS, the Engineering team is the main engine of our growth. Your work will have a direct impact on our end customers and your taste for challenge will allow the whole group to grow.Within the R&D department, you will join a squad to work on our solutions.Responsibilities:Reporting directly to the Director of Engineering and supported by the Team Lead, you will take part in the development of the platform. Your main missions will be the following:Collaborate with team members to develop high-traffic low-latency applications while delivering high-availability and performance Build, optimize, and scale the platform and infrastructure Evangelize best software development practices (DDD, TDD, CICD) Perform code reviews and design reviews to ensure compliance with development standards Maintain high standards of software quality within the team by establishing best practices and habits Technical stack:Backend: PHP SymfonyFrontend: AngularDatabase: MySQL, PostgreSQL, MongoDB, NoSQLContainer: Kubernetes / Docker CI/CD: Gitlab Cloud provider: AWS & GCPOther: Redis, Talend, Kafka, ELK, Jira, ... Requirements+5 years of experience in software and web development At least 4 years as a developer working with Agile Method Demonstrated project management and delivery experience You can communicate effectively with other team members to explain and advocate your choicesGood organization and problem-solving skillsAnalytical mindset and good executive reporting skillsFluent in English BenefitsA division at the forefront of innovation in terms of marketing technology.  A team that is passionate about their work and highly effective in the areas of expertise, enabling you to quickly develop your skills.   The opportunity to play a strategic role within a dynamic structure in an innovative and competitive market. The opportunity to participate in seminars and other events organised by the group in France or abroad.  A possibility to work in a hybrid way from home or from the office depending on your work/life balance.  Restaurant tickets with the Swile Card Health insurance company, ... A prospect of internal development thanks to the structuring of the group on a national and international scale.   The opportunity to be part of a group that develops an entrepreneurial and intrapreneurial spirit: let your creativity and your desires speak for themselves!


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['MySQL', 'PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['JIRA']}"
Data analyst H/F,Inetum,"St.-Ouen, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-inetum-3782168962?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=M0ahXxZqb04iinrEzXxcEg%3D%3D&position=4&pageNum=11&trk=public_jobs_jserp-result_search-card,"Détail de l'offre  Informations générales  Entité de rattachement  Nous sommes une ESN agile, un groupe international certifié Top Employer Europe 2023.A l'ère de la post-transformation digitale, nous mettons tout en œuvre pour que chacun de nos 28 000 athlètes du digital puisse se renouveler perpétuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi façonner son parcours de carrière selon ses appétences, entreprendre de manière pragmatique avec ses clients pour un monde à impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-être personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste Métier Métier AS (Application Services) - Technique AS Intitulé du poste Data analyst H/FDescription De La MissionLes missions du Data Analyst sont variéesRecueil et extraction des sources de données pertinentes et de qualité qu’il traduit ensuite en données statistiques ;Traitement, exploitation et intégration des données dans un data warehouse (entrepôt de données) ;Création de dashboards, mise en place de KPIs et reporting des performances pour donner une vision cohérente des résultats aux différentes équipes ;Mise en place de process/requêtes et automatisation ; Production d’analyses métiers et de recommandations aux managers ;Gestion des outils d’analyses pour que les décideurs internes et les clients puissent suivre l’évolution de leurs produits ; Veille technologique des nouveaux outils visant à l’améliorer l’analyse des données. Profil Le Data Analyst possède des compétences techniques avec la maitrise de divers outils et logiciels (Excel, Web Analytics, BI, SAS, VBA, Python etc.), ainsi que des langages de programmation tel que R. Il doit à la fois faire preuve d’une grande aisance rédactionnelle et avoir une passion pour les chiffres et les statistiques. Son orientation business et son aisance relationnelle avec les métiers lui permettent de réaliser des recommandations pertinentes et de simplifier les problématiques techniques. Rigoureux, organisé, réactif et d'esprit analytique, le Data Analyst pourra ainsi être capable d’apporter une vision cohérente des tendances d’activité de l'entreprisLocalisation du poste Localisation du poste France Ville Saint OuenCritères candidat Niveau d'études min. requis Bac+5 Niveau d'expérience min. requis Plus de 2 ans Compétences ExcelPythonVBA Langues Anglais (Courant)Français (Bilingue)


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirmé (F/H),Micropole,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-f-h-at-micropole-3742749162?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=1Sh7V99xYvatFPtXhOVmRw%3D%3D&position=5&pageNum=11&trk=public_jobs_jserp-result_search-card,"Rejoignez le Groupe Micropole. Devenez un(e) #InnovativePeople ! Mission Comme nous, vous êtes passionné(e) par la donnée et convaincu(e) que la validation du  patrimoine data des entreprises  est la clé de leur performance ? Vous voulez accompagner les entreprises dans leur stratégie data driver et les aider à se transformer grâce aux nouvelles technologies qu'amène le Cloud, pour préparer dès à présent leur futur ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitales, au sein d’une agence à taille humaine où règnent entraide et convivialité et engagée en faveur d’un numérique plus responsable au service de clients principalement implantés régionalement ?Rejoignez l'aventure Micropole à Niort !Vous viendrez renforcer une équipe niortaise soudée qui porte l’esprit d’équipe, ayant à cœur de faire de votre intégration un succès et de vous accompagner dans votre montée en compétences.En intégrant Micropole vous aurez l'opportunité d'intervenir sur des projets data innovants, riches et variés et participerez activement au rayonnement de l'agence sur le bassin niortais.Dans vos missions quotidiennes , vous serez amené(e) à:Participer au recueil des besoins des métiers ;Rédiger les dossiers de conception technique ;Modéliser les entrepôts de données ;Développer des flux de données via des ETL,Concevoir des tableaux de bord via des outils de reporting et datavisualisation ;Accompagner la maîtrise d’ouvrage dans la validation de livrables, les tests, l’assistance à la recette et la conduite du changement sur le projet. Profil Vos Compétences TechniquesVous maîtrisez la manipulation des données (préparation, modélisation, restitution),Vous maîtrisez parfaitement au moins un ETL du marché (Informatica, Talend, BigQuery, Datafactory,...) et la création de tableaux de bord (Power BI, Tableau, QlikSense, SAP BO, ...),Python ou SQL n’ont plus de secrets pour vous,Vos atouts :Diplômé(e) d’une formation supérieure en Informatique parcours BI, Data, Aide à la Décision,Vous possédez une expérience d'au moins 3 ans dans la fonction,Votre esprit d’analyse, de synthèse, votre organisation et vos capacités rédactionnelles sont souvent reconnus,Vous appréciez travailler en équipe, dans un contexte multi-projets.DEVENIR #INNOVATIVE PEOPLE C’EST : Intégrer une communauté de 1200 experts passionnés répartis entre la France, la Belgique, le Luxembourg, la Suisse, l’Espagne et la Chine.Construire ensemble les solutions stratégiques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale.Participer au développement de nos 4 centres d’excellences cloud : AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies grâce à Micropole Campus.S’assurer d’une innovation continue grâce à : Notre écosystème de partenaires technologiques Notre accélérateur de start’up databoost’R Nos lieux d’innovations « innovativeSpaces » et de co-construction avec les clients Notre management par les talents naturels La Vie Chez Micropole, C’est Une vie interne rythmée pour se familiariser à la culture d’entreprise et aux valeurs de Micropole ; Des évènements internes réguliers pour partager les connaissances aussi bien techniques que fonctionnelles ; Une politique de formation attractive et éclectique (certifications prises en charge) ; Un travail en équipe valorisé pour une meilleure cohésion ; La participation à des projets internes sur la base du volontariat. Processus De Recrutement Chez Micropole, le processus de recrutement est réactif et transparent.Si votre profil correspond à nos attentes, vous êtes recontacté(e)s dans les 72 heures qui suivent votre candidature par nos Talent Specialist en région pour un premier échange téléphonique puis un entretien est planifié avec l'un d'entre eux sur site à distance,  Vous rencontrez le Manager de l’équipe Data de Niort pour un second entretien. MICROPOLE GRAND-OUESTMicropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un développement rapide sur le Data, le Digital et Cloud, les équipes portent l’ensemble de la proposition de valeur du Groupe.Présent au plus près de l’écosystème de partenaires, de réseaux professionnels et d’acteurs du développement économique, nous accompagnons nos clients des secteurs de l’assurance-banque, du retail, de l’agro-alimentaire, de l’industrie et du public dans leur transformation data et digitale, notamment au travers de méthodologies innovantes comme le Datathinking® ou Lego Serious Play®.L’agence Grand Ouest, sous l’impulsion de sa Directrice d’Agence, Adeline Chaye, investit et met en place des méthodes, compétences et expertises pour le développement d’un numérique responsable au sein des organisations.À PROPOS DU GROUPE MICROPOLEGroupe international de conseil et technologies innovantes, MICROPOLE est spécialisé dans les domaines de la Data & Digital. Depuis ses 14 agences situées en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts métiers, ingénieurs, UX designers…) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil à leur réalisation, et sur la conduite du changement.MICROPOLE réalise 35% de son chiffre d’affaires à l’international et est coté sur le marché Eurolist compartiment C d’Euronext Paris, segment Next Economy.Pour en savoir plus : https://www.linkedin.com/company/micropole/mycompany/Mot du manager Dans une ambiance familiale, rejoignez notre agence d'experts et de consultants (Digital & Data) en plein centre de Niort et devenez à votre tour un acteur incontournable de la réussite des projets de nos clients !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Viz Engineer H/F,METEOJOB by CleverConnect,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-viz-engineer-h-f-at-meteojob-by-cleverconnect-3805814276?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=Sg3d0SEpl8Y5ejoqBCIcMQ%3D%3D&position=6&pageNum=11&trk=public_jobs_jserp-result_search-card,"EntrepriseChez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L'intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons plus d'une centaine de disciplines, de l'optique à la physique quantique, du traitement du signal à la connectivité et à l'intelligence artificielle. Rejoindre Thales, c'est repousser les limites de la technologie et la mettre au service du progrès et du développement durable de nos sociétés. C'est donc être au cœur d'une formidable aventure technique. Une attention portée à l'équilibre des collaborateurs au service de leur réussite. C'est pourquoi, notamment, nous nous efforçons de créer un environnement de travail accueillant et d'accorder la flexibilité nécessaire à l'équilibre entre vie professionnelle et vie personnelle. Nous savons que cet équilibre est essentiel à votre épanouissement et à la réussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en équipe, côtoyer des experts et donc apprendre et développer ses compétences en permanence tout en faisant bénéficier le Groupe de son savoir-faire. C'est aussi la possibilité d'évoluer, de changer de fonction ou d'activité, voire de pays.Description Du PosteQUI SOMMES-NOUS ?Thales propose des systèmes d'information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d'importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d'information critiques et cybersécurité, répondent aux besoins de marchés où l'utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l'activité Systèmes d'information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d'information afin de faire face aux ruptures technologiques et aux cybermenaces.L'équipe de la BI Factory recherche un(e) Data Viz Engineer (H/F)QUI ETES-VOUS ?De formation Ingénieur ou Bac +5 (école d'ingénieur ou Université), vous justifiez d'une expérience professionnelle dans le monde de la DataViz / BI d'au moins 3 ans autour des solutions Qlik ou Power BI.Vous souhaitez mettre à disposition votre expertise dans le monde de la Data et continuer à développer vos compétences dans les aspects : Big Data, Data valorisation, Data Vizualisation, Data engineering et/ou Data Science et êtes doté d'un bon relationnel.Vous êtes pragmatique, curieux et organisé et aimez le travail bien fait.Vous êtes autonome, capable de travailler dans un environnement en évolution permanente et avez le sens du service (engagement et livraison)Vous êtes familier avec les pratiques agiles.Votre niveau d'anglais vous permet de rédiger des documents ou d'animer des réunions en anglais par téléphone/visio dans un contexte international.Vous vous reconnaissez ?Ce Que Nous Pouvons Accomplir EnsembleLe domaine de la Data est devenu aujourd'hui un enjeu majeur dans la stratégie des entreprises et leur transformation digitale. C'est pourquoi nous répondons aux besoins de nos client en leur offrant des solutions high-tech reposant d'une part sur notre connaissance des métiers, et d'autre part sur notre capacité d'innovation et notre savoir-faire autour de la Data (collecte, traitement, analyse, valorisation).Vous serez intégré(e) dans le centre de compétences « Augmented Data » de Brest, au sein de l'équipe BI Factory.La BI Factory, c'est une équipe dédiée agile à taille humaine qui adresse les besoins Data Vizualisation & Business Intelligence au sein du Groupe Thales et également pour nos clients hors Groupe.Vous interviendrez sur une diversité de projets de développement de systèmes d'information de nos clients locaux, mais aussi nationaux (domaines Défense, Banque, Assurance, Energie).Au Sein De Ce Centre, Vous Rejoindrez Notre Équipe De Data Engineers, Data Architects Et Data Scientistes Installée à Brest. Data Viz Engineer, Vous Vous Verrez Confier Les Missions Principales Suivante Mener des ateliers de cadrage avec les utilisateurs finaux afin de recueillir tout d'abord leurs besoins puis ensuite leur présenter votre travail, Participer à la conception de l'architecture générale des systèmes décisionnels de nos clients, Être force de proposition et orienter les choix techniques en fonction de votre expérience et de la politique technique du groupe, Implémenter les solutions validées par nos clients, Etre le garant de la qualité technique des solutions produites et du respect de l'architecture initiale, Contribuer au sein du département à l'effort d'animation technique, de veille technologique et d'innovation au sein des groupes de travail mis en place, Partager vos connaissances au sein de la communauté BI Thales en présentant vos expériences sur vos travaux récents et approches innovantes.Nous Vous Offrons Une diversité de projets vous permettant de découvrir plusieurs environnements techniques et fonctionnels ainsi que l'ensemble de nos métiers au sein du groupe Thales, Des conditions de travail motivantes et un plan de carrière personnalisé offrant de réelles perspectives d'évolution, La possibilité de vous investir dans une entreprise dont la réputation est mondiale avec des ambitions constantes d'innovations techniques, Un cadre de travail privilégié dans des bureaux situés à un endroit dynamique du port de commerce de Brest, La possibilité de télé-travailler jusqu'à 10 jours par mois.Nous sommes toujours en phase ? Alors n'attendez plus, rejoignez-nous ! Thales reconnaît tous les talents : la diversité est notre meilleur atout. Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd'huiLe poste pouvant nécessiter d'accéder à des informations relevant du secret de la défense nationale, la personne retenue fera l'objet d'une procédure d'habilitation, conformément aux dispositions des articles R.2311-1 et suivants du Code de la défense et de l'IGI 1300 SGDSN/PSE du 09 août 2021.Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd'hui.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer GCP (F/H),Apside,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2902806697?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=wZ1Qg1H5dEplHh%2BPBVhM0A%3D%3D&position=7&pageNum=11&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une entreprise apprenante ? Engagée pour t’accompagner dans ton évolution professionnelle et dans tes projets personnels ?Rejoins Apside pour travailler sur les projets de demain !Le poste ?Pour le compte de notre client acteur mondial de la beauté et cosmétique, tu interviendras dans la transformation d’un projet worlwide, où tu devras développer la Data Platform et l'ensemble des services Data qui seront exposés aux différentes équipes du client. Aussi, tu seras amené à développer des use cases data. Dans ce sens, tes missions seront les suivantes : Designer l'architecture et développer la solutionDéfinir et développer les Data ModelÊtre garant de la qualité du codeÊtre DevOps (Utilisation/mise en place de chaine CI/CD et support niveau L3 des développements)Environnement technique :GCP (BigQuery, Cloud Run, Cloud Build)SQL PythonDevOps (Github)API DevelopmentTerraformMéthodologie AgileToi ? Tu as déjà travaillé sur Google Cloud Platform (GCP) ?Tu es autonome, rigoureux, et bon communiquant ? Tu souhaites participer à un projet d’envergure associant cloud et Big Data ? Et la suite ?Tu rencontres d’abord l’équipe RH pour parler de tes attentes, ton projet, ton futur ! Puis les managers pour parler concret : missions, projets, parcours de carrière, et bien sûr salaire et avantages J Et tu discutes avec un de nos Tech Leads, pour évaluer tes compétences/ te challenger.Les infos en plus !Télétravail ! 😊Un salaire attractif en fonction de ton expérience + différents avantagesUn groupe en pleine croissance avec un management bienveillantEt une évolution personnalisée avec la possibilité de se former via une plateforme interneTu souhaites donner un nouvel élan à ta carrière ? Rejoins la vie Apsidienne !Pour en savoir plus à www.apside.com


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Toulouse H/F,Expleo Group,"Haute-Garonne, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-toulouse-h-f-at-expleo-group-3803168961?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=f%2B5PD5xg2nvPqFHmfBYfzQ%3D%3D&position=9&pageNum=11&trk=public_jobs_jserp-result_search-card,"En savoir plus  Soyez vous-même.  Devenez qui vous voulez. Acteur mondial de l’ingénierie, de la technologie et du conseil, Expleo accompagne des entreprises reconnues dans leur innovation afin d’accélérer leur réussite.Nous nous appuyons sur plus de 40 ans d’expérience dans le développement de produits complexes, l’optimisation des processus de fabrication et la performance des systèmes d’information.Notre expérience sectorielle nous permet d’apporter à nos clients une expertise approfondie propre à stimuler l’innovation à chaque étape de la chaîne de valeur.Le groupe réalise un chiffre d’affaires annuel de plus d’un milliard d’euros. Expleo  est un groupe responsable qui s’engage à placer l’éthique et la diversité au centre de ses pratiques, ainsi qu’à œuvrer pour une société plus durable et plus sûre.Chez Expleo, épanouissez-vous au cœur d’une communauté de 19 000 collaborateurs hautement qualifiés qui fournissent des solutions à forte valeur ajoutée dans 30 pays.Nos postes sont accessibles aux personnes en situation de handicap.Pourquoi nous rejoindre ? Un accompagnement technique sur le terrain  Des formations continues via nos experts techniques  Des valeurs humaines entre nos collaborateurs  La diversité de nos équipes  Une montée en compétences tout au long de sa carrière  Travailler sur des projets de grandes ampleurs  Mission Notre offre ?Au sein du département Digital & Emerging Technologies, vous accompagnerez nos clients sur les enjeux liés à la Data et à la mise en production de solutions innovantes en travaillant en équipe selon la méthode Agile.Localisation ?L’opportunité se situe à Toulouse (31).Votre rôle ?  Concevoir et optimiser des solutions de pipelines de données (On-Premise, Hybrid, Cloud)  Réaliser des audits d’architecture data et des préconisations d’évolution  Participer aux développements techniques  Répondre aux enjeux variés autour de la donnée (création/migration de datalakes, Move-to-cloud, industrialisation de produits de data science...)  Assurer le reporting technique du projet au client  Réaliser une veille technologique afin de proposer des solutions innovantes  Accompagner des ingénieurs Data juniors dans leur montée en compétences  Profil Qui êtes-vous ?Diplômé(e) d’une formation supérieure (Bac +5), vous avez une première expérience significative (3 ans exp hors études).Vos compétences ?  Expert(e) d'un ou de plusieurs langages suivants : Python, SQL, Java, Scala  Connaissance d'au moins un Cloud Provider : GCP, AWS, Azure, Snowflake, etc  Connaissance du management de bases de données (SQL, NoSQL) et de l'écosystème BigData  Connaissance des principes et des éléments de Hadoop (HDFS, Hive, HBase), d'Apache Spark et/ou de Kafka  Connaissance des principes du CI/CD (ex : Git)  Connaissances des outils de virtualisation, de conteneurisation (Docker) et d'orchestration (Kubernetes)  Intérêt pour les architectures microservices (REST API's)  Anglais courant Quels sont nos avantages ? Politique interne sur le télétravail  CSE  13 RTT  Tickets restaurant  Prévoyance Santé  Compte Epargne temps  Prime de vacances  Prime de cooptation Quel est notre process de recrutement ?Vous êtes contacté par un spécialiste du recrutement lors d’un échange téléphonique.À la suite de cela, nous organisons un entretien à la fois technique et RH.Une décision peut être prise dès cet entretien pour une embauche.Quoi qu’il arrive, vous aurez un retour de notre part.Vous souhaitez en savoir plus sur nos activités =>  EXPLEOLa localisation des postes n’est qu’indicative, une mobilité géographique sur le territoire national peut être requise si la mission client le nécessite ou si une nouvelle mission est proposée . A bientôt dans nos équipes !  😊


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer (Snowflake),MindPal,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3783808070?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=50%2BxtdahCBGnGKvUc1fENQ%3D%3D&position=10&pageNum=11&trk=public_jobs_jserp-result_search-card,"We are looking for experienced Data Engineers with knowledge of Snowflake platform.ResponsibilitiesCreating and managing data in the Snowflake environment Designing and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms Optimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately Automating data processing workflows using tools such as Airflow or other workflow management tools Deploying and configuring tools to monitor and report on the performance of the Snowflake system RequirementsMinimum 1 year of experience as a Data Engineer Ability to use Snowflake Very good knowledge of SQL and programming in Python Ability to work with databases, including the Snowflake platform Knowledge of ETL tools and data integration Ability to work in a team and good communication skills Fluent English in speaking and writing We OfferB2B contract type Full-time job Remote and flexible working hours


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Embedded Software Engineer,5V Tech,"St.-Marcellin, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/embedded-software-engineer-at-5v-tech-3796385518?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=tP4ELVVmTZhVTBxGq5eJ%2FQ%3D%3D&position=11&pageNum=11&trk=public_jobs_jserp-result_search-card,"Embedded Software Engineer📍 St.-Marcellin, Near Grenoble - France📄 CDI, Permanent position💶 UP TO €70,000 Per Year Salary 🏡 Hybrid Working FlexibilityThis company is a French multinational that designs and manufactures digital building infrastructure systems, including smart lighting control, power management, climate automation, and wireless gateways.They are searching for a Senior Embedded Software Engineer to join their dynamic R&D team (near Grenoble) to take a vital role in the design, development, and integration of software for connected products running Embedded Linux on STM32 and nRF MCUs with BLE, Matter, Wi-Fi, Thread, Zigbee, and 5G connectivity options.This will provide the opportunity to make your mark on the connected device industry and provide cutting-edge solutions for new intelligent commercial spaces.You Will Be...· Creating functional and technical specifications of Embedded Software;· Designing, Developing, and Integrating Embedded Software for Embedded Linux systems, including wireless protocol stacks for BLE, ZigBee, Matter, Thread, etc;· Focusing on Cybersecurity and Quality adherence in software development;· Working with groups from France, Germany, and Australia.If You Have...· Strong experience in Embedded Software Development for Embedded Linux environments;· An affinity for C and modern C++ versions...· Experience developing software for wireless systems and integrating relevant protocol stacks; - This is very nice to haveThen this could be just the opportunity for you! APPLY NOW to discuss further.5V Tech are acting as an Employment Agency for the purposes of this job vacancy. We offer a reward scheme if you can recommend someone for this position, up to £250 for you and an additional £250 to a charity of your choice, 5V Tech are recognised talent solutions experts within IoT and Deep Tech working across Europe, the UK, and North America.


        Show more

        


        Show less","{'ProgLanguage': ['C++', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer- F/H - Comptabilité (H/F),Seyos,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-comptabilit%C3%A9-h-f-at-seyos-3801396458?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=VHte5aDdp8r3XO21k2uThg%3D%3D&position=12&pageNum=11&trk=public_jobs_jserp-result_search-card,"Cette offre d’emploi est fournie par Pôle emploi DescriptionDescriptif du poste: Notre client est un groupe comptable international qui a été fondé il y a plus de six décennies. En France, notre client dispose d'un réseau de 16 agences couvrant l'ensemble du pays. L'objectif de notre client est de standardiser son infrastructure à l'échelle nationale. Chiffres clés : - 1200 Collaborateurs en France et 110 sur l'agence de Nantes - 135 millions de CA en France et 6 millions pour l'agence de Nantes - 6 groupe comptable mondiale Le pôle conseil assiste une clientèle variée, composée de PME et d'ETI, qu'elles soient françaises ou internationales (dans des secteurs tels que le Retail, l'Énergie, le Private Equity, l'Industrie, la Santé, les Services, etc.). Dans le cadre du développement de son activité, notre client recherche un Ingénieur Data - H/F Vos missions : - Examiner la qualité des données et des processus en collaboration avec les Data Analysts. - Conception et amélioration des flux de données et de traitements d'information - Mise en place d'un Datalake Environnement technique : Python, Spark, SQL, Azure (data factory), AWS (S3, Athena, Redshift), Localisation : Nantes (Saint-Herblain) Rémunération : 40 000 - 50 000 Euros selon profil Télétravail : 2 jours Les avantages : - 13 mois - 13 jours de RTT - Tickets Restaurant (60% de prise en charge) - Mutuelle - Participation au Transport - Horaires flexibles Profil recherché: - Vous avez une Première expérience réussie sur un poste similaire - Vous êtes curieux(se), organisé(e), autonome, rigoureux(se) et possédez un bon relationnel - Vous maîtrisez le langage de programmation Python - Vous avez des connaissances Big DataPROFIL SOUHAITÉExpérienceExpérience exigée de 2 An(s)Source: Pole emploi (https://www.pole-emploi.fr)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER (F/H),METEOJOB by CleverConnect,"Saint-Herblain, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-meteojob-by-cleverconnect-3805843296?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=HXBu%2F3gjooMt6oq7eehpEw%3D%3D&position=13&pageNum=11&trk=public_jobs_jserp-result_search-card,"EntrepriseExpectra, leader en France de l'intérim spécialisé et du recrutement en CDI de cadres et agents de maîtrise.Les consultants du Département Informatique - Infogérance vous proposent des opportunités de carrière. Nous recherchons pour le compte de notre client, expert en audit, conseil (IT, RISK, industrie...), expert comptable, DATA ENGINEER (F/H) dans le cadre du développement d'un pôle conseil BI.Pourquoi rejoindre cette entreprise ?Rejoindre cette entreprise, c'est s'engager auprès d'une organisation à taille humaine qui valorise le bien-être de ses salariés ainsi que leur évolution professionnelle.Description Du PostePrêt(e) à relever de passionnants challenges en tant que Data Engineer (F/H) au sein d'un nouvel établissement ?Rejoignez notre client pour gérer et optimiser le flux des données, contribuez aux développements de leurs clients tout en améliorant continuellement leurs processus.Vos Missions Seront Les Suivantes Audit de la qualité des données et des processus en relation avec les Data Analyst F/H Conduite de la gestion du produit : planification et animation Conception de l'architecture des flux de données et des traitements, ainsi que des optimisations pertinentes Développement des lacs de données : mise en œuvre des connecteurs, contrôles et transformations Encadrement et coaching des collaborateurs juniors.Découvrez Cette Offre AlléchanteContrat: CDITélétravail partiel possible 2 jours / semaineLe salaire est à partir de 40 000 € par an et négociable selon vos expériences et compétences.Description Du ProfilIdéalement doté(e) d'une formation big data et décisionnel, de niveau BAC+5 et justifiant d'une première expérience en ESN ou en entreprise, vous détenez une expertise ingénierie data plus particulièrement sur les technologies Microsoft : Azure Synapse, Apache Spark, Azure Databricks, Azure Stream analytics ou encore Azure Data Factory . Vous aimez le travail en équipe et particulièrement au sein d'une équipe dynamique.Vous Maîtrisez Idéalement Les TechnologiesAmazon : S3, Athena, RedshiftLangages : SQL, Python, Spark (Python et SQL)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer AWS,Apside,"La Garenne-Colombes, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-aws-at-apside-3798361466?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=rejKmmrkzdqXahOj%2FdjMVQ%3D%3D&position=14&pageNum=11&trk=public_jobs_jserp-result_search-card,,"{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data engineer – Paris, France (H/F)",Astek,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-paris-france-h-f-at-astek-3779836007?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=kE9eYBPgPKtzRTC3kSWkeQ%3D%3D&position=15&pageNum=11&trk=public_jobs_jserp-result_search-card,"CDIParis - FrancePubliée il y a 2 moisCe Que Nous Pouvons Accomplir Ensemble :Venez rejoindre l’équipe digital et data, en tant que  Data  Engineer (H/F ) et intervenez sur nos projets d’innovation dans le secteur financier !Votre mission (…si vous l’acceptez !) : Développement de la collecte, pré-traitements, stockage, modélisation, monitoring et transformation de données.  Participation à la mise en place des normes de développement (GitFLow)  Administration Hadoop/Hive  Développement des producers et consumers Kafka  Méthodologie Agile : Travailler en conformité avec la méthodologie Agile en place.  Mise en place de la chaine CI/CD. Stack technique : Python, Hadoop, Hive, Kafka, Azure.Les Atouts Du Projet :Vous évoluerez au sein d’une équipe agile, réactive et déterminée.Vous :Vous êtes issu(e)  d’une formation BAC + 5 type école d’ingénieur ou équivalent universitaire  et vous justifiez d’au moins 3 ans d’expérience en tant que data engineer. Vous êtes attiré(e) par le challenge technologique, vous êtes organisé(e), autonome et bon communiquant. Une expérience dans le secteur bancaire est un plus !Enfin, vous êtes curieux et déterminé(e) ! L’informatique est une passion pour vous plus qu’un métier !NOUS ?Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 7200 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.Rejoignez un Groupe en fort développement en France et à travers le monde et ayant réalisé un chiffre d’affaires de 500 M€ en 2022.✨ Tous les détails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : blog.groupeastek.com.Rencontrons-nous !Vous vous êtes reconnu sur l’annonce et Astek vous plaît ?Lindsey, votre talent acquistion, vous contactera pour en savoir plus sur vous !Alors, on tente l’aventure ?Caractéristiques de l'emploiCatégorie ConsultantPostuler en ligneNom *Prénom *Email *Un email valide est requis.Téléphone *Un numéro de téléphone valide est requis.Joindre un CV *Vous :Vous êtes issu(e)  d’une formation BAC + 5 type école d’ingénieur ou équivalent universitaire  et vous justifiez d’au moins 3 ans d’expérience en tant que data engineer. Vous êtes attiré(e) par le challenge technologique, vous êtes organisé(e), autonome et bon communiquant. Une expérience dans le secteur bancaire est un plus !Enfin, vous êtes curieux et déterminé(e) ! L’informatique est une passion pour vous plus qu’un métier !NOUS ?Créé en France en 1988, Astek est un acteur mondial de l’ingénierie et du conseil en technologies, présent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le déploiement intelligent de leurs produits et de leurs services, et dans la mise en œuvre de leur transformation digitale.Depuis sa création, le Groupe a fondé son développement sur une forte culture d’entrepreneuriat et d’innovation, et sur l’accompagnement et la montée en compétence de ses 7200 collaborateurs qui s’engagent chaque jour à promouvoir la complémentarité entre les technologies numériques et l’ingénierie des systèmes complexes.Rejoignez un Groupe en fort développement en France et à travers le monde et ayant réalisé un chiffre d’affaires de 500 M€ en 2022.✨ Tous les détails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : blog.groupeastek.com.Rencontrons-nous !Vous vous êtes reconnu sur l’annonce et Astek vous plaît ?Lindsey, votre talent acquistion, vous contactera pour en savoir plus sur vous !Alors, on tente l’aventure ?


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer - ProcessOut (Golang),Checkout.com,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-processout-golang-at-checkout-com-3796165620?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=uTzzpfhL%2BgZFbacSsY0z1A%3D%3D&position=16&pageNum=11&trk=public_jobs_jserp-result_search-card,"Company DescriptionCheckout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We’re the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Binance, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.We empower passionate problem-solvers to collaborate, innovate and do their best work. That’s why we’re on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we’re just getting started. We’re building diverse and inclusive teams around the world — because that’s how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.Job DescriptionThe roleThis role will sit in the team responsible for maintaining and evolving a Payment Orchestration Platform called ProcessOut. This platform was acquired by Checkout.com in March 2020 and is already powering many large and famous brands like Glovo, NordVPN, and Bolt (with many more that we can’t name and even more to come).We are a self-sufficient team that operates in a fully agile way. We are supported by our very own Product and DevOps teams, and we build and evolve our product together.When it comes to technical stack, we are hosted in AWS, use EKS and our primary development language is Go. As we always strive to use the best tool for the job, we use a combination of Redis, DynamoDB and Postgres for the persistence layer, and REST, gRPC and queues for communication.We are experiencing constant growth in the number of handled transactions, new clients and integrations. That’s why we pay very close attention to the elegant design and scalability of the platform. We are looking for dedicated engineers who would like to join us on our journey.How You’ll Make An ImpactWork together with other backend engineers and DevOps engineers on scaling our platform. Contribute to services and overall architecture by discussing, putting forward ideas on enhancements and actively contributing to our codebases. Cooperate with the Product team on designing, building and releasing new features. QualificationsWhat we’re looking for At least 3 years of software development experience, including at least 1 year with GoKnow your way around the web-related tech (HTTP, TLS, proxies, API conventions...)Worked with RESTful APIs and with gRPCExperience deploying applications as a part of a service-oriented architectureCurious and unafraid of digging deeper to understand how systems of all kinds workAdditional InformationApply without meeting all requirements statement If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.We believe in equal opportunitiesWe work as one team. Wherever you come from. However you identify. And whichever payment method you use.Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.Take a peek inside life at Checkout.com viaOur Culture video https://youtu.be/BEwnpHuadSwOur careers page https://www.checkout.com/careersOur LinkedIn Life pages bit.ly/3OaoN1U Our Instagram https://www.instagram.com/checkout_com/


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': ['VPN'], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Software Engineer (F/H),AXA en France,"Wasquehal, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/senior-software-engineer-f-h-at-axa-en-france-3798515116?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=ss6Ktty7V1EHg9BjQWqzqg%3D%3D&position=17&pageNum=11&trk=public_jobs_jserp-result_search-card,"Afin de renforcer ses équipes, AXA France recherche un Software Engineer Expérimenté F/H.Vous intégrerez des équipes organisées en features teams (dev, tech lead, testeurs, PO), qui utilisent à la fois les méthodologies Agile Scrum et Kanban.Tous nos projets appliquent les principes du software craftsmanship (TDD, BDD, Code Legacy, Clean Code, Code reviews, automatisation, ...) permettant d'améliorer en continu la qualité des applications.ENVIRONNEMENT TECHNIQUE :ReactJSBackend à partir de .NET Framework 4.7Microsoft AzureDevOps (CI/CD)Container + PaaSVous serez amené à travailler sur des projets à destination de nos assurés ou nos agents.Les sujets sont variés et challengeant :Souscription multicanale permettant le démarrage du process en ligne et la finalisation optionnelle en agenceDéclaration de sinistres en ligne en selfcareMutualisation des contrats sur une seule plateformeSécurisation d’applications web et mobileEt autres...ResponsabilitésAu sein d’une « squad » de 6 à 8 développeurs, votre mission consistera à :Délivrer des solutions opérationnelles et de qualité en respectant les principes d’architecture et les bonnes pratiques de développement, de sécurité et d’UXRenforcer les compétences d’ingénierie de votre équipe grâce à la pratique de revue de codes collectives, le partage des pratiques d’ingénierie/Craft de la guilde de dev et la formationContribuer à la culture Tech de la guilde de dev et à l’innovation AXA à travers la veille technologique, les travaux de nos communautés de pratique et les synergies avec des acteurs externes. QualificationsTitulaire de formation supérieure en informatique7 ans d’expérience minimum sur les technos .NET et React JSIntérêt particulier pour les best practices (TDD, BDD, Clean Code…)Adepte du travail en équipeContribuer à la transformation de notre entreprise où le client est au centre de nos enjeux est essentiel pour vous


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
QA Data Engineer (F/H),Hilti Group,"Boulogne-Billancourt, Île-de-France, France",https://fr.linkedin.com/jobs/view/qa-data-engineer-f-h-at-hilti-group-3799264603?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=1S0arC%2F06hP10Tk3RDjQRA%3D%3D&position=18&pageNum=11&trk=public_jobs_jserp-result_search-card,"What's the role?We’re looking for a highly skilled QA Data Engineer who’ll act as a testing specialist within the wider Marketing & Sales Data and Digital Impact Measurement team, ensuring the accuracy of our large-scale data pipelines. As a QA engineer you will play a central role in in crafting and defining our testing approach at a pivotal time for our digital strategy. Being part of the data infrastructure team focusing on building scalable data services and pushing towards innovation and impact in across our organization.Who is Hilti?If you’re new to the industry, you might not have heard of us. We provide leading-edge tools, technologies, software and services for the global construction sector. We have a proud heritage, built over 75 years, and a worldwide reputation for pioneering products and exceptional service. With 30,000 people in more than 120 countries we operate with a unique direct sales model and generate around 250,000 customer interactions every day.What does the role involve?You will be responsible for testing and ensuring the accuracy of key data platforms, services and pipelines used across Digital Marketing & Sales initiatives.Taking hands on part in code reviews and maintaining high quality data services that produce tangible business value.In this light, you will review requirements, specifications, and technical design implementations to provide timely and meaningful feedback while creating detailed, comprehensive, and well-structured test plans and test cases for our diverse data products. You will also estimate, prioritize, and plan testing activities to identify bugs by means of regression testing and monitoring. Overall, you will develop and execute automation scripts to identify, record, document thoroughly, and track results ensuring new and existing data products meet data quality expectations.We have more than 200,000 interactions with our customers every day. It’s how we get to know their businesses, understand their needs and develop the precise products and services that will help them.What do we offer?To further accelerate in digital marketing, we are building our Global Digital Hub in Paris. You will experience the agile mentality combining the stabilityof a sound business model and the working environment of an award-winning culture. You can make an impact from day one in an international and diverse team by shaping the future of digital at Hilti and revolutionize customer interactions. You’ll be the owner of your professional development and will have the ownership to design your career map.Job benefits: From 60k to 82k€ package  25 vacation days + RTT  Childcare  Health insurance fully covered  Retirement plans What you need is: Min. 2-3 years of experience as a QA Engineer (preferably in automatisation using Python )  Experience with public cloud infrastructure (preferably AWS)  Experience in writing clear, concise, and comprehensive test plans and test cases (manual & test automation)  Hands-on experience with both white box and black box testing  Hands-on experience with automated testing tools  Good understanding of API based integration i.e. REST, XML, Microservices etc.  Ability to quickly understand domains and develop a test strategy.  Knowledge of agile methodologies and continuous delivery (including continuous deployment tools)  A problem solver, with an eye for detail and a keen focus on data quality.  Knowledge of structured or custom ETL/ELT management (Airflow, Luigi, etc.), including, ideally, solid understanding of the AWS cloud.  Knowledge of “Big Data”/NoSQL platforms and services (Druid, MongoDB, Kafka)  Fluency in English Why should you apply?We’re investing more than ever in our digital transformation. As a company whose lifeblood is innovation, we give our customers the next level of digital offerings on an impressive global scale! For you, it means unrivalled opportunities to work in a ‘start-up within’ environment, develop an international career and really have an impact on the shape of things to come.During your interviews, you will meet several members of the digital team including leadership. This way you get to know more about us, and we get to know more about you.Tempted to apply? Click “apply now” and send us your resume (English version) today!Do you want to know more? Go to https://careers.hilti.com/en/digital-marketingJoin us and #TransformDigital
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage – Data Engineer (H/F) – Paris,Crédit Agricole Technologies et Services,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/stage-%E2%80%93-data-engineer-h-f-%E2%80%93-paris-at-cr%C3%A9dit-agricole-technologies-et-services-3799016250?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=8kh%2BokaRsn3TXwcZWfzBHg%3D%3D&position=19&pageNum=11&trk=public_jobs_jserp-result_search-card,"A la recherche d’un stage de 6 mois à partir de mars 2023 ?  NOUS REJOINDRE C’EST … Intégrer le partenaire IT des Caisses Régionales Crédit Agricole, banques mutualistes et solidaires, Bénéficier d'un parcours d'intégration dédié aux étudiants et d'un accompagnement de proximité, Participer et être moteur de projets riches et formateurs dans un cadre qui offre la liberté d'innover, Evoluer dans une entreprise apprenante qui mise sur l'intelligence collective à travers des formations, et des ateliers (thématiques développement personnel, Tech ou Métier) tout au long de l'année Faire partie d’une entreprise humaine et inclusive qui met en place des actions concrètes en faveur de l'égalité professionnelle et de la diversité (99/100 sur l’index égalité Femmes / Hommes en 2022), Travailler dans un environnement alliant modernité et bien-être (espaces agiles et de créativité, télétravail (2 jours), engagements RSE) ; L’équilibre vie professionnelle/vie personnelle est un sujet au cœur de notre politique RH, Faire partie de la communauté interne des Jeunes talents et profiter de nombreuses animations et de moments de partage avec les stagiaires et alternants CA-TS.   TA TEAM ET TES MISSIONS Tu rejoindras La squad Usage Data et IA ayant pour mission d’industrialiser les cas d’usages Datascience en utilisant des modèles algorithmiques d’IA avec l’aide de technologies avancées et langages Big DATA.  Le sujet principal de ton stage est le suivant : participer à l’industrialisation d’un moteur de recommandation client basé sur l’IA : Next Best Offer (NBO). NBO vise à trouver la meilleure offre personnalisée pour un client en fonction de son profil, ses intérêts, son comportement, son historique bancaire, ses préférences.  Accompagné(e) de ta tutrice Clara, tes missions principales seront : Participer à l’industrialisation du moteur de recommandation : -Contribuer au développement et à l’industrialisation des pipelines des traitements de pré-processing, d’entrainement, de prédiction et de post-processing,-Participer à la mise en place de l’ordonnancement des différents traitements, -Participer à l’exécution des tests (test d’intégration, test unitaires),-Contribuer à la rédaction de la documentation,Participer à la fabrication du monitoring de la solution (calcul de métriques et restitution). Environnement Tech Python -Numpy -Pandas -Matplotlib -Keras -Tensorflow -Pytest Pyspark Plateforme CDP Hive / HDFS Docker SQL (Teradata) Suite ELK Gitlab   TON PROFIL Tu es en formation informatique, ingénieur avec une spécialité data & IA, Idéalement, tu as une première expérience (professionnelle ou projet scolaire) dans le domaine, Tu apprécies le travail en équipe et tu fais preuve de curiosité, Tu fais preuve d’autonomie et de rigueur, Tu es à l’aise avec un mode de feedback régulier sur tes activités, ton ressenti.  EN TOUTE TRANSPARENCE … Ta candidature sera analysée par nos recruteuses et si cette dernière est retenue, tu seras contacté(e) sous 10 jours pour un premier échange RH téléphonique. Si cet entretien RH est concluant, tu rencontreras ton/ta futur(e) tuteur/tutrice pour un entretien plus opérationnel. Ainsi tu en sauras plus sur tes collègues, tes missions et l’environnement technique liés au poste. Un bon moment pour poser tes questions !  Notre délai moyen de retour après ton dernier entretien ? 2 semaines maximum   ET APRES TA FORMATION ? Chez CA-TS ton expérience est gagnante-gagnante, nous voulons tout faire pour que tu continues l'aventure avec nous. Tu auras accès en priorité à nos offres disponibles en CDI.  Avec le temps et selon tes appétences, tu pourras continuer à développer tes compétences et connaissances, être accompagné∙e ou accompagner (formations, intégration, mentorat/tutorat, actions marque employeur).


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Spark'], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataView': ['Matplotlib'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer (F/H),LesJeudis,"Vélizy-Villacoublay, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-lesjeudis-3788991516?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=8LoKSygyaNU9Uqk8l4jNrg%3D%3D&position=20&pageNum=11&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Au sein du site de Vélizy, nos équipes hautement qualifiées conçoivent et produisent des amplificateurs de puissance (tubes à ondes progressives, klystrons, gyrotrons, sous-systèmes pour les Grandes Infrastructures de Recherche, etc.) à destination des marchés Défense, Sécurité, Spatial et Scientifique. Chaque jour nos cadres, ingénieurs, techniciens et opérateurs mettent en commun leurs savoir-faire unique au service de l'innovation.QUI SOMMES-NOUS ?Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs présents sur tous les continents. Le Groupe investit dans les innovations du numérique et de la""deep tech""- big data, intelligence artificielle, connectivité, cybersécurité et quantique - pour construire un avenir de confiance, essentiel au développement de nos sociétés, en plaçant l'humain au cœur des décisions. Thales propose des solutions, services et produits qui aident ses clients - entreprises, organisations, Etats - dans cinq grands marchés vitaux pour le fonctionnement de nos sociétés : identité et sécurité numériques, défense, aéronautique, espace, et transport.QUI ETES-VOUS ?De formation Ingénieur ou Bac+5, Ecole d'ingénieur ou Université vous justifiez d'une expérience professionnelle d'au moins 4 ans.Compétences TechniquesCompétences en développement (Shell unix, Perl, PHP, Python, git, github)PostGreSQLPythonCe Que Nous Pouvons AccomplirensembleL'accélération de la transformation digitale des métiers du Groupe s'appuie sur les actions suivantes :Construire une infrastructure technique performante et sûreMieux mobiliser nos ressources""Tech&Data""pour générer de la valeurGagner en agilité et en efficacité dans notre manière de servir les métiersProposer à nos clients une meilleure expérience numériqueVous serez intégré au sein d'une équipe agile et à ce titre vous réaliserez la mission en collaboration avec les membres de l'équipe et dans les standards de développement du groupe.A Ce Titre, Vous Serez En ChargeDu développement de nouvelles fonctionnalités sur la plateformeDu maintien en condition opérationnelle de l'application,De la mise en œuvre et l'évangélisation des bonnes pratiques de développement au sein de l'équipe,De la résolution des recommandations d'architecture et de sécurité sur la plateforme,De la mise en œuvre de pipeline de build, tests, déploiementEn nous rejoignant, vous vous verrez confier les missions suivantes :Code pour en améliorer la qualité, la performance, la sécurité, et la maintenabilitéBonnes pratiques en matière de développementFonctionnalités complémentaires permettant d'améliorer l'expérience des utilisateurs finaux, en fonction de leurs besoins et retours d'expérience.Recueil de l'existant : récupération, tests et mise en repository des codes / scripts / données utilisés dans les prototypesDocumentation du fonctionnement des prototypes : cinématique globale, description des fonctionsAméliorations (qualité, performance, sécurité) sur les parties qui seront reprises des prototypesEvolutions fonctionnelles suite aux échanges avec les utilisateurs finauxDesign de la solution tactique basée sur les socles digitaux du groupe. Solutions de backup en cas de délais sur la disponibilité des socles groupes.Tests unitaires et globauxConduite du changement des entités internesSupport aux entités internes / utilisateurs finaux sur l'exploitation de la solutionNous Vous OffronsUne diversité de projets vous permettant de découvrir l'ensemble de nos métiers,Des conditions de travail motivantes et un plan de carrière personnalisé offrant de réelles perspectives d'évolution,La possibilité de vous investir dans une entreprise dont la réputation est mondiale avec des ambitions constantes d'innovations techniques.Innovation, passion, ambition :rejoignez Thales et créez le monde de demain, dès aujourd'hui.Innovation, passion, ambition : rejoignez Thales et créez le monde de demain, dès aujourd'hui.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer - H/F,Devoteam G Cloud,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-h-f-at-devoteam-g-cloud-3801924922?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=IjWV73VGiNBqMK7hFXAmBw%3D%3D&position=21&pageNum=11&trk=public_jobs_jserp-result_search-card,"Tu auras pour mission d’accompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l’écosystème solutions open source associé.Intégré(e) à une équipe d’experts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d’étudier et cadrer les besoins clientsPréconiser les solutions et architectures ciblesDéfinir les méthodologies de déploiement et plans de migrationRédiger les dossiers d’architecture et spécifications techniquesConstruire les architectures de donnéesConcevoir et mettre en place des systèmes de données résilients et sécurisés (data warehouse, data lake, systèmes temps-réels)Construire et déployer les pipelines de données (ETL / ELT)Assurer la migration des données vers les nouveaux environnementsAnalyser les donnéesAnalyser les données sources afin d’identifier et évaluer des cas d’usage métierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, DataStudio…)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les équipes clients aux méthodes et concepts du cloudTu seras accompagné(e) en interne pour monter rapidement en compétences sur GCP dans l’objectif d’étendre tes certifications Google sur ta practice.Ton profilDiplômé(e) d'une école d'ingénieurs ou d'un Master 2 en Informatique, tu disposes d'une expérience significative (2 ans) au sein de projets Data : architecture, traitement ou analyse de données.Tu maîtrises au minimum un langage de programmation appliqué à l’analyse de données (Scala, R, Python, Java).Tu as de bonnes compétences dans l’architecture des systèmes, bases de données, méthodologies d’analyse. Tu sais te repérer dans le vaste écosystème Data et tu sais notamment quelle brique utiliser en fonction des cas d’usages. Tu es passionné(e) par la Business Intelligence, le Big Data, l’Internet des objets (IoT) et le Machine LearningTu possèdes la certification Google Cloud Platform - Professional Data EngineerTu as une solide compréhension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et à l’écoute, tu possèdes un réel esprit d’analyseTa maîtrise de l'anglais te permettra de gérer des projets en contexte internationalLe Groupe Devoteam œuvre pour l'égalité des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au mérite et lutte activement contre toute forme de discrimination. Nous sommes persuadés que la diversité contribue à la créativité, au dynamisme et à l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst  - H/F,E.Leclerc,"Mont-de-Marsan, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-e-leclerc-3806613411?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=EbysG1l4x15Yc5jrc1TJzg%3D%3D&position=22&pageNum=11&trk=public_jobs_jserp-result_search-card,"DescriptionAu sein du service Data Management, situé à Mont-de-Marsan (40), de la DSI du GALEC, vous serez en charge de mettre en œuvre des outils informatiques, des techniques et des méthodes statistiques pour permettre de contrôler et analyser efficacement les données produits chez Leclerc et aider à leur mise en qualité.A Ce Titre, Vos Principales Missions Seront DePiloter le projet de nouvelle brique d’analyse pour l’équipe,Participer à l’élaboration des nouveaux outils pour la modernisation de l’activité Data Management : outil de collecte, outil de contrôle qualité, outil de suivi des anomalie/des collectes, analyse, suivi contacts fournisseurs,Travailler avec l'équipe automatisation de la DSI pour simplifier, automatiser les process existants,Analyser les process existants et être force de propositions pour des optimisations, simplifications ou automatisation nécessaires,Collaborer avec les différents pôles du service pour comprendre leurs besoins en matière d'analyse de données et proposer des solutions appropriées,Concevoir, développer et maintenir des tableaux de bord et des rapports sur BO, Looker studio et tout autre nouvel outil,Travailler en collaboration avec les différents acteurs internes et externes au GALEC,Effectuer des analyses ponctuelles et approfondies liées aux problématiques de qualité de données produits,Participer à la conception et à l'optimisation des architectures de données pour assurer la performance et la fiabilité des systèmes d'analyse,Mettre en œuvre des méthodes et outils d’analyse de données avancées pour analyser et interpréter des ensembles de données complexes afin de détecter les anomalies dans la qualité de données produits.ProfilDe formation bac + 5 universitaire ou ingénieur en Data Sciences (statistiques, IA), vous avez acquis une expérience de 10 à 15 ans dans l’analyse de données. Une expérience dans le domaine de la grande distribution serait un plus.Vous avez un esprit analytique, êtes autonome, proactif(ve) et rigoureux(se).Vous avez une bonne communication écrite et orale.Vous avez une approche proactive de la résolution des problèmes.En Termes De Compétences Techniques, VousMaîtrisez les langages de type Python et des outils ou librairies facilitant l’analyse de données,Maîtrisez les bases de données SQL et NoSQL, Savez analyser flux JSON, utiliser des API externes, Savez concevoir et mettre en œuvre des modèles statistiques et des algorithmes prédictifs,Avez une connaissance sur les outils BI et de datavisualisation. Nous recherchons des personnalités dynamiques, sachant prendre des initiatives et qui souhaitent s’impliquer dans les évolutions de notre secteur et du mouvement. Il est important que nos candidats démontrent un réel engagement, des valeurs communes aux valeurs fortes portées par le mouvement Leclerc depuis sa fondation.Le sens du collectif, l'esprit de cohésion et d'équipe, la volonté d'innover et de transmettre seront les éléments clés de la réussite de votre intégration.En rejoignant le Galec, vous pourrez valoriser et démontrer votre potentiel, développer vos compétences et acquérir une expérience enrichissante, à travers des passerelles entre les différents marchés, métiers et entités du Mouvement !Mieux nous connaitreLe Mouvement E.LECLERC est un groupement coopératif dont les adhérents sont les propriétaires de magasins, soit 592 entrepreneurs, dont Michel-Edouard Leclerc est le porte-parole. Le Mouvement E.leclerc compte 133 000 collaborateurs, qui travaillent collectivement à la réussite de nos 721 magasins (hypers, supers et express), 690 Drives et 2 541 enseignes spécialisées.Le Galec est l'entité au cœur du système, c'est même le réacteur ! Le Galec conjugue les talents d’une équipe de plus de 824 collaborateurs qui travaillent ensemble au service du front de vente omnicanal de l’Enseigne, c’est-à-dire les hyper/supermarchés, les magasins spécialisés, le drive, le site marchand E.Leclerc et E.Leclerc relais.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirmé (H/F),EXAKIS NELITE,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-exakis-nelite-3807583818?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=vabK3k47FyZ6q4zpETmsYA%3D%3D&position=23&pageNum=11&trk=public_jobs_jserp-result_search-card,"Exakis Nelite, entité du groupe Magellan Partners, est le premier partenaire pure-player Microsoft indépendant en France avec l’ambition de devenir le premier partenaire Européen et en Afrique Francophone avec sa forte présence au Maroc.Nés du rapprochement de 2 leaders spécialistes de l’intégration des solutions Microsoft, nous allions expertise technique et fonctionnelle pour répondre concrètement aux enjeux de demain : accélération de la transformation digitale, Cybersécurité, Intelligence Artificielle, IoT, Data, transformation vers le cloud Azure, Services Cognitifs et Intelligence Artificielle…En rejoignant la communauté Exakis Nelite dans l’une de nos agences, représentant 650 collaborateurs, vous intégrerez une équipe passionnée et impliquée dans les projets les plus innovants. Vous rejoindrez une structure construite autour de valeurs tournées vers ses collaborateurs : intelligence collective, convivialité et bienveillance.Exakis Nelite a reçu la certification Great Place to Work et se place 5ème en 2023 parmi les entreprises où il fait bon travailler en France !Poste et missionsEn tant que Data Engineer confirmé(e) vous serez responsable du développement, de la gestion et de l'optimisation des solutions de données basées sur la plateforme Azure pour répondre auxbesoins métiers du client :- Conception et développement de solutions de données : concevoir, développer etmettre en œuvre des pipelines de données efficaces et évolutifs sur la plateforme Azure, en utilisant des technologies telles qu'Azure Synapse et Azure Data Factory.- Optimisation des performances : assurer la performance, la fiabilité et lascalabilité des solutions de données existantes en optimisant les requêtes SQL, ensurveillant les performances et en mettant en œuvre des bonnes pratiques.- Collaboration avec l'équipe architecturale : travailler en étroite collaboration avecl'architecte senior de la plateforme de données pour garantir l'alignement dessolutions de données avec la vision globale de l'architecture.- Gestion des données : Mettre en place des processus de gestion des données, ycompris la collecte, la transformation, le stockage et la distribution des données demanière sécurisée et conforme aux réglementations en vigueur.- Documentation et bonnes pratiques : documenter les solutions de données, lesprocessus et les bonnes pratiques pour assurer la traçabilité et la reproductibilité destravaux.- Veille technologique : rester à jour avec les dernières avancées technologiques dans ledomaine du Big Data et des technologies Azure pour continuellement améliorer les solutionsexistantes.Profil recherché - Au moins 5 d'expérience en tant que Data Engineer, avec une expertise avérée dansl'écosystème Azure.- Solide expérience dans la conception et le développement de pipelines de données avec Azure Synapse, Azure Data Factory, et Azure DevOps.- Maîtrise des langages de requête SQL et des compétences en modélisation de données.- Capacité à travailler en équipe et à communiquer efficacement avec des interlocuteurs métiers.- Certification Azure (par exemple, DP203 Azure Data Engineer) serait un atout.Ce poste offre une opportunité passionnante de contribuer à la transformation des données en utilisant les dernières technologies Azure. Vous serez au cœur de la prise de décision basée sur les données et contribuera directement à la réussite du client.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Consultant BI / Azure Data Engineer H/F,Talan,"Paris, Île-de-France, France",https://fr.linkedin.com/jobs/view/consultant-bi-azure-data-engineer-h-f-at-talan-3797837777?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=mQ2RnHhjvdaqlkbnSgsUuw%3D%3D&position=24&pageNum=11&trk=public_jobs_jserp-result_search-card,"Talan est un cabinet de conseil en innovation et transformation par la technologie.Depuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en œuvre leurs projets de transformation et d’innovation en France et à l'international. Présent sur cinq continents, le groupe prévoit de réaliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant·e·s et vise à dépasser la barre du milliard d’€ de CA à horizon 2024.Le Groupe met l'innovation au cœur de son développement et intervient dans les domaines liés aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.Présent dans les événements incontournables du secteur, comme Viva Technology, Talan prend régulièrement la parole sur les enjeux de ces technologies révolutionnaires aux côtés d'acteurs majeurs du secteur et de parlementaires (Syntec Numérique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny…).Talan est une entreprise responsable, attachée à la diversité. Des aménagements de poste peuvent être organisés pour tenir compte des personnes en situation de handicap.Retrouvez nos engagementsRSEiciet nos actions en faveur de la diversitéiciJob DescriptionVOTRE ROLE SUR NOS PROJETS :Vous interviendrez sur des projets de:Mise en place de Modern Data PlatformInterconnexion d’applications opérationnelles en temps réelAu sein d’équipes projet, votre rôle sera de:Concevoir et mettre en place des flux d’intégration de donnéesGarantir la qualité des développementsRédiger des spécifications fonctionnelles et techniquesModéliser l’entrepôt de donnéesMettre en place des solutions de suivi et pilotage des flux de donnéesProposer des solutions d’optimisationMettre en place ou faire évoluer des chaînes CI/CDVOTRE ROLE CHEZ TALAN :Au sein du pôle Tech For Data, vous contribuerez à la croissance et la prospérité de la communauté au travers des activités suivantes:Benchmark de solutions et conseil auprès de nos clients sur les solutions technologiques à adopter, en lien avec leurs besoinsRéalisation de POC (Proof Of Concept)Partage de connaissances et formations internesPassage de certificationsVeille technologiqueParticipation à la rédaction de réponse à appel d’offreQualificationsDiplômé d’un Bac+5 en informatique/data, vous justifiez d’une expérience d’au moins 3 ans sur des problématiques d’intégration, traitement et mise en qualité de données en ayant mis en œuvre des flux de données sur AZURE (la maîtrise d’autres solutions de traitement de données est un plus).Vous avez une première expérience dans des environnements incluant entre autres Azure Data services :Azure Data FactoryAzure SQLAzure Synapse (sql pool, spark pool)Azure blob storageAzure DatalakesStream AnalyticsEventHubVous maîtrisez les concepts de modélisation de données et les architectures de type DataLake, DWH, Datamarts (la connaissance de la modélisation Datavault est un plus).Vous savez évoluer dans un environnement avec un modèle de données complexe et évolutif.Vous disposez d’un très bon relationnel et vous êtes reconnu pour votre capacité à évoluer efficacement avec des interlocuteurs aussi bien techniques que non-techniques.Force de proposition, vous savez mobiliser autour de vos idées et de vos projets.Vous savez évoluer dans un contexte data ops et avez une connaissance des chaînes CI / CD (Gitlab, Azure Devops, ...)La maîtrise de la méthodologie Agile est un plus.Ensemble réalisons de nouveaux projets Talantueux!!VOTRE SOUHAIT D’EVOLUTION:Si vous êtes passionné par l’innovation, et souhaitez élargir vos compétences techniques dans la data, accéder à des fonctions de management de projet et d’équipe, participer au développement commercial et organisationnel, ou tout simplement pouvoir valoriser vos prises d’initiatives et développer de nouveaux terrains de jeux, alors rejoignez-nous!Additional InformationAvantages:Top 3 du Palmarès Great Place to WorkManagement de proximité par des expertsOrganisation sous forme decommunautésUn parcours excellence Agile devopsFinancement de plusieurs certifications officielles à l’année grâce à nos partenaires éditeursUn accès à la plateforme CampusTalan avec plus de 1000 formations disponibles dès votre arrivéeUne mobilité interne facilitéeUn engagement auprès des travailleurs en situation de handicapDes événements et afterworks réguliersSiège parisien situé au 14–20,rue Pergolèse, àParis16ème (près de Porte Maillot et de l'Avenue de la Grande Armée)Tickets restaurants digitalisésMutuelle d’entreprise prise en charge à 100%Prime vacancesPrime de participationPrime de cooptationActionnariat1% logementPartenaire de l'organisme Mobility dans le cadre de l'accompagnement à la mobilité et à la recherche de logementRTT.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,IDEAL MATCH,"Lyon, Auvergne-Rhône-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-at-ideal-match-%E2%8E%AE-cabinet-de-recrutement-tech-it-3791420764?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=bym7UoJROVdpakIx0v0tVA%3D%3D&position=25&pageNum=11&trk=public_jobs_jserp-result_search-card,"Présentation de la sociétéPionnière en matière de Data immobilière, cette société créée il y a plus de 30 ans compte aujourd’hui plus de 120 collaborateurs. Elle propose des solutions permettant de réaliser des analyses de marché pour l’ensemble des acteurs du foncier, de l’aménagement et de l’immobilier (promoteurs, bailleurs, aménageurs et collectivités) afin de les accompagner dans la réussite de leurs projets, dans la compréhension de leurs marchés et dans le développement de leurs stratégies.Afin de garantir la mise en œuvre du Dataflow de la société, notre client recherche un Data Engineer pour renforcer son équipe.DescriptionAu sein d’une équipe Data composée de 3 personnes, vous serez amené à collaborer avec les différents pôles pour comprendre leurs besoins en données.Votre Mission :Participer à la conception d'architectures de donnéesEffectuer la mise en œuvre de pipelines de donnéesS'assurer de la qualité et de la sécurité des solutions mises en placeAssurer l’intégration et d’industrialisation des sources de données dans une perspective de réduction du time to market des nouvelles sourcesOptimiser les performances des infrastructures de donnéesMigrer le cloud interne de l’entreprise vers des cloud publiquesMettre en place des outils de machine learning et IAStack technique: Spark, Hadoop, Airflow, Python 3+, Talend, Azure, AWS, Docker, Kubernetes, Git, Jenkins, SQL/NoSQL, PostgreSQLExigencesVous êtes idéalement titulaire d’un bac +5 dans l’informatiqueVous avez au minimum 2 ans d’expérience en tant que Data EngineerVous avez une appétence pour le machine learning et idéalement l’IAVous êtes rigoureux, autonome, ouvert d’esprit et aimez travailler en équipeAvantages2 jours de télétravail par semaineMutuelle familiale remboursée à 80%Ticket restaurant 8.5€Participation / intéressement9-12 RTT


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
