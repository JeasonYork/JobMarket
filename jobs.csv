title,company,location,link,description,skills
Data Engineer (H/F) - Lille,Logic@l Conseils,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-lille-at-logic%40l-conseils-3782133344?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=pwOdnUGc6NYA8db3%2B5%2BpzA%3D%3D&position=2&pageNum=0&trk=public_jobs_jserp-result_search-card,"Dans le cadre du d√©veloppement de nos activit√©s sur la m√©tropole Lilloise, nous recherchons un consultant data engineer (H/F) pour intervenir chez l'un de nos grands comptes clients.Vos missions :Recueillir les besoins m√©tiers et des √©quipes dataConcevoir et mettre en place les traitements de donn√©esR√©aliser les tests de validation Assurer l‚Äôalimentation du datawareR√©aliser les ordonnancements des traitementsEtre garant de la mise en place, du suivi et de l‚Äôexploitation des outils d√©ploy√©sAssurer une veille technologique r√©guli√®reEnvironnement technique :D√©veloppement : Python, Scala, R, Java, Framework : Spark, Hadoop, Outils Big data : Yarn, Pig, Hive, Kafka, SplunkBases de donn√©es : MongoDB, HBase, CassandraETL : Talend, ODI, StambiaPlateforme : Hortonworks, Cloudera, Map Reduce, AWS, GCP, Azure Votre profil :Vous disposez d‚Äôune exp√©rience d‚Äôau moins 2 ans en tant que data engineer ou dans le domaine de l‚Äôanalyse et du traitement de donn√©es.V√©ritable passionn√© de la data, vous √™tes force de proposition sur les solutions techniques √† mettre en ≈ìuvre. Vous maitrisez l‚Äôanglais dans un contexte professionnel.Comp√©tences requises :Analyses qualitatives et quantitatives (Interm√©diaire)Anglais (Interm√©diaire)Architecture fonctionnelle SI (D√©butant)D√©veloppement d'ouvrages, produits ou √©v√©nements (D√©butant)Gestion des contr√¥les, tests et diagnostics (D√©butant)Gestion des risques (Interm√©diaire)Ma√Ætrise des logiciels (Interm√©diaire)Mise en exploitation / Production et maintenance (D√©butant)Nos valeursNous avons d√©cid√© de renverser la pyramide du management pour placer nos collaborateurs en t√™te des priorit√©s de l‚Äôentreprise.En effet, attach√© √† des valeurs fortes, telles que la proximit√©, la sinc√©rit√©, la fid√©lit√©, la confiance et le respect, nous sommes persuad√©s que la r√©ussite r√©side dans le bien-√™tre de nos collaborateurs.Cela se traduit par un accompagnement de proximit√©, de la transparence sans langue de bois, des √©changes r√©guliers avec les managers r√©f√©rents, un accompagnement dans le d√©veloppement de carri√®re qui est construit et jalonn√© avec les formations et certifications n√©cessaires et les missions en ad√©quation, pour mener √† bien l‚Äô√©volution de carri√®re. Pour vous convaincre de nous rejoindre, nos avantages salari√©s compl√©mentaires :Environnement bienveillant et stimulant au sein de 3 p√¥les d‚ÄôexpertisesFormations et Certifications √† la demandeTickets restaurants : 13‚Ç¨ par ticketRemboursement √† 100 % des abonnements de transports en communMutuelle frais de sant√© avec de hautes garantiesPrise en charge √† 100% de l‚Äôassurance Pr√©voyanceCh√®que Cadeau Culture 120 ‚Ç¨Compte CSE avec une cagnotte de 390 ‚Ç¨Compte CE : billetterie, voyages, culture, sorties, √† des tarifs pr√©f√©rentielsDes √©v√®nements chaque mois : activit√©s associatives, sportives, afterwork, s√©minaire,Partenariat Losc (participation aux match dans la loge VIP logical conseils ‚Äì (Une Vingtaine de match par an)Possibilit√© de t√©l√©travailEn int√©grant Logic@l Conseils, vous participez √† une r√©elle aventure humaine, alors pour postuler, il suffit de cliquer ci-dessous !Tous nos postes sont ouverts, √† comp√©tences √©gales, aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [' MongoDB', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Cr√©dit Agricole de Champagne-Bourgogne,"Dijon, Bourgogne-Franche-Comt√©, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-cr%C3%A9dit-agricole-de-champagne-bourgogne-3734715864?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=9dgoE6Y0TMkHBFhkNsKgzw%3D%3D&position=3&pageNum=0&trk=public_jobs_jserp-result_search-card,"Ing√©nieur.e DATA avec une sensibilit√© marketing ? Reconnu.e pour votre esprit d‚Äô√©quipe et votre aisance relationnelle ?  Vous aimez vous impliquer ? Ce job est fait pour vous ! Rejoignez le service Marketing du Cr√©dit Agricole de Champagne-Bourgogne √† Dijon. Vous serez accueilli.e par Catherine, votre manager. Au sein d‚Äôun p√¥le d√©di√© √† la Data Client, vous travaillerez en compl√©mentarit√© d‚Äôune √©quipe de datascientists et d‚Äôexperts du marketing.En tant qu‚Äôing√©nieur.e data, vous serez un v√©ritable appui au d√©veloppement des mod√®les de datascience. Vous serez responsable de la cr√©ation des architectures et de l‚Äôinfrastructure data analytique ainsi que de sa maintenance op√©rationnelle. Vos principales missions : Cr√©er et maintenir des infrastructures de donn√©es :Assurer la conception de bases de donn√©es, leurs √©volutions, l‚Äôarchitecture, la mod√©lisation des donn√©es, l‚Äôaide √† la data pr√©paration.Industrialiser, automatiser et mettre en production les traitements sur les donn√©es.D√©ployer et maintenir des infrastructures serveurs :Installer des middlewaresConfigurer des serveurs (Windows & Linux) Accompagner les √©quipes et assurer une veille technologique sur les outils autour de la data :Travailler en collaboration avec les interlocuteurs internes et externes √† notre Caisse R√©gionale.Mettre √† disposition des flux de donn√©es (interne et/ou externe) pour exploitation par les datascientists.Assurer une assistance et la mont√©e en comp√©tences des membres de l‚Äô√©quipe dans la mise en pratique de d√©veloppements informatiques Pour r√©ussir ce d√©fi, vous avez au moins une exp√©rience r√©ussie dans la conception de bases de donn√©es et vous avez une forte expertise sur le stockage des donn√©es et des outils ETL. Vous avez une vision syst√©mique, technologique et globale des syst√®mes d‚Äôinformation ainsi que des notions avanc√©es en PHP/JavaScript/SQL.Des connaissances en R/Python/Go ainsi qu‚Äôen architecture logicielle et dans les outils Big Data (Hadoop, Spark, HDFS, ‚Ä¶) sont un plus.Vous avez une exp√©rience en administration syst√®me et connaissez au moins un syst√®me d‚Äôexploitation parmi Windows et Linux. Vous avez d√©j√† travaill√© sur un outil de gestion des flux de type Kafka, Apache Flink. Pourquoi nous rejoindre ?- Pour le challenge d‚Äô√™tre au c≈ìur de la construction d‚Äôune infrastructure de gestion des donn√©es.- Int√©grer une entreprise toujours en mouvement, innovante et leader sur son secteur. Une entreprise attach√©e √† des valeurs humaines et de proximit√©, actrice sur son territoire et en mati√®re de RSE.- Travailler au sein d‚Äôune d‚Äôune √©quipe dynamique et conviviale (8 personnes).- Des √©volutions possibles au sein du Groupe. - Des avantages : Un int√©ressement entre 2 et 4 mois de salaire, un 13√®me mois, une variable, une mutuelle prise en charge √† 90%, des avantages salari√©s sur certains produits bancaires et d‚Äôassurance, 24 jours de RTT/an, un accord de t√©l√©travail, une prise en charge des transports en commun √† 75% et une restauration d‚Äôentreprise sur place.Statut cadre, salaire fixe en fonction de votre exp√©rience.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux', 'Windows'], 'SoftDB': [], 'SoftBigDataProcessing': ['Apache Flink'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Lille - I&D (F/H),Capgemini,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-lille-i-d-f-h-at-capgemini-3759212804?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=qqWDFHpahDNc6dW%2BfBqGlA%3D%3D&position=4&pageNum=0&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques motsCapgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans pr√®s de 50 pays. Partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie, le Groupe est guid√© au quotidien par sa raison d‚Äô√™tre : lib√©rer les √©nergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d‚Äôexp√©rience, Capgemini est reconnu par ses clients pour r√©pondre √† l‚Äôensemble de leurs besoins, de la strat√©gie et du design jusqu‚Äôau management des op√©rations, en tirant parti des innovations dans les domaines en perp√©tuelle √©volution.Insights & Data en quelques motsDans ce contexte, notre practice Insights & Data (I&D) s‚Äôappuie sur une √©quipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette √©quipe combine des comp√©tences m√©tiers avec une forte expertise data, analytique et d‚Äôintelligence artificielle pour mettre en ≈ìuvre des solutions qui visent √† am√©liorer la gestion et la valorisation des donn√©es. Pour renforcer les √©quipes d‚ÄôI&D, nous recherchons actuellement un.e Data Engineer (H/F).Pourquoi nous rejoindre ?Une culture forte et bienveillante, et une grande place laiss√©e √† la libert√©Les avantages d'un grand groupe (Participation, Int√©ressement, Plan d'√©pargne... avec abondement, cong√©s d'anciennet√©)Un accompagnement personnalis√© tout au long de votre carri√®re avec des perspectives vari√©es et ambitieusesLa diversit√© de nos clients et nos projets d'envergureUne approche pragmatique, qui r√©pond aux vrais enjeux des entreprises.Votre r√¥le, vos comp√©tences : Vous ma√Ætrisez au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (SQL, Scala, Python, Java)Vous √™tes passionn√© par le Big Data et le Machine LearningVous concevez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©esVous configurez des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, majoritairement dans le cloud (Google Cloud Platform, Azure, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks).Votre profil : Vous comptez au moins 2 ans d‚Äôexp√©rience (au sein d‚Äôune ESN ou chez un int√©grateur) en conseil client√®le et une solide culture technologique, un bon niveau d‚Äôanglais.¬´ CAPGEMINI, Entreprise handi accueillante, conform√©ment √† la norme ANFOR NF X50-783, est √©galement signataire de la charte de la diversit√© en entreprise ¬ª


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),MERITIS,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3797191392?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=%2BNDWcADHGzebekvZquYTIg%3D%3D&position=5&pageNum=0&trk=public_jobs_jserp-result_search-card,"Descriptif de l‚Äôentreprise et du poste :Meritis est un cabinet de conseil, pilotage et d√©veloppement IT fond√© en 2007 pr√©sent sur tout le territoire fran√ßais.Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d‚Äôavance.Nous accompagnons nos clients dans l‚Äôint√©gralit√© de leurs besoins √† travers de nombreux domaines d‚Äôexpertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybers√©curit√© ou encore Agilit√©.Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des T√©l√©communications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.Fort de nos valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, nous comptons aujourd‚Äôhui plus de 900 collaborateurs.Proches de nos collaborateurs, nous les accompagnons de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise. Certifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.En tant que DevOps S√©nior (H/F), vous int√©grerez une entreprise dynamique √©voluant dans un contexte international et un environnement de travail agile.Vos missions chez notre client seront :Collecte, nettoyage transformation et analyse des donn√©es via diff√©rents sources, outilsConception des bases de donn√©es pour stocker efficacement les informationsD√©veloppement d'algorithmes et de proc√©dures informatiques pour veiller √† la qualit√© des donn√©esS√©curit√© des donn√©es : Prot√©ger les informations sensiblesVisualisation des donn√©es : Cr√©er des graphiques et des tableaux pour rendre les r√©sultats compr√©hensiblesConfiguration de r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, sur site ou dans le cloud (AWS, Google Cloud, Microsoft Azure)Travailler avec d'autres √©quipes pour r√©pondre aux besoins de l'entrepriseVeille technologiqueEnvironnement technique :Frameworks : Spark, Hadoop, KafkaLangages de programmation : Scala, Python, SQL, Java,..Data visualisation : PowerBI, Qliksense...Bases de donn√©es : Oracle, PosgresSQL, NoSQL, Teradata,...Outils DevOps : Jenkins, Docker, KubernetesCloud : GCP, AWS, AzureCe poste est-il fait pour vous ?Vous avez un dipl√¥me d‚Äôing√©nieur (Bac+5)Vous avez une exp√©rience d'au moins trois ans sur ce m√©tierVous √™tes √† l'aise sur DataikuVous ma√Ætrisez l'anglais aussi bien √† l'oral qu'√† l'√©critCe poste est uniquement ouvert √† du CDI.Pr√™t.e √† d√©marrer de nouveaux challenges dans une structure o√π il fait bon vivre ?√ätre consultant.e chez Meritis c‚Äôest :Evoluer dans un environnement o√π l‚Äôapprentissage est favoris√© : formations certifiantes, e-learning, meetUp, concours de code, parcours d‚Äô√©volutions etc.Faire partie de communaut√©s d‚Äôexperts qui partagent leurs savoirs et exp√©riencesAvoir le choix de sa missionB√©n√©ficier d‚Äôun r√©seau de clients qui nous font confiance et que nous √©toffons d‚Äôann√©es en ann√©esTravailler dans un environnement convivial avec de nombreux √©v√©nements : d√©jeuners, afterworks, teambuilding, soir√©es annuelles etc.Rejoindre une entreprise o√π il fait bon vivre, certifi√©e ¬´ Great Place to Work ¬ªNos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis est engag√©e en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap.Nous sommes √† votre √©coute. Vous pouvez contacter ethiquegroup@meritis.fr si vous pensez √™tre victime ou t√©moin d‚Äôune discrimination.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data engineer H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3798407382?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=3ZPCvpRwsMLz7r7pp%2FuAmA%3D%3D&position=6&pageNum=0&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre  Informations g√©n√©rales  Entit√© de rattachement  Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste M√©tier M√©tier AS (Application Services) - D√©veloppement Intitul√© du poste Data engineer H/F Contrat CDIDescription De La MissionDans le cadre de son d√©veloppement, Inetum recrute un Data Engineer (H/F) pour sa branche Applications Services.Vous interviendrez chez l‚Äôun de nos clients sur des projets BI et/ou Big Data en m√©thode agile.Le Data Engineer sera en charge deApporter une expertise en Data permettant la manipulation de donn√©esAccompagner nos clients dans la r√©alisation de projets dans un contexte Big Data et CloudParticiper √† r√©unions permettant de valider les principes techniques et algorithmiques pour des projets Profil De formation Bac +5, vous justifiez d'une exp√©rience d‚Äôau moins 4 ans dans le domaine de la Data. Vous avez √©volu√© dans le monde du d√©veloppement (Python, Spark, Aws...)Vous √™tes capable de prendre des initiatives, autonome, rigoureux(se) et vous savez vous adaptez √† de nouveaux environnements.Vous appr√©ciez le travail en √©quipe dans un contexte agile, et aimez relever des d√©fis.La ma√Ætrise de l‚Äôanglais est un vrai plusLocalisation du poste Localisation du poste France, Ile-de-France, 93 Seine-Saint-Denis Ville saint ouenCrit√®res candidat Niveau d'√©tudes min. requis Bac+5 Niveau d'exp√©rience min. requis Plus de 2 ans Langues Anglais (Professionnel)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Ippon Technologies,"Bouches-du-Rh√¥ne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3800692629?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=D68LwkttRqUPnoiWE1VXeg%3D%3D&position=7&pageNum=0&trk=public_jobs_jserp-result_search-card,"IPPON l‚Äô√©nergie du collectif au service de la technologie positive !IPPON est une soci√©t√© de conseil et d‚Äôexpertise sp√©cialis√©e dans des solutions digitales innovantes.Nos √©quipes dans le monde accompagnent les organisations dans la transformation d'id√©es innovantes en solutions logicielles de haute qualit√© avec un focus particulier sur le Time To Market.Nos valeurs : PERFORMANCE : vous permettre de monter en comp√©tences avec nos formations internes : programme de mentoring BlackBeltPARTAGE : communaut√© d‚Äôexpertises, meetups internes & externes, blog techniqueSOLIDARIT√â : la fondation IPPON vient en aide au plus d√©munis et accompagne les anciens sportifs dans leur reconversionNotre culture d‚Äôentreprise :BIENVEILLANCE : la transparence et la confianceEXCELLENCE : le test & learn, n‚Äôayons pas peur de bousculer l‚Äôexistant !Le job :intervenir sur les data platforms de nos clients pour d√©velopper de nouveaux pipelines de donn√©es (ingestion, traitement, exposition),travailler en collaboration avec les m√©tiers et les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©gration continue, scalabilit√© des mod√®les, craftsmanship etc...),d√©ployer des infrastructures cloud full infra-as-code (Terraform, CloudFormation),participer aux √©v√®nements internes √† la communaut√© data (BBL, webinar, datap√©ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups),capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.Le profil recherch√© : Vous √™tes de temp√©rament curieux, force de proposition, vous avez le sens du partage, l‚Äôenvie de vous am√©liorer en continue et de participer activement √† une communaut√© data pleine de projets.De formation Bac+5 avec une premi√®re solide exp√©rience en data engineering, vous ma√Ætrisez quelques technologies parmi les suivantes :un framework de calcul distribu√© tel que Spark, Storm, Flinkun ou plusieurs langages de programmation (Python, Scala, Java...)diff√©rents syst√®mes de stockage de donn√©es (SQL ou NoSQL) et bien s√ªr le langage SQL. la connaissance de Snowflake est bienvenueun framework de streaming de donn√©es tel que Kafka ou Amazon Kinesisune exp√©rience sur les technologies Cloud : AWS, GCP, AzureLe delivery et les projets en production faisant partie de notre ADN, vous √™tes capable de livrer du code de qualit√© dans des environnements agiles.Les + du job :travailler avec une √©quipe o√π vous pourrez apporter vos propres id√©esdevenir ceinture noire en Data gr√¢ce √† notre programme d‚Äôaccompagnement de carri√®re Blackbelt ! (formations, certifications AWS/GCP/Azure, mentoring, coaching)une √©volution de carri√®re adapt√©e √† votre exp√©rience et vos souhaitsune charte de t√©l√©travail (2 jours par semaine en situation ‚Äúnormale‚Äù)la possibilit√© de s‚Äôengager aupr√®s de notre Fondation pour participer √† la r√©duction de la fracture num√©rique au travers d‚Äôactions sociales et humanitaires en France et dans le mondeSi vous vous retrouvez dans ce profil, alors vous vous √©panouirez sans aucun doute au sein de la team data !En attendant voici le live d‚Äôun de nos projets data : https://www.youtube.com/watch?v=47hMhZWaavY&t=5sNous sommes √† la recherche de passionn√©s qui aiment apprendre, partager et qui ont de l‚Äôambition.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H en CDI,La Banque Postale Consumer Finance,"St.-Denis, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-en-cdi-at-la-banque-postale-consumer-finance-3794947500?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=0XKCVPKlepHtRJnYDbNMIA%3D%3D&position=8&pageNum=0&trk=public_jobs_jserp-result_search-card,"Rejoindre La Banque Postale Consumer Finance, c‚Äôest participer √† un projet ambitieux : celui de devenir l‚Äôun des acteurs incontournables du Cr√©dit √† la consommation !Au quotidien, nous nous appuyons sur des pratiques responsables, p√©dagogiques et solidaires que ce soit en mati√®re d‚Äôoffres et d‚Äôaccompagnement de nos clients ; ou au travers de notre politique de d√©veloppement des comp√©tences de nos collaborateurs !Vous avez le go√ªt du challenge et l‚Äôenvie de participer √† une aventure humaine ?N‚Äôattendez plus, rejoignez-nous !Rattach√© au responsable p√¥le data, vos principales missions en tant que data Engineer :Administration, exploitation technique et gestion de l‚Äôenvironnent SAS ; et de l‚Äôenvironnement python et d√©veloppements machine learning,Maintenance √©volutive et corrective et suivi des applications et bases de donn√©es sas,Gestion habilitations et suivi de circuit des habilitations,Participation aux projets LBPCF en lien avec les donn√©es,Assurer une bonne qualit√© des donn√©es et s√©curisation d‚Äôacc√®s aux environnements,Support aux utilisateurs sas et python.Descriptions des activit√©s principales:- Comprendre, analyser et proposer des solutions techniques r√©pondant aux besoins des divers clients des donn√©es de p√¥le data de la direction Score et Data Science ;- Maintenance, exploitation et suivi des applications et bases de donn√©es sous sas ;- Participation aux diff√©rentes phases de conception des datamarts utilisateurs et recette avec les √©quipes de dwh LBPCF (DWH BIRD/oracle) ;- Contr√¥le qualit√© des donn√©es et s√©curisation d‚Äôacc√®s aux donn√©es ;- Export de donn√©es, requ√™tage et production de reportings et tableaux de bord n√©cessaires au pilotage de l‚Äôactivit√© ;- Cr√©ation d‚Äôoutils de suivi et pilotage des traitements de production ;- Pilotage et mise en ≈ìuvre de projets en lien avec les data de la direction score et data science et en particulier la mise en place d‚Äôun environnement industrialis√© big-data ;- Administration et maintenance de la plateforme SAS et les environnements python ;- R√©f√©rent technique SAS et python.Votre profil:Bac + 4/5 ing√©nieurMaitrise SASVous disposez d'une exp√©rience d'au moins 3 ans √† un poste similaire.Vos comp√©tences :- Solide connaissance en data architecture et traitement des donn√©es ;- Maitrise de l‚Äôenvironnement SAS (de pr√©f√©rence 9.4) et de sql oracle (Une premi√®re exp√©rience sur la plateforme SAS Viya serait appr√©ci√©e) ;- Solide connaissance de l‚Äôenvironnement python et big-data (Une premi√®re exp√©rience sur la plateforme Dataiku serait appr√©ci√©e) ;-Maitrise de syst√®me d‚Äôexploitation UNIX et Windows (scripting, ksh, sh, bat) ;- Solide connaissance en qualit√©, s√©curit√© et protection des donn√©es (RGPD) ;- Maitrise de la micro-informatique et bureautique ; Vos aptitudes et qualit√©s Autonomie, organisationPoste bas√© √† la Plaine Saint-Denis (93) ‚Äì accessible RER D ou RER BDate de prise de poste : D√®s que possible AvantagesSalaire fixe + part variable + participationAcc√®s parking entreprise, restaurant d‚Äôentreprise2 jours de t√©l√©travail par semaineOffres CSERemboursement du Titre de transport √† hauteur de 75%""Banque citoyenne, La Banque Postale s'engage en faveur de la diversit√© et de l'√©galit√© des chances pour donner acc√®s √† tous ses m√©tiers sans discrimination de genre, d'origine sociale ou culturelle, d'orientation sexuelle ou de handicap. Rejoignez notre Groupe et construisons ensemble La Banque Pr√©f√©r√©e des Fran√ßais.""


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Windows'], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),MERITIS,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3796119551?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=Y%2F9b0Xy8efhW%2Bj6Fh8OU6g%3D%3D&position=9&pageNum=0&trk=public_jobs_jserp-result_search-card,"Descriptif de l‚Äôentreprise :‚ÄãMeritis est un cabinet de conseil, pilotage et d√©veloppement IT fond√© en 2007 pr√©sent √† Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bient√¥t sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d‚Äôavance.‚ÄãNous accompagnons nos clients dans l‚Äôint√©gralit√© de leurs besoins en transformation num√©rique √† travers de nombreux domaines d‚Äôexpertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybers√©curit√© ou encore Agilit√©.‚ÄãIntervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des T√©l√©communications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.‚ÄãFort de nos valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, nous comptons aujourd‚Äôhui plus de 900 collaborateurs.‚ÄãNous mettons un point d‚Äôhonneur √† √™tre proche de nos collaborateurs et √† les accompagner de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise. Certifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.‚ÄãLes missions qui vous attendent :Au sein du p√¥le Data , vous int√©grerez les √©quipes qui sont responsables de la collecte des donn√©es, vous serez en charge de :R√©cup√©rer, organiser et mettre en forme la donn√©eD√©velopper de nouvelles fonctionnalit√©sR√©aliser les tests techniquesFaire √©voluer l'architectureProduire la documentationCe poste est-il fait pour vous ?‚ÄãVous avez un dipl√¥me d'ing√©nieur ou √©quivalent Bac +5.Vous avez un minimum de 3 ans d'exp√©rience professionnelle en tant Data Engineer.Vous disposez de plus de 3 ans d'exp√©rience en d√©veloppement JavaVous √™tes autonome, rigoureux.se et organis√©.eVous parlez couramment anglaisCe poste est uniquement ouvert √† du CDI.Outils / technologies :JavaSparkSQLHadoopTeradataDevenir collaborateur Meritis c‚Äôest :‚ÄãDes parcours professionnels sur mesure (√©volution de carri√®re, formations adapt√©es, mentoring‚Ä¶) ;‚ÄãAvoir le choix de sa mission et un accompagnement personnalis√© tout au long de votre carri√®re ;‚ÄãEvoluer dans un environnement o√π l‚Äôapprentissage est favoris√© : formations certifiantes, e-learning, meetUp, concours de code, parcours d‚Äô√©volutions etc ;‚ÄãFaire partie de communaut√©s d‚Äôexperts qui partagent leurs savoirs et exp√©riences au sein de nos centres de comp√©tences ;‚ÄãUn environnement convivial avec de nombreux √©v√©nements festifs (soir√©e annuelle, s√©minaires & teambuiding, d√©jeuners et afterworks‚Ä¶) ;‚Äã‚ÄãMeritis est engag√©e dans la Responsabilit√© Soci√©tale des Entreprises. Nous valorisons notre impact positif sur la soci√©t√© et l'environnement. Notre d√©marche RSE guide chacune de nos actions pour promouvoir l'√©quit√©, la durabilit√© et le bien-√™tre de nos collaborateurs. Rejoignez-nous pour √™tre partie prenante de cette d√©marche responsable, o√π chacun de nos talents contribue √† construire un avenir meilleur.Nos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis s'implique en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Ippon Technologies,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-ippon-technologies-3792840687?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=5aDCz8RKap3omVgMbWeKrg%3D%3D&position=10&pageNum=0&trk=public_jobs_jserp-result_search-card,"Le contexte - la Practice DataEnvie de rejoindre la communaut√© data la plus dynamique de France ? Notre sp√©cialit√© est de construire des data platform dans le Cloud public avec les meilleurs technos du moment : Snowflake, Databricks, Matillion, DBT.Membre de la Practice Data, la.e futur.e Data Engineer sera int√©gr√©.e √† nos √©quipes de conseil et sera suivi par un.e mentor qui l‚Äôaidera √† monter en comp√©tences.Pour s‚Äôimpliquer dans la Practice c‚Äôest tr√®s simple, il suffit de participer aux √©v√©nements comme les datap√©ros ou des data lunchs, puis pourquoi pas de proposer tes propres sujets.Votre champs d‚ÄôexpertiseIntervenir sur les data platforms de nos clients pour d√©velopper de nouveaux pipelines de donn√©es (ingestion, traitement, exposition).Travailler en collaboration avec les m√©tiers et les data scientists pour leur fournir un support √† l‚Äôindustrialisation de leurs travaux (tests, int√©gration continue, scalabilit√© des mod√®les, craftsmanship etc‚Ä¶)D√©ployer des infrastructures cloud full infra-as-code (Terraform, CloudFormation).Participer aux √©v√®nements internes √† la communaut√© data (BBL, webinar, datap√©ro interne, meetup, blog, dojos) et externes (Salon du Big Data, GCP Summit, Spark Summit, AWS Summit, Devoxx, workshop partenaire, meetups)Capitaliser sur les missions et les diff√©rents √©v√®nements de la communaut√© au travers d‚Äôarticles de blogs, REX, BBL interne.Vos connaissances Un framework de calcul distribu√© tel que Spark, Storm, Flink.Un ou plusieurs langages de programmation (Python, Scala, Java...)Diff√©rents syst√®mes de stockage de donn√©es (SQL ou NoSQL) et bien s√ªr le langage SQL.La connaissance de Snowflake est bienvenue ;-)Un framework de streaming de donn√©es tel que Kafka ou Amazon Kinesis.Une exp√©rience sur les technologies Cloud : AWS, GCP, AzureLe delivery et les projets en production faisant partie de notre ADN, vous √™tes capable de livrer du code de qualit√© dans des environnements agiles.De plus en plus de nos projets se font en remote avec des clients du monde entier, il devient n√©cessaire d‚Äô√™tre √† l‚Äôaise en Anglais.Ippon technologies c‚Äôest aussi :üëçB√©n√©ficier d'un suivi de proximit√© r√©alis√© par votre manager technique : points r√©guliers pour votre suivi en mission, votre formation et votre √©volution de carri√®re‚úåÔ∏èRejoindre une entreprise o√π les valeurs du sport sont nos leitmotiv : d√©passement de soi, travail en √©quipe, bienveillance.üóíÔ∏èApprendre via notre programme de formation BlackBelt : https://bit.ly/3ByqcILüòÅTravailler en pair programming ou avec un.e mentor pour gravir les √©chelons !üí™Pouvoir participer √† une aventure humaine au sein de notre Fondation Ippon pour r√©duire la fracture num√©rique dans le monde !ü§ùParticiper √† nos ap√©ros et divers √©v√®nements internes pour consolider la coh√©sion d‚Äô√©quipeEt apr√®s ?Et oui alors ? Que se passe-t-il une fois que vous √™tes convaincu d‚Äôavoir lu l‚Äôoffre d‚Äôemploi qui vous correspond bien ?Nous vous proposons de prendre contact et de nous rencontrer !Les Next Steps :1 call RH1 Entretien RH1 Entretien TechniqueSi le match est bon des deux c√¥t√©s : Hadjim√© ! Vous vous lancerez sur le tatami Ippon !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - DataBricks,Visian,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-databricks-at-visian-3796114769?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=a4ndLcO6egs5x%2Bl1DFaJTQ%3D%3D&position=11&pageNum=0&trk=public_jobs_jserp-result_search-card,"Opportunit√© CDI - DATA EngineerResponsabilit√©s :En tant que Data Engineer chez Visian, vous serez responsable du d√©veloppement, de la gestion et de l'optimisation de nos pipelines de donn√©es. Vous collaborerez √©troitement avec nos √©quipes multidisciplinaires pour garantir une gestion efficace des donn√©es, de l'acquisition √† l'analyse. Les principales responsabilit√©s incluent :Concevoir, d√©velopper et maintenir des pipelines de donn√©es robustes.Utiliser Python et DataBricks pour cr√©er des solutions efficaces et √©volutives.Travailler en √©troite collaboration avec les √©quipes de conception produit, d'innovation et de gestion de projet IT.Optimiser les performances des pipelines existants et r√©soudre les probl√®mes li√©s aux donn√©es.Collaborer avec les Data Scientists pour assurer une int√©gration fluide des mod√®les dans les pipelines de donn√©es.Exigences :Minimum 3 ans d'exp√©rience en tant que Data Engineer.Dipl√¥me d'une √©cole d'ing√©nieur ou √©quivalent.Excellente ma√Ætrise de Python et de l'√©cosyst√®me des biblioth√®ques de donn√©es.Exp√©rience pratique avec DataBricks.Bonne compr√©hension des meilleures pratiques en mati√®re de gestion de donn√©es.Comp√©tences avanc√©es en anglais et en fran√ßais (√† l'oral et √† l'√©crit).


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer H/F,Extia,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3599188121?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=jrv0hePZQCkiLs3%2Bc%2BxczA%3D%3D&position=12&pageNum=0&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez Extia !Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e depuis 2012 par le label Great Place to Work¬Æ.Chez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !D'abord quiVous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple,Vous maitrisez les bases de l‚Äôanalyse statistique,Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,Vous maitrisez Spark et HadoopVous √™tes familiaris√© avec l‚Äôenvironnement Linux,Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts.Ensuite quoiVous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes.Vous serez en charge de :Participer √† la d√©finition des besoins et √† la r√©daction des User Stories,Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e,Concevoir et construire des architectures de donn√©es,Int√©grer des sources de donn√©es,Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives,Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Exp√©riment√© (F/H) - I&D Toulouse,Capgemini,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-exp%C3%A9riment%C3%A9-f-h-i-d-toulouse-at-capgemini-3802713821?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=XToYpk2PNzN55aBGJUeAkQ%3D%3D&position=13&pageNum=0&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques motsCapgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans pr√®s de 50 pays. Partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie, le Groupe est guid√© au quotidien par sa raison d‚Äô√™tre : lib√©rer les √©nergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d‚Äôexp√©rience, Capgemini est reconnu par ses clients pour r√©pondre √† l‚Äôensemble de leurs besoins, de la strat√©gie et du design jusqu‚Äôau management des op√©rations, en tirant parti des innovations dans les domaines en perp√©tuelle √©volution.  Insights & Data en quelques motsDans ce contexte, notre practice Insights & Data (I&D) s‚Äôappuie sur une √©quipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette √©quipe combine des comp√©tences m√©tiers avec une forte expertise data, analytique et d‚Äôintelligence artificielle pour mettre en ≈ìuvre des solutions qui visent √† am√©liorer la gestion et la valorisation des donn√©es. Pour renforcer les √©quipes d‚ÄôI&D Toulouse, nous recherchons actuellement un(e) Data Engineer Exp√©riment√©(e).  Votre quotidienVous concevez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©esVous configurez des r√©f√©rentiels de donn√©es √† la pointe de la technologie dans des environnements distribu√©s, majoritairement dans le cloud (Google Cloud Platform, Azure Databricks, AWS) et/ou en environnement Hadoop (distribution MapR, Cloudera, Hortonworks)Vous construisez des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©e  Votre profilDipl√¥m√©(e) de Bac+5 en informatique, vous comptez au moins 3 ans d‚Äôexp√©rience (au sein d‚Äôune ESN ou chez un int√©grateur) en conseil client√®le et une solide culture technologique, un bon niveau d‚Äôanglais.Vous √™tes passionn√© par le Big Data et le Machine Learning.Vous maitrisez au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es(Java, Python, Scala).  Les plus du posteEn plus de votre quotidien, vous pourrez entreprendre, √™tre form√©, utiliser nos incubateurs pour innover, et vous dessiner une trajectoire de carri√®re personnalis√©e. Vous int√©grerez une √©quipe ambitieuse, fun et dynamique ! Une culture forte et bienveillante, et une grande place laiss√©e √† la libert√©Des clients vari√©s, leaders de leur secteurUne approche pragmatique, qui r√©pond aux vrais enjeux des entreprisesUn v√©ritable accompagnement dans l‚Äô√©volution de votre carri√®reUne √©quipe √† taille humaine, en renouvellement et en hyper croissanceUne priorit√© accord√©e au d√©veloppement des collaborateurs ‚Äì un management qui aide les √©quipes √† progresser, √† r√©ussir  C‚Äôest quoi la suite ?Nous vous proposons un processus de recrutement court, un accompagnement personnalis√©, une √©volution qui s‚Äôadapte √† vous. ¬´ Capgemini, Entreprise handi accueillante, conform√©ment √† la norme AFNOR NF X50-783, est √©galement signataire de la charte de la diversit√© en entreprise ¬ª


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,Valeuriad,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-valeuriad-3741223009?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=5QV40J6Ll8hDCdLYnsVvwA%3D%3D&position=14&pageNum=0&trk=public_jobs_jserp-result_search-card,"Rejoins la Team Data cr√©√©e par Nicolas Greffard, Docteur en Intelligence Artificielle, d√©j√† compos√©e de 20 Data Engineers et Datascientists talentueux üòçNous recherchons de nouvelles p√©pites pour rejoindre notre √©quipe de choc et r√©pondre aux multiples probl√©matiques Big Data de nos clients nantais mais √©galement contribuer √† nos projets de R&D et travailler sur des conf√©rences incroyables (DevFest, Salon de la Data) ü§©Ta future mission si tu l'acceptes üòâNous te proposons d'intervenir au sein de nos grandes DSI clientes, sur des sujets de collecte, d'alimentation et de transformation de donn√©es sur un environnement Big Data Apache (Hadoop, Spark, Ambari, Hive) sur les technologies suivantes : Hadoop, Apache Ambari, RabbitMQ, Java, Scala, YarnApplication, Teradata, Squoop, Kudu, Hue, Hive, Impala, Dataiku, Flink, Kafka, Spark, Kibana, Oozie, Git, GitLabCI, Jenkins, AWS. Le job en d√©tail ü§© √âtude, conception et r√©alisation de traitements Big Data ; √âchange avec les architectes, les PO et PPO, les d√©veloppeurs et la gouvernance de donn√©es ; Exploration des donn√©es et des usages des utilisateurs avec Impala ; Import de donn√©es (SFTP, Kafka, RabbitMQ) ; Alimentation du cluster Hadoop via des composants d√©velopp√© en Java avec le Framework Spark sur IntelliJ ; Utilisation d‚ÄôApache Ambari pour g√©rer et surveiller un cluster Hadoop, visualisation des jobs en cours via YarnApplication et des flux Oozie ; Collecte des donn√©es depuis Teradata via l‚Äôoutil Sqoop dans une base de donn√©es Hive ; Transformation des donn√©es avec Spark (HDFS, Hive, Kafka, Hbase, Phoenix) ; Utilisation de Apache Kudu afin d'optimiser les requ√™tes utilisateurs sur les donn√©es chaudes ; Exposition de donn√©es sur Dataiku pour la cr√©ation de mod√®le de DataScience ; R√©alisation en Java ‚Äì Flink pour g√©rer les traitements complexe et volumineux ; Gestion de configuration sous Git avec GitLab ; Int√©gration continue avec Jenkins et Sonar ; Lecture de fichier parquet depuis un r√©pertoire S3 sous AWS ; Requ√™tage de bases de donn√©e depuis l'outil Athena d'AWS ; Transformation des donn√©es et calcul d'indicateurs sous Hive ; Utilisation de Oozie pour l‚Äôordonnancement de flux ; Utilisation de Kibana pour visualiser et mesurer la volum√©trie de traitements quotidien et en streaming.Pourquoi choisir Valeuriad ? üòäEn plus d‚Äô√™tre aujourd‚Äôhui un acteur nantais reconnu de l‚Äôexpertise IT, nous nous inscrivons depuis notre cr√©ation dans une d√©marche d'entreprise Opale et Holacratique, o√π l'ensemble de nos prises de d√©cisions et projets sont r√©alis√©s par et avec l'ensemble de nos 119 co√©quipiers üí™Rejoindre Valeuriad, c'est pouvoir s'investir dans la co-construction de l'entreprise : Par un r√¥le, avec une fiche de poste et un temps d√©di√© (gestionnaire des Ci‚Äôs, porteur des partenariats √©coles, organisateur d‚Äô√©v√©nements, PO des projets internes, gestion de l'Acad√©mie Valeuriad‚Ä¶). Par les projets strat√©giques (200 jours mis √† disposition pour les co√©quipiers chaque ann√©e) pour cr√©er et faire grandir des projets structurants (cr√©ation de nouveaux avantages √† l'anciennet√©, cr√©ation d'indicateurs mensuels pour √™tre toujours plus transparents, m√©c√©nat de comp√©tences pour des associations caritatives...). Par les projets cagnottes (150‚Ç¨ par co√©quipiers et par an) pour r√©aliser des projets collaboratifs qui te tiennent √† c≈ìur avec d'autres Valeurieux (d√©couverte du c√©cifoot, challenge √©cologique, challenges sportifs pour des dons √† des associations humanitaires, borne photo...). Par les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont propos√©s par les diff√©rents porteurs de projets et sont ouverts √† tous les volontaires.Mais avant-tout nous sommes une √©quipe soud√©e, des coll√®gues qui appr√©cient passer du temps ensemble lors de nos soir√©es hebdomadaires et se cr√©er des souvenirs inoubliables ü§© C'est pour √ßa que chez Valeuriad, le plus important pour nous reste le savoir-√™tre : des passionn√©s, du dynamisme, des sourires, de l'√©coute et le sens de la f√™te üòâ
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': ['HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Wewyse,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-wewyse-3703684760?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=Hy1kpmgmJ8S6bhGoUiBeDg%3D%3D&position=15&pageNum=0&trk=public_jobs_jserp-result_search-card,"Wewyse est un cabinet de conseil sp√©cialis√© en Data et en Intelligence Artificielle. C'est aussi et surtout une communaut√© de passionn√©s partageant l'ambition de grandir ensemble et d'ouvrir le champ des possibles dans leurs domaines.Si vous pensez que la Data et l'Intelligence Artificielle ont beaucoup √† offrir au monde de demain, et si vous souhaitez apporter votre contribution √† ce monde, avec humilit√© et enthousiasme, alors vous √™tes un Wyser en puissance.√ätre Data Engineer chez Wewyse c'est :Int√©grer une communaut√© d‚Äôexperts Data passionn√©s.Recevoir et partager de la connaissance et des savoirs-faire lors de nombreux √©v√®nements.Intervenir chez des clients pour y porter l'expertise Wewyse dans des contextes et des secteurs vari√©s.Participer √† des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires acad√©miques et des start up.Viser l‚Äôexcellence des d√©veloppement en s‚Äôappuyant sur le Software craftsmanshipConcevoir des architectures logicielles modernes.Penser DevOps pour l‚Äôautomatisation des d√©ploiements et la continuit√© des services.√ätre encourag√©, conseill√© et accompagn√© dans un parcours de formation adapt√© √† vos ambitions professionnelles.Faire partie de la famille Wemanity avec ses √©v√®nements et ses multiples opportunit√©s de carri√®re.Ce que nous aimons :Les personnalit√©s ouvertes, curieuses, ambitieusesLes langages Scala, Python et JavaLe cloud : AWS, GCP, AzureLes √©cosyst√®mes : Hadoop et SparkLa conteneurisation : Docker et KubernetesLes m√©thodes AgilesLe SQL et le NoSQL .L'approche DevOps : Jenkins, Ansible et TerraformLe versionning : GitL'anglaisVous vous reconnaissez ? Alors n'h√©sitez pas √† postuler !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer,MERITIS,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-meritis-3767627899?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=pgziwUHwCaIkG4JLUGp6Gg%3D%3D&position=16&pageNum=0&trk=public_jobs_jserp-result_search-card,"Descriptif de l‚Äôentreprise :‚ÄãMeritis est un cabinet de conseil, pilotage et d√©veloppement IT fond√© en 2007 pr√©sent √† Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bient√¥t sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d‚Äôavance.‚ÄãNous accompagnons nos clients dans l‚Äôint√©gralit√© de leurs besoins en transformation num√©rique √† travers de nombreux domaines d‚Äôexpertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybers√©curit√© ou encore Agilit√©.‚ÄãIntervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des T√©l√©communications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.‚ÄãFort de nos valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, nous comptons aujourd‚Äôhui plus de 900 collaborateurs.‚ÄãNous mettons un point d‚Äôhonneur √† √™tre proche de nos collaborateurs et √† les accompagner de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise.Certifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.‚ÄãNous recherchons un Data Engineer Spark/Scala H/F, ayant au moins 4 ans d'exp√©rience, pour intervenir chez notre client leader du secteur du retail, pour les accompagner dans l'√©tablissement d'une strat√©gie de gestion de donn√©es ambitieuse pour le groupe et ses marques en d√©veloppant des donn√©es et des pipelines de donn√©esVos missions :Cr√©er et maintenir une architecture optimale de pipeline de donn√©es Assembler de grands ensembles de donn√©es complexes qui r√©pondent aux besoins fonctionnels / non fonctionnels de l‚ÄôentrepriseConstruire l‚Äôinfrastructure requise pour optimiser l‚Äôextraction, la transformation et le chargement de donn√©es provenant de sources tr√®s diverses au moyen des technologies ¬´ big data ¬ª SQL et AWS Travailler avec les Data Scientists et l‚ÄôIT pour r√©soudre les probl√®mes techniques li√©s aux donn√©es et r√©pondre √† leurs besoins d‚Äôinfrastructure de donn√©esTravailler avec les experts en analyse de donn√©es pour am√©liorer la fonctionnalit√© des syst√®mes de donn√©esCe poste est √† pourvoir en CDIEnvironnement technique :Framework : SparkLangages de programmation : Scala, Python, SQLBases de donn√©es : NoSQL, Teradata,...Cloud : AWS (EC2, EMR, RDS, Redshift)Ce poste est-il fait pour vous ? :Vous √™tes dipl√¥m√© d'un Bac +5 et justifiez d'au moins 4 ans d'exp√©rience en tant que Data EngineerVous avez de l'exp√©rience sur les outils Python, SQL Server et avez de l'exp√©rience sur GCPVous parlez anglais courammentVous avez une passion pour le domaine de la Data et souhaitez monter en comp√©tencesVos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis est engag√©e en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez √™tre victime ou t√©moin d‚Äôune discrimination, vous pouvez contacter ethiquegroup@meritis.fr. ¬ª


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),FBD Group,"Tremblay-en-France, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-fbd-group-3804327995?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=us0%2BhOZNshnWJSPoK%2BMzTw%3D%3D&position=17&pageNum=0&trk=public_jobs_jserp-result_search-card,"Vous aimez :Conduire le changement dans le secteur de la distributionPartager les challenges d‚Äôune entreprise agile en forte croissanceL‚Äôesprit d‚Äô√©quipe et l‚Äôambiance qui r√®gnent dans un groupe √† taille humaine (250 collaborateurs)L‚Äôinnovation, le num√©rique et les nouvelles technologies au service de l‚Äôexp√©rience clientLa gestion de projet Vous aimerez accompagner l‚Äôentreprise dans son √©volution en concoctant de belles histoires.FBD recrute dans le cadre d'un CDI, un(e) Data Engineer, pour sa direction Achats/Produits.Rattach√©(e) √† la Directrice Achats et d√©veloppement de l‚Äôoffre vos missions seront les suivantes :Garant(e) de la qualit√© des donn√©es catalogues produits et du respect des processAccompagnement dans le quotidien des gestionnaires (aide, suivi d‚Äôactivit√©, gestion des priorit√©s, contr√¥le des anomalies, formations ..) Gestion des projets √©volution, am√©lioration continue, cr√©ation de programmes et process utilis√©s par la base de donn√©es (cdc, plan de recette, r√®gles de gestion, recettage, formation utilisateurs, cr√©ation et mises √† jour des modes op√©ratoires) Relation et coordination avec les services achats, produits, IT, fournisseurs Participer aux diff√©rents projets lanc√©s par le groupe ou initi√©s en interne.Issu(e) d‚Äôune formation sup√©rieure en data sciences, big data, ou en statistiques. Vous avez une exp√©rience confirm√©e en gestion base de donn√©es dans le retail (minimum 5 ans).Vous avez une bonne maitrise des outils techniques et bureautique, plus particuli√®rement d'Excel et de ses formules, vous avez √©galement :un grand sens de la rigueur et de l'organisationun esprit d'analyse et de synth√®seune bonne anticipation et r√©activit√©Comp√©tences :Coordination, pilotage, suivi des process et projets. Anglais professionnel/ courant souhait√©. Pourquoi nous rejoindre ?La brigadeUne Direction qui accorde une attention particuli√®re au bien √™tre des collaborateurs : Nous sommes Great Place to Work !Les ingr√©dientsVous aurez tous les ustensiles n√©cessaires pour votre recette (ordinateur, t√©l√©phone portable professionnel etc.)Une r√©mun√©ration fixe + Prime annuelle li√©e √† vos objectifs + Prime de participationLes assaisonnementsUne mutuelle familiale prise en charge √† 100% par le Groupe FBDL‚Äôacc√®s √† un Restaurant Interentreprises2 jours de t√©l√©travail par semaine sans condition d‚Äôanciennet√©Des locaux √† Roissy √† 200m du RER B et une annexe √† Paris 9√®meUn r√©seau social Entreprise pour vous mettre au courant et participer √† la vie d‚ÄôentrepriseLa cerise sur le g√¢teauBoissons chaudes et fruits Bio √† disposition pour bien commencer la journ√©e !Des activit√©s tous les mois pour les collaborateurs, pr√©par√©s par notre service Com Interne + 2 √©v√®nements groupe par an. En cuisine, le meilleur reste √† inventer ! Nous vous attendons !
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3800671866?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=hdNEqUve3hPOCNwpe1O%2BoQ%3D%3D&position=18&pageNum=0&trk=public_jobs_jserp-result_search-card,"Big Data, Data Science, Data analyse, Data architecture ... √áa n‚Äôa pas de secret pour vous ?Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.Si vous souhaitez int√©grer nos √©quipes √† Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int√©resser.En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement, de la gestion et de l'int√©gration des syst√®mes bas√©s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r√¥le implique la mise en place d'architectures √©volutives et hautement disponibles pour r√©pondre aux besoins de traitement et de stockage de donn√©es de l'entreprise.Fonctions et responsabilit√©sVos responsabilit√©s seront les suivantes:-Maintenir et d√©velopper des solutions bas√©es sur les services AWS pour le stockage, le traitement et l'analyse de donn√©es-Utiliser les services AWS appropri√©s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r√©pondre aux exigences du projet.-Cr√©er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS-Participer √† la maintenance et √† la mise en place d'environnements OpenShift pour l'h√©bergement d'applications et de services-G√©rer et administrer les clusters Kafka pour garantir la disponibilit√©, la performance et la s√©curit√© du syst√®me de messagerieParticiper √† l‚Äôassistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn√©esEn rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).Qualit√©s requises pour r√©ussir dans ce r√¥leAyant une premi√®re exp√©rience en tant que Data Engineer, vous avez une premi√®re exp√©rience relative aux points suivants:-D√©veloppement et int√©gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop-Connaissance avanc√©e de l'administration Kafka, y compris la configuration, la gestion et la r√©solution des probl√®mes-Mise en ≈ìuvre de l'infrastructure en tant que code √† l'aide de Terraform-Bonne compr√©hension des bonnes pratiques de s√©curit√© pour les syst√®mes cloud, les clusters Kafka et les plateformes HadoopCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': []}"
Stage Data & Analytics Engineer H/F,Sonepar,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-analytics-engineer-h-f-at-sonepar-3797425590?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=4lqbulqFXsNJjdyoPEd8Hg%3D%3D&position=19&pageNum=0&trk=public_jobs_jserp-result_search-card,"Qui sommes nous ?Sonepar est un groupe familial ind√©pendant, leader mondial de la distribution aux professionnels de mat√©riels √©lectriques, solutions et services associ√©s. Gr√¢ce √† la densit√© de son r√©seau d‚Äôenseignes op√©rant dans 40 pays, le Groupe conduit une ambitieuse transformation pour devenir le premier distributeur de mat√©riel √©lectrique au monde √† proposer √† tous ses clients une exp√©rience omnicanale enti√®rement num√©ris√©e et synchronis√©e. Fort des comp√©tences et de la passion de ses 44 000 collaborateurs, Sonepar a r√©alis√© un chiffre d‚Äôaffaires de 32,4 milliards d‚Äôeuros en 2022.Le groupe Sonepar met tout en ≈ìuvre pour faciliter la vie de ses clients, en agence, en visite sur le terrain, par t√©l√©phone ou via un site Internet ‚Äì quel que soit le mode d‚Äôinteraction souhait√©.üöÄ Vous avez de l‚Äôambition et de l‚Äô√©nergie ?Nous partageons cet √©tat d‚Äôesprit. Nous valorisons le sens de l‚Äôinitiative et la cr√©ativit√© : nos collaborateurs sont libres d‚Äôexprimer leurs id√©es et initiatives et de les mettre en pratique. Nous appr√©cions les esprits audacieux. Chez Sonepar, nous avons √† c≈ìur que chaque collaborateur se sente bien dans son poste et que son travail et son investissement soient reconnus. En 50 ans de croissance, nous avons toujours favoris√© les investissements √† long terme plut√¥t que les gains √† court terme.Les comp√©tences, la personnalit√© et la diversit√© de nos collaborateurs sont les moteurs de notre activit√©, tant sur les march√©s locaux que mondiaux. Cette alliance du local et de l‚Äôinternational nous permet d‚Äô√™tre le leader mondial de notre secteur et soutient notre volont√© d‚Äô√™tre ¬´ La R√©f√©rence ¬ª.üéØ Vos missions :Au sein du service Data & Analytics Engineering compos√© d‚Äôune √©quipe internationale, vous aurez notamment les missions principales suivantes :-Contribuer √† la mise en place des pratiques Data & Analytics afin d‚Äôacc√©l√©rer l‚Äôindustrialisation des solutions d√©velopp√©es en interne.‚Ä¢ Fournir √† l‚Äôentreprise l‚Äôinformation Business n√©cessaire pour comprendre et d√©cider,‚Ä¢ Contribuer √† mettre en place les m√©canismes d‚Äôingestion de la donn√©e et √† leur documentation,‚Ä¢ Contribuer au d√©veloppement des pipelines de donn√©es et l‚Äôenrichissement du Datalake de Sonepar,‚Ä¢ Contribuer au d√©veloppement des outils analytiques.-R√©aliser les analyses Business demand√©es par la Direction Marketing et achat.‚Ä¢ L‚Äôextraction ad hoc ou automatique des donn√©es (par exemple en R, Python, etc.),‚Ä¢ L‚Äôanalyse et la visualisation des donn√©es,‚Ä¢ La restitution de l‚Äôanalyse et la formulation de recommandations.Les missions sont susceptibles d‚Äô√©voluer selon vos app√©tences.‚≠ê Votre Profil :¬∑ Vous recherchez un stage d'√©tudes (Big data, SI et G√©nie Logiciel, Data Engineering, IA, Intelligence Op√©rationnelle ...),¬∑ Vous avez une forte app√©tence pour la conception de bases de donn√©es, l'architecture data & BI¬∑ Vous avez un esprit d'analyse et de synth√®se, le sens du r√©sultat et une bonne aisance relationnelle,¬∑ Vous √™tes √† l'aise avec Pack Office, Java/scala, R, DataOps,¬∑ Id√©alement, vous connaissez Azure et PowerBi,¬∑ Vous √™tes √† l‚Äôaise en anglais, √† l‚Äô√©crit comme √† l‚Äôoral (minimum B2)Ce √† quoi vous pouvez vous attendre ?Le r√¥le - Vos activit√©s quotidiennes seront int√©ressantes, stimulantes et diversifi√©es... Aucun jour ne ressemble √† un autre !L'organisation - Vous travaillerez pour le leader mondial dans un environnement international.L'√©quipe - Int√©grez une √©quipe dynamique, ouverte d'esprit et talentueuse qui est impatiente d'accueillir un autre membre !La culture - Faites partie de la famille Sonepar en partageant les m√™mes valeurs !‚úÖ Les avantages ‚Äì nombreux au sein de Sonepar, voici les principaux :¬∑ Remboursement de votre pass mensuel ou annuel de transport √† hauteur de 75%.¬∑ Carte de ticket restaurant Swile¬∑ Salle de sportQuel est le process de recrutement ?1. Entretien RH & N+1 (Tuteur)2. Entretien N+2Que devez-vous retenir ?üìç La localisation - Holding ‚Äì Paris 8eüìùStage, √† partir de mars (6 mois)‚úã √ätes-vous pr√™t √† faire la diff√©rence ?üëâVeuillez postuler en envoyant votre CV !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Devoteam G Cloud,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-devoteam-g-cloud-3163526462?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=AASL9FMzyHWzusUXKp8VnA%3D%3D&position=20&pageNum=0&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseCr√©√©e en 2009, Devoteam G Cloud a pour mission de conseiller et d'accompagner les soci√©t√©s dans leurs transformations digitales avec les solutions Google Cloud (G Suite, Google Cloud Platform, Google Maps Platform, Devices‚Ä¶).Avec plus de 1 300 clients et 1 000 000 utilisateurs d√©ploy√©s, Devoteam G Cloud s'impose depuis 10¬†ans comme 1er partenaire EMEA de Google Cloud sur l'int√©gration des nouvelles plateformes SaaS.¬†En savoir plus : http://devoteamgcloud.com.  Description du posteTu auras pour mission d‚Äôaccompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l‚Äô√©cosyst√®me solutions open source associ√©.Int√©gr√©(e) √† une √©quipe d‚Äôexperts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d‚Äô√©tudier et cadrer les besoins clientsPr√©coniser les solutions et architectures ciblesD√©finir les m√©thodologies de d√©ploiement et plans de migrationR√©diger les dossiers d‚Äôarchitecture et sp√©cifications techniquesConstruire les architectures de donn√©esConcevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els)Construire et d√©ployer les pipelines de donn√©es (ETL)Assurer la migration des donn√©es vers les nouveaux environnementsAnalyser les donn√©esAnalyser les donn√©es sources afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio‚Ä¶)S√©lectionner, entra√Æner, √©valuer et d√©ployer des mod√®les pr√©dictifs en s‚Äôappuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les √©quipes clients aux m√©thodes et concepts du cloudTu seras accompagn√©(e) en interne pour monter rapidement en comp√©tences sur GCP dans l‚Äôobjectif de devenir certifi√© Google sur ta practice.  Qualifications Dipl√¥m√©(e) d'une √©cole d'ing√©nieurs ou d'un Master 2 en Informatique, tu disposes d'une exp√©rience significative au sein de projets Data : architecture, traitement ou analyse de donn√©es.Tu ma√Ætrises au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (Scala, R, Python).Tu as de bonnes comp√©tences dans de l‚Äôarchitecture des syst√®mes, bases de donn√©es, m√©thodologies d‚ÄôanalyseTu es passionn√©(e) par la Business Intelligence, le Big Data, l‚ÄôInternet des objets (IoT) et le Machine LearningUne connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, ‚Ä¶) est un plus.Tu as une solide compr√©hension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et √† l‚Äô√©coute, tu poss√®des un r√©el esprit d‚ÄôanalyseTa ma√Ætrise de l'anglais te permettra de g√©rer des projets en contexte international  Informations suppl√©mentairesLe Groupe Devoteam oeuvre pour l'√©galit√© des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m√©rite et lutte activement contre toute forme de discrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Sidetrade,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-sidetrade-3799018498?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=2epQHcPf8HsTPSSzqycLXg%3D%3D&position=21&pageNum=0&trk=public_jobs_jserp-result_search-card,"Calling all tech enthusiasts! Are you a problem-solving, curious, and strategic Data Engineer? Join us at Sidetrade, the leading global SaaS provider recognized by Gartner.() https://go.sidetrade.com/GartnerMagicQuadrant22.ht... Indulge your passion for high-availability software and performance enhancement as part of our dynamic team. Embrace the challenge, embrace the excitement - become a Data Engineer and thrive! Shape the future of AI-powered Order-to-Cash at Sidetrade today. Join us in creating innovative solutions that redefine the industry! About Sidetrade‚ÄØand its amazing R&D team Sidetrade is a fast-growing international software company that is transforming the Order-to-Cash process for global enterprises. Its AI-powered SaaS platform digitizes the financial customer journey, empowering CFOs to secure and accelerate cash flow generation. Recognized as a Leader in Gartner's Magic Quadrant for two consecutive years, Sidetrade fosters a culture of innovation, collaboration, and customer-centricity from its headquarters in Europe and North America.The R&D team comprises experienced tech professionals who share a deep passion for technology. Together, they are dedicated to developing cutting-edge software solutions that drive the transformation of our customers' work processes. We provide comprehensive training, coaching, resources, and mentorship to empower every team member's growth and nurture their success.RequirementsWe are seeking a passionate and knowledgeable Data Engineer with a multifaceted skill set. Immerse yourself in the exhilarating world of Microservices & AI within our cutting-edge tech environment. Collaborate with like-minded individuals, embracing the latest tools, techniques, and technologies. Fuel your professional growth and innovation within our agile development ecosystem. As a key member of our development team you will : Design and develop robust data pipelines. Data is at the heart of everything we do. The pipelines you build will power our analytics, machine learning and product featuresYou will build and improve our Dataflows (ETL, Daemon, workers, ... ) and Datastorage.   Build tools and automation      capabilities for data pipelines. The data we ingest and the appetite to      consume it is ever increasing - and therefore so is the importance of      making data integration more reliable and scalable Extend our Data Warehouse and      Data Lake to empower data-driven decisions Help build a data-platform to      democratize data - we want to create a single source of truth of all our      data, which is open to and consumable by everyone at Sidetrade Ensure unit tests are created      and green with sufficient coverage Ensure code analysis are green      (sonar) Support implementation of      secure design principles according to policies and standards of      Information Security  You'll have most of the following key skills and experience: Master's degree in related      field preferred 5 years' experience in Data      Engineering Excellent knowledge of SQL and      Python Object Tableau, talend, Elastic Ssearch, Kafka, GreenPlum, DBT Good understanding of      relational and NoSQL, databases (including data modelling, data      warehousing) Mastery of data mining      technologies  Knowledge of Rest API Experience developing and      supporting robust, automated and reliable data pipelines Attention to detail -      downstream analytics, machine learning and product features are only as      good as the data integrity and quality from the data pipeline Be familiar with Agile and      DevOps frameworks Sound knowledge of data      architecture, scalability and security/compliance Knowledge of security concepts      for data storage Native-level proficiency in French and fluent in EnglishYour first 90 days: Join our Immersive BootcampReview your onboarding plan with your manager and develop an action plan to achieve your goalsCollaborate with the team and participate to the roadmap Build your internal network across all departmentsExpand your skill set, share your expertise and unlock your full potential   At Sidetrade, we cultivate a multicultural environment that fuels innovation. With over 22 nationalities represented, we strongly value diversity, gender equality, inclusivity, and fairness. As an equal opportunity employer, we reject all forms of discrimination and harassment. Your unique contributions are celebrated, driving collective success in our inclusive workplace. Discover more on http://www.sidetrade.com/ Agencies : Only applications from invited agencies through the Workable portal will be accepted. Unsolicited CVs sent directly to managers or HR will not incur any fees.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3800673691?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=CnpFrwUiV9ZWH5xbooluoQ%3D%3D&position=22&pageNum=0&trk=public_jobs_jserp-result_search-card,"Big Data, Data Science, Data analyse, Data architecture ... √áa n‚Äôa pas de secret pour vous ?Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.Si vous souhaitez int√©grer nos √©quipes √† Niort et accompagner les plus grands acteurs du secteur des Assurances, cette annonce est susceptible de vous int√©resser.En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement, de la gestion et de l'int√©gration des syst√®mes bas√©s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r√¥le implique la mise en place d'architectures √©volutives et hautement disponibles pour r√©pondre aux besoins de traitement et de stockage de donn√©es de l'entreprise.Fonctions et responsabilit√©sVos responsabilit√©s seront les suivantes:-Maintenir et d√©velopper des solutions bas√©es sur les services AWS pour le stockage, le traitement et l'analyse de donn√©es-Utiliser les services AWS appropri√©s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r√©pondre aux exigences du projet.-Cr√©er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS-Participer √† la maintenance et √† la mise en place d'environnements OpenShift pour l'h√©bergement d'applications et de services-G√©rer et administrer les clusters Kafka pour garantir la disponibilit√©, la performance et la s√©curit√© du syst√®me de messagerieParticiper √† l‚Äôassistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn√©esEn rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).Qualit√©s requises pour r√©ussir dans ce r√¥leAyant une premi√®re exp√©rience en tant que Data Engineer, vous avez une premi√®re exp√©rience relative aux points suivants:-D√©veloppement et int√©gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop-Connaissance avanc√©e de l'administration Kafka, y compris la configuration, la gestion et la r√©solution des probl√®mes-Mise en ≈ìuvre de l'infrastructure en tant que code √† l'aide de Terraform-Bonne compr√©hension des bonnes pratiques de s√©curit√© pour les syst√®mes cloud, les clusters Kafka et les plateformes HadoopCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': []}"
Data Engineer,Reply,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-reply-3803195911?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=OPnVsjGwz9PIgMEwgZ9%2Bng%3D%3D&position=23&pageNum=0&trk=public_jobs_jserp-result_search-card,"DATA ENGINEERQui sommes nous:Data Reply est une marque du groupe Reply offrant une r√©elle expertise dans les domaines de la Data et de l'intelligence artificielle. Nous sommes pr√©sents dans plusieurs pays avec plus de 300 experts dans la Data.Forts de notre expertise en Data Engineering et en Data Science, nous accompagnons nos clients dans leurs projets de transformation Data et dans la mise en place de solutions innovantes. Nous conseillons nos clients dans le choix de la technologie la plus appropri√©e ainsi qu'√† la mise en place d'Architectures Data robustes et √©volutives.Nous nous appuyons sur notre notori√©t√© √† l‚Äô√©chelle internationale afin de f√©d√©rer nos connaissances, de d√©velopper des acc√©l√©rateurs et de cr√©er une √©mulation entre toutes les entit√©s Data Reply dans le monde.Nous sommes r√©solument tourn√©s vers l‚Äôinnovation et les nouvelles technologies. Nos diff√©rents partenariats technologiques, nos campagnes r√©guli√®res de certification de nos consultants et les cas d‚Äôusages que nous mettons en place pour nos clients nous assurent une forte √©minence sur le march√©.Vos Missions:Nous avons besoin de vous pour nous aider √† :Accompagner nos clients √† :‚Ä¢ Impl√©menter les nouveaux cas d‚Äôusage :‚Ä¢ Cartographier des donn√©es et des flux de donn√©es‚Ä¢ Impl√©menter les pipelines d‚Äôanalyse et de traitement de donn√©es‚Ä¢ Industrialiser les flux de donn√©es et leurs visualisations en dashboards, reporting.‚Ä¢ R√©aliser les tests unitaires et les tests d‚Äôint√©grationParticiper √† la vie de Data Reply :‚Ä¢ Participer √† la diffusion et le partage de connaissance au sein de Data Reply‚Ä¢ Participer aux √©v√©nements organis√©s par Data Reply (Reply eXchange, hackathon, AWS summit ‚Ä¶)‚Ä¢ Participer au d√©veloppement des offres packag√©es en appui des teams leadersCe que nous vous proposons:Vastes possibilit√©s de formation et d'apprentissageProgression de carri√®re structur√©e - chez Reply, nous encourageons l'evolution de carri√®re et vous donnerons les outils et les conseils pour acqu√©rir une expertise technique et managerialeR√©mun√©ration comp√©titiveProgrammes de certification pour votre √©volution de carri√®reEnvironnement de travail diversifi√© et dynamique - vous serez entour√© de coll√®gues qui partagent votre passion pour la technologieOpportunit√©s de participer √† des Hackathons, Code Challenges et Lab Camps ainsi qu'√† la diffusion et le partage de connaissance au sein de l'√©quipe Data ReplyVotre savoir ne doit pas se limiter √† vos acquis! Nous sommes fiers de notre culture d'apprentissage continu sur les technologies √©m√©rgentesPossibilit√© de travailler sur des projets avec les plus grandes marques mondialesVos Qualifications:‚Ä¢ Vous √™tes dipl√¥m√©.e d'une √©cole d‚Äôing√©nieur ou d‚Äôun master dans un domaine li√© √† la Data et √† l‚Äôinformatique‚Ä¢ Vous avez le go√ªt pour le m√©tier du conseil et vous avez une vraie dimension humaine‚Ä¢ Vous avez au moins 3 ans d‚Äôexp√©rience sur des probl√©matiques de data engineering, de construction de pipelines de transformation de donn√©es en batch ou en streaming, d‚Äôindustrialisation d‚Äôapplications data science, de mod√©lisation de base de donn√©es‚Ä¢ Vous avez de solides comp√©tences en Python et/ou en Scala‚Ä¢ La connaissance d‚Äôun ETL (Talend, Informatica), des technologies de Data Visualisation (power BI, Tableau), des technologies temps r√©el (Kafka, CDC) est un plus‚Ä¢ Vous maitrisez le SQL et un ou plusieurs langages dans l‚Äô√©cosyst√®me NoSQL (cassandra, mongodb)‚Ä¢ Vous √™tes certifi√©.e et/ou avez de l‚Äôexp√©rience sur un ou plusieurs environnements cloud (GCP, Azure, AWS)‚Ä¢ Vous avez d√©j√† travaill√© en mode agile et avez une bonne connaissance des processus et outils de d√©veloppement modernes (DevOps, Git, CI/CD)‚Ä¢ Vous mettez en application les bonnes pratiques de d√©veloppement (TDD, peer-programming)‚Ä¢ Vous √™tes curieu.x.se et avez l‚Äôenvie d‚Äôentreprendre‚Ä¢ Vous ma√Ætrisez l‚Äôanglais √† l‚Äô√©crit comme √† l‚Äôoral


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER,Blue Consulting,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-blue-consulting-3798309749?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=Mm%2BQPSxp34morAvEPtcsaQ%3D%3D&position=24&pageNum=0&trk=public_jobs_jserp-result_search-card,"Titre du Poste : Data EngineerLieu : Ile-de-FranceS√©niorit√© : 5 √† 7 ans d‚Äôexp√©rience D√©finition de la prestation :Fiche de poste : Principales activit√©s : - Recueillir les besoins m√©tiers des diff√©rentes unit√©s demandeuses- Concevoir des applications transforment les donn√©es brutes en informations exploitables- G√©rer le d√©veloppement et de la maintenance de ses applications- G√©rer l‚Äôinfrastructure de donn√©es et de d√©ployer des applications de traitement des donn√©es- Industrialiser et automatiser le nettoyage de la donn√©e selon les sp√©cifications retenues- G√©rer le cycle de vie de la donn√©e conform√©ment aux directives inscrites dans le RGPD- Mise √† jour permanente sur les technologies et langages utilis√©s dans le but de partager ses connaissances et aider √† l‚Äôavancement du projet.Expertises :- Langage : Python, Scala, Spark, SQL- Bass de donn√©es : PostgreSQL, NoSQL- Orchestration : Airflow, Luigi- DevOps : GitLab, CI-CD, Docker, Ansible, Terraform- Outils Cloud : GCP, Databricks- Les plus : Dbt, Looker Studio, BigQuery, Airflow, Kafka, Dataflow, Firestore


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
DATA ENGINEER F/H,CENISIS,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cenisis-data-agency-3793647312?refId=1KWRirNS8Pt3HA6v%2FO7gng%3D%3D&trackingId=fVA%2BBpNR4S8E0uYsMShMpg%3D%3D&position=25&pageNum=0&trk=public_jobs_jserp-result_search-card,"üíº Data Engineer F/H üíºA propos de nous Rejoindre CENISIS Agency, c‚Äôest rejoindre une entreprise qui place l‚Äôambition et le d√©veloppement national au c≈ìur de nos objectifs dans un environnement riche et stimulant, une √®re en plein changement et offrir ainsi de nouvelles perspectives √† ton projet professionnel.Depuis 26 ans, CENISIS accompagne les grands comptes dans la gestion et la valorisation de leurs donn√©es.Bas√© sur Euratechnologies, nous avons men√©, en 2020, 32 projets avec succ√®s pour les entreprises telles que AG2R La Mondiale, Auchan, CGI Finance, Orange, Labeyrie, ADEO/Leroy Merlin, Macif, Saint-Maclou. Nos consultants sp√©cialis√©s en data interviennent sur la gouvernance des donn√©es, le data usage, la data quality mais aussi sur le master data management. CENISIS mise beaucoup sur le dynamisme et la prise d‚Äôinitiative de ses consultants. Il faut sortir des sentiers battus afin d‚Äô√©voluer dans un domaine en constante Data-√©volution. Tu souhaites rejoindre une communaut√© Data Addict √† taille humaine ?Nous recherchons un Data Analyst Marketing F/H qui aura un r√¥le √† part enti√®re dans la communaut√© CENISIS.Nous t‚Äôapportons l‚Äôopportunit√© d‚Äôintervenir sur un large choix de projets mais √©galement de faire partie de la CENISIS Academy.Tes missions ?G√©rer et mettre en place les structures n√©cessaires ainsi que les donn√©es de type big data pour permettre l'exploitabilit√© par les data scientistsPermettre la collecte, le stockage et l'exploitabilit√© fluide des donn√©esConstruire les outils de collecte et d'analyse de donn√©es (structur√©es et non structur√©es)Choisir la ou les m√©thode(s)/technologie(s) les plus adapt√©e.Rejoindre CENISIS, c‚Äôest rejoindre une entreprise qui :‚ôüPositionne ses consultants au c≈ìur de la strat√©gie de transformation digitale üöÄ‚ö°Ô∏èPermet √† ses collaborateurs d‚Äôavoir un r√©el impact, d‚Äôinnover, tester et construire notre avenir üí•üåèChoisit de porter des valeurs fortes et d‚Äô√™tre avanc√© au niveau social et environnemental avec une forte politique de diversit√© et d‚Äôinclusion #TeamRSE üçÉüèü Anime des formations en interne et en externe #CENISISAcademy üìöCe qui nous anime ?Nos valeurs bas√©es sur l‚Äôaudace, la coh√©sion, l‚Äôauthenticit√© et la responsabilit√© nous poussent √† l‚Äôinnovation et √† la croissance. Pour cela, en 2020, CENISIS a int√©gr√© l‚Äôacc√©l√©rateur BPI d√©di√© aux entreprises ambitieuses pour ainsi, devenir une Data Agency.En tant qu‚Äôentreprise engag√©e dans une d√©marche responsable, nous accordons une grande importance √† l‚Äôimpact du bien-√™tre personnel et collectif et √† l‚Äôengagement envers la diversit√©, l‚Äô√©quit√© et l‚Äôinclusion.Ton profil ? Tu es issu(e) d‚Äôune formation sup√©rieure Bac+3/5 de type licence ou master dans le domaine de l'ing√©nierie avec une orientation Data. Id√©alement tu poss√®des une exp√©rience significative de 3 ans dans la Data.Ton savoir √™tre : Ta capacit√© √† f√©d√©rer une √©quipe et √† contribuer √† la r√©ussite de celle-ci dans ses diff√©rents projetsTa curiosit√©, ton envie de toujours innover, et ton autonomieTu es force de proposition et tu aimes le challenge et challenger les autresTa diff√©rence, ce qui fait ta force et ta richesse pour l'entreprise Ton savoir-faire : Ton expertise √©lev√©e dans les technologies de manipulation des donn√©esTa ma√Ætrise des technologies de base de donn√©es (NoSql, SQL),Ta ma√Ætrise des technologies type Cassandra, Python, R, Ta compr√©hension des probl√©matiques des datascientists Ta capacit√© √† mettre en musique des solutions dans une d√©marche DataOpsAlors tu es partant(e) pour relever le d√©fi ? N‚Äôh√©site pas √† postuler, ce serait le d√©but d‚Äôune superbe aventure ensemble !A comp√©tences √©gales, tous nos postes sont ouverts aux personnes en situation de handicap. Le processus de recrutement ? Premi√®re rencontre avec Marine, Human Resource Manager.Deuxi√®me √©change avec ton futur Manager,Troisi√®me √©change avec Gilles, Directeur Offres et Innovation et/ou C√©dric, Dirigeant.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Omnilog,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-omnilog-3800958837?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=tic5ShPuIeRBRnVOtGwsYQ%3D%3D&position=1&pageNum=1&trk=public_jobs_jserp-result_search-card,"Qui sommes nous ?Depuis son lancement en 1999, OMNILOG met au c≈ìur de ses priorit√©s l‚Äôaccompagnement, la proximit√© et la stabilit√© de ses collaborateurs. Accr√©dit√©s par le label ""Choosemycompany : HappyAtWork¬Æ"", nous permettons √† nos collaborateurs d‚Äô√©voluer dans un cadre professionnel id√©al (√©v√©nements, formations, missions longues, √©quilibre vie pro/vie perso, t√©l√©travail...). Nos clients sont les acteurs majeurs des m√©dias, de l'√©nergie et du e-commerce, avec lesquels nous collaborons depuis plus de 20 ans (TF1, Canal+, l‚ÄôEquipe, la FFF, Place des Tendances, JCDecaux‚Ä¶) et bien d‚Äôautres. R√©partis entre Paris, Bordeaux et Lyon, nos 300 Omnilogiens sont sp√©cialis√©s dans l‚ÄôIT de pr√©cision.Que recherchons-nous ?Nous recherchons un(e) Ing√©nieur Data H/F pour intervenir aupr√®s de l'un de nos clients, un acteur majeur du secteur de l'√©nergie, dans le but d'assurer la qualit√© technique de ses applications. Le poste est bas√© √† La D√©fense, avec un rythme de 3 jours en pr√©sentiel et 2 jours en t√©l√©travail.Vos missions seront les suivantes :Intervenir dans la mise en place et l'optimisation des processus techniques des pipelines de donn√©es.Participer √† l'√©tude op√©rationnelle de cadrage et d'architecture en anticipant les contraintes avec les r√©f√©rents de l'√©quipe.R√©aliser des POC et contribuer √† l'√©claircissement du backlog.Participer √† la pr√©paration des environnements techniques, notamment la configuration et l'automatisation des processus, ainsi que la templatisation des proc√©dures.Assumer la responsabilit√© des Run, MCO, MEP, et de la partie CI/CD.Enrichir l'√©quipe avec des comp√©tences en ing√©nierie de donn√©es et en d√©veloppement.Ma√Ætriser le scripting Python, avoir une expertise sur les API, les tests, les bonnes pratiques, etc.L‚Äôenvironnement technique du projet est le suivant :Cloud : AWS DEV : Python, API (Fast ou Flask), GraphQL, Airflow, Linux, Git (Code review, Merge Request, etc.), DockerDevOps : Docker, Terraform, CI/CD, Gitlab, Gitlab CI, etc. DATA : BDD, SGBDR, DataWarehouse,SQL, NOSQL BIGDATA : HDFS, SPARK, Hadoop, etc. Data Science (Mod√©lisation, MLOPS)Les indispensables :Empathie, √©coute active et communication aupr√®s d'utilisateursExp√©rience de 4 ans minimum en tant qu‚Äôing√©nieur DataForte capacit√© d‚Äôanticipation, d‚Äôorganisation et de coordinationMotivation et esprit d‚Äô√©quipeLe poste est √† pourvoir imm√©diatement, un membre de la Team Recrutement reviendra vers vous prochainement !See you soon ! üòä


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
ML Ops / Data & Machine Learning Engineer,Allianz Trade en France,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/ml-ops-data-machine-learning-engineer-at-allianz-trade-en-france-3727090615?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=TAWG%2BfJLEPPWKlecNpiP5A%3D%3D&position=2&pageNum=1&trk=public_jobs_jserp-result_search-card,"As a member of the Group Data Analytics teams, the Machine learning engineer has to Design & build industrial Machine Learning platforms and technical assets to support the ambitious roadmap of the team in implementing data science within Allianz Trade. Work autonomously and act as a technical referent for junior colleagues.Your Responsibilities Review technical implementations (code, architecture) from colleagues  Act as a technical referent on ML Engineering topics  Given requirements for a model, propose technical implementation  Develop relevant pieces of the technical stack to ensure the build/run of data science models  Develop data pipelines  Develop generic data analytics tooling  Ensure MLOps role for the production & work platforms  Your background  Master‚Äôs degree in informatics and at least 2 years in a similar role  Good background in Python development in CI/CD. Knowledge of unit test practice and Sonarqube  Previous Data Science experience or knowledge of Machine Learning pipelines is a plus ‚Äì you will learn about it very quickly with us  Knowledge of AWS related to data management or data science  Knowledge of Terraform and Gitlab  Fluent in English  Knowledge of Prometheus and Graphana is a plus  Technical curiosity and ability to dive deep into topics to solve issues  Ability to work on various projects at the same time and prioritize  Curiosity and teamwork  Good written and verbal communication skills #FRANCE#PARISIf you are interested in the position above and think you have the right profile please follow the online application process. For more detailed information on the company and our career opportunities please go to our website: https://www.allianz-trade.com/en_global/careers/


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer Assistant,Teads,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/software-engineer-assistant-at-teads-3768799543?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=bszW2MgoDTPkONRpkJqohQ%3D%3D&position=3&pageNum=1&trk=public_jobs_jserp-result_search-card,"Teads, The Global Media Platform, has an engineering team that brings together 200+ talented individuals in 3 main locations (Montpellier, Paris, and Bucharest). We are organized in agile and autonomous feature teams and share technical knowledge within several communities of practice.To innovate, we promote diversity and are committed to creating an inclusive environment for all employees.Our organization gives the possibility to work remotely part of the time and more flexibility is open to discussion.üëâ Join a team of passionate people who build quality and responsible advertising, at scale!Our main Engineering challenges at Teads Working in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).Rich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.Management of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).Build efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.A fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.Bring a wide diversity of profiles to the same level of quality and knowledge.What will you do?As a Software Engineer Assistant, your missions will be to:Provide technical leadership and consultation for infrastructure engineers and developers to ensure the secure deployment of technologyAs part of a team, ensure the adoption of security architecture and engineering initiatives in order to effectively and securely support the organization in meeting specific business technology needsDrive consideration of cybersecurity tools and datasets to enhance detective and preventative control setsUnderstand technical security issues and the implications to Teads businesses and be able to communicate them to management Understand emerging security technologies and determine the appropriate use within business applicationsMaintain and enforce Teads cybersecurity policies and secure design baselinesExecute and improve Teads Security architecture review process and ensure compliance for all business initiativesArchitect global programs that deploy strong security patterns and controls across applications and computing environments, while addressing security, business resiliency, privacy and compliance frameworksIdentify security vulnerabilities and guide developers and engineers in addressing these issuesImprove architectural adoption through automation and efficiently use security tools to solve challenges at scaleValidate reference architectures for security best practices and recommend changes to enhance security and reduce riskCollaborate with the corporate functions including Finance, HR, Legal and Privacy to ensure that Teads maintains a strong cybersecurity postureWhat will you bring to the team?Good programming abilities. Testing your development is a second nature to you, and you are very mindful about your application‚Äôs architecture, performance and maintainability and its‚Äô overall qualityMultiple shipped projects in Software EngineeringStrong problem solving skillsWorking collaboratively with the team, be able to explain your decision and share your knowledgeWhy work at Teads?At Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to scale our business while continuing to create new and exciting products.We value team spirit, pragmatism, listening and we encourage initiatives.We promote end-to-end development: ‚ÄúYou build it, you run it, you monitor it‚Äù.We share knowledge and support with each other beyond any organizational boundary.We fix issues during a blameless postmortem and learn from it so that it doesn‚Äôt happen twice.We are working together to create great engineering, but we are also supportive to promote a great work-life balance.We Care About YouSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).Career Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).Life Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.Wellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).Discover more about our culture and benefits on our Engineering website.About TeadsTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.As an end-to-end solution, Teads‚Äô modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world‚Äôs best publishers and content providers.Through exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.Teads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.We're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3798195830?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=iODW4hmRraSz4Oyy473eUA%3D%3D&position=4&pageNum=1&trk=public_jobs_jserp-result_search-card,"Big Data, Data Science, Data analyse, Data architecture ... √áa n‚Äôa pas de secret pour vous ?Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.Si vous souhaitez int√©grer nos √©quipes √† Bordeaux et accompagner les plus grands acteurs du secteur bancaire, cette annonce est susceptible de vous int√©resser.En tant que Data Engineer, vous serez responsable de la conception, du d√©veloppement, de la gestion et de l'int√©gration des syst√®mes bas√©s sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop. Ce r√¥le implique la mise en place d'architectures √©volutives et hautement disponibles pour r√©pondre aux besoins de traitement et de stockage de donn√©es de l'entreprise.Fonctions et responsabilit√©sVos responsabilit√©s seront les suivantes:-Maintenir et d√©velopper des solutions bas√©es sur les services AWS pour le stockage, le traitement et l'analyse de donn√©es-Utiliser les services AWS appropri√©s tels que Amazon EC2, S3, RDS, Lambda, etc., pour r√©pondre aux exigences du projet.-Cr√©er et maintenir les configurations Terraform pour la gestion de l'infrastructure en tant que code (IaC) sur AWS-Participer √† la maintenance et √† la mise en place d'environnements OpenShift pour l'h√©bergement d'applications et de services-G√©rer et administrer les clusters Kafka pour garantir la disponibilit√©, la performance et la s√©curit√© du syst√®me de messagerieParticiper √† l‚Äôassistance utilisateurs sur les briques de la plateforme Hadoop Cloudera Data-Travailler avec les projets et les devOps pour assurer un traitement efficace des donn√©esEn rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).Qualit√©s requises pour r√©ussir dans ce r√¥leAyant une premi√®re exp√©rience en tant que Data Engineer, vous avez une premi√®re exp√©rience relative aux points suivants:-D√©veloppement et int√©gration sur les technologies AWS, Terraform, OpenShift, Kafka et Hadoop-Connaissance avanc√©e de l'administration Kafka, y compris la configuration, la gestion et la r√©solution des probl√®mes-Mise en ≈ìuvre de l'infrastructure en tant que code √† l'aide de Terraform-Bonne compr√©hension des bonnes pratiques de s√©curit√© pour les syst√®mes cloud, les clusters Kafka et les plateformes HadoopCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['OpenShift'], 'Collaboration': []}"
Data Engineer H/F,Altitude Infra,"Val-de-Reuil, Normandy, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-altitude-infra-3799077872?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=XfG1GP3ZEscNjn8rW602Ww%3D%3D&position=5&pageNum=1&trk=public_jobs_jserp-result_search-card,"√Ä propos de nousDu Tr√®s Haut D√©bit pour tous, voil√† notre mission !Expert en fibre optique, Altitude Infra a le privil√®ge de contribuer au d√©ploiement du nouveau r√©seau Tr√®s Haut D√©bit fran√ßais. Nous construisons, exploitons et commercialisons des r√©seaux fibre optique permettant un acc√®s Internet Tr√®s Haut D√©bit pour tous, √† la ville comme √† la campagne !¬´ Notre activit√© a une vraie utilit√© citoyenne ! ¬ªDoroth√©e Lebarbier, PDG du groupe AltitudeNotre grande √©quipe est compos√©e de 900 collaborateurs et d‚Äôautant de personnalit√©s, de comp√©tences et d‚Äôhistoires √† partager. Reconnue pour notre audace et sous nos airs de ¬´ startup ¬ª, nous embarquons avec nous, de nouveaux collaborateurs aux 4 coins du territoire √† la conqu√™te de nouveaux projets ! Aucun profil ou dipl√¥me n‚Äôest privil√©gi√©, l‚Äôessentiel : √ätre soi-m√™me et avoir envie.¬´ Nous pr√©f√©rons des t√™tes bien faites aux t√™tes bien pleines. L‚Äôimportant est d‚Äô√™tre dynamique, motiv√© et d‚Äôavoir le go√ªt pour le travail d‚Äô√©quipe ¬ªDoroth√©e Lebarbier, PDG du groupe AltitudeEntreprise en hyper croissance, il nous tient √† c≈ìur d‚Äôint√©grer avec soins et bienveillance, les talents qui nous porteront vers demain.MissionAu c≈ìur de la DSI, sous la responsabilit√© du responsable SI Gestion, vous int√©grez l‚Äô√©quipe DATA. Vous Serez Amenez √† TravaillerDans le d√©veloppement global de l‚Äôenvironnement d√©cisionnel, de la conception du DWH jusqu‚Äôaux dataviz sous Power BIAvec tous les m√©tiers de l‚Äôentreprise. Construction, exploitation, production, commerce, finance et bien d‚ÄôautresEn dominante la politique RSE groupeVous devez √™tre en mesure de comprendre d‚Äôo√π vient la donn√©e et challenger la sourceAnalyser la meilleure fa√ßon d‚Äôautomatiser la r√©cup√©ration de la donn√©eConcevoir ¬´ l‚Äôarchitecture ¬ª de r√©colte et de compilation de la donn√©ePr√©parer/anticiper la future restitution, en int√©grant le croisement de dimension avec d‚Äôautres reportings (notamment financiers et Indicateurs)ProfilEntit√©sTemporalit√© et granularit√© dans le tempsSc√©narios : Budget ou R√©el Groupe / Sous Groupe / ConsoEn collaboration avec les chefs de projet SI afin de consolider les diff√©rents r√©f√©rentiels SIEn environnement Full Microsoft : MSSQL, SSIS, SSAS, SSRS, Power BIVous √™tes titulaire d‚Äôun Master ou cycle d‚Äôing√©nieur sp√©cialis√© dans l‚ÄôIT Vous avez une premi√®re exp√©rience sur un poste √©quivalentVous maitris√© le langage SQL, Langages, Python, RVous maitrise des environnements SSIS, MSSQL, SSAS, PowerBIPourquoi nous ? Une formation √† nos m√©thodes, process, outils, techniques et services Des possibilit√©s d‚Äô√©volution De bonnes conditions de travail (investissement, proximit√©, r√©activit√©‚Ä¶) Un fonctionnement collaboratif en mode projet et dans le support aux m√©tiers Une entreprise √† la pointe de la technologie (R&D, High Tech, Innovations digitales‚Ä¶)R√©f√©rence de l'offre : 409b6h3w0q
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3782168944?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=MrWi9FDzxdf%2BlPr%2FxCOw6A%3D%3D&position=6&pageNum=1&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre  Informations g√©n√©rales  Entit√© de rattachement  Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste M√©tier M√©tier AS (Application Services) - Technique AS Intitul√© du poste Data Engineer H/F Contrat CDIDescription De La MissionLe p√¥le BFA de la branche Application Services du groupe INETUM, recherche plusieurs Data Engineers afin d'intervenir aupr√®s de clients grands comptes au sein des march√©s bancaires et de l'assurance.Au sein de l'√©quipe Data, en tant que Data Engineer, vous participez √† la r√©alisation de divers projets et vos missions sontApporter votre connaissance en Big Data permettant la manipulation des donn√©esConcevoir les plateformes permettant de traiter des volumes de donn√©es importantsMettre en place des bases de donn√©esPr√©parer le pipeline de donn√©es pour que les donn√©es d√©ploy√©es soient s√©curis√©es et claires afin d'√™tre analys√©es et transform√©es. Profil De formation ing√©nieure en informatique Bac + 5 informatique ou scientifiqueBonne communication orale et √©crite en fran√ßais et niveau d‚Äôanglais professionnelSavoir- √™tre Bon esprit d'analyse et de synth√®se, sens de l'organisation et de la qualit√©, force de proposition, rigueur, travail en √©quipe, adaptabilit√©.Si vous vous reconnaissez, n'h√©sitez pas √† postuler !Localisation du poste Localisation du poste France Ville Saint-OuenCrit√®res candidat Niveau d'√©tudes min. requis Bac+5 Niveau d'exp√©rience min. requis Plus de 2 ans Comp√©tences SQL
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,EarthDaily Agro,"Balma, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-earthdaily-agro-3787906604?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=Y1Cncg8Hco6VXxP6j5G9zg%3D%3D&position=7&pageNum=1&trk=public_jobs_jserp-result_search-card,"About UsEarthDaily Agro provides space age data and analytics to the organizations and people who feed the planet!‚ÄØ‚ÄØWith 35 years of industry experience, EarthDaily Agro provides customers with the data, analysis and knowledge they need to make more efficient and effective decisions. B2B services range from global risk management and monitoring of agricultural commodities to the marketing of inputs and precision agriculture consulting, using the latest research in agronomy, information technologies and remote sensing.‚ÄØ‚ÄØ‚ÄØEarthDaily Agro also develops highly customized business solutions for agricultural lenders, insurers, input suppliers and food companies, with easy-to-use analytics, that help reduce the daily risks of agriculture.‚ÄØ‚ÄØ‚ÄØEarthDaily Agro is headquartered in Minneapolis, MN, USA, with offices in France, Brazil, Australia and Switzerland and is a division of EarthDaily Analytics Corp.‚ÄØ‚ÄØ‚ÄØ‚ÄØEarthDaily Analytics Corp., a vertically-integrated data processing and analytics company, is launching a new constellation of earth observation satellites. The EarthDaily satellite constellation will significantly enhance geospatial analytics capabilities in agriculture, forestry, environment, financial services, and intelligence, among many other verticals.‚ÄØ‚ÄØMain Job Tasks And ResponsibilitiesAs a EarthDailyAgro Data Engineer, your primary responsibility will be to design, develop, and manage data pipelines and infrastructure specialized for geospatial and remote sensing applications. You will work closely with data scientists, geospatial analysts, remote sensing experts, software engineers, and DevOps teams to ensure the successful deployment and scaling of data pipeline to feed geospatial data machine learning models. Your role will be crucial in optimizing the geospatial machine learning ecosystem and ensuring the seamless integration of AI-driven geospatial solutions into real-world applications.‚ÄØYour Responsibilities IncludeCloud-based data pipeline Conceptualization, Development and Scaling: Build up pipeline to ingest large volumes of geospatial data, pre-process them and meet data scientists‚Äô requirements, in terms of accessibility, speed, format, quality. Automation and CI/CD: Industrialization of pipeline deployment, orchestration, workflows, and versioning. Cost & Speed Optimization: Collaborate with infrastructure team to develop, optimize, and fine-tune pipeline.‚ÄØ Cloud and Containerization: Experience with cloud platforms (e.g., AWS, Azure, GCP) and containerization tools. ‚ÄØ Infrastructure Management: Utilize containerization technologies and cloud-based services to set up and manage infrastructure, enabling seamless deployment and scalability.‚ÄØ Monitoring and Anomaly Detection: Implement monitoring systems to track pipeline performance and identify anomalies.‚ÄØ Version Control and Data Version Control: Proficient with version control systems like Git and DVC.‚ÄØ Security and Compliance: Ensure the security and privacy of geospatial data, adhering to relevant data protection regulations and industry best practices.‚ÄØ Collaboration and Communication: Collaborate with interdisciplinary teams to integrate data pipeline into existing applications or develop new geospatial products. Issue Resolution and Troubleshooting: Identify and resolve promptly technical issues related to geospatial data processing, performance, or infrastructure.‚ÄØ Education, Knowledge And AbilitiesRequirements‚ÄØEducation: Master's degree in Computer Science, specialisation in Geomatics and/or Remote sensing would be a plus.‚ÄØ Experience: 3+ years experiences with data pipeline processes and deployment is a must-have. Proven hands-on experience in setting up pipelines and data processes with opensource tools (e.g., MLFlow, Argo, Kubeflow) is desirable.‚ÄØ Programming Skills: Proficiency in Python and with data manipulation frameworks (e.g., dataframe, numpy, pandas, xarray, rasterio) and librairies (e.g., Dask).‚ÄØ Problem-Solving Skills: Autonomous, and strong analytical and problem-solving abilities to address complex geospatial data and analysis challenges.‚ÄØ Communication Skills: Excellent communication and interpersonal skills to collaborate effectively with cross-functional teams and stakeholders.‚ÄØ French mandatory (job based in France). Fluent in English (oral and written):‚ÄØmeetings with internal are mostly in‚ÄØEnglish. ‚ÄØ Preferred Additional SkillsExperience with Earth Observation (EO) data analysis and processing.‚ÄØ Experience with geospatial data formats (e.g., GeoTIFF, Shapefile, NetCDF). Spatial Analysis Techniques: Understanding of spatial analysis techniques and algorithms commonly used in geospatial data manipulation.‚ÄØ Remote Sensing Integration: Knowledge of remote sensing data sources (e.g., STAC catalog, satellite imagery, LiDAR, SAR) integration into data pipelines for accurate and up-to-date geospatial analysis.‚ÄØ CONDITIONS‚ÄØFull time job based in Balma, near Toulouse, France.‚ÄØFixed + Bonuses‚ÄØTR / ""Family"" insurance / CSE‚ÄØPowered by JazzHRW9rcjWJtyB
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer GCP (F/H),Apside,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2859485219?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=h01FjIq7mtDbTPbCn%2BXtIg%3D%3D&position=8&pageNum=1&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une entreprise apprenante ? Engag√©e pour t‚Äôaccompagner dans ton √©volution professionnelle et dans tes projets personnels ?Rejoins Apside Paris pour travailler sur nos projets de demain !Le poste :Tu seras amen√© √† participer √† la migration des donn√©es et le traitements Big Data depuis un cluster Hadoop interne vers l'infrastructure Google Cloud Platform.Dans ce sens, tes missions seront les suivantes : Participation aux chantiers de cadrage de la migrationContribution √† la mise en place des environnements et outils de d√©ploiement automatis√©sAccompagnement et formation des √©quipes √† l‚Äôoutil GCP...Environnement technique :Jira Big dataCloud GCPHadoopKubernetesSpark, Kafka, PythonToi ?Tu as d√©j√† particip√© √† un projet demigration Google Cloud Platform (GCP) ? Tu es rigoureux, bon communiquant ? Tu souhaites participer √† un projet d‚Äôenvergure associant cloud et Big Data ? Alors ce poste de Data Engineer GCP est fait pour toi !Et la suite ?Tu rencontres d‚Äôabord l‚Äô√©quipe RH pour parler de tes attentes, ton projet, ton futur !Puis les managers pour parler concret : missions, projets, parcours de carri√®re, et bien s√ªr salaire et avantages :)  Et tu discutes avec un de nos Tech Leads, pour √©valuer tes comp√©tences et te challenger.Tu souhaites donner un nouvel √©lan √† ta carri√®re ? Rejoins la vie Apsidienne !Pour en savoir plus √† www.apside.com


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': ['JIRA']}"
DATA ENGINEER SCALA/SPARK JUNIOR - H-F,ITNOVEM.,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-scala-spark-junior-h-f-at-itnovem-3781872584?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=zfYU5XMv8uZQ2NTpYmNwfw%3D%3D&position=9&pageNum=1&trk=public_jobs_jserp-result_search-card,"ITNOVEM, qui sommes-nous ? Filiale technologique du groupe SNCF, int√©gr√©e √† la Direction du Digital et des Syst√®mes d‚Äôinformation, Itnovem. se positionne comme expert de l‚ÄôInternet Industriel. Porteuse de grands projets de la r√©volution digitale, notre soci√©t√© est en constante recherche de profils pour rejoindre la grande aventure de l‚ÄôInternet des objets, de la data science et de l‚Äôaccompagnement des projets digitaux.Qu‚Äôil s‚Äôagisse de maintenance pr√©dictive, d‚Äôaide √† la d√©cision sur la maintenance des infrastructures, de gare 4.0, d‚Äôusine du futur, ou de s√©curisation des assets, nos √©quipes font valoir √† la fois une exp√©rience m√©tier et une expertise technique sans cesse renouvel√©e, dans le respect des valeurs du groupe : Excellence, Innovation, Collectif, Agile, Engagement.CONTEXTEAu sein du p√¥le Factory Data & IA et dans le cadre de la mont√©e en charge des projets, nous sommes √† la recherche d'un¬∑e data engineer Scala/Spark junior.  Rattach√©¬∑e aux √©quipes Data Engineering et en collaboration avec les membres de l‚Äô√©quipe, son r√¥le sera de contribuer aux projets data sur stack Scala/Spark et √† l‚Äôam√©lioration de l‚Äôoutillage et des process internes.  Le recrutement intervient dans le cadre de la cr√©ation d‚Äôun plateau projet d√©di√© √† l‚Äôactivit√© TGV sur Nantes.   MISSIONS  Participer au d√©veloppement des projets data sur stack Scala/Spark Etre acteur de la mise en place de bonnes pratiques de communication entre les plateaux nantais et parisiens Avec l‚Äôappui de l‚Äô√©quipe, √™tre impliqu√©¬∑e dans la roadmap technologique (pratiques, outils) et de l‚Äôam√©lioration continue du p√©rim√®tre Scala/Spark Contribuer proactivement √† la qualit√© et aux comp√©tences des √©quipes Data Science et Engineering : veille techno, capitalisation‚Ä¶  LE PROFIL RECHERCHE  Comp√©tences m√©tiers & outils :  Exp√©rience professionnelle (alternance, stage) ou acad√©mique sur le langage Scala et le d√©veloppement d‚Äôapplications Spark Connaissances autour du SQL (principes, langage, mod√©lisation) App√©tence sur les aspects fonctionnels et m√©tiers d‚Äôun projet Notions de CI/CD (notre stack : Maven, Gitlab, Jenkins, Artifactory, Ansible) Comp√©tences transverses :  Int√©r√™t prononc√© pour le software engineering Aisance relationnelle Proactivit√© et clart√© dans la communication Rigueur et organisation Force de proposition Bonne communication √©crite et orale Exp√©riences et formations  Titulaire d‚Äôun bac+5 sp√©cialis√© g√©nie logiciel / d√©veloppement ou exp√©rience √©quivalente.  Vous venez d‚Äôobtenir votre dipl√¥me ou occupez d√©j√† votre premier poste dans le domaine du d√©veloppement de pipelines Data. Localisation Poste bas√© √† Nantes sur plateau m√©tier d√©di√©, avec des d√©placements ponctuels (France) pour participer aux r√©unions d‚Äô√©quipe Data Engineering et Factory Data & IA (Saint Denis). T√©l√©travail jusqu‚Äô√† 3 jours par semaine.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA Engineer - Bordeaux H/F,Capgemini Engineering,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-bordeaux-h-f-at-capgemini-engineering-3804527199?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=LdU8AO9GMvsKYShLx3hplA%3D%3D&position=10&pageNum=1&trk=public_jobs_jserp-result_search-card,"Capgemini Engineering est la marque du groupe Capgemini r√©unissant les services d'ing√©nierie et de R&D d‚ÄôAltran, leader mondial du secteur dont Capgemini a finalis√© l‚Äôacquisition en 2020, et l‚Äôexpertise de Capgemini dans le domaine du digital manufacturing. Gr√¢ce √† une connaissance sectorielle approfondie et √† la ma√Ætrise des technologies digitales et logicielles de pointe, Capgemini Engineering accompagne la convergence des mondes physique et num√©rique. Conjugu√©e avec l‚Äôensemble des capacit√©s du Groupe, elle aide les entreprises √† acc√©l√©rer leur transformation vers l'Intelligent Industry. Capgemini Engineering compte plus de 52 000 ing√©nieurs et scientifiques dans plus de 30 pays, dans des secteurs tels que l'a√©ronautique, l'automobile, le ferroviaire, les communications, l'√©nergie, les sciences de la vie, les semi-conducteurs, les logiciels et l'Internet, le spatial et la d√©fense, et les biens de consommation.Vous √™tes passionn√©.e par la DATA et vous souhaitez prendre part √† un projet d‚Äôenvergure dans le secteur des telecom ? Rejoignez notre √©quipe Hybrid Intelligence au sein de Capgemini Engineering en tant que DATA Engineer.Vous avez acquis une exp√©rience solide dans le d√©veloppement de pipelines de donn√©es et de solutions pour le traitement d'un grand volume de donn√©es, vous √™tes capable de cr√©er des solutions qui r√©pondent aux besoins de diff√©rentes parties prenantes telles que les sp√©cialistes de la visualisation de donn√©es, les scientifiques de donn√©es et les analystes de donn√©es. En qualit√© de Data engineer, vos missions sont les suivantes : ‚ñ™ Concevoir et d√©velopper des solutions Data/IA √† des fins analytics & dashboarding‚ñ™ Accompagner les M√©tier dans la compr√©hension des Analytics et mise en ≈ìuvre de solution ""data driven""‚ñ™ Collaborer avec les data scientist et data ops dans la construction d'une culture ax√©e sur les donn√©es‚ñ™ G√©rer un √©cosyst√®me de partenaires data science et assurer un haut niveau d'expertise‚ñ™ Assurer un r√¥le de veille technologique sur tous les outils autours de la data, IA et BI.Vous √™tes issu.e d‚Äôune formation ing√©nieur ou √©quivalent bac+5 informatique sp√©cialis√© en DATA et vous justifiez d‚Äôune exp√©rience r√©ussie dans le domaine du d√©veloppement de pipelines de donn√©es et de solution Data (2 ans min).Vous ma√Ætrisez les technologies informatiques pour manipuler des bases de donn√©es de type : Oracle, posgres, NoSQL,.. et framework : Hadoop, spark , hive , oozie , Nifi, jupyter, kafka , ... Votre ma√Ætrise des langages : SQL, SCALA, Pyhton, JAVA, shell... vous permettent d‚Äô√™tre autonome sur la manipulation de donn√©es. Enfin, vous avez acquis une exp√©rience dans les outils BI, data visualisation : Kibana, qliksense , power bi ... La ma√Ætrise de l‚ÄôAnglais est n√©cessaire pour ce poste. Vous pensez avoir toutes les comp√©tences pour mener √† bien les missions ? N‚Äôattendez plus et prenez votre place au sein de nos √©quipes !CAPGEMINI, entreprise handi accueillante, conform√©ment √† la norme AFNOR NF X50-783, est √©galement signataire de la charte de la diversit√© en entreprise


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer Assistant,Teads,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-assistant-at-teads-3781123010?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=EfC6bWo4IKFUXh1lTz%2FrCA%3D%3D&position=11&pageNum=1&trk=public_jobs_jserp-result_search-card,"Teads, The Global Media Platform, has an engineering team that brings together 200+ talented individuals in 3 main locations (Montpellier, Paris, and Bucharest). We are organized in agile and autonomous feature teams and share technical knowledge within several communities of practice.To innovate, we promote diversity and are committed to creating an inclusive environment for all employees.Our organization gives the possibility to work remotely part of the time and more flexibility is open to discussion.üëâ Join a team of passionate people who build quality and responsible advertising, at scale!Our main Engineering challenges at TeadsWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).Rich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.Management of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).Build efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.A fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.Bring a wide diversity of profiles to the same level of quality and knowledge.What will you do?As a Software Engineer Assistant, your missions will be to:Collaborate with a variety of teams to develop complex services Create, design develop test and monitor your code in production autonomously and reliablyWork with the Engineering Manager to frame projects and be accountable for their executionGet a good understanding of the business to provide relevant solution to clients Be a work facilitator and help communication inside and outside TeadsStay up-to-date on new technologies and architectures, and share it with the team. Eventually you will propose ways to implement them into our current software engineering processWhat will you bring to the team?Good programming abilities. Testing your development is a second nature to you, and you are very mindful about your application‚Äôs architecture, performance and maintainability and its‚Äô overall qualityMultiple shipped projects in Software EngineeringStrong problem solving skillsWorking collaboratively with the team, be able to explain your decision and share your knowledgeWhy work at Teads?At Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to scale our business while continuing to create new and exciting products.We value team spirit, pragmatism, listening and we encourage initiatives.We promote end-to-end development: ‚ÄúYou build it, you run it, you monitor it‚Äù.We share knowledge and support with each other beyond any organizational boundary.We fix issues during a blameless postmortem and learn from it so that it doesn‚Äôt happen twice.We are working together to create great engineering, but we are also supportive to promote a great work-life balance.We Care About YouSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).Career Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).Life Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.Wellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).Discover more about our culture and benefits on our Engineering website.About TeadsTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.As an end-to-end solution, Teads‚Äô modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world‚Äôs best publishers and content providers.Through exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.Teads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.We're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),APGAR,"Neuilly-sur-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-apgar-3803710671?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=8vqnWTzLzYf4mtUMEiDXgw%3D%3D&position=12&pageNum=1&trk=public_jobs_jserp-result_search-card,"Apgar Consulting, fond√©e en 2013, est une soci√©t√© de conseil en Data de premier plan, reconnue par les analystes comme Gartner, qui accompagne ses clients dans leur parcours pour construire une base de donn√©es fiables.De la sensibilisation des personnes aux changements organisationnels en passant par l'activation et le support technologiques, nous concevons et fournissons des solutions sur mesure qui fournissent des donn√©es de mani√®re coh√©rente, s√©curis√©e et pr√©cise.Nous sommes des experts dans la Data Advisory, la Data Arcthitecture, la Data Academy et la Data for Green, ainsi que dans la mise en ≈ìuvre et le support de solutions de Platform Data telles que la Data Preparation, le Master Data Management, le Meta Data Management et la Data Integration.Apgar Consulting agit pour les petites et grandes entreprises, en Europe, aux √âtats-Unis et au Moyen-Orient.Construit avec des valeurs fortes, Apgar Consulting a pour objectif de fournir des services de conseil durables.L'innovation et le pragmatisme sont les cl√©s de notre approche orient√©e Data.Nous sommes une v√©ritable entreprise centr√©e sur les personnes et ax√©e sur les objectifs et nous offrons un environnement de d√©veloppement personnel et de croissance de carri√®re avec une v√©ritable conscience sociale.Nous recrutons des profils Data et nous misons en priorit√© sur les Soft-Skills sachant que nous ne sp√©cialisons pas nos talents sur des secteurs d'activit√© et que nous favorisons l'accompagnement et la mont√©e en comp√©tences.Le PosteEn qualit√© de Data Engineer, vous travaillez au sein d'une √©quipe intervenant directement sur un projet client pour participer aux missions suivantes : Vous √™tes impliqu√©(e) sur l'ensemble du projet d√®s son d√©marrage et serez en interaction avec le client / m√©tier et les consultants techniques ; Vous participez √† toutes les phases de mise en ≈ìuvre de solutions de Data Management ; Vous participez √† l'analyse des besoins, r√©digez les sp√©cifications fonctionnelles et assurez l'ad√©quation de la solution avec le besoin du client ; Vous assurez un reporting fiable et pertinent de votre activit√© aupr√®s de votre responsable ; Vous accompagnez le client dans la recette et la mise en service de la solution ; Vous √™tes responsable de la qualit√© des livrables et des prestations fournis et contribuez √† la qualit√© globale des projets et missions auxquels vous participez.En fonction de votre degr√© d'exp√©rience, vous √™tes amen√©(e) √† intervenir sur un p√©rim√®tre plus important : Vous prenez la responsabilit√© d'un chantier qui vous aura √©t√© confi√© par votre chef de projet ; Vous √™tes impliqu√©(e) sur l'ensemble du projet d√®s son d√©marrage et serez en interaction avec le client / m√©tier et les consultants techniques ; Vous assurez un reporting fiable et pertinent de votre activit√© aupr√®s de votre responsable ; Vous animez les ateliers de conception fonctionnelles et r√©digez les comptes-rendus.Selon vos souhaits de carri√®re et app√©tences vous aurez la possibilit√© d'√©voluer progressivement vers un poste de consultant(e) technico-fonctionnel(le), vous continuerez √† jouer votre r√¥le de consultant(e) fonctionnel(le) tout en intervenant sur la configuration et param√©trage de la solution.ProfilProfil recherch√© : De formation Bac+5 minimum au sein d'une grande √©cole d'ing√©nieur ou d'informatique, vous disposez de minimum 2 ans d'exp√©rience sur ce type de fonction ; Vous avez des app√©tences relationnelles et avez des facilit√©s √† r√©diger et √† vous exprimer ; Vous avez la capacit√© de comprendre et de r√©diger des sp√©cifications fonctionnelles ; Une exp√©rience en lien avec l'une de nos offres (MDM, M√©ta data, Data Integration et Data Preparation) est un plus.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Back-End Software Engineer H/F,Air France,"Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/back-end-software-engineer-h-f-at-air-france-3761231260?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=JYgLyWBqDpQRVmVuvxP91A%3D%3D&position=13&pageNum=1&trk=public_jobs_jserp-result_search-card,"Description du poste Intitul√© du poste Back-End Software Engineer H/F M√©tier Syst√®mes d'informations - D√©veloppement Cat√©gorie socio-professionnelle Cadre Pr√©sentation du contexte Le Syst√®me Informatique de notre compagnie est un √©l√©ment strat√©gique pour l'ensemble de nos activit√©s.Nos √©quipes IT d√©veloppent et d√©ploient de nombreuses solutions informatiques pour accompagner les diff√©rents m√©tiers de la compagnie (Cargo, Marketing, Suivi des vols, Maintenance des avions....)La cl√© de la r√©ussite de toutes ces solutions innovantes est l'Int√©gration. Sans communication inter-applicative efficace, il n'y a pas de projet possible.En rejoignant le Centre de Services Integration (SCI), vous participerez √† la conception, au d√©veloppement et au d√©ploiement des projets d'Integration de l‚Äôensemble des m√©tiers du groupe Air France-KLM.Pour cela, rien de plus simple, postulez !Description De La MissionAccompagn√© de coll√®gues passionn√©s par les sujets d'Int√©gration : Vous participez √† la mise en place de solutions d'int√©grations performantes pour les projets informatiques du groupe Air France KLM (API, Services REST, SOAP, Events...) Vous aidez les √©quipes de d√©veloppement en participant au support offert par le Centre de Services En tant que d√©veloppeur, vous participez √† la r√©alisation de l'outillage n√©cessaire √† la gestion des solutions d'integration (R√©f√©rentiel de services, gestion des habilitations, Frameworks d'int√©gration...)Vous serez en contact avec l'ensemble des directions du groupe Air France KLM. Profil recherch√© De formation ing√©nieur ou Master 2 en informatique, vous √™tes jeune dipl√¥m√©(e) avec une exp√©rience de moins de 3 ans avec une app√©tence pour les projects back-end et les communications inter applicatives.Vous abordez le changement et les nouvelles technologies telles que les technologies cloud et/ou bigData sans frilosit√©, et mesurez l'int√©r√™t des organisations ¬´ agile ¬ª.Vous avez √† c≈ìur d‚Äôacqu√©rir de nouvelles comp√©tences, techniques et fonctionnelles.Vos qualit√©s de communication et votre souci du client vous permettent d'√™tre √† son √©coute et produire la solution dont il a besoin.Ce que nous vous offrons De la cr√©ation de valeur pour l‚Äôensemble des m√©tiers d‚ÄôAir France KLM Des challenges et probl√©matiques complexes √† r√©soudre Des parcours de carri√®re riches et vari√©s Un accompagnement permanent, une offre de formation adapt√©e Un esprit d‚Äô√©quipe avec des coll√®gues sympathiques et brillantsOn vous attend le plus rapidement possible ! Et pour une dur√©e ind√©termin√©ePlus d'informations ?Les femmes et les hommes qui composent nos √©quipes nous ont choisis pour nos valeurs, notre d√©termination √† satisfaire nos clients et √† doter les m√©tiers et clients d‚ÄôAir France et du groupe Air France-KLM d‚Äôoutils informatiques performants, atouts concurrentiels d√©terminants pour l‚Äôavenir de la compagnie et du groupe.Travaillant en √©troite collaboration avec les m√©tiers, nos collaboratrices et collaborateurs ont √† c≈ìur d‚Äôapporter leur expertise IT afin d‚Äôaccompagner la digitalisation du groupe et ses nombreux projets de transformation.Afin de maintenir un haut niveau d‚Äôexcellence, nous attachons beaucoup d'importance au d√©veloppement des comp√©tences de nos salari√©s tout leur apportant un accompagnement permanent dans leur parcours professionnel.C‚Äôest √©galement la qualit√© de vie sur nos centres informatiques dont celui de Sophia Antipolis et notre attachement √† l‚Äôhumain qui est pl√©biscit√©. Entrer √† Air France, c‚Äôest rejoindre un employeur qui sait reconnaitre la valeur de ses collaborateurs, d√©velopper leurs comp√©tences et leur donner la possibilit√© de construire un parcours professionnel √©volutif, riche en exp√©riences fonctionnelles et techniques.Tous les m√©tiers de l‚ÄôIT se trouvent repr√©sent√©s sur nos centres informatiques et les opportunit√©s professionnelles sont nombreuses.Toutes nos offres sont ouvertes aux candidats en situation de handicap. Air France s‚Äôengage √† cr√©er un environnement de travail inclusif.Notre richesse √† l‚ÄôIT ce sont les femmes et les hommes qui la composent. Type de contrat CDI Temps partiel possible Non Type d'horaires AdministratifProfil candidat Niveau d'√©tudes min. requis Bac + 5 et plus / 3√®me ann√©e grande √©cole Niveau d'exp√©rience min. requis Moins de 3 ans Langue Anglais (4 - Confirm√© / C1)Langues - Informations compl√©mentaires Score minimum requis au TOEIC en anglais (datant de moins de 2 ans) Plus de 850Localisation du poste Localisation du poste France, Provence-Alpes-C√¥te d'Azur, Alpes Maritimes (06) Site ValbonneInformations CCA Titulaire du CCA Non
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER SCALA/SPARK JUNIOR - H/F,ITNOVEM.,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-scala-spark-junior-h-f-at-itnovem-3740805832?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=zpr5JGOu8eFKH9FlDqb26g%3D%3D&position=14&pageNum=1&trk=public_jobs_jserp-result_search-card,"ITNOVEM, qui sommes-nous ? Filiale technologique du groupe SNCF, int√©gr√©e √† la Direction du Digital et des Syst√®mes d‚Äôinformation, Itnovem. se positionne comme expert de l‚ÄôInternet Industriel. Porteuse de grands projets de la r√©volution digitale, notre soci√©t√© est en constante recherche de profils pour rejoindre la grande aventure de l‚ÄôInternet des objets, de la data science et de l‚Äôaccompagnement des projets digitaux.Qu‚Äôil s‚Äôagisse de maintenance pr√©dictive, d‚Äôaide √† la d√©cision sur la maintenance des infrastructures, de gare 4.0, d‚Äôusine du futur, ou de s√©curisation des assets, nos √©quipes font valoir √† la fois une exp√©rience m√©tier et une expertise technique sans cesse renouvel√©e, dans le respect des valeurs du groupe : Excellence, Innovation, Collectif, Agile, Engagement.CONTEXTEAu sein du p√¥le Factory Data & IA et dans le cadre de la mont√©e en charge des projets, nous sommes √† la recherche d'un¬∑e data engineer Scala/Spark junior.Rattach√©¬∑e aux √©quipes Data Engineering et en collaboration avec les membres de l‚Äô√©quipe, son r√¥le sera de contribuer aux projets data sur stack Scala/Spark et √† l‚Äôam√©lioration de l‚Äôoutillage et des process internes.Le recrutement intervient dans le cadre de la cr√©ation d‚Äôun plateau projet d√©di√© √† l‚Äôactivit√© TGV sur Nantes.MISSIONS Participer au d√©veloppement des projets data sur stack Scala/SparkEtre acteur de la mise en place de bonnes pratiques de communication entre les plateaux nantais et parisiensAvec l‚Äôappui de l‚Äô√©quipe, √™tre impliqu√©¬∑e dans la roadmap technologique (pratiques, outils) et de l‚Äôam√©lioration continue du p√©rim√®tre Scala/SparkContribuer proactivement √† la qualit√© et aux comp√©tences des √©quipes Data Science et Engineering : veille techno, capitalisation‚Ä¶LE PROFIL RECHERCHE Comp√©tences m√©tiers & outils :Exp√©rience professionnelle (alternance, stage) ou acad√©mique sur le langage Scala et le d√©veloppement d‚Äôapplications SparkConnaissances autour du SQL (principes, langage, mod√©lisation)App√©tence sur les aspects fonctionnels et m√©tiers d‚Äôun projetNotions de CI/CD (notre stack : Maven, Gitlab, Jenkins, Artifactory, Ansible)Comp√©tences transverses :Int√©r√™t prononc√© pour le software engineeringAisance relationnelleProactivit√© et clart√© dans la communicationRigueur et organisationForce de propositionBonne communication √©crite et oraleExp√©riences et formationsTitulaire d‚Äôun bac+5 sp√©cialis√© g√©nie logiciel / d√©veloppement ou exp√©rience √©quivalente.Vous venez d‚Äôobtenir votre dipl√¥me ou occupez d√©j√† votre premier poste dans le domaine du d√©veloppement de pipelines Data.LocalisationPoste bas√© √† Lyon sur plateau m√©tier d√©di√©, avec des d√©placements ponctuels (France) pour participer aux r√©unions d‚Äô√©quipe Data Engineering et Factory Data & IA (Saint Denis).T√©l√©travail jusqu‚Äô√† 3 jours par semaine.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,ELOSI,"Villeneuve-d‚ÄôAscq, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-elosi-3800230436?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=VQk44VPsZZuEKSh1MLjOXA%3D%3D&position=15&pageNum=1&trk=public_jobs_jserp-result_search-card,"A propos d'ElosiCr√©√©e en 2005, Elosi r√©unit maintenant 120 collaborateurs pour mener √† bien les projets digitaux de ses clients depuis leurs locaux ou depuis notre centre de service et R&D √† Villeneuve d‚ÄôAscq.Le poste et vos missionsPour l'un de nos clients grand compte de la m√©tropole lilloise, nous recherchons un data engineer. Vous travaillerez en collaboration avec les √©quipes de d√©veloppement.Vos missions :Correction et cr√©ation des nouvelles features d'int√©gration de donn√©es sur plusieurs produits digitaux ;Cr√©ation des pipeline d'int√©gration des donn√©es stambia ou outils internes vers google BigQuery ;Mise en place des dashboard powerBI ; Transformation des donn√©es en √©laborant des mod√®les conceptuels. L'environnement techniqueStambia, Google BiQuery, PowerBIVotre profilDe formation sup√©rieure en informatique, vous avec une exp√©rience en d√©veloppement de flux Stambia d'au moins 2 ans, vous connaissez Google BigQuery.Vous aimez ""pr√©parer"" les donn√©es brutes, faciliter leur exploitation et les rendre ""propres"" pour l'analyse qui suivra.Votre anglais est op√©rationnel.Nous rejoindre, c'est :Rejoindre une communaut√© de passionn√©s et la participation √† des conf√©rences techniques (DevoXX, DevFest Lille, atelier LiveCoding, Pair programming, Ap√©r‚ÄôOps‚Ä¶) ; De la convivialit√©, du partage, de la proximit√© ; Des perspectives d‚Äô√©volutions tant technique que m√©tier ! Des avantages : carte restaurant, formations, primes‚Ä¶Si ce poste vous anime, n'h√©sitez plus et postulez !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Tours, Centre-Val de Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3803138116?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=JYbgdP6tzPhfw1X8qDShqA%3D%3D&position=16&pageNum=1&trk=public_jobs_jserp-result_search-card,"Description de posteBig Data, Data Science, Data analyse, Data architecture, ... √áa n‚Äôa pas de secret pour vous ?Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.Rejoignez notre centre d‚Äôexcellence en innovation √† Tours et rendez unique l‚Äôexp√©rience digitale de nos clients en travaillant sur des sujets tels que le marketing digital, User eXperience, CRM, RPA, data, d√©veloppement web et mobile, API management ou encore cybers√©curit√©.Environnement Technique :D√©veloppement : Python, R, Java, ScalaFramework : Hadoop, SparkOutils Big data : Talend for Big Data, Yarn, Pig, Hive, Kafka, SplunkBases de donn√©es : MongoDB, HBase, Cassandra, SQL Server, Postgresql, OracleETL : Talend, MSBI, Informatica, Datastage, ODI, StambiaPlateforme : Hortonworks, Cloudera, Map Reduce, AWS, GCP, AzureFonctions et responsabilit√©sVos missions sont :- Recueillir les besoins m√©tiers et des √©quipes data- Concevoir et mettre en place les traitements de donn√©es- R√©aliser les tests de validation- Assurer l‚Äôalimentation du dataware- R√©aliser les ordonnancements des traitements- √ätre garant de la mise en place, du suivi et de l‚Äôexploitation des outils d√©ploy√©s- Assurer une veille technologique r√©guli√®reEn rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).Qualit√©s requises pour r√©ussir dans ce r√¥le- Passionn√©(e) d‚Äôinformatique et de donn√©es, vous aimez le travail en √©quipe, apprendre et partager. Vous √™tes √©galement dot√©(e) d'un esprit audacieux et ambitieux.- Vous faites preuve d‚Äôinitiative et travaillez sur le long terme.- Vous justifiez de 2 √† 5 ans d'exp√©rience professionnelle au sein d‚Äôune entreprise de services num√©riques ou d‚Äôun cabinet de conseil dans le domaine de la Data.- Vous disposez d'une vision large des technologies et vous ma√Ætrisez au moins une technologie Big Data.CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer BI - Nantes F/H,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-f-h-at-capgemini-3791935676?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=Q%2FoquJSx9XOau226mMwavQ%3D%3D&position=17&pageNum=1&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques motsCapgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans pr√®s de 50 pays. Partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie, le Groupe est guid√© au quotidien par sa raison d‚Äô√™tre : lib√©rer les √©nergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d‚Äôexp√©rience, Capgemini est reconnu par ses clients pour r√©pondre √† l‚Äôensemble de leurs besoins, de la strat√©gie et du design jusqu‚Äôau management des op√©rations, en tirant parti des innovations dans les domaines en perp√©tuelle √©volution. Insights & Data en quelques motsDans ce contexte, notre practice Insights & Data (I&D) s‚Äôappuie sur une √©quipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette √©quipe combine des comp√©tences m√©tiers avec une forte expertise data, analytique et d‚Äôintelligence artificielle pour mettre en ≈ìuvre des solutions qui visent √† am√©liorer la gestion et la valorisation des donn√©es. Pour renforcer les √©quipes d‚ÄôI&D, nous recherchons actuellement un.e Data Engineer BI.A propos du poste :  Int√©gr√© au sein d‚Äôune √©quipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activit√©s divers, vous serez notamment en charge des missions suivantes :Mener les analyses fonctionnelles destin√©es √† traduire les besoins du client,Mener les travaux de conception et de mod√©lisation,Diriger le d√©veloppement de la solution / des traitements d'alimentation du DataWareHouse,Organiser et pr√©parer les travaux de recette utilisateurs,Mettre en place les processus d'industrialisation et mener cette derni√®re.Pourquoi nous rejoindre ? Une culture forte et bienveillante, et une grande place laiss√©e √† la libert√©Des clients vari√©s, leaders de leur secteurUne approche pragmatique, qui r√©pond aux vrais enjeux des entreprises.Vous arrivez au bon moment pour prendre place dans une √©quipe √† taille humaine, en renouvellement et en hyper croissance. Pas de profil type chez Capgemini, mais quelques ingr√©dients pour laisser la magie op√©rer ... ! Dipl√¥m√© d'un Bac + 5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire, vous avez au moins 3 ans d‚Äôexp√©rience en BI ou en lien avec un ETLVous avez d√©j√† encadr√© des √©quipesVous √™tes un(e) passionn√©(e) de la Data, enthousiaste et curieux(se)Vous √™tes pr√™t(e) √† partager de fa√ßon accessible √† une audience non ¬´ data expert ¬ªVous ma√Ætrisez une ou plusieurs des technologies suivantes :BI : SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB InitioDataviz : Microsoft Power BI, Tableau, QlikviewBig Data : Ecosyst√®me Hadoop (HIVE, PIG, Mahout‚Ä¶), Cloudera, Pivotal, Spark, HNXAnalytics : R, SAS, IBM SPSSEnglish speaker, because we are French but also international ¬´ Capgemini, Entreprise handi accueillante, conform√©ment √† la norme AFNOR NF X50-783, est √©galement signataire de la charte de la diversit√© en entreprise ¬ª


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Big Data,Beelix,Greater Bordeaux Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-big-data-at-beelix-3798708272?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=Rr9ehZ%2BUZajM9xcZ%2FsTzvA%3D%3D&position=18&pageNum=1&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui cr√©e et am√©liore les produits digitaux des marques ambitieuses ?Depuis 2016, nous compl√©tons les √©quipes de nos clients avec les meilleurs consultants en Product Management et Data Thinking.Aujourd'hui, plus de 100 clients font confiance √† Beelix, des startups aux plus grands groupes tels que : Renault, EDF, Engie ou encore la Soci√©t√© G√©n√©rale.Nous recherchons actuellement pour intervenir chez l'un de nos clients grands comptes un Data Engineer Big Data (F/H).Vos missions principales seront les suivantes:Participation aux d√©veloppements informatiques sur les technologies Hadoop, HDFS, Hive, Spark Sql et PySpark, SqoopParticipation au maintien en conditions op√©rationnellesConceptionD√©veloppementsLivraisonsRecettesProfil recherch√©: Une exp√©rience significative de 4 ans minimum sur un poste similaireVous travaillez en m√©thode agileVous ma√Ætrisez les outils, technologies et domaines suivants: Hadoop, PySpark, Python, SQL Vous parlez anglais courammentVous vous reconnaissez dans cette offre ? N'h√©sitez plus, postulez chez nous!


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3782175142?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=MV6qalHo7QARdPRsglNqFA%3D%3D&position=19&pageNum=1&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre  Informations g√©n√©rales  Entit√© de rattachement  Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste M√©tier M√©tier AS (Application Services) - D√©veloppement Intitul√© du poste Data Engineer H/F Contrat CDIDescription De La MissionDans un environnement en constante √©volution, Inetum souhaite relever les d√©fis de ses clients en proposant les solutions et les produits adapt√©s, ainsi que les m√©thodes du futur sur des technologies innovantes.Dans le cadre d'un projet innovant nous recherchons un Ing√©nieur D√©veloppeur Big DataVotre r√¥le sera d'intervenir au sein d'une √©quipe ax√© sur le d√©veloppement d'une application innovante. en tant qu'Ing√©nieur big data sur l'ensemble des phases du projet l'√©tude, la conception, le d√©veloppement, l'optimisation d'applications.Vous rejoindrez notre √©quipe et participez aux phases d‚Äôanalyses d‚Äôimpact, d‚Äô√©tude de solution, architecture et conception technique et fonctionnelle d√©taill√©e, dans un cycle de projet agile. Profil Comp√©tences techniquesSpark / Spark StreamingStockage MongoDBMessage Broker KafkaWebService RESTTravail en m√©thode Agile/SafeUn bon niveau en Anglais est aussi requis.Une sensibilit√© au RealTime, au monitoring est indispensable.Profil recherch√©Dipl√¥me / niveau d'√©tudes Bac +5 en informatiqueExp√©rience 2 ans minimumLocalisation du poste Localisation du poste France, Ile-de-France, 93 Seine-Saint-Denis Ville Saint-OuenCrit√®res candidat Niveau d'√©tudes min. requis Bac+5 Niveau d'exp√©rience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Snowflake,Key Performance Consulting (KPC),"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-kpc-3794833700?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=mkhd0zcJ7ZsEKbWTdXevHA%3D%3D&position=20&pageNum=1&trk=public_jobs_jserp-result_search-card,"Rejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !VOS MISSIONS :Elaboration d'architectures optimis√©es dans un contexte Snowflake,Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des co√ªts d utilisation Snowflake (FinOps)VOTRE PROFIL :Vous √™tes issu d'une √©cole d'ing√©nieur ou d'un Master 2Vous avez une premi√®re exp√©rience sur du Snowflake ou au moins 2 ans de SQLDEVENEZ NOTRE PROCHAIN(E) Data Engineer Snowflake !Vous recherchez une entreprise o√π vous pouvez t√©l√©travailler tout en gardant un lien de proximit√©, qui laisse de l‚Äôautonomie, et o√π il fait bon travailler, alors nous vous souhaitons la bienvenue chez KPC.Vous avez une exp√©rience d'au moins 2 ans en d√©veloppement SQL ou une premi√®re exp√©rience sur Snowflake ?Vous souhaitez travailler au sein d‚Äôune √©quipe d'experts technico-fonctionnels ?Rejoignez l‚Äôentreprise KPC ! Une entreprise √† taille humaine avec un mode de management dynamique et de proximit√©.Notre c≈ìur de m√©tier de KPC : la business intelligence. Nous sommes int√©grateurs de solutions GOLD PARTENAIRE de SAP, Qlik, Microsoft BI, Tableau, Snowflake, Semarchy etc.Notre gold partenariat nous permet d'offrir des formations certifiantes pour nos collaborateurs, d'avoir des liens de proximit√©s avec les √©diteurs et de revendre leurs solutions.Rejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !VOS MISSIONS :Elaboration d'architectures optimis√©es dans un contexte Snowflake,Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des co√ªts d utilisation Snowflake (FinOps)VOTRE PROFIL :Vous √™tes issu d'une √©cole d'ing√©nieur ou d'un Master 2Vous avez une premi√®re exp√©rience sur du Snowflake ou deux/trois ans de SQLPROCESSUS DE RECRUTEMENT :Vous pensez √™tre celui, celle qu‚Äôil nous faut et vous vous √™tes reconnu dans notre organisation, alors venez vivre votre premi√®re exp√©rience KPC en postulant √† cette offre :Vous serez appel√©(e) par Ludivine (charg√©e de recrutement) pour une premi√®re prise de contactNous pourrons poursuivre les √©changes avec Olivier (Directeur Sud-Ouest) pour l‚Äôapproche projet et techniquePour clore ce processus de recrutement, nous vous inviterons √† rencontrer Gabriel (Directeur Sud-Ouest)Et tout √ßa dans un temps record üòä : 15 jours en moyenne pour allier r√©activit√© et efficacit√©.Nous garantissons l‚Äô√©galit√© des chances pour toutes et tous car pour nous la diversit√© est une force !KPC EN QUELQUES MOTS ?Nous sommes une entreprise sp√©cialis√©e dans la Data.Depuis treize ans, nous accompagnons nos clients √† valoriser leurs donn√©es de mani√®re innovante et efficace pour d√©velopper leur performance, am√©liorer leurs processus et exp√©riences utilisateurs. Nous intervenons en mode projet (50% r√©gie, 50% forfait)Nous avons d√©velopp√© 3 grandes activit√©s :ANALYTICS (BI, Data Science/Big Data, Data Gouvernance, EPM, Digital)ERP SAPCRMPour cela, nous travaillons en partenariat avec les plus grands √©diteurs du march√© tels que : SAP, QLIK, DATAGALAXY, SALESFORCES, SNOWFLAKE, TALEND, MICROSOFT, ONESTREAM, IMAGINO.En forte croissance, nous cherchons de nouveaux talents pour participer √† cette aventure humaine au service des entreprises de demain.KPC EN QUELQUES CHIFFRES :300 collaborateurs20 % Croissance annuelle8 agences en France (Aix-en-Provence, Nice, Montpellier, Lyon, Toulouse, Bordeaux, Paris et Nantes)Des grands groupes en tant que clients : CMA CGM, PERNOD RICARD, AIRBUS, CDISCOUNT, CULTURA, GIFI, POLE EMPLOI, L'OREAL ...VOS AVANTAGES :Organisation du travail 100% flexible avec du t√©l√©travail, participation aux frais t√©l√©phonique et internet et un forfait √©quipement fournitureUn parcours d'int√©grationDes formations et des certifications avec les √©diteurs sur les technos de pointeIK voiture, v√©loCarte resto, mutuelle, pr√©voyance sant√©Prime ¬´ Vacances ¬ªPOURQUOI NOUS REJOINDRE ?Une entreprise √† taille humaineUn mode de management dynamique, agile et de proximit√©Une vie d'agence anim√©e, engag√©e et conviviale dans des locaux sympasUne attention particuli√®re √† un √©quilibre de vie pro / persoUne entreprise qui encourage les initiatives et l'autonomieUne entreprise certifi√©e Ecovadis Silver pour des actions concr√®tes en termes de RSEUn cadre de travail agr√©able prenant en compte les enjeux soci√©taux et environnementauxVous √™tes ou voulez √™tre consultant(e), chef de projet, expert(e) technique, manager ? Notre promesse : vous accompagner de fa√ßon personnalis√©e et continue quel que soit votre projet √† court, moyen et long terme.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),Hilti Group,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-hilti-group-3803059730?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=XKZKDzZFgSgn1ToVKZN0tA%3D%3D&position=21&pageNum=1&trk=public_jobs_jserp-result_search-card,"What's the role?As a Data Engineer, you will be responsible for analyzing & profiling data for designing scalable solutions. You will help the team troubleshoot complex data issues & perform root cause analysis to proactively resolve product & operational issues. Within a team of data engineers, you will be responsible for implementing data models & data structures needed for each use case as defined by Data Architect, in the most convenient format to be used by Data ScientistWho is Hilti?If you‚Äôre new to the industry, you might not have heard of us. We provide leading-edge tools, technologies, software and services for the global construction sector. We have a proud heritage, built over 75 years, and a worldwide reputation for pioneering products and exceptional service. With 30,000 people in more than 120 countries we operate with a unique direct sales model and generate around 250,000 customer interactions every day.What does the role involve? Provide technical support related to data structures, data models and meta data management to Data Architect and other relevant stakeholders.  Participate in early data modeling and testing for use case development, provide input on how to improve proposed solutions and implement necessary changes  Work closely with IT teams on internal data acquisition (e.g., CRM, ERP, Website) and with Data Architect for external data acquisition We have more than 200,000 interactions with our customers every day. It‚Äôs how we get to know their businesses, understand their needs and develop the precise products and services that will help them.What do we offer?To further accelerate in digital marketing, we are building our Global Digital Hub in Paris. You will experience the agile mentality combining the stabilityof a sound business model and the working environment of an award-winning culture. You can make an impact from day one in an international and diverse team by shaping the future of digital at Hilti and revolutionize customer interactions. You‚Äôll be the owner of your professional development and will have the ownership to design your career map.Job benefits: From 60k to 82 ‚Ç¨  25 vacation days + RTT  Childcare Health insurance fully covered  Retirement plans What you need is: Master‚Äôs degree in Computer Science, Information systems  5+ years experience with advanced data management platform (e.g., Hadoop, AWS Redshift, Google cloud platform)  3-4 years of experience with ETL development  Experience in SQL  Experience with AWS Sagemaker , AWS cloudFormation, EMR, Glue, Lambda , S3, Athena, lakeformation, EC2  Deep expertise in data modeling and structuring, experience in high volume data environments,  Expertise in Python (Pyspark is a plus)  Knowledge in Jupiter Notebooks  Understanding of Map reduce concept  Ability to quickly learn new technologies  Good analytical and problem solving skills  Fluency in English Why should you apply? Implements complex automated workflows and routines using workflow scheduling tools.  Build continuous integration, test-driven development and production deployment frameworks.  Drive collaborative reviews of design, code, test plans and dataset implementation performed by data engineers in support of maintaining data engineering standards.  Resolves roadblocks and gives guidance to team members.  Enjoy high freedom to act.  Open excellent international and cross-functional career prospects in a dynamic environment During your interviews, you will meet several members of the digital team including leadership. This way you get to know more about us, and we get to know more about you.Tempted to apply? Click ‚Äúapply now‚Äù and send us your resume (  English version  ) today!Do you want to know more? Go to https://careers.hilti.com/en/digital-marketingJoin us and #TransformDigital
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage - Data Engineer,Numberly,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-at-numberly-1000mercis-group-3802295348?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=TcCPtnnyhYcqRAxVX2ww8A%3D%3D&position=22&pageNum=1&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseNumberly est reconnu comme l‚Äôun des meilleurs sp√©cialistes mondiaux du Data Marketing avec pr√®s de 500 collaborateurs et 8 bureaux dans le monde au service de clients de premier plan (LVMH, BNP Paribas, Hill‚Äôs, Beneteau, L'Or√©al, Ipsen, Ouigo, Maje, HSBC...).En mettant la technologie au service des marques et des consommateurs, Numberly est au c≈ìur de la croissance des entreprises et de l‚Äôaspiration de chacun √† un marketing plus responsable et plus pertinent. Numberly s‚Äôappuie sur les avanc√©es les plus r√©centes en mati√®re de traitement, d‚Äôanalyse et d‚Äôactivation media et CRM des donn√©es, dans un contexte vertueux alliant comp√©titivit√© des entreprises et respect renforc√© de la vie priv√©e et de la protection des donn√©es.Nous analysons des sets de donn√©es comportementales, personnelles, contextuelles et transactionnelles, dans tous les environnements technologiques existants, et les articulons avec les enjeux business et digitaux de nos clients.Nous construisons chaque jour des strat√©gies data et marketing digital qui am√©liorent la pertinence et l‚Äôimpact des interactions de nos clients avec leurs audiences, en alimentant nos recommandations strat√©giques avec toute l‚Äôexpertise technologique, data, et op√©rationnelle du groupe.Description du posteNumberly recherche un(e) Data Engineer en stage pour rejoindre son √©quipe d√©di√©e aux probl√©matiques Data. Vous participerez aux traitements, transformations et restitutions des donn√©es aupr√®s des √©quipes internes afin d‚Äôam√©liorer les performances des campagnes et des strat√©gies marketing de nos clients.Vous :Aimez la donn√©e sous toutes ses formes : brute, travaill√©e et analys√©e ;Avez le d√©sir de la comprendre et de la faire parler ;Poss√©dez une formation ax√©e sur la big data, la fouille de donn√©es ou plus g√©n√©ralement en software engineering;Appr√©ciez le travail bien fait, avez le sens du d√©tail et vous aimez comprendre les probl√©matiques de vos clients ;Aspirez √† travailler pour des clients vari√©s et prestigieux sur des probl√©matiques pointues ;√ätes √† l‚Äôaff√ªt des nouveaux langages/technologies et des derni√®res tendances open source;√ätes spontan√©(e) et appr√©ciez le travail en √©quipe en collaborant avec diff√©rents m√©tiers de la data;Portez de l'int√©r√™t au Marketing et souhaitez d√©couvrir ce domaine. Stage de 6 mois d√©butant en f√©vrier 2024.R√©mun√©ration : 1400 ‚Ç¨ brut mensuel en M1 et 1700 ‚Ç¨ brut mensuel en M2.QualificationsVous connaissez :Mod√©lisationSQL PythonETL Encore mieux si vous connaissez :Workflows management platformsEnvironnement HadoopSyst√®mes et calculs distribu√©sAPI REST, Web ServicesRealtime / StreamingDocker Ce que nous utilisons :UbuntuSuite Microsoft (SSMS, SSIS, SSRS, Power BI)Hdfs Spark / HiveGit / CICDAirflowKafkaKubernetesInformations suppl√©mentairesChez Numberly, nous partageons une passion pour la transmission √† nos √©quipes comme √† nos clients : des talks internes hebdomadaires, des rencontres avec des professionnels experts dans leur domaine, un apprentissage permanent. Un onboarding rapide et puissant, notamment gr√¢ce aux Vis ma vie dans des √©quipes diff√©rentes ; aux Happy Meetings (des rendez-vous mensuels internes pour se retrouver avec toutes nos √©quipes dans le monde et partager l‚Äôactualit√© du groupe). Nous cultivons la libert√© de parole qui permet √† tous de participer au d√©veloppement du groupe. Nous agissons positivement sur notre √©cosyst√®me √† travers 1000mercis impacts et via nos activit√©s qui cr√©ent de la valeur dans l‚ÄôOpen Internet et participent √† l‚Äôenrichissement de l‚ÄôOpen Source : https://github.com/numberlyNumberly est acteur de la diversit√© et Gender Equal by design (certification WeConnect International et gender equity score de 97/100). Numberly propose un environnement international avec plus de 30 nationalit√©s. Des bureaux √† l‚Äôimage de chacune des √©quipes, une biblioth√®que g√©n√©reuse, un grand studio de musique tout √©quip√©, deux chats, du tri s√©lectif et du lombricompostage, la possibilit√© de venir avec votre animal de compagnie et de la place pour les v√©los ! Dans chaque cuisine : caf√©, th√©, infusions √† volont√© et aussi des mystery lunchs. Un abonnement Gymlib, des cours de sport et des soir√©es (souvent d√©guis√©es). Possibilit√© d'√™tre en remote jusqu'√† 50% de votre temps (√† organiser comme vous le souhaitez). Carte Swile (titres-restaurants). Numberly accueille les personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer H/F,Inetum,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3782175181?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=qQm8ygOo3axtPKy46LMCCw%3D%3D&position=23&pageNum=1&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre  Informations g√©n√©rales  Entit√© de rattachement  Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste M√©tier M√©tier AS (Application Services) - Consultant Intitul√© du poste DATA Engineer H/F Contrat CDIDescription De La MissionDans le cadre de la croissance de notre agence lilloise, nous d√©veloppons notre Practice Data et recrutons des profils Data de divers horizons Data Analyst, Data Engineer, Data Scientist et Data Gouv.Les besoins m√©tiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversit√© de comp√©tences.Vous pourriez √™tre l‚Äôun d‚Äôeux et rejoindre Inetum.En tant que Data Engineer, vos principales missions consistent √†Analyser et retranscrire le besoin clientConcevoir et mettre en ≈ìuvre les solutions permettant de traiter des volumes de donn√©es important afin de les mettre √† disposition des Data Analyst ou Data ScientistVous √™tes le premier maillon de la cha√Æne garantissant l'int√©grit√© et la qualit√© de la donn√©e Profil Pour mener √† bien votre r√¥le, il vous fautUne ma√Ætrise de la conception des entrep√¥ts de donn√©esUne expertise dans le stockage de donn√©es et leurs manipulationsBase de donn√©es parmi les SGBD MySQL, PostgreSQL, Oracle, Snowflake, BigQuery, etc...NoSQL parmi MongoDB, Cassandra, HBase, Neo4J, etc...ETL parmi Talend, Stambia, SSIS, etc...Une app√©tence pour la programmation parmi Python, Scala, Java, NodeJS, etc..Et si en plus vous disposez des comp√©tences dans les environnements cloud et/ou dans les technologies BigData Hadoop, Spark, Kafka, etc...un choix de missions encore plus large s'offre √† vous.Vous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !Notre plus Rejoindre la r√©gion Nord-Est, c‚Äôest b√©n√©ficier des avantages d‚Äôun Grand Groupe tout en gardant la proximit√© r√©gionale.Nous mettrons tout en ≈ìuvre pour vous apporter un √©quilibre vie perso / vie pro. C‚Äôest pourquoi nous vous proposons un rythme hybride (selon les contraintes clients).Inetum a d‚Äôailleurs sign√© un accord de t√©l√©travail en 2021 pour que chaque collaborateur puisse adapter son rythme de travail.Une trajectoire de carri√®re personnalis√©e et adapt√©e √† vos souhaits d'√©volution gr√¢ce √† une implantation √† l‚Äôinternational (26 pays, 7 Fablab), des formations cibl√©es et des projets couvrant l‚Äôensemble de la cha√Æne de valeur IT (+25 fili√®res m√©tiers).Int√©grer un collectif d‚Äôexperts partageant des valeurs de solidarit√© et d‚Äôexcellence.Localisation du poste Localisation du poste France, Nord Ville LilleCrit√®res candidat Niveau d'√©tudes min. requis Bac+5 Niveau d'exp√©rience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'Neo4j', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['MySQL', 'PostgreSQL', 'Oracle', 'Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-inetum-3782170788?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=kxFTyM%2FLfeYS%2FwrTKreLbw%3D%3D&position=24&pageNum=1&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre  Informations g√©n√©rales  Entit√© de rattachement  Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste M√©tier M√©tier AS (Application Services) - Consultant Intitul√© du poste Data Engineer H/F Contrat CDIDescription De La MissionDans le cadre de son d√©veloppement, Inetum recrute un Data Engineer (H/F) pour sa branche Applications Services.Le Data Engineer interviendra chez l‚Äôun de nos clients sur des projets BI et/ou Big Data avec une approche Data Driven et ce, en m√©thode agile.Le Data Engineer sera en charge de Apporter une expertise en Big Data permettant la manipulation de donn√©es Accompagner nos clients dans la r√©alisation de projets dans un contexte Big Data et Cloud Participer √† des POCs (Proof Of Concept) permettant de valider les principes techniques et algorithmiques pour des projets Concevoir des plateformes permettant de traiter des volumes importants de donn√©es D√©velopper des pipelines de donn√©es pour assembler les donn√©es en provenance de multiples syst√®mes D√©velopper des applications d‚Äôinjection et de traitements massifs sur des volum√©tries importantes Participer √† l‚Äôindustrialisation d‚Äôapplications partiellement r√©alis√©es (optimisation du code, optimisation des performances, utilisation maximis√©e des possibilit√©s des outils et du cluster disponible) Mettre en place des bases de donn√©es (SQL, NoSQL‚Ä¶) Profil De formation ing√©nieure en informatique (Bac+5), vous avez √©volu√© dans le monde du d√©veloppement (langages Java, Scala, python, R, Spark, Tensorflow) avec une culture Devops, une ma√Ætrise des BDD, du Shell/Unix‚Ä¶Vous disposez d'une exp√©rience significative dans le d√©veloppement (2/3ans) et une exp√©rience √©galement sur une distribution Hadoop (Cloudera, Horthonworks ou MAP-R).Vous √™tes √† l‚Äôaise avec les principes du cloud, une premi√®re exp√©rience avec l‚Äôun des cloud provider suivant AWS, Azure, GCP serait un plus...Vous avez un esprit d'analyse, orient√© sur la mise en place d‚Äôalgorithmes de manipulation de donn√©es volumineuses, sur la mani√®re de les rendre plus performantes (parall√©lisation, distribution de charge) et dans des conditions de hautes disponibilit√©s.Vous appr√©ciez le travail en √©quipe et les challenges.Vous poss√©dez des qualit√©s de communication qui vous am√®ne naturellement √† partager vos connaissances avec vos clients et vos collaborateurs.Si vous vous reconnaissez, n'h√©sitez pas √† postuler !Localisation du poste Localisation du poste France, Ile-de-France, 93 Seine-Saint-Denis Ville Saint OuenCrit√®res candidat Niveau d'√©tudes min. requis Bac+5 Niveau d'exp√©rience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER F/H,Minist√®re de la D√©fense,"La Rochelle, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-minist%C3%A8re-des-arm%C3%A9es-3803147909?refId=wqkChtzzc7rm%2BATH4YOcpw%3D%3D&trackingId=k8rIm2lWQi3jHK1T1gGEVA%3D%3D&position=25&pageNum=1&trk=public_jobs_jserp-result_search-card,"Description du service : Le service des pensions et des risques professionnels (SPRP) a en charge la pr√©-liquidation des pensions de retraite et d'invalidit√© des fonctionnaires et des militaires et la liquidation des pensions et rentes des ouvriers de l'Etat. Le bureau du pilotage des cha√Ænes pensions est charg√© :d‚Äôanimer les cha√Ænes et fournir un appui fonctionnel et technique aux employeurs ;de r√©aliser la maintenance corrective et √©volutive du SI Pensions ;de garantir la gestion des flux entrants et sortants ainsi que l‚Äôarchivage interm√©diaire ;d‚Äôassurer la conduite, l‚Äôanimation et le suivi des projets de transformation num√©rique.Le SPRP a demand√© la cr√©ation d‚Äôun infocentre dans le cadre des travaux d‚Äôurbanisation de l‚Äô√©cosyst√®me num√©rique Pensions.Au sein de la section ¬´ management du syst√®me d‚Äôinformation ¬ª, le Data Engineer est en charge de l'infocentre mais √©galement en charge de la collecte et la mise √† disposition des donn√©es en lien avec les √©quipes m√©tier, ainsi que l‚Äôexploitation des r√©sultats sous forme de publication des r√©sultats, de tableaux de bord et d'outils d'aide √† la d√©cision.Vos missions :Mod√©liser les cha√Ænes de collecte, de stockage, de traitement et de restitution des donn√©es.Concevoir et cr√©er les mod√®les √† r√©aliser ainsi que les algorithmes servant √† la corr√©lation des donn√©es avec les r√®gles de gestion de l‚Äôorganisme.Appliquer les techniques (statistiques, text mining, ‚Ä¶) d‚Äôextraction et d‚Äôanalyse des informations.Organiser, √©tudier et synth√©tiser les sources de donn√©es sous forme de r√©sultats exploitables.Ma√Ætriser la qualit√© des donn√©es tout au long de leur traitement.Concevoir les produits de diffusion permettant de r√©pondre aux commandes adress√©es.Profil recherch√© : Ing√©nieur dipl√¥m√© d‚Äôune √©cole sp√©cialis√©e dans la manipulation de la donn√©e, vous disposez d‚Äôune exp√©rience significative dans le domaine de la statistique et de la data science ou en Big Data. Vous maitrisez le fonctionnement d‚Äôun Extract-transform-load (ETL) et connaissez les outils Qlik Sense et TALEND.Dot√© d‚Äôesprit d‚Äôanalyse, vous maitrisez les m√©thodes d‚Äôing√©nierie et la conduite de projets en syst√®me d‚Äôinformation.Si vous vous reconnaissez, n‚Äôh√©sitez plus √† postuler !Informations compl√©mentaires :Localisation : LA ROCHELLEType de contrat : CDD de 3 ans (renouvelable)R√©mun√©ration : Soumise √† la grille statutaire de la fonction publiquePossibilit√©s de restauration sur place (MESS) ;T√©l√©travail (1 jour) ;18 RTT ;Accessible par les transports (train et bus);Formation d'adaptation √† l'emploi.A r√©ception de votre CV, ce dernier sera √©tudi√© et fera l‚Äôobjet d‚Äôun retour dans un d√©lai de 15 jours, si votre profil correspond, votre candidature sera transmise au manager op√©rationnel qui prendra attache avec vous pour vous recevoir √† l‚Äôoccasion d‚Äôun entretien en pr√©sentiel. Consultez l‚Äôensemble de nos offres d‚Äôemploi via : https://contractuels.civils.defense.gouv.fr/Le minist√®re des arm√©es est engag√© dans une politique active en faveur de la diversit√©, de l‚Äô√©galit√© professionnelle et du handicap.Tous les postes du minist√®re des Arm√©es sont ouverts aux candidatures d‚Äôune RQTH.A ce titre, les candidats F/H ne doivent indiquer aucune information personnelle (√¢ge, situation de famille, photographie) sur leur candidature.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer (Lille),Cenova,"Hauts-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-lille-at-cenova-3799076593?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=F5bG69a57OHSZvbSXqh8ng%3D%3D&position=1&pageNum=2&trk=public_jobs_jserp-result_search-card,"Entrez dans notre univers ¬´ √™tre s√©rieux sans se prendre au s√©rieux ¬ª !Cabinet √† forte croissance, √† Lille, Cenova accompagne ses clients, grands comptes des secteurs du #Retail dans leurs projets de transformation Data et Digitale, et ce sur l‚Äôensemble des probl√©matiques m√©tiers (marketing, produit, supply, RSE, ‚Ä¶).VOS MISSIONS :Vous travaillerez chez l‚Äôun de nos clients, sp√©cialiste du #Retail, au sein de l‚Äô√©quipe Data sur le d√©veloppement de solutions Data Analytics. Vos missions, si vous les acceptez, seront les suivantes :¬∑ Participer aux rituels agiles de l'√©quipe,¬∑ Analyser les besoins des utilisateurs et proposer des solutions innovantes et en phase avec les drivers de l'entreprise,¬∑ √ätre garant de l'acc√®s qualitatif aux sources de donn√©es,¬∑ S‚Äôassurer de la ma√Ætrise de la donn√©e et √™tre garant de la qualit√© de son utilisation (r√©f√©rencement, normalisation, et qualification) afin d'en faciliter l'exploitation par les √©quipes (Data Analysts et Data Scientists),¬∑ Contribuer √† la d√©finition de la politique de la donn√©e et √† la structuration de son cycle de vie dans le respect des r√©glementations en vigueur,¬∑ √ätre capable d‚Äôintervenir sur les syst√®mes applicatifs autour de la gestion de la donn√©e et du traitement, et sur les plateformes Big Data,¬∑ Assurer la supervision et l'int√©gration des donn√©es de diverse nature qui proviennent de ces sources multiples et v√©rifier la qualit√© des donn√©es qui entrent dans le Data Lake.Environnement technique :SQL, Python, ETLPower BI, Data Studio, Looker, Tableau, Business ObjectCI/CD, Github, Terraform, Kafka, Airflow, DatabricksGCP (BigQuery), AWS, AzureVOTRE PROFIL :Vous avez une exp√©rience minimale de 2 ans sur des missions de Data Engineering et vous disposez d‚Äôune grande app√©tence technique.Vous appr√©ciez comprendre le cycle de vie de la donn√©e et vous √™tes √† l‚Äôaise avec les concepts de data lineage, data gouvernance, data privacy. Vous √™tes amateur.e de datavisualisation, id√©alement avec PowerBI.Travailler en mode agile ? Vous adorez !Vous avez par ailleurs, le contact facile et vous comprenez les enjeux business et adaptez vos analyses en ce sens.Vous √™tes proactif(ve), autonome, bon(ne) communiquant(e) et vous √™tes √† l‚Äôaise en anglais.Votre personnalit√© et votre savoir-faire feront le reste.POURQUOI NOUS REJOINDRE ?Au-del√† de missions passionnantes chez des clients de notori√©t√© internationale, Cenova c'est avant tout un cabinet √† taille humaine pr√©sent sur Lille et Paris.Rejoindre Cenova c‚Äôest :‚úÖ Un respect de vos attentes concernant vos missions, un √©quilibre vie pro/ perso et une r√©elle proximit√© manag√©riale pour vous accompagner dans votre √©volution.‚úÖ Sa CenoAcademy et sa CenoLife, vous permettront d‚Äô√©voluer dans vos expertises et d‚Äôavoir une vie de cabinet stimulante, tout en profitant d‚Äôautres avantages significatifs, en plus de la r√©mun√©ration attractive.Ces quelques mots suscitent votre curiosit√© ? Candidatez !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Chantelle,"Cachan, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-chantelle-3809716037?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=F5d5cJkAYHBiBXAqMo%2Fn%2FQ%3D%3D&position=2&pageNum=2&trk=public_jobs_jserp-result_search-card,"La Direction des Syst√®mes d'Information et du Digital du groupe Chantelle recherche son/sa futur.e Data Engineer H/F H/F, pour le lancement du grand chantier de r√©novation de l'architecture Data : la bascule de l'int√©gralit√© de son Data Warehouse historique vers Google Big Query.Nous souhaitons recruter un Senior Data Engineer H/F, charg√©.e de contribuer √† la d√©finition de la feuille de route de la Chantelle Data Plaform. En tant que Data Engineer vous travaillerez au sein de l'√©quipe Data Int√©gration en charge de la Chantelle Data Platform.Vos Missions Mettre en ≈ìuvre une infrastructure autour de Google Cloud Platform permettant de collecter, transformer, exposer (dataviz, applications, ...) et historiser les donn√©es g√©n√©r√©es par l'entreprise. Travailler en √©troite proximit√© avec les responsables des diff√©rents domaines fonctionnels (R√©f√©rentiels, Supply Chain, Manufacturing, B2B, Retail & e-commerce, Finance, ...), avec notre √©quipe de Data Analysts ainsi qu'avec l'√©quipe technique en charge des infrastructures transverses √ätre force de proposition sur tous les sujets d'architecture et de mod√©lisation (choix de mise en place de pipeline temps r√©els ou au contraire de flux de donn√©es en mode batch, ou bien encore stockage sur Big Query / Big Table en fonction des cas d'usage). D√©finir les √©l√©ments structurants, en justifiant vos choix, et les mettez en ≈ìuvre. Rationaliser et moderniser notre architecture d'int√©gration inter-applicative Faire la refonte de la BI de nombreux use cases tels que le pilotage de nos stocks, personnalisation de nos sites e-commerce en temps r√©el en fonction de nos profils client, etc‚Ä¶Pourquoi travailler chez Chantelle ?Une flexibilit√© dans votre lieu de travail, selon la politique de t√©l√©travail de l'entreprise.11 jours de RTT/an ainsi qu'un 13√®me mois.Une culture d'entreprise familiale bas√©e sur des valeurs de respect, de cr√©ativit√©, de durabilit√© et de transparenceUne aventure dans laquelle vous pourrez vous √©panouir, apprendre et entreprendre, avec une grande vari√©t√© de missions et beaucoup d'autonomieDes √©quipes ressources humaines et des managers √† votre √©coute pour vous accompagner dans votre parcours professionnelDes r√©ductions sur nos produits et des ventes au personnelDes avantages dans votre qualit√© de vie au travail : une conciergerie compl√®te proposant un large panel de services, des activit√©s en interne, un CSE.Vous souhaitez rejoindre un Groupe familial, innovant, engag√© et leader dans son secteur en France comme √† l'international et vous souhaitez apporter votre expertise et authenticit√© pour guider votre √©quipe vers le succ√®s : postulez et rejoignez le Groupe Chantelle !
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H/X),Goaheadspace,"Pantin, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-x-at-goaheadspace-3805968002?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=2sa4k%2BtdbiUrpA30K2E6sA%3D%3D&position=3&pageNum=2&trk=public_jobs_jserp-result_search-card,"MFG Labs est une soci√©t√© de conseil et r√©alisation experte en data, qui aide les entreprises √† am√©liorer leurs prises de d√©cision, √† automatiser leurs processus et √† cr√©er de nouveaux services gr√¢ce √† la data science, au design et √† l'utilisation des derni√®res technologies.MFG Labs intervient √† toutes les √©tapes de votre transformation data : de la cr√©ation d'une feuille de route de projets data, √† la d√©couverte d'insights, √† la mod√©lisation de probl√©matiques complexes, de la cr√©ation d'un mod√®le pr√©dictif √† l'impl√©mentation technique d'une solution data sur-mesureMFG Labs accompagne ses clients de diff√©rentes mani√®res :Strat√©gieSolutionsFondationsMFG Labs d√©ploie une approche holistique pluridisciplinaire, en m√™lant des data scientists, des designers, des data engineers et des consultants, afin d'apporter des solutions compl√®tes de bout en bout √† des probl√©matiques complexes.Dans le cadre du d√©veloppement de l‚Äô√©quipe, nous recherchons un.e Data Engineer √† Pantin (magasins g√©n√©raux).Au sein de l‚Äô√©quipe Data Technology, vous aurez pour mission de travailler sur des probl√©matiques de collecte de la donn√©e sur tout type de support digital : web, mobile, application, voire IoT.Votre r√¥le au sein de l‚Äô√©quipe : Faire partie d‚Äôune √©quipe pluridisciplinaire avec des talents en Design de Service, Consulting et Data science. D√©velopper des applications de production int√©grant diff√©rents outils : des Math√©matiques Appliqu√©s, Machine (Deep) Learning, Recherche Op√©rationnelle, Statistiques. D√©velopper des pipelines de traitement de donn√©es avec l‚Äô√©quipe de Data Science pour : ing√©rer, transformer et d√©livrer des donn√©es et mod√®les √† nos applications. D√©ployer des applications utilisant les derniers outils mis √† disposition par les diff√©rents Clouds publics. √Ä propos de vous : Vous √™tes titulaire d'un niveau Bac +4/Bac +5 d'une √©cole d'ing√©nieurVous √™tes rigoureux¬∑se vis-√†-vis de vous-m√™me et des autres quant √† la qualit√© du code.Vous avez quelques connaissances et comp√©tences solides en d√©veloppement et en en Data Ing√©nierie au sens large.En d√©veloppementPython 3 et SQL Framework de traitement de donn√©es (Spark ou √©quivalent) Docker GIT En +Framework permettant de d√©ployer des APIs (Flask ou √©quivalent) CI/CDEn Data Ing√©nierieDatawarehouse ou Datalake Data Pipelines Batch et/ou Straming En +Outils de BI (Tableau, Power BI‚Ä¶) Outils MLOps (Sagemaker, VertexAI, etc.) Comp√©tences sp√©cifiques :Exp√©rience ou int√©r√™t pour l‚Äôintelligence artificielle g√©n√©rative et en particulier les Large Langage Models.Si vous vous reconnaissez dans cette annonce, n'h√©sitez pas √† postuler !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer,Onepoint,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-onepoint-3030924688?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=Urq0Sd1Sg04EC%2BOKcbn2EA%3D%3D&position=4&pageNum=2&trk=public_jobs_jserp-result_search-card,"Un data engineer est en charge de concevoir, de construire et de d√©ployer des pipelines de traitement de donn√©es. Curieux, il est √† l‚Äôaise avec du batch et du temps r√©el, de l‚Äôon premise et du cloud, des datalakes ou des data warehouses modernes. Ses traitements sont robustes, s√©curis√©s, et performants, et il n‚Äôh√©site pas √† les factoriser et les automatiser.Vos Missions Seront Les Suivantes√âtudier les syst√®mes sources‚ÄØ; Choisir et impl√©menter les solutions de stockage et les mod√®les de donn√©es ad√©quats‚ÄØ; Extraire et charger les donn√©es des syst√®mes sources‚ÄØ; Uniformiser, structurer et transformer les donn√©es‚ÄØ; Exposer ces donn√©es (API, Web services ‚Ä¶) ; Planifier et orchestrer ces traitements‚ÄØ; Industrialiser selon les pratiques CI/CD ; Mettre en place des solutions de monitoring‚ÄØ; Documenter le code‚ÄØ; Exp√©rimenter, √©valuer, faire de la veille technologique. #TECH #DATAVous Maitrisez Une Ou Plusieurs Des Solutions SuivantesLes langages SQL, Python, Scala, Java ‚Ä¶ L‚Äô√©cosyst√®me Hadoop (Spark, HDFS, Hive, HBase ‚Ä¶) Les services Data de GCP, Azure et AWS‚ÄØ: Azure Data Factory, Azure Synapse Analytics, Dataflow, BigQuery, Glue, Redshift ‚Ä¶ Les data platforms Cloudera, Databricks, Snowflake, Confluent, Dremio ‚Ä¶ Les ETL Informatica (PowerCenter, iPaas), Talend Data Fabric et NiFi Les bases de donn√©es ElasticSearch (et la suite ELK), Cassandra, MongoDB, Neo4J ‚Ä¶ Les outils d‚ÄôOps : github/gitlab, Jenkins, CircleCI ‚Ä¶ De Plus‚ÄØVous avez une ou plusieurs certifications en cours de validit√© sur l‚Äôune des technologies cit√©es ci-dessus‚ÄØ; Vous disposez d‚Äôun tr√®s bon relationnel, d‚Äôun bon sens de l‚Äô√©coute et d‚Äôempathie‚ÄØ; Vous faites preuve d‚Äôinitiative, vous √™tes naturellement force de proposition, vous avez envie de partager vos connaissances et savoir-faires et d‚Äôapprendre de vos pairs.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB', 'Cassandra', 'Neo4j', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer,Experfy,France,https://fr.linkedin.com/jobs/view/data-engineer-at-experfy-3719405786?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=jlZBgriIPmVEdvNIMRym1A%3D%3D&position=5&pageNum=2&trk=public_jobs_jserp-result_search-card,"Iterative. They are excited to prototype at all levels of fidelity‚Äîand have the humility to walk away from ideas when they failCollaborative. They have the ability and enthusiasm to work with researchers, engineers, business consultants, and other designers who will challenge and support one anotherComfortable with ambiguity. They know projects and businesses move fast. That means the path forward isn't always well-defined. They are comfortable and collaborative through our processInterdisciplinary. They deliver data products for digital solutions, deploy analytical models into production, fix existing data platforms, or coach and enable other teams in best practices depending on needYou're Good At:Working with a diverse set of clients across domains and industriesImplement data orchestration pipelines, data sourcing, cleansing, and augmentation and quality control processesDeploying machine learning models in productionLeading data architects in designing data architecturesDesign flexible and scalable data architectures tailor made for the clientMentoring data engineers to further their personal and professional growthLeading other engineering staff on projectsDeveloping team's talent by providing direction and facilitating technical architectural discussionsContribute to the running of BCG Platinion | MAYA Design's consulting business by: Assisting with business development through writing proposals, scoping projects; Contributing to our thought leadership through written publications and speaking at events and conferencesTranslating business needs into solutionsDesigning overall data solution, integration, and enterprise architectureYou'll Bring:6+ years of experience working on large scale, full lifecycle data implementation projectsBS/BA in data engineering, software engineering, data science, computer science, applied mathematics, or equivalent experience5+ years of experience in a client facing role2+ years professional development experience with some of the AWS/Azure/GCP data stack: S3, Redshift, AWS glue, EMR, Azure Data Warehouse, Azure Blob Store, Google Big QuerySubject matter expert in at least one area related to data management: An RDBMS technology; a Big Data technology; Enterprise Data Management, Governance, Strategy, etcA deep knowledge of performant SQL and understanding of relational database technologyHands-on RDBMS experience (data modeling, analysis, programming, stored procedures)Expertise in developing ETL/ELT workflows with one or more of the following: Python, Scala, JavaDeployment of data pipelines in the Cloud in at least AWS, Azure, or GCPA deep understanding of relational and warehousing database technology, working with at least one of the major databases platforms (Oracle, SQLServer, Teradata, MySQL, Postgres)Additional consideration to candidates who possess some of the following criteria:Experience working with Big Data technologies such as Spark, Hive, Impala, Druid, or PrestoA solid foundation in data structures, algorithms, and OO Design with fundamentally strong programming skillsProven success working in and promoting a rapidly changing, collaborative, and iterative product development environmentStrong interpersonal and analytical skillsIntellectual curiosity and an ability to execute projectsAn understanding of ""big picture"" business requirements that drive architecture and design decisionsDevOps and DataOps skills including ""infrastructure as code"" systems like CloudFormation or TerraformData system performance tuningImplementation of predictive analytics and machine learning models (MLlib, scikit-learn, etcWillingness to travel around the globe to work with clients and BCG teams. At times, this role involves significant travel to client sites. The amount of travel will depend on client needs and nature of projectsWhat to include in your application:A link to your portfolio that demonstrates your affinity for data engineering and shows how you approach digital challenges


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['Scikit-Learn'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['MySQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform', 'CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Software Engineer, Chrome",Google,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-chrome-at-google-3797082498?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=YEjPc5pueuOgb5EGMHqxVA%3D%3D&position=6&pageNum=2&trk=public_jobs_jserp-result_search-card,"Google welcomes people with disabilities.Minimum qualifications:Bachelor‚Äôs degree or equivalent practical experience.2 years of experience with software development in one or more programming languages, or 1 year of experience with an advanced degree in an industry setting.Preferred qualifications:Experience developing end-user applications.Experience with iOS development.Excellent attention to detail and an interest in user interface.About The JobGoogle's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google‚Äôs needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.Chrome is dedicated to building a better, more open web. We‚Äôre focused on making a better browser (on both desktop and mobile) to help users take advantage of all the web has to offer in a safe and secure way.Chrome is available across all major platforms ‚Äî iOS, Android, Windows, Mac, Linux and Chrome OS. We also built Chrome as an open source project so the entire web ecosystem could benefit from the latest innovations in speed, simplicity and security.ResponsibilitiesDesign new user-facing features in Chrome for iOS, in collaboration with Product Managers and UX designers.Implement, test, and launch features with peers.Own features long-term, evolving with the platform and the product.Manage project priorities, deadlines, and deliverables.Work in the open-source repository as well as Google‚Äôs proprietary code base.Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux', 'Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Junior Data Engineer,Helsing,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/junior-data-engineer-at-helsing-3809390920?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=YbkoaGy9ozSyMaZP2fVEVg%3D%3D&position=7&pageNum=2&trk=public_jobs_jserp-result_search-card,"Who we areHelsing is a defence AI company. Our mission is to protect our democracies. We aim to achieve technological leadership, so that open societies can continue to make sovereign decisions and control their ethical standards.As democracies, we believe we have a special responsibility to be thoughtful about the development and deployment of powerful technologies like AI. We take this responsibility seriously.We are an ambitious and committed team of engineers, AI specialists and customer-facing programme managers. We are looking for mission-driven people to join our European teams ‚Äì and apply their skills to solve the most complex and impactful problems. We embrace an open and transparent culture that welcomes healthy debates on the use of technology in defence, its benefits, and its ethical implications.The role At Helsing, data lies at the core of our AI capabilities and we put huge emphasis on acquiring real world records to validate our algorithms . As this is an entry level role, you are given the task of leading the data acquisition and labelling process for the development of our AI algorithms, enabling you to learn how advanced AI algorithms are trained and deployed in real life applications. Over time you will become a recognised expert at Helsing on how to collect and annotate data most useful for our products and grow your career by working closely with our AI researchers and software engineers. The day-to-day You will support the engineering team, in various steps of the data preparation pipeline (collection, annotation, quality control, storage & management of mission critical datasets)When requested, working outdoors to collect / record video data, such as by flying drones, driving vehicles, and operating camerasYou will use our data annotation tools to tag captured images / videos with metadata and upload them for access by other Helsing engineersYou will assess, scope, and prioritise requests for data from other teams at Helsing You should apply if youHold a BSc in computer science, engineering or related fieldAre an independent and creative problem solving skills (you can make use of duct tape and a screwdriver)Possess strong communication skills, written and verballyHold a driving licence valid in EUHave experience operating from a terminal and writing scripts to automate tasks, using a programming language such as PythonAre meticulous at housekeeping and pay extra attention to detail Note: The above bullet points describe the ideal candidate. None of us matched all of these at once when we first joined Helsing. We encourage you to apply even if you believe you meet only part of our wish list.Nice to have An interest in computer vision applications and familiarity with annotation tools such as CVATExperience in data acquisition / annotationA license to fly drones ( Open A3 )An interest in defence hardware or previous service in the armed forces Join Helsing and work with world-leading experts in their fields Helsing‚Äôs work is important. You‚Äôll be directly contributing to the protection of democratic countries while balancing both ethical and geopolitical concernsThe work is unique. We operate in a domain that has highly unusual technical requirements and constraints, and where robustness, safety, and ethical considerations are vital. You will face unique Engineering and AI challenges that make a meaningful impact in the worldOur work frequently takes us right up to the state of the art in technical innovation, be it reinforcement learning, distributed systems, generative AI, or deployment infrastructure. The defence industry is entering the most exciting phase of the technological development curve. Advances in our field of world are not incremental: Helsing is part of, and often leading, historic leaps forwardIn our domain, success is a matter of order-of-magnitude improvements and novel capabilities. This means we take bets, aim high, and focus on big opportunities. Despite being a relatively young company, Helsing has already been selected for multiple significant government contractsWe actively encourage healthy, proactive, and diverse debate internally about what we do and how we choose to do it. Teams and individual engineers are trusted (and encouraged) to practise responsible autonomy and critical thinking, and to focus on outcomes, not conformity. At Helsing you will have a say in how we (and you!) work, the opportunity to engage on what does and doesn‚Äôt work, and to take ownership of aspects of our culture that you care deeply about What we offer A focus on outcomes, not time-trackingCompetitive compensation and stock optionsRelocation supportSocial and education allowancesRegular company events and all-hands to bring together employees as one team across EuropeA hands-on onboarding program (affectionately labelled ‚ÄúInfraduction‚Äù), in which you will be building tooling and applications to be used across the company. This is your opportunity to learn our tech stack, explore the company, and learn how we get things done - all whilst working with other engineering teams from day one Helsing is an equal opportunities employer. We are committed to equal employment opportunity regardless of race, religion, sexual orientation, age, marital status, disability or gender identity. Please do not submit personal data revealing racial or ethnic origin, political opinions, religious or philosophical beliefs, trade union membership, data concerning your health, or data concerning your sexual orientation.Helsing's Candidate Privacy and Confidentiality Regime can be found here: https://helsing.ai/candidate-privacy-and-confidentiality-regime/


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage - Data Engineer - ML (H/F),Withings,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-ml-h-f-at-withings-3613476264?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=0vK6jUJOONxiInjbs5SCZA%3D%3D&position=8&pageNum=2&trk=public_jobs_jserp-result_search-card,"Chez Withings, nous d√©veloppons des appareils de sant√© connect√©e : nos balances connect√©es, montres hybrides, tensiom√®tres, moniteurs de sommeil et tous les dispositifs de notre gamme sont aujourd'hui utilis√©s par des millions d'utilisateurs. Notre objectif est de permettre la pr√©vention, le d√©pistage et l'accompagnement d'un certain nombre de maladies chroniques via des produits et des services innovants afin de r√©volutionner la mani√®re dont on prend soin de notre sant√©.Au sein de l'√©quipe Machine Learning, nous d√©veloppons des algorithmes pour extraire des informations physiologiques et m√©dicales pour nos utilisateurs tels que le SPO2, la fr√©quence cardiaque, la d√©tection de diverses pathologies comme la fibrillation atriale, l'apn√©e du sommeil...Int√©gr√©.e au sein de l'√©quipe Machine Learning, tu auras une ou plusieurs des responsabilit√©s suivantes :D√©velopper un outil de monitoring de la dette technique, des mauvaises pratiques de code, des failles de s√©curit√© ; Construire des dashboards de visualisation ; Construire un syst√®me d'alerte pour notifier les contributeurs d'√©ventuels probl√®mes ; D√©velopper des outils permettant de corriger les √©ventuels probl√®mes de fa√ßon automatis√©e ; Requirements√Ä la recherche d'un stage d'une dur√©e de 3 √† 6 mois ; Pr√©paration d'un Master en √©cole d'ing√©nieur ou √©quivalent / ann√©e de c√©sure possible ; Ma√Ætrise de Python ; Ma√Ætrise de Debian ou de Ubuntu, de Shell et de l'environnement Linux ; Premi√®re exp√©rience sur du d√©veloppement logiciel ; Culture DevOps (omnipr√©sence du monitoring, automatisation des t√¢ches, ...) Compr√©hension de la culture et des besoins des diff√©rents membres de l'√©quipe ; Rigueur, autonomie, prise d'initiative, curiosit√©BenefitsRejoindre l'aventure Withings, c'est :Int√©grer un des pionniers et leaders mondiaux de la sant√© connect√©e, plusieurs fois prim√© au Consumer Electronic Show Contribuer √† des projets innovants et ambitieux pour la sant√© de demain dans un environnement agile et en constante √©volution Int√©grer une entreprise internationale, membre de la FrenchTech 120, dont les √©quipes sont bas√©es √† Issy-les-Moulineaux, Boston, Hong-Kong et Shenzhen Participer √† l'am√©lioration continue de nos produits et services en les b√™ta-testant avant leur sortie, notamment lors de nos nombreuses sessions sportives entre coll√®gues Participer √† la Withings Med Academy en assistant √† des conf√©rences de professionnels de sant√© afin de renforcer ses connaissances dans le domaine m√©dical Collaborer avec des coll√®gues passionn√©s et c√©l√©brer ensemble chacune de nos r√©ussites ! Toutes les candidatures re√ßues sont √©tudi√©es ind√©pendamment de l'origine ethnique, des croyances, de la religion, du genre, de l'orientation sexuelle ou de la sant√© des candidats. Withings aspire √† offrir et garantir l'√©galit√© des chances aux candidats et seules les personnes habilit√©es (RH et Management) auront acc√®s aux informations concernant votre candidature.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,ADVANCED Schema,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-advanced-schema-3235566526?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=BMibyItZHaNjPFuKpZ9Y8Q%3D%3D&position=9&pageNum=2&trk=public_jobs_jserp-result_search-card,"En tant que Data Engineer, vous aurez les missions suivantes :Concevoir des modeÃÅlisations physiquesConstruire des mappings techniques et r√©daction de sp√©cifications d‚Äôalimentation.D√©velopper des flux des donn√©esContribuer au pilotage de projets, de proof of conceptsParticiper aÃÄ des missions d‚ÄôexpertiseComp√©tences professionnelles & niveau d'√©tudes requis : Vous √™tes titulaire d'un dipl√¥me Bac +3 minimum dans le domaine de la dataVous poss√©dez minimum 1 an d'exp√©rience dans le m√©tier √ätre enthousiaste √† l'id√©e d'apprendre de nouvelles technologiesExp√©rience de la m√©thodologie Agile / ScrumCapacit√© √† planifier et √† prioriser les t√¢ches et les activit√©s confi√©es en autonomieMa√Ætrise de l‚Äôanglais oral et technique obligatoireExpeÃÅrience av√©r√©e dans l'√©criture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQL


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Bash'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,ADVANCED Schema,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-at-advanced-schema-3539059697?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=URdTDdpBGfQm4SV0GnPTVQ%3D%3D&position=10&pageNum=2&trk=public_jobs_jserp-result_search-card,"ADVANCED SCHEMA est une soci√©t√© de services informatiques sp√©cialis√©e dans la donn√©e.Depuis 20 ans, nous cr√©ons des plateformes data sur mesure pour nos clients, orient√©es usages et alliant qualit√©, performance, s√©curit√© et gouvernance. ADVANCED SCHEMA a d√©velopp√© de nouvelles activit√©s pour r√©aliser l'ambition du groupe : devenir une entreprise end-to-end, en proposant une offre √† 360¬∞ √† nos clients pour les accompagner √† chaque √©tape de leurs projets. √Ä ce jour, nous sommes pr√®s de 220 passionn√©s r√©partis entre Paris, Lille, Nantes, Lyon mettant √† profit leur expertises aussi bien dans le domaine du retail, de la finance/assurance, du luxe, des m√©dias, de la sant√© et de l'industrie.Aujourd‚Äôhui, nous souhaitons int√©grer de nouveaux renforts dans nos √©quipes Lilloises.En tant que Data Engineer, vous aurez les missions suivantes :Concevoir des modeÃÅlisations physiquesConstruire des mappings techniques et r√©daction de sp√©cifications d‚Äôalimentation.D√©velopper des flux des donn√©esContribuer au pilotage de projets, de proof of conceptsParticiper aÃÄ des missions d‚ÄôexpertiseComp√©tences professionnelles & niveau d'√©tudes requis :Vous √™tes titulaire d'un dipl√¥me Bac +3 minimum dans le domaine de la dataVous poss√©dez minimum 2 ans d'exp√©rience dans le m√©tierPositif(ve), curieux(se), rigoureux(se) et dot√©(e) d'une bonne aisance relationnelle√ätre enthousiaste √† l'id√©e d'apprendre de nouvelles technologiesExp√©rience de la m√©thodologie Agile / ScrumCapacit√© √† planifier et √† prioriser les t√¢ches et les activit√©s confi√©es en autonomieMa√Ætrise de l‚Äôanglais oral et technique obligatoireExp√©rience av√©r√©e dans l'√©criture de code propre avec 2 ou plusieurs des technologies suivantes : BASH, SQL, Java, Python, NoSQLNotre proposition :Temps plein en CDI avec un salaire attractif + participation aux b√©n√©fices + prime(s) sur investissement personnelMode de travail hybride (agence, site, t√©l√©travail selon projets/clients)Ticket restaurant (Sodexo)Mutuelle financ√©e √† 50%Pr√©voyanceComit√© entreprise5 jours d‚Äôonboarding plein temps via la ADVANCED SCHEMA AcademyNotre investissement :Chez ADVANCED SCHEMA, nous t‚Äôoffrons un environnement de travail stimulant et collaboratif ainsi que des possibilit√©s de croissance et de d√©veloppement professionnel. √âgalement un accompagnement/support au quotidien pour te faire grandir et monter en comp√©tences, sur des projets qui r√©pondent √† de vrais enjeux pour nos clients. Si tu es passionn√©(e) par les donn√©es et pr√™t(e) √† relever de nouveaux d√©fis, alors nous aussi nous aimerions te rencontrerProcess de recrutement :Si ta candidature retient notre attention, nous te proposons :Un premier √©change t√©l√©phonique/visioUn entretien physique (+questionnaire d‚Äô√©valuation) avec un senior managerUn entretien final √† notre si√®ge Parisien afin de rencontrer le DG


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - DBA MySQL/MariaDB Senior M/F,Transatel | NTT,"Puteaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-dba-mysql-mariadb-senior-m-f-at-transatel-ntt-3756893073?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=IX7FAqd5nGRjfvxVgscOJw%3D%3D&position=11&pageNum=2&trk=public_jobs_jserp-result_search-card,"Transatel est un fournisseur mondial de solutions de connectivit√© cellulaire et le 1er agr√©gateur d‚Äôop√©rateurs mobiles alternatifs MVNO en Europe. Et si vous connectiez le monde, au-del√† des fronti√®res ?Votre mission Vous √™tes passionn√©(e) par les nouvelles technologies? Vous r√™vez de construire des infrastructures et des services qui ont une envergure mondiale dans une soci√©t√© multiculturelle ? Vous souhaitez progresser techniquement et bosser sur des sujets int√©ressants ? Vous aimez travailler dans une bonne ambiance ? Alors rejoignez-nous !Le r√¥le du DBA est de concevoir, maintenir, superviser et d√©velopper l‚Äôinfrastructure des bases de donn√©es pour la plateforme Transatel afin de r√©pondre aux exigences de services pour les clients externes et les usages internes. Transatel propose ses services √† l‚Äôinternational pour des grands comptes ayant une haute exigence de disponibilit√© et d‚Äôefficacit√©. Cette activit√© permet aux DBA d‚Äôavoir des responsabilit√©s vari√©es et stimulantes avec de belles opportunit√©s d‚Äô√©volution.Au sein de la DTSI, rattach√©(e) au Responsable Infrastructure, vous int√©grez une √©quipe de 12 personnes dans les p√©rim√®tres SysAdmins, DBA, Monitoring.Vos principales missions :Assurer le maintien en conditions optimales des bases de donn√©es (performances, disponibilit√©)Optimiser les performances des traitements SQL effectu√©s par les plateformes TransatelAm√©liorer l‚Äôautomatisation des t√¢ches r√©currentes et des tests de supervisionParticiper aux mises en production des composants d√©velopp√©s et op√©r√©s par TransatelRafraichir les environnements de d√©veloppement/test avec des donn√©es √† jour et d√©sensibilis√©esSuperviser et analyser l‚Äôactivit√© DB, Surveiller les jobs, Traiter les incidentsAppliquer la politique de s√©curit√©, G√©rer les utilisateursConserver un environnement propre en assurant l‚Äôarchivage des donn√©es et le nettoyage des structures de donn√©esMaintenir la qualit√© des donn√©es maitres et donn√©es de r√©f√©rences, en relation avec les chefs de projetsApporter son expertise aux d√©veloppeurs pour la conception des structures de donn√©es et le d√©veloppement SQL Signes particuliers de la plateforme :Trafic en forte croissancePlateforme en Dual site et hybride (Cloud Public)Environ 30 instances SQL ServerPlus de 2TB de donn√©es pour MySQL.Etc.Votre profil Bonne gestion du stress,Capacit√© d'analyse (investigation) m√©thodique et sens relationnel,Bonne gestion des priorit√©s et respect des d√©lais,Travail collaboratif dans une direction technique avec des chefs de projets, d√©veloppeurs, sysadmin, r√©seau et t√©l√©com, BDD, Support,Capacit√© r√©dactionnelle, esprit synth√©tique afin de rendre compte des actions et des r√©alisations entreprises,Capacit√© √† transmettre son savoir et son savoir-faire,Exp√©rience de 3 ans minimum (hors stage) en tant que DBA MySQL & NoSQL.Le monde des Telecom ne vous est pas inconnuAnglais techniqueVotre univers technologique :MySQL/MariaDB, Percona, ColumStore, Galera Cluster,ElasticSearch 6.X Etc.Linux Debian, Centos, RedhatBash, Python, AnsibleNotre process de recrutement Chez Transatel, nous nous effor√ßons d‚Äôavoir un process global efficace afin de finaliser nos recrutements dans les meilleurs d√©lais (environ 3 semaines).Voici les diff√©rentes √©tapes du processus de recrutement :1i√®re prise de contact RH par t√©l√©phoneEntretiens : Un entretien Manager / RH + un ou plusieurs entretien(s) op√©rationnel(s) ou technique(s)Un test de personnalit√© en ligneUn appel RH vous pr√©sentant l‚Äôoffre de collaboration en d√©tails puis r√©ception de celle-ci par mail Accueil & parcours d‚Äôint√©grationLes avantages Package salarial : fixe + bonus individuel + int√©ressement semestriel et participation (pla√ßables sur PEE ou PER)Comit√©s de salaire tous les 6 moisJusqu‚Äô√† 2 jours de t√©l√©travail, 25 jours de cong√©s + des jours offertsCSE, restaurant d‚Äôentreprise dans les locaux, mutuelle avantageuse, remboursement navigo √† 50% ou forfait mobilit√© durablePour plus d‚Äôinformation, se r√©f√©rer √† la page carri√®re de Transatel : https://www.transatel.com/fr/nous-rejoindre/remuneration-et-avantages/Si vous √™tes arriv√©s jusqu‚Äôen bas de cette offre, il serait dommage de remettre votre candidature √† plus tard, postulez !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'NoSQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
R&D Software Data Engineer (H/F) - CDI,AYRO,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/r-d-software-data-engineer-h-f-cdi-at-ayro-3799031985?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=v1UuRyuWVP6HM7BvAlVgvw%3D%3D&position=12&pageNum=2&trk=public_jobs_jserp-result_search-card,"About AYROAYRO is a French, Deep Tech startup, with the global ambition of enabling the decarbonization of the maritime shipping industry worldwide. We design, build and sell the OceanWings, enabling commercial vessels to reduce their fuel consumption and therefore their CO2 emissions by up to 50% using the power of the wind. By 2050, shipping could represent 15% of all CO2 emissions: the emission reduction potential of our solution could be measured in Gigatons of CO2 in the next 5-10 years. Our OceanWings 363 have recently been installed on the Canop√©e shipping vessel who will transport the Ariane 6 rocket from Europe to Kourou in French Guyana and many other large projects are in the worksJob OverviewYour mission is to participate in the design and industrialization of OceanWings¬Æ by contributing to the development of our control software platform for OceanWings¬Æ on board ships, as well as the software and tools necessary for R&D. You will join AYRO's R&D team of about thirty people, with a specific focus on the software development team in its early stages.Main MissionsYou are tasked with developing our data analysis environment, including the following:‚Ä¢ Consolidating the data harvesting architecture of OceanWings¬Æ installed on boats.‚Ä¢ Consolidating the architecture for data storage, cleaning, and enrichment.You will implement this exciting project in the following technical environment:‚Ä¢ Development in Python, with a focus on PySpark.‚Ä¢ Use of an SQL database.‚Ä¢ Integration with AWS/Azure services.Profil et comp√©tences requises‚Ä¢ Your knowledge acquired through your Master's degree (Bac+5),‚Ä¢ Your experience as a data engineer (2-4 years),‚Ä¢ Knowledge in databases (SQL language),‚Ä¢ Fluency in English,‚Ä¢ A first experience in Agile software development, preferably Scrum,‚Ä¢ Analytical and synthesis skills, autonomy.Your additional assets to help us develop the team and projects:‚Ä¢ Knowledge of ETL/ELT processes,‚Ä¢ Familiarity with cloud environments is appreciated (ideally AWS or Azure),‚Ä¢ Advanced programming skills in Python (knowledge in PySpark would be appreciated).What we offer‚Ä¢ Work on innovative projects contributing to the decarbonization of the planet.‚Ä¢ Contribute to building a team from the ground up.‚Ä¢ Join a motivated team that is receptive to your suggestions.‚Ä¢ Work in a pioneering spirit with sustained growth.‚Ä¢ Enjoy a permanent contract (CDI) as a salaried employee with 218 working days, following the metallurgy industry's collective bargaining agreement.‚Ä¢ Be based in Paris, in modern offices, with occasional travel within France (factory located in Caen) and potential international travel (initially in Europe).‚Ä¢ Be available to start as soon as possible.‚Ä¢ Receive an attractive salary based on your experience, meal vouchers, 50% reimbursement for public transportation, and opportunities to participate in foosball and darts tournaments.‚Ä¢ Experience a personalized recruitment process that includes technical and HR interviews, with an additional AYRONAUT available at your request.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Big Data - Java Spark - I&D (H/F),Capgemini,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-big-data-java-spark-i-d-h-f-at-capgemini-3779429753?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=EbLYRc20PV1JH4np86HXpg%3D%3D&position=13&pageNum=2&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques motsCapgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans pr√®s de 50 pays. Partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie, le Groupe est guid√© au quotidien par sa raison d‚Äô√™tre : lib√©rer les √©nergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d‚Äôexp√©rience, Capgemini est reconnu par ses clients pour r√©pondre √† l‚Äôensemble de leurs besoins, de la strat√©gie et du design jusqu‚Äôau management des op√©rations, en tirant parti des innovations dans les domaines en perp√©tuelle √©volution.Insights & Data en quelques motsDans ce contexte, notre practice Insights & Data (I&D) s‚Äôappuie sur une √©quipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette √©quipe combine des comp√©tences m√©tiers avec une forte expertise data, analytique et d‚Äôintelligence artificielle pour mettre en ≈ìuvre des solutions qui visent √† am√©liorer la gestion et la valorisation des donn√©es. Pour renforcer les √©quipes d‚ÄôI&D, nous recherchons actuellement un.e Data Engineer Java/Spark. A quoi ressemblera ton quotidien ? Vous concevrez et mettez en ≈ìuvre des strat√©gies s√©curis√©es d'acquisition et d'int√©gration de donn√©esVous construirez des pipelines de donn√©es pour collecter, transformer et traiter des donn√©es en collaboration avec des scientifiques de donn√©es afin de r√©pondre aux exigences de la mod√©lisation de donn√©es d'analyse avanc√©eVous participerez au d√©veloppement du data processingSparkSQL en Java (connaissances solides en Java 11 ET Spark ET SQL indispensables), mais aussi HiveQL, Shell.Vous exploiterez des outils DevOps (GitLab, Jenkins, K8S , ArgoCD, Sonar, Nexus, Maven‚Ä¶) pour l‚Äôint√©gration dans le process CI/CDVous effectuerez le chargement des donn√©es en streaming (Kafka / MaprES) et en batch dans des bases Hive/ MapRDB / Mongo DB.Les donn√©es proviendront en grande majorit√© du mainframe (CDC / DB2 / Fichiers MVS) mais √©galement de SGBD.VOTRE PROFIL¬∑ Dipl√¥m√©(e) d'un Bac+5 en informatique¬∑ Vous comptez au moins 3 ans d‚Äôexp√©rience (au sein d‚Äôune ESN ou chez un int√©grateur ou √©diteur) en conseil client√®le¬∑ Vous ma√Ætrisez le langage Java Spark¬∑ Vous √™tes familier √† l‚Äô√©cosyst√®me Big Data (Hadoop, Spark, Kafka)¬∑ Vous avez une exp√©rience en Build et en Run¬∑ Vous avez d√©j√† exploit√© des outils DevOps (GitLab, Jenkins, Nexus, Maven‚Ä¶)¬∑ Vous avez de bonnes connaissances des pratiques Agiles / SAFe, utilisation de JIRALES PLUS DU POSTE En plus de votre quotidien, vous pourrez entreprendre, √™tre form√©, utiliser nos incubateurs pour innover, et vous dessiner une trajectoire de carri√®re personnalis√©e.Vous int√©grerez une √©quipe ambitieuse, fun et dynamique !¬∑ Une culture forte et bienveillante, et une grande place laiss√©e √† la libert√©¬∑ Des clients vari√©s, leaders de leur secteur¬∑ Une approche pragmatique, qui r√©pond aux vrais enjeux des entreprises¬∑ Un v√©ritable accompagnement dans l‚Äô√©volution de votre carri√®re¬∑ Une √©quipe √† taille humaine, en renouvellement et en hyper croissance¬∑ Une priorit√© accord√©e au d√©veloppement des collaborateurs ‚Äì un management qui aide les √©quipes √† progresser, √† r√©ussir


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA']}"
Data engineer confirm√© (CDI),Retail Shake,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-cdi-at-retail-shake-competitive-intelligence-3784292969?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=3%2FIhnysj2AvFXckySxHr7g%3D%3D&position=14&pageNum=2&trk=public_jobs_jserp-result_search-card,"Que faisons-nous chez Retail Shake ?Nous proposons une solution SaaS (abonnement) ainsi que des projets sur-mesure aux pros de la grande distribution (g√©n√©raliste ou sp√©cialis√©e), aux marketplaces ainsi qu‚Äôaux marques, quel que soit leur domaine d‚Äôactivit√© ! Cet outil permet √† nos clients d'avoir une vision 360¬∞ de leur environnement concurrentiel sur leur march√© et d‚Äô√™tre alert√©s quotidiennement : produits, veille tarifaire, promos, surveillance des stocks g√©olocalis√©e, distribution, avis client, benchmark prix, le plan merchandising et la strat√©gie marketing.¬†Tes aptitudes et comp√©tencesTu es organis√©(e), dot√©(e) d‚Äôun bon relationnel afin de travailler en √©quipeTu es autonome et rigoureux(se) : livrer de la qualit√© et √† tempsEnfin, tu es int√©ress√©ÃÅ(e) par le milieu du retail et des nouvelles technologiesTes missionsSous la responsabilit√© du CTO (Chief Technology Officer) tes missions seront les suivantes :Scraping :¬† conception de solutions permettant le traitement de volumes importants de pipelines data.¬†Matching : structuration de la dataAssurance qualit√© : monitoring des pipelines de donn√©esBusiness Intelligence : construction de dashboards pour comprendre la dataMise √† jour permanente sur les technologies et langages utilis√©s dans le but de partager ses connaissances et aider √† l‚Äôavancement des projets.Tes technologiesPython, Scrapy, Google Cloud (Storage, BigQuery, Looker), Azure (Storage, PowerBI), Grafana, ElasticSearch, Docker, TensorFlow.Ton profil¬†Tu aimes les projets innovants, l‚Äôentreprenariat, les environnements dynamiques, les ‚Äúpetites‚Äù √©quipes (nous sommes une startup). Tu es d√©brouillard(e), s√©rieux(se), autonome, bon(ne) communicant(e), tu aimes travailler en √©quipe, l'entraide et partager tes comp√©tences.Ta r√©mun√©rationDe 30K‚Ç¨ √† 50K‚Ç¨ bruts en fonction de ton profil + tickets restaurant + 100% mutuelle prise en charge + 50% transports en commun.Lieu74 rue des Arts, Lille = quartier Lille Centre / Op√©ra / Vieux Lille A deux pas des gares, du m√©tro et du tram On est entour√©s de beaux immeubles et de belles boutiques, c‚Äôest le quartier le plus agr√©able de la M√©tropole !Le process de recrutement√âchange visio introductif avec le CTOEntretien physique et mise en situation avec Irwan, le fondateur


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow'], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer Snowflake F/H,Key Performance Consulting (KPC),"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-f-h-at-kpc-3794836507?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=EPjgSw0jC32Iuua4nsjb6w%3D%3D&position=15&pageNum=2&trk=public_jobs_jserp-result_search-card,"DEVENEZ NOTRE PROCHAIN(E) Data Engineer Snowflake ! Vous recherchez une entreprise o√π vous pouvez t√©l√©travailler tout en gardant un lien de proximit√©, qui laisse de l‚Äôautonomie, et o√π il fait bon travailler, alors nous vous souhaitons la bienvenue chez KPC.Vous avez une exp√©rience d'au moins 2 ans en d√©veloppement SQL ou une premi√®re exp√©rience sur Snowflake ?Vous souhaitez travailler au sein d‚Äôune √©quipe d'experts technico-fonctionnels ?Rejoignez l‚Äôentreprise KPC ! Une entreprise √† taille humaine avec un mode de management dynamique et de proximit√©.Notre c≈ìur de m√©tier de KPC : la business intelligence. Nous sommes int√©grateurs de solutions GOLD PARTENAIRE de SAP, Qlik, Microsoft BI, Tableau, Snowflake, Semarchy etc.Notre gold partenariat nous permet d'offrir des formations certifiantes pour nos collaborateurs, d'avoir des liens de proximit√©s avec les √©diteurs et de revendre leurs solutions.Rejoignez la plus grosse √©quipe SNOWFLAKE certifi√©e en France ! KPC est Partner Elite Snowflake, le plus haut niveau de certification.Vous souhaitez int√©grer une ESN √† taille humaine vous permettant de travailler sur des projets challengeant et de monter en comp√©tences ? Ce poste est pour vous !VOS MISSIONS :Elaboration d'architectures optimis√©es dans un contexte Snowflake,Conception et mise en place des ingestions de donn√©es (temps r√©el, Kafka, Snowpipe),Mod√©lisation de donn√©es (Star Sch√©ma, DataVault, DataMesh, virtualisation) - DataOpsMise en oeuvre des transformations et de la valorisation des donn√©es (SQL, Python, Java, Scala) - DataOpsOptimisation des performances et des co√ªts d utilisation Snowflake (FinOps)VOTRE PROFIL :Vous √™tes issu d'une √©cole d'ing√©nieur ou d'un Master 2Vous avez une premi√®re exp√©rience sur du Snowflake ou deux/trois ans de SQLPROCESSUS DE RECRUTEMENT :Vous pensez √™tre celui, celle qu‚Äôil nous faut et vous vous √™tes reconnu dans notre organisation, alors venez vivre votre premi√®re exp√©rience KPC en postulant √† cette offre :Vous serez appel√©(e) par Camille ou Ang√©lique (charg√©es de recrutement) pour une premi√®re prise de contactNous pourrons poursuivre les √©changes avec Anthony (consultant manager Snowflake) et/ou Mickael (Directeur Data) pour l‚Äôapproche projet et techniquePour clore ce processus de recrutement, nous vous inviterons √† rencontrer St√©phane (directeur d'agences PACA)Et tout √ßa dans un temps record üòä : 15 jours en moyenne pour allier r√©activit√© et efficacit√©.Nous garantissons l‚Äô√©galit√© des chances pour toutes et tous car pour nous la diversit√© est une force !KPC EN QUELQUES MOTS ? Nous sommes une entreprise sp√©cialis√©e dans la Data. Depuis treize ans, nous accompagnons nos clients √† valoriser leurs donn√©es de mani√®re innovante et efficace pour d√©velopper leur performance, am√©liorer leurs processus et exp√©riences utilisateurs. Nous intervenons en mode projet (50% r√©gie, 50% forfait) Nous avons d√©velopp√© 3 grandes activit√©s : ANALYTICS (BI, Data Science/Big Data, Data Gouvernance, EPM, Digital) ERP SAP CRM Pour cela, nous travaillons en partenariat avec les plus grands √©diteurs du march√© tels que : SAP, QLIK, DATAGALAXY, SALESFORCES, SNOWFLAKE, TALEND, MICROSOFT, ONESTREAM, IMAGINO. En forte croissance, nous cherchons de nouveaux talents pour participer √† cette aventure humaine au service des entreprises de demain. KPC EN QUELQUES CHIFFRES :300 collaborateurs20 % Croissance annuelle8 agences en France (Aix-en-Provence, Nice, Montpellier, Lyon, Toulouse, Bordeaux, Paris et Nantes)Des grands groupes en tant que clients : CMA CGM, PERNOD RICARD, AIRBUS, CDISCOUNT, CULTURA, GIFI, POLE EMPLOI, L'OREAL ...NOS AVANTAGES :Organisation du travail 100% flexible avec du t√©l√©travail, participation aux frais t√©l√©phonique et internet et un forfait √©quipement fournitureUn parcours d'int√©grationDes formations et des certifications avec les √©diteurs sur les technos de pointeIK voiture, v√©loCarte resto, mutuelle, pr√©voyance sant√©Prime ¬´ Vacances ¬ªPOURQUOI NOUS REJOINDRE ?Une entreprise √† taille humaineUn mode de management dynamique, agile et de proximit√©Une vie d'agence anim√©e, engag√©e et conviviale dans des locaux sympasUne attention particuli√®re √† un √©quilibre de vie pro / persoUne entreprise qui encourage les initiatives et l'autonomieUne entreprise certifi√©e Ecovadis Silver pour des actions concr√®tes en termes de RSEUn cadre de travail agr√©able prenant en compte les enjeux soci√©taux et environnementauxVous √™tes ou voulez √™tre consultant(e), chef de projet, expert(e) technique, manager ? Notre promesse : vous accompagner de fa√ßon personnalis√©e et continue quel que soit votre projet √† court, moyen et long terme.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Scientist / Engineer,Cephalgo,France,https://fr.linkedin.com/jobs/view/data-scientist-engineer-at-cephalgo-3760013350?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=Pe%2Fs%2Fr7zNA9BX1J8p8c9og%3D%3D&position=16&pageNum=2&trk=public_jobs_jserp-result_search-card,"The ideal candidate's favorite words are learning, data, scale, and agility. You will leverage your strong collaboration skills and ability to extract valuable insights from highly complex data sets to ask the right questions and find the right answers.¬†¬†ResponsibilitiesCollect, process, and clean data from diverse sources to prepare it for analysis, ensuring consistency and reliabilityAnalyze raw data: assessing quality, cleansing, structuring for downstream processing and applying machine learning (ML) and deep learning (DL) techniquesA focus on quantitative analytics and data modeling.Design accurate and scalable prediction algorithmsEnsuring scalable ML/DL pipeline constructionImplementing data storage solutions that optimize for volume, velocity, and variety of EEG dataCollaborate with the team to bring analytical prototypes to productionStay up-to-date with the latest technologies and trends in data science and machine learningQualificationsMaster's degree or equivalent experience in quantitative field (Statistics, Mathematics, Computer Science, Engineering, etc.)At least 1 - 2 years' of experience in ML/DL, quantitative analytics and data modelingA strong statistical and programming backgroundExperienced in MLOP pipeline construction and big data technologies like Spark, MLFlow, Snowflake, Hadoop for hosting the dataDeep understanding of predictive modeling, machine-learning, clustering and classification techniques, and algorithmsFluency in a programming language (Python, C,C++, Java, SQL)Excellent problem-solving skills and ability to work independently or as part of a teamExperienced in working interdisciplinary tasksWe OfferCompetitive salary and benefits packageA collaborative work environment with a supportive teamOpportunities for professional growth and developmentAccess to the latest tools and technologies.Flexible working hours and remote work optionsCEPHALGO focuses on introducing technological innovations to assist medical professionals to provide better mental health care. Located in Strasbourg, extended beyond Europe, CEPHALGO‚Äôs patient monitoring technique using EEG and AI has been applied in psychiatry across Europe. Further information can be found at https://cephalgo.com.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Consultant Junior Data Engineer - Paris - 2023,Mazars,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/consultant-junior-data-engineer-paris-2023-at-mazars-3771285480?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=QZuar61jEkMzRFwL87fDUA%3D%3D&position=17&pageNum=2&trk=public_jobs_jserp-result_search-card,"Votre posteMazars est un groupe international et int√©gr√© sp√©cialis√© dans l‚Äôaudit, la fiscalit√© et le conseil ainsi que dans les services comptables et juridiques*. Pr√©sents dans plus de 95 pays et territoires √† travers le monde, nous nous appuyons sur l‚Äôexpertise de plus de 47 000 professionnels ‚Äì plus de 30 000 au sein de notre partnership int√©gr√© et plus de 17 000 via ¬´ Mazars North America Alliance ¬ª ‚Äì pour accompagner les clients de toutes tailles √† chaque √©tape de leur d√©veloppement.*Dans les pays o√π les lois en vigueur l‚Äôautorisent.Vos principales missionsL‚Äô√©quipe Data Services de Mazars, c‚Äôest plus de 150 consultants sp√©cialistes de la data, r√©partis sur 2 hubs (Paris La D√©fense, New-York). Ils couvrent l‚Äôensemble de la cha√Æne de valeur de la donn√©e : Data Strategy et qualification de cas d‚Äôusage, Gouvernance et qualit√© des donn√©es, Data Visualisation, Data Science, Data Engineering et Data Architecture.Nous sommes convaincus que le Data Engineering est la pierre angulaire de cette industrie. Nous mobilisons, pour servir nos clients, une stack technologique riche et vari√©e, tant sur les outils open-sources (Python, Pandas, PySpark, FastAPI, Vim, SQL/NoSQL, ...) que sur les solutions du march√© (Snowflake, AWS, Azure, ...).Notre √©quipe de Data Engineers travaille au quotidien avec les membres de Mazars R&D et nos Data Analysts. Pour nos clients, nous produisons des solutions qui int√©grent le DevOps (GitLab, Ansible, Docker, Terraform, ...) d√®s la phase de conception.Vous serez form√©(e) √† nos m√©thodologies et aurez l‚Äôopportunit√© de travailler au sein d‚Äô√©quipes pluridisciplinaires, y compris les √©quipes de R&D qui d√©veloppent et maintiennent nos outils d‚ÄôAnalytics ainsi que notre infrastructure interne (GitLab-CI, VMs OpenNebula, CephFS, etc...).Vous interviendrez de fa√ßon op√©rationnelle sur des missions de conseil data ambitieuses et innovantes pour nos clients du CAC40 et SBF120, en France et √† l‚Äôinternational.Vous Participerez Notamment √† L‚Äôam√©lioration de la performance op√©rationnelle de nos clients au travers de l‚Äôexploitation et la valorisation de donn√©es sur des cas d‚Äôusage m√©tier concrets (strat√©gie, marketing et vente, R&D, finance, RSE, etc.). Le d√©veloppement de bout en bout de flux de donn√©es, de l‚Äôextraction / transformation jusqu‚Äô√† leur consommation (API, BI / Visualisation, ...) Le d√©ploiement et l‚Äôint√©gration continus de pipelines sur plusieurs paradigmes : serverless cloud (AWS Lambdas, Azure Functions, GC Functions, Kubernetes) ou cloud priv√© (OpenNebula, CloudStack, CephFS)Pourquoi nous rejoindre ? ACCOMPAGNEMENT PAR DES EXPERTS : Les Associ√©s en charge de l‚Äô√©quipe Data Services cumulent une expertise rare dans leurs domaines respectifs, e.g. √©quipe pionni√®re du MLOps (CI/CD op√©rationnelle depuis 2013). Ils participent activement √† la mise en place des activit√©s les plus pointues du cabinet et de la cr√©ation de start-up technologiques acquises par Mazars. Cet environnement √† la fois exigeant et formateur vous propulsera au top des bonnes pratiques coding et op√©rationnelles pour assurer un delivery projet de qualit√© ! AUTONOMIE ET AMBITION : √âcosyst√®me jeune, dynamique et tr√®s responsabilisant, aux fortes ambitions de croissance. Venez vous impliquer dans le d√©veloppement du Lab Mazars et construire l‚Äôoffre de service en conseil data du cabinet ! HACKING SPIRIT : Veille technologique omnipr√©sente, √† la pointe des technologies open-source les plus performantes du moment. Nos consultant(e)s se forment en permanence pour √©largir leur socle de comp√©tences. CABINET INTERNATIONAL : Rejoindre Mazars c‚Äôest int√©grer un cabinet aux dimensions internationales et b√©n√©ficier d‚Äôopportunit√©s d‚Äô√©volution de carri√®re : bootcamp data, learning center de pointe (Mazars Academy, LinkedIn learning, etc.) et mobilit√©s internationales.Venez partager avec nous cette fiert√© que nous avons d‚Äôapporter des r√©ponses pertinentes √† nos clients. Vous vous d√©passez sur des sujets techniques vari√©s et ambitieux, au sein d‚Äôune √©quipe humaine et bienveillante !#JTVotre profilDe Formation Bac+5 Type √âcole D‚Äôing√©nieur G√©n√©raliste Ou Sp√©cialis√©e, Ou D‚Äôun 3√®me Cycle Dans Un Domaine Connexe √† La Data (syst√®mes D‚Äôinformations, Traitements De Donn√©es, Big Data, Statistiques, G√©nie Logiciel, Etc.) Vous avez d√©j√† montr√© un int√©r√™t pour le domaine du d√©veloppement applicatif int√©grant une composante Data, √† travers des stages, cours ou projets personnels impliquant le d√©veloppement back-end et/ou front-end d‚Äôune application. Vous avez une exp√©rience pratique et une bonne connaissance de : Un ou plusieurs langages de programmation analytique (Python, R, Haskell, Rust, etc.) Une ou plusieurs couches de persistance (MySQL, MongoDB, ElasticSearch, S3, Node4j) Vous n‚Äôenvisagez pas de travaux s√©rieux en dehors d‚Äôun syst√®me Linux (Ubuntu, Debian, CentOS), ou sans syst√®me de contr√¥le de version (Git), et l‚Äôutilisation d‚Äôune cha√Æne d‚Äôint√©gration vous parait naturelle Vous pensez que l‚Äô√©cosyst√®me tech open-source est un puissant terrain de jeu √† la pointe de la technologie, qui met √† disposition l‚Äôensemble des outils n√©cessaires √† la r√©alisation des projets les plus ambitieux. Vous souhaitez travailler avec les utilisateurs m√©tiers et les clients pour comprendre leurs besoins. Vous √™tes curieux (se), autonome, entreprenant(e) et savez faire preuve d‚Äôinitiatives. Vous ma√Ætrisez l‚Äôanglais oral et √©crit.Une premi√®re exp√©rience des technologies suivantes est un plus : Sensibilisation √† la qualit√© logicielle et aux cha√Ænes d‚Äôint√©gration continue (DevOps) Sensibilisation √† l‚Äôinteraction avec des √©quipes fullstack (RestAPI, VueJS, ReactNative) Exp√©rience sur l‚Äôun des cloud providers (Azure, AWS, GCP) Cha√Æne d‚Äôanalyse pr√©dictive (scikit-learn, TensorFlow, etc.) Outil de Business Intelligence (Power BI, Qlik, Tableau, etc.)Vous serez bas√©(e) √† Paris, avec d‚Äô√©ventuels d√©placements en province et √† l‚Äô√©tranger.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow'], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': ['MySQL', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer,DEXTON Consulting,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-dexton-consulting-3724473517?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=UQMFJTTBOJxOyD4w07G1eA%3D%3D&position=18&pageNum=2&trk=public_jobs_jserp-result_search-card,"Vous souhaitez int√©grer un groupe √† taille humaine ayant un grand potentiel ? Notre groupe est en pleine croissance notamment en France. Rejoignez-nous et soyez au c≈ìur de notre expansion, vous b√©n√©ficierez d‚Äôun positionnement riche en opportunit√©s.Vous aurez l‚Äôoccasion de collaborer avec les meilleurs talents du conseil pour cr√©er des solutions innovantes et de haute qualit√© qui r√©pondent aux besoins de nos clients.Au sein d‚Äôune √©quipe de consultants experts, vous intervenez en tant que consultant dans le but de contribuer aux √©volutions majeures des SI de nos clients. Vos principales missions sont :Le recueil des besoins aupr√®s des utilisateurs/clients.La conception, la construction et la maintenance de pipelines pour l'extraction, le chargement et la transformation de donn√©es √† grande √©chelleLa mise en place et la gestion des bases de donn√©es SQL ou NoSQLLe d√©veloppement des syst√®mes d‚Äôanalyse de donn√©es en utilisant des technologies telles que SparkSQL et Spark StreamingL‚Äô√©valuation et l‚Äôam√©lioration des performances des pipelines de donn√©es pour garantir une haute disponibilit√© et une faible latence, en utilisant des technologies bas√©es sur le CloudLe travail en √©troite collaboration avec les √©quipes de Data Science pour fournir des solutions appropri√©esLe reporting aux √©quipes m√©tiers des solutions mises en place via des outils de Dashboarding (PowerBI, Tableau, etc.)Exigences :Vous justifiez d‚Äôau moins 3 ans d‚Äôexp√©rience en tant que Data Engineer ou dans un r√¥le similaireVous b√©n√©ficiez d‚Äôune exp√©rience d‚Äôau moins 6 mois sur la technologie Spark (Pyspark ou Scala)Vous justifiez d‚Äôune exp√©rience sur le Cloud Azure d‚Äôau moins 6 mois (Databricks, Data Factory, Data Lake Gen 2, etc.)Vous ma√Ætrisez les langages Python et SQLVous avez des comp√©tences en conception de bases de donn√©es non relationnelles (Hbase, Cassandra,etc.)Vous avez de bonnes connaissances sur l‚Äôenvironnement Hadoop (Hive, Pig, Oozie, etc.)Id√©alement, vous avez d√©j√† travaill√© avec des outils de planification et d‚Äôautomatisation de pipelines (Apache Airflow, Apache Nifi, Azure Pipeline, Azure Data Factory, etc.)Vous √™tes autonome.Vous √™tes force de proposition et capable de soumettre et d√©fendre des recommandations.Vous avez un bon niveau d‚Äôanglais.En rejoignant nos √©quipes, vous travaillerez au quotidien aupr√®s des experts reconnus du monde du Big Data. Vous ma√Ætriserez une m√©thodologie performante et progresserez gr√¢ce √† un large choix de formation. Et surtout, vous aurez un impact majeur sur les transformations strat√©giques des entreprises.Programmation¬†:Du lundi au vendrediHoraires flexiblesP√©riode de travail de 8 heuresTravail en journ√©ePackage de r√©mun√©ration :. Salaire fixe + Bonus. Type d'emploi : Temps plein, CDI. Statut : Cadre. Salaire¬†: En fonction de l'exp√©rience. Primes. Primes annuellesAvantages¬†:Prise en charge du transport quotidienRTTTitre-restaurantLieu du poste : T√©l√©travail hybride (Paris (75))


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks', 'Apache Airflow'], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Intern,STATION F,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-intern-at-station-f-3792803573?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=l4R%2FLe3w9DaiX6EouC9yyg%3D%3D&position=19&pageNum=2&trk=public_jobs_jserp-result_search-card,"AboutData&Data is an intelligence technology company that provides services to Luxury brands to help them gain market insights about their online distribution and growth of their products in the grey market, leveraging all through the power of Artificial Intelligence. After launching our anti-counterfeiting solution in 2015, we launched an unprecedented solution against grey market sales in 2016.Follow us to know more about the company culture and updates:LinkedIn: https://www.linkedin.com/company/data&data-consultingFacebook: https://www.facebook.com/DataandDataYouTube: https://www.youtube.com/channel/UC2YP_PN4Z9qWPMivVhUJQyQJob DescriptionWe are looking for a developer to help us implement new functionalities in our product. You will have the possibility to work on a wide variety of projects, including: Enhancing our crawling and scraping algorithms. Untangling the APIs of services from around the world. Designing data processing and analysis algorithms. Scaling our architecture to process more bytes faster. Implementing a bulletproof strategy for testing and maintenance. Developing internal monitoring or productivity tools.Why join us? Challenges: never short of those, you‚Äôll have the opportunity to apply many skills. Responsibilities: expect your first release into production on week one. Work life: flexible hours, flat hierarchy, casual Fridays everyday. Team: a small and dynamic team. Location: Station F, the largest startup incubator - Paris. Salary: ‚Ç¨6k ‚Äì ‚Ç¨18kYou Preferred Experience  Are fluent in at least one scripting or OO language, ideally Python. Know the basics of SQL, and can find your way around in a Unix terminal. Are driven, with strong interpersonal, analytical and problem solving skills. Are well rounded, proactive, can multitask and ship high-caliber solutions on time.SkillsPython, Machine Learning, SQL, Cloud Computing, Big Data, Databases, DevOps, Backend Development, Unix, Microsoft AzureA Unicorn Would Have Experience With Big data, cloud or NoSQL technologies (Hadoop, Azure, Neo4j, etc.). Applied machine learning or computer vision. Working with startups or agile teams. Foosball and perks of working at STATION F.Additional Information Contract Type: Internship  Location: Paris  Salary: between 1000‚Ç¨ and 1500‚Ç¨ / month


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Neo4j'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER (H/F),SFR,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sfr-3675546210?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=rl9LVmup%2F2Uq1x4nGqCGzA%3D%3D&position=20&pageNum=2&trk=public_jobs_jserp-result_search-card,"En tant que Data Ing√©nieur exp√©riment√©, vous occuperez un r√¥le essentiel dans notre √©quipe Data Science. Vous serez responsable de la conception, du d√©veloppement et de la maintenance des pipelines de donn√©es ainsi que de l'int√©gration de sources de donn√©es multiples. Votre expertise sera cruciale pour garantir une gestion efficace des flux de donn√©es, ainsi que pour faciliter l'analyse et la visualisation des donn√©es en plus du support aux data scientists vos missions seront les suivantes : Architecture projet des donn√©es : Concevoir et d√©velopper des architectures projet de donn√©es robustes, √©volutives et performantes pour int√©grer et g√©rer de grandes quantit√©s de donn√©es provenant de sources multiples. Assurer la fiabilit√©, l'√©volutivit√© et la s√©curit√© des flux de donn√©es entrant d‚Äôun projet Data Science.Int√©gration des donn√©es : √âlaborer des pipelines de donn√©es efficaces pour l'extraction, la transformation et le chargement des donn√©es (via notre Framework ELT/ETL interne) provenant de diff√©rentes sources. Mettre en place des processus d'int√©gration automatis√©s et veiller √† la qualit√© des donn√©es.Gestion des bases de donn√©es : Concevoir et optimiser des bases de donn√©es pour r√©pondre aux besoins analytiques et de reporting. Assurer la performance, la disponibilit√© et la s√©curit√© des bases de donn√©es, ainsi que la gestion efficace des requ√™tes.Collaboration interfonctionnelle : Support des Data Scientists, vous travaillerez avec les √©quipes business pour comprendre leurs besoins et fournir des conseils et des recommandations bas√©s sur les donn√©es.Optimisation des performances : Surveiller et optimiser les performances des pipelines de donn√©es, des bases de donn√©es et des requ√™tes. Identifier les goulots d'√©tranglement et les points d'optimisation, et proposer des am√©liorations pour garantir des performances optimales.S√©curit√© et conformit√© : Veiller √† ce que les donn√©es soient trait√©es et stock√©es conform√©ment aux normes de s√©curit√© et de confidentialit√©. Mettre en place des m√©canismes de s√©curit√© pour prot√©ger les donn√©es sensibles et garantir la conformit√© aux r√©glementations en vigueur.Votre profil : Vous avez un Dipl√¥me universitaire en informatique, en g√©nie logiciel, en science des donn√©es ou dans un domaine connexe et vous avez √† minima 5 ans d'exp√©rience en tant que Data Ing√©nieur. Vous poss√©dez √©galement une solide ma√Ætrise des technologies et des outils suivants : Hadoop, Spark, SQL, Kafka, GCP BigQuery, De plus vous avez une bonne compr√©hension des architectures, des mod√®les et des concepts de base de donn√©s avec une exp√©rience avanc√©e dans la mise en ≈ìuvre de pipelines ETL et dans la gestion de bases de donn√©es.Vos connaissances en mati√®re de s√©curit√© des donn√©es, de conformit√© aux r√©glementations ainsi que vos comp√©tences en programmation scripting et en d√©veloppement logiciel seront un plus. Vos excellentes comp√©tences en communication seront des qualit√©s appr√©ci√©es et un niveau d'anglais (appliqu√©e au domaine technique) est un plus.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer (Python) H/F,WINSEARCH,"Salasc, Occitanie, France",https://fr.linkedin.com/jobs/view/software-engineer-python-h-f-at-winsearch-3804496383?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=cALC62%2Bp9MhE1f3te0Xc5w%3D%3D&position=21&pageNum=2&trk=public_jobs_jserp-result_search-card,"Le cabinet Winsearch, recrute pour l'un de ses clients, sp√©cialis√© dans la pr√©servation de l'environnement et dans l'accompagnement des acteurs des √©nergies renouvelables, un D√©veloppeur Logiciel Python en CDIMissions du poste :Vous r√©alisez le codage et les tests des produits logiciels et des outils d'exploitation, et r√©alisez la documentation associ√©e, Vous effectuez les tests de validation, et r√©alisez la documentation associ√©e, Vous installez et param√©trez les logiciels sur les mat√©riels avant d√©ploiement, Vous analysez les donn√©es et les remont√©es terrain et identifiez les am√©liorations et solutions √† mettre en oeuvre. Vous travaillez en √©troite collaboration avec les autres services de la Soci√©t√©, pour l'exploitation ou l'installation des sitesTECH : Python, environnement Linux et Windows, MySQLExp√©rience de 5 ans en d√©veloppement en Python pour des environnements Windows et Linux Exp√©rience dans les domaines du traitement et de l'analyse de donn√©es dans un milieu industriel embarqu√© La maitrise des bases de donn√©es (mySQL) est n√©cessaire. La maitrise des r√©seaux informatiques et des technologies de communication s√©curis√©es (VPN, SSH) est un plus Rigueur, autonomie, capacit√© d'organisation et de structuration, sens de la communication et du travail en √©quipe Parfaite maitrise du fran√ßais et bonne ma√Ætrise de l'anglais obligatoire19139856-55584
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux', 'Windows'], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': ['VPN'], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER - H/F,Generali France,"Seine-St.-Denis, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-generali-france-3806809881?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=rwkdUS1yBbooMpU8NgoP%2BA%3D%3D&position=22&pageNum=2&trk=public_jobs_jserp-result_search-card,"GeneraliAvec plus de 69 millions de clients et un chiffre d‚Äôaffaires de 81,5 milliards d‚Äôeuros en 2022, Generali est l‚Äôun des leaders de l‚Äôassurance et de la gestion d‚Äôactifs dans le monde. Assureur responsable, nous pla√ßons la durabilit√© au c≈ìur de notre strat√©gie.Notre directionLe march√© des particuliers IARD et pr√©voyance assure l'offre, la commercialisation, la gestion et l'indemnisation de nos produits IARD et pr√©voyance destin√©s aux particuliers. Il assure √©galement la Relation client et interm√©diaires, le marketing, le digital et la pr√©voyance individuelle ainsi que la gestion et l'indemnisation des contrats emprunteurs pour l'ensemble de notre entreprise.Vos missionsL'expertise Marketing, Digital & Data est plus que jamais cl√© pour mener √† bien la transformation de Generali France et faire face aux enjeux auxquels sont confront√©s les acteurs de l'Assurance.Au sein de la Direction Marketing & Digital,nous recherchons un(e) Data Scientist ayant au minimum 5ans d‚Äôexp√©rience sur des probl√©matiques d‚Äôexploitation des donn√©es (clients, prospects, digitales, campagnes, transactionnelles, ‚Ä¶) √† des fins Marketing (ciblage, cr√©ation de score, reporting de bout-en-bout, optimisation des op√©rations Marketing, ‚Ä¶).Les principales missions :D√©velopper, automatiser et industrialiser :Les traitements de donn√©es sous diff√©rents environnements/outilsLes reporting dynamiques et app sous Tableau / PowerBI ou Streamlit (suivi de la performance des leads de bout-en-bout, des interm√©diaires ‚Ä¶)Les outils de suivi des actions marketing (campagnes d√©veloppement clients, bilan d'activit√© ‚Ä¶)D√©velopper ou superviser les d√©veloppements des traitements en Python (PySpark en cas de forte volum√©trie) pour pr√©parer les donn√©es, entra√Æner et optimiser les mod√®les de data science, √©valuer et valider leur performanceAssurer la documentation des travaux et analyses qui vous sont confi√©sProduire les √©tudes & analyses :Aider √† la d√©cision sur des sujets marketing en apportant une approche quantitative via des √©tudes et des analyses (analyses d'impact des op√©rations marketing)R√©aliser ou encadrer la r√©alisation des analyses n√©cessaires √† une bonne prise en charge des donn√©es √† disposition, au contr√¥le de la coh√©rence, la validation de leur lectureEnrichir les Donn√©es :D√©finir la trajectoire d‚Äôenrichissement de donn√©es notamment sur l‚Äôint√©gration de celles-ci dans Salesforce Marketing Cloud avec le m√©tierIdentifier les sources ad√©quates et les r√®gles de gestion appropri√©es aupr√®s des directions techniquesPiloter et assurer la mise en ≈ìuvre de cette trajectoireRepr√©senter le Marketing dans la Gouvernance des donn√©esProfil recherch√©C‚Äôest dans ce cadre que nous recherchons un(e) Data Engineer ayant avec au minimum 5 ans d‚Äôexp√©rience sur des probl√©matiques de pilotage data.Comp√©tences :Rigueur, organisation, autonomie, go√ªt pour le travail en √©quipe, sens de l'analyse, force de proposition.Environnements & outils :Langage PythonEnvironnement Azur (ADLS)HadoopPysparkSolutions de dataviz : Power BI, Tableau & StreamlitNous rejoindre, c'est :int√©grer une entreprise dynamique qui place l‚Äôinnovation et la durabilit√© au c≈ìur de sa strat√©gierelever des challenges, faire preuve d‚Äôinitiative et organiser son travail en mode hybrideconstruire sa carri√®re et d√©velopper ses comp√©tencesse nourrir des diff√©rences de chacun dans une entreprise qui m√®ne des actions concr√®tes en faveur de la diversit√©, l‚Äô√©quit√© et l‚Äôinclusionavoir la possibilit√© de s‚Äôengager au sein de notre fondation The Human Safety Net, pour soutenir les personnes vuln√©rables et participer √† l‚Äôimpact positif que nous g√©n√©rons.Pour en savoir plus, visitez notre site.Engag√© en faveur de l'√©galit√© des chances, Generali √©tudie avec la plus grande attention les candidatures de personnes en situation de handicap et leurs √©ventuels besoins sp√©cifiques.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F) - Paris,BPCE Solutions informatiques,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-paris-at-bpce-solutions-informatiques-3802921297?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=fRXpyi1PvxceRcs12u%2FK0g%3D%3D&position=23&pageNum=2&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseBPCE SI est une entreprise informatique du Groupe BPCE. Avec ses 19 implantations en r√©gions, BPCE SI intervient au plus pr√®s des √©tablissements bancaires.Chaque jour, plus de 2600 collaborateurs imaginent, inventent, testent des solutions innovantes pour faciliter la vie des utilisateurs des Caisses d‚ÄôEpargne, des Banques Populaires et de plusieurs filiales et √©tablissements bancaires comme le Cr√©dit Coop√©ratif et la SocFim.A travers l‚Äôutilisation de nos solutions bancaires, nous sommes pr√©sents dans le quotidien de pr√®s de 1 Fran√ßais sur 2 !Plus de 80 m√©tiers sont pr√©sents au sein de BPCE SI et plus de 50 technologies et langages de d√©veloppement sont utilis√©s dans nos solutions bancaires !Entreprise humaine et engag√©e, notre politique de Responsabilit√© sociale de l‚Äôentreprise porte des sujets cl√©s comme la mixit√©, la diversit√©, le handicap, la qualit√© de vie au travail et le d√©veloppement durable.Nous attachons une attention particuli√®re √† la r√©ussite de chacun(e). Nos √©quipes sont accompagn√©es tout au long de leur parcours et √©voluent dans un environnement de travail stimulant pour exprimer leurs talents.Alors, pour booster votre carri√®re et profiter de la diversit√© des terrains de jeux que proposent BPCE Solutions informatiques et le Groupe BPCE, rejoignez-nous !Poste et missionsAu sein de la ¬´ Plateforme Assurances ¬ª vous int√©grez l‚Äô√©quipe Data Management Office sous la responsabilit√© du manager de l‚Äô√©quipe.L‚Äô√©quipe DMO est en charge de mettre en place les nouveaux projets li√©s √† la feuille de route Data des m√©tiers de l‚Äôassurance non vie et de maintennir les solutions d√©cisionnelles.Vous Interviendrez Sur Le P√©rim√®tre IndemnisationSur le p√©rim√®tre RUN, vous assurez la gestion, l'analyse et le suivi de r√©solution des incidents et des √©volutions remont√©es par les utilisateurs.Sur le p√©rim√®tre projet, vous assurez le cadrage fonctionnel du projet avec les m√©tiers, le suivi des d√©veloppements et les tests.Votre R√¥le Sera DeCollaborer avec les r√©f√©rents m√©tier pour recueillir leurs besoin ;R√©diger des sp√©cifications techniques et fonctionnelles ;Collaborer avec les r√©f√©rents applicatifs pour √©tablir les mapping li√©s aux besoins m√©tier ;Collaborer avec les intervenants IT (Infrasctructure, DBA) ;Participer aux phases de mod√©lisation (mod√©lisation relationnelle / BI) ;Assurer la conception et le d√©veloppement des flux d‚Äôint√©gration du DWH et des Datamart m√©tier ;Mise en place des strat√©gies de tests unitaires et fonctionnelles ;La mise en place des normes de d√©veloppements et les bonnes pratiques (mod√®les de traitements, ‚Ä¶) ;Mise en place des documents de r√©f√©rence ;Pilotage des d√©veloppeurs intervenant sur le p√©rim√®tre indemnisation.Profil et comp√©tences requisesVous avez d√©j√† particip√© √† un ou plusieurs projets BI, sur des probl√©matiques de Data Integration (mise en place des bonnes pratiques pour des flux otpimis√©s) ou plus g√©n√©ralement dans la mise en place de Datawarehouses/Datamarts.Vous attachez une importance particuli√®re √† la qualit√© de vos d√©veloppements (respect de l‚Äôarchitecture, normes de codage, tests unitaires,‚Ä¶).Vous avez une tr√®s bonne ma√Ætrise des outils suivants :Stambia: TalendSGBD : SQL Server, OracleReporting : Microstrategy, PowerBIInformations compl√©mentaires sur le poste
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Cloud H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-h-f-at-inetum-3802985453?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=qdV7o%2B4mkiwymjU2DfhZfw%3D%3D&position=24&pageNum=2&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre Informations g√©n√©rales Entit√© de rattachement Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 27 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste M√©tier M√©tier AS (Application Services) - D√©veloppementIntitul√© du poste Data Engineer Cloud H/FContrat CDIREJOINDRE LES EQUIPES DATA D‚ÄôINETUM, C‚ÄôEST Int√©grer une communaut√© d‚Äôexperts de plus de 700 collaborateurs en France,Travailler en ¬´ mode projet ¬ª autour des Modern DATA Platform & accompagner nos clients sur des probl√©matiques de Gouvernance, d‚ÄôInt√©gration, de Visualisation‚Ä¶Avoir des missions challengeantes chez nos clients sp√©cialis√©s sur les secteurs Banque, Telecom, Energie, Finance, Assurance, Industrie, Secteur Public,...Evoluer au sein d‚Äôune structure avec de nombreux partenariats strat√©giques (Microsoft Azure, AWS, GCP‚Ä¶)CE QUE NOUS RECHERCHONSInetum recherche un(e) Data Engineer Cloud, disposant de solides connaissances techniques.CE QUE NOUS ATTENDONS DE VOUSEn tant que Data Engineer Cloud, vous concevez, mettez en place et administrez des solutions Big Data.Vos missions d√©taill√©es Analyse et compr√©hension des besoins m√©tiers,Participation √† la d√©finition et √† la conception de l‚Äôarchitecture,Gestion des donn√©es pr√©paration, ingestion, traitement, contr√¥le qualit√©,D√©veloppements des jobs (Par exemple Spark) et automatisation des flux d‚Äôalimentation du Data Lake,Tests de charge, tests unitaires‚Ä¶Maintenabilit√© de la solution Big Data /Cloud (Optimisation et performance des traitements).VOUS ETESIng√©nieur de formation, vous disposez d‚Äôune exp√©rience de 3 ans minimum en tant que Data Engineer. Vous ma√Ætrisez les langages Java, Scala ou Python et √™tes expert sur les framework Spark et/ou Hadoop. Vous avez id√©alement d√©j√† travaill√© sur Microsoft Azure, GCP ou AWS. Vous avez une expertise sur les services Cloud Data Platform suivants Azure Data Lake, Azure Synapse, Azure Data Factory, Azure Data Explorer, Azure Databricks, Cloud Storage, BigQuery, DataPrep, DataProc ...NOUS VOUS OFFRONSDes missions engageantes aupr√®s des grands acteurs du march√©,Un management de proximit√© toujours bienveillant et √† l‚Äô√©coute et avec qui vous pourrez √©changer au quotidien sur les enjeux de votre mission et √©voquer vos futurs projets afin que nous puissions vous aider √† les r√©aliser.La possibilit√© d‚Äô√©voluer et de monter en comp√©tences gr√¢ce √† des formations et √† des certifications notamment via notre Data Academy.La possibilit√© d'appartenir √† une vraie communaut√© Data.INETUM SPIRITDes communaut√©s d‚Äôexpertises sur les sujets de la Data,De super nouveaux locaux qui sont en plus accessibles facilement,Une √©cole de formation int√©gr√©e,Des √©v√®nements des soir√©es avec les consultants, des 12@13‚Ä¶Une entreprise labellis√©e ""Top Employer Europe 2023"".N‚Äôattendez plus, rejoignez INETUM et venez nous rencontrer dans nos nouveaux locaux situ√©s √† Saint-Ouen#DevenezInetumien!Localisation du poste Localisation du poste France, Ile-de-France, 93 Seine-Saint-DenisVille Saint-Ouen-Sur-SeineCrit√®res candidat Niveau d'√©tudes min. requis Bac+5Niveau d'exp√©rience min. requis Plus de 2 ans


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirm√© - Scala (F/H/X),AVIV Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-scala-f-h-x-at-aviv-group-3802366537?refId=0P9VLTK3r2AZZQS4m6q5Rw%3D%3D&trackingId=I5KtAc6G7i0QAr9GhdvMFQ%3D%3D&position=25&pageNum=2&trk=public_jobs_jserp-result_search-card,"Description De L'entrepriseVous rejoindrez l'une des plus grandes entreprises priv√©es de technologie immobili√®re au monde et une filiale d'Axel Springer. Notre mission est de trouver l'endroit id√©al pour chacun ! Vous travaillerez sur certaines des marques immobili√®res num√©riques les plus connues d'Europe, notamment : üá´üá∑ Meilleurs Agents, üá´üá∑ Groupe SeLoger, üáßüá™ Immoweb, üá©üá™ Immowelt, üá™üá∏ Housell et üáÆüá± Yad2.Au sein du groupe AVIV, vous aurez l'autonomie n√©cessaire pour travailler dans le style qui vous convient le mieux pour √™tre le plus productif.Cette autonomie et la libert√© de travailler quand et o√π vous le souhaitez nous ont permis d'attirer les meilleurs talents √† nos c√¥t√©s.Vous travaillerez avec des √©quipes tr√®s performantes pour construire une plateforme commune qui alimente plusieurs marques et nous aide √† devenir la solution de choix pour tout ce qui concerne l'immobilier.Les d√©veloppeurs jouent un r√¥le cl√© dans l'am√©lioration de l'exp√©rience d'achat de domicile de nos clients en utilisant une combinaison de logiciels open source, de solutions cloud et d'approches ax√©es sur les donn√©es pour √©laborer des solutions innovantes.Description Du PosteRejoignez l‚Äô√©quipe Marketplace Design AVIVLa marketplace AVIV est le lieu de rencontre privil√©gi√© de tous les acteurs de l‚Äôannonce immobili√®re: potentiels acqu√©reurs ou locataires, propri√©taires ou agents, ‚Ä¶ Afin de garder notre position, nous devons fournir la meilleure qualit√© de service possible en termes de s√©curit√©, de confiance, d‚Äôefficacit√© et de pertinence des √©changes entre ces acteurs. Plusieurs facteurs entrent en ligne de compte: qualit√© et s√©rieux des prospects et des agents ainsi que la qualit√© des informations affich√©es.Le r√¥le de l‚Äô√©quipe Marketplace design est de concevoir et ex√©cuter toutes les actions n√©cessaires pour assurer la satisfaction de nos utilisateurs : qualit√© et correction des donn√©es, scoring, matching, gamification, et am√©lioration continue. Ces actions requi√®rent un usage important des donn√©es, l‚Äô√©quipe Data Operations est responsable de la gouvernance, la mod√©lisation et la qualit√© des donn√©es ainsi que de fournir les data-sets cl√©s et maintenir une data platform robuste et efficace pour tout le groupe AVIV.Vos responsabilit√©s :En tant que Data Engineer au sein de l‚Äô√©quipe Data Operations, vous travaillez en √©troite collaboration avec un Product Manager et votre Engineering Manager. Vos d√©veloppements respectent les bonnes pratiques en place et sont align√©s avec l‚Äôarchitecture d‚Äôentreprise AVIV. Vous apportez votre expertise technique √† votre √©quipe, vous cr√©ez, adaptez et am√©liorez la qualit√© des data-sets et des outils largement utilis√©s chez AVIV.L‚Äô√©quipe Data OperationsL‚Äô√©quipe est constitu√©e d‚Äôenviron 40 personnes, avec notamment:Coach AgileData EngineersData Quality EngineersData Analysts & ModelersDevops EngineersEnterprise & Solution ArchitectsProduct ManagersLes projetsD√©centraliser la data et Mettre en place le Data Mesh au sein du groupe AvivFournir les insights sur les usages des diff√©rents sites et apps mobiles europ√©ens Notre Stack Technique dataAWS (CloudFormation, EMR, S3, Glue, Athena, Redshift, SNS/SQS)SparkGit, CircleCI, DatadogScala, JavaVous avez id√©alement des connaissances compl√©mentaires telles que :Python Apache Airflow, KubernetesJenkins, Argo CD, Grafana, VictoriaMetricsQualificationsNous recherchons une personne capable de:Cr√©er et maintenir des datasets complexes et √† gros volumes selon des sp√©cifications fonctionnelles pr√©cises. Participer √† la cr√©ation d‚Äôune infrastructure solide et optimale pour l‚Äôextraction, la transformation et le chargement (ETL) de donn√©es √† partir de nombreuses sources. Utilisation de SQL et de technologies big data cloud. Identifier, concevoir et impl√©menter les processus internes d‚Äôam√©lioration: automatisation, optimisation du delivery, scalabilit√©, etc‚Ä¶Travailler avec des experts data et donn√©es analytiques au d√©veloppement de nouvelles fonctionnalit√©s Maitriser la m√©thodologie Agile: communication directe, adaptation, fail fast, am√©lioration continue et Software CraftsmanMa√Ætriser le produit et le business, impactant l‚Äôam√©lioration du service aux clients, du produit et de l‚ÄôarchitectureRigueur, curiosit√©, autonomie et √©tat d‚Äôesprit positif Partager des connaissances et ouvert aux nouveaut√©sMa√Ætriser les sujets RGPD, s√©curit√© et respect de la vie priv√©eExp√©rience recherch√©eExp√©rience r√©ussie de data engineering, dans diff√©rents environnements, notamment Spark. Ma√Ætrise des design patterns actuels et des architectures d√©veloppements courants. Ma√Ætrise de l‚Äôanglais professionnel. Informations suppl√©mentairesCe que nous vous offrons :Nous sommes l'une des principales plateformes PropTech en Europe. Si vous avez d√©j√† lou√© ou achet√© un bien immobilier, vous avez peut-√™tre utilis√© l'un de nos portails de petites annonces. C'est le moment id√©al pour nous rejoindre et contribuer √† l'√©l√©vation de notre marque AVIV. La possibilit√© de travailler de mani√®re hybride au sein de notre zone d'activit√©, avec des d√©placements internationaux vers nos sites en France, en Belgique et en Allemagne. L'autonomie pour travailler dans le style qui vous convient le mieux pour √™tre le plus productif. La libert√© de nous dire quels sont les outils dont vous avez besoin pour r√©ussir dans votre travail, afin que nous puissions vous pr√©parer √† y parvenir. Ce poste est ouvert UNIQUEMENT en CDIChez Aviv, nous sommes un employeur garantissant l'√©galit√© des chances et o√π chacun est invit√© √† √™tre lui-m√™me. Aussi nous vous invitons √† postuler quelle que soit votre origine, que vous soyez parent, membre de la communaut√© LGBTQIA+, ou encore en situation de handicap. Si vous avez besoin d'ajustements, lors du processus de candidature, ou si vous souhaitez discuter de demandes de travail √† temps partiel ou flexible, veuillez nous en informer.Dans votre candidature, n‚Äôh√©sitez pas √† indiquer les pronoms que vous utilisez (ex: elle/il/iel, etc.). A tr√®s vite !Notre ambition est d'√™tre le premier employeur de PropTech √† travers l'Europe et c'est un moment cl√© pour nous rejoindre et trouver votre emploi id√©al !INDSPO


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Apache Airflow'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['CloudFormation'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Engineer Confirm√©(e)/Senior (CDI),CBTW,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-e-senior-cdi-at-cbtw-3797662873?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=gS6IKNug19rZHMtPsH1wXg%3D%3D&position=1&pageNum=3&trk=public_jobs_jserp-result_search-card,"Salut √† tous les Data wizards !Chez Positive Thinking Company, on est toujours en qu√™te de talents audacieux pour rejoindre notre communaut√© d'experts en pleine croissance. Si tu as l'esprit cr√©atif, une passion pour l'innovation et un d√©sir d'apprendre constamment, tu es exactement le profil que nous recherchons.En tant que notre futur(e) Data Engineer, tu auras l'opportunit√© de travailler sur des projets stimulants, de d√©velopper tes comp√©tences techniques et de contribuer √† la croissance d'une entreprise dynamique et inclusive.Nous recherchons un Data engineer minimum 3 ans d'exp√©rience significative, passionn√© par l'ing√©nierie des donn√©es et poss√©dant une solide exp√©rience en conception, d√©veloppement et maintenance de pipelines de donn√©es robustes et √©volutifs. Nous cherchons quelqu'un qui a des comp√©tences techniques solides dans les domaines suivants :Conception et d√©veloppement de solutions de stockage de donn√©es, telles que des data warehouses et des data lakesMise en place de flux de travail pour l'extraction, la transformation et le chargement de donn√©es (ETL)Ma√Ætrise d'au moins un langage de programmation couramment utilis√© dans l'ing√©nierie des donn√©es, tels que Python ou ScalaConnaissance de l'utilisation de technologies de traitement de donn√©es distribu√©es, telles que Hadoop, SparkCompr√©hension des principes fondamentaux des bases de donn√©es relationnelles et non relationnellesCapacit√© √† travailler avec des outils d'automatisation et de gestion de code, tels que Git, Jenkins ou AnsibleLe candidat id√©al sera √©galement capable de travailler en √©quipe et de communiquer efficacement avec des coll√®gues ayant des comp√©tences techniques diff√©rentes.Si vous √™tes pr√™t √† relever des d√©fis stimulants et √† faire partie d'une √©quipe dynamique, n'h√©sitez pas √† postuler d√®s maintenant. Nous avons h√¢te de vous rencontrer !PS : D√©marrage en Septembre


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data Engineer ‚Äì Lille, France (H/F)",Astek,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-lille-france-h-f-at-astek-3780224382?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=yp0hihXpk51b0VG999Ab7w%3D%3D&position=2&pageNum=3&trk=public_jobs_jserp-result_search-card,"CDILille - FrancePubli√©e il y a 2 joursData Engineer ‚Äì Lille, France (H/F)Ce Que Nous Allons Accomplir Ensemble :Intervenir au sein d‚Äôune direction informatique dans le domaine du retail au sein de l‚Äô√©quipe Data.Votre Future √âquipe :Vous int√©grerez une squad Data √† taille humaine en charge d‚Äôun p√©rim√®tre fonctionnel.Votre mission (‚Ä¶si vous l‚Äôacceptez !) :Participer aux rituels agiles de l‚Äô√©quipe.Participer aux diff√©rentes r√©unions de travail li√©es au projet.Analyser les besoins des utilisateurs et proposer des solutions innovantes en phase avec les drivers de l‚Äôentreprise.D√©velopper des solutions Data (Alimentation, Stockage, Mod√©lisation, Restitution).Am√©liorer et optimiser le patrimoine actuel de son √©quipe.Maintenir des solutions existantes (Run).Contribuer √† la construction du nouveau socle et des services sur la plateforme GCP.Accompagner et acculturer les m√©tiers sur les bonnes pratiques de l‚Äôexploitation de la Data.Vos stacks de jeu : SQL / BigQuery / ETL / ELT / github / Terraform / UML / LookML / Power BI / Data Studio / Looker vizLes Petits Plus Du Projet :Il s‚Äôagit d‚Äôune mission qui s‚Äôinscrit sur du long terme (3 ans) o√π vous interviendrez sur les syst√®mes applicatifs et sur les plateformes Big Data, IoT.Vous ?De formation Ing√©nieur, vous justifiez d‚Äôune premi√®re exp√©rience en tant que Data Engineer. Vous aimez √™tre garant de la ma√Ætrise de la donn√©e et de la qualit√© de son utilisation.Vous souhaitez √™tre un acteur d√©terminant dans la d√©finition de la politique de la donn√©e et de la structuration de son cycle de vie dans le respect des r√©glementations en vigueur.Nous ?Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale. Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 7800 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes. Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde et ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ hors acquisition en 2023.‚ú® Tous les d√©tails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : blog.groupeastek.com.Rencontrons-nous !Vous vous √™tes reconnu sur l‚Äôannonce et Astek vous pla√Æt !Pour en savoir plus sur vous, Clarisse, notre charg√©e de recrutement vous contactera. Puis, vous aurez 3 entretiens max, avec Louis (votre futur n+1), et Jonathan notre responsable de Business Unit !Bienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !Caract√©ristiques de l'emploiCat√©gorie Ing√©nieurLieu Lille - Hauts-de-FranceExp√©rience Data EngineerPostuler en ligneNom *Pr√©nom *Email *Un email valide est requis.T√©l√©phone *Un num√©ro de t√©l√©phone valide est requis.Joindre un CV *Data Engineer ‚Äì Lille, France (H/F)Les Petits Plus Du Projet :Il s‚Äôagit d‚Äôune mission qui s‚Äôinscrit sur du long terme (3 ans) o√π vous interviendrez sur les syst√®mes applicatifs et sur les plateformes Big Data, IoT.Vous ?De formation Ing√©nieur, vous justifiez d‚Äôune premi√®re exp√©rience en tant que Data Engineer. Vous aimez √™tre garant de la ma√Ætrise de la donn√©e et de la qualit√© de son utilisation.Vous souhaitez √™tre un acteur d√©terminant dans la d√©finition de la politique de la donn√©e et de la structuration de son cycle de vie dans le respect des r√©glementations en vigueur.Nous ?Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale. Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 7800 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes. Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde et ayant r√©alis√© un chiffre d‚Äôaffaires de 600 M‚Ç¨ hors acquisition en 2023.‚ú® Tous les d√©tails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : blog.groupeastek.com.Rencontrons-nous !Vous vous √™tes reconnu sur l‚Äôannonce et Astek vous pla√Æt !Pour en savoir plus sur vous, Clarisse, notre charg√©e de recrutement vous contactera. Puis, vous aurez 3 entretiens max, avec Louis (votre futur n+1), et Jonathan notre responsable de Business Unit !Bienvenue dans la team ! Allez-y, maintenant c‚Äôest √† vous de jouer !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),Groupe SII,"Rouen, Normandy, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-groupe-sii-3807748993?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=I%2Fic6jXW%2FnB1jtLDFObQXg%3D%3D&position=3&pageNum=3&trk=public_jobs_jserp-result_search-card,"Nous recherchons un(e) Data Engineer (H/F) pour accompagner les d√©veloppements faits aupr√®s des applications de l‚Äôun de nos clients Grand Compte.En mode Agile et organis√©e en ""Feature Team"", l'√©quipe technophile vous permettra de participer √† toute la cha√Æne projet.En qu√™te de d√©fis techniques ? Alors n‚Äôh√©sitez plus, postulez! Votre Mission Pr√©parer les donn√©es √† traiter,  Analyser les mod√®les,  Concevoir des algorithmes,  Programmer en back-end,  Interpr√©ter et pr√©senter les r√©sultats,  Mettre en production des solutions. Votre ProfilDipl√¥m√©(e) d‚Äôun Bac+5 en informatique, math√©matique ou statistique (Grandes Ecoles, Universit√©s), vous justifiez d'au moins une premi√®re exp√©rience significative dans le traitement de donn√©e avec utilisation ou connaissance d‚Äôun ETL (Talend ou Informatica).Vous √™tes curieux(se), investi(e) et surtout passionn√©(e) par le monde du web. Vous savez travailler en √©quipe et vous vous int√©grer rapidement, vous √™tes autonome, organis√©(e) et rigoureux (se), bon communiquant et dou√©(e) du sens de l'√©coute . Qui sommes-nous ? Le Groupe SII est une soci√©t√© d‚Äôing√©nierie et de conseils en technologies (ICT) et une entreprise de services num√©riques (ESN). Nous sommes au c≈ìur de l'innovation au service de grands comptes dans des secteurs d'ing√©nierie vari√©s.En 2023, pour la 6e ann√©e cons√©cutive, SII France a obtenu le label Great Place To Work¬Æ. Nous avons √©t√© reconnus 3e entreprise de ¬´ + de 2500 salari√©s ¬ª o√π il fait bon vivre et nous en sommes tr√®s fiers ! Ce succ√®s est le reflet de notre culture bas√©e sur notre volont√© de proposer √† tous nos salari√©s un cadre de travail √©panouissant pour le d√©veloppement de leurs comp√©tences et carri√®res.En fonction de la mission, il est possible de r√©aliser jusqu‚Äô√† 50 % de t√©l√©travail gr√¢ce √† notre accord d√©di√©.Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la cr√©ativit√©, la proximit√© et l‚Äôesprit d‚Äô√©quipe sont mis √† l‚Äôhonneur.Le Groupe SII est une soci√©t√© handi-accueillante, signataire de la Charte de la diversit√© en entreprise. Alors si ces valeurs vous parlent, rejoignez-nous !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),LesJeudis,"Clermont-Ferrand, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3795161577?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=16%2BDOZ5CXlJBgIztTpRgUA%3D%3D&position=4&pageNum=3&trk=public_jobs_jserp-result_search-card,"Bienvenue chez Atos, o√π nous imaginons le futur de la tech.Leader international du num√©rique s√©curis√© et d√©carbon√©, Atos contribue √† fa√ßonner les nouvelles technologies avec ses clients.Dans un environnement multiculturel, collaboratif et agile, nous offrons des parcours de carri√®re valorisants bas√©s sur des programmes de formation, de certification et de mobilit√©.C'est pourquoi chez Atos, la diversit√© des comp√©tences et des exp√©riences de nos √©quipes nous permet, ensemble, de faire les bons choix avec nos clients, pour l'avenir de notre entreprise et de la soci√©t√©.La Mission Que L'on Vous ConfieVous maintenir au top des nouvelles technologies les plus modernes, c'est essentiel pour vous ?Nous avons les projets ambitieux et les clients qui veulent prendre un temps d'avance.Vous aimez partager vos convictions en mati√®re de technos pour nous faire tous progresser ? Nous sommes preneurs !Au sein d'√©quipes dynamiques, vous aurez pour missions principales :Conseiller en architecture en gouvernance de la donn√©e.Intervenir dans les aspects Data Ingestion, Data Analytiques et Data Science / IA.Mettre en place, int√©grer, d√©velopper et optimiser des solutions de pipeline sur des environnements Cloud pour les projets strat√©giques de nos clients.Votre Profil Pour R√©ussirDe formation sup√©rieure BAC +5 en Informatique d'une Ecole d'Ing√©nieur ou d'un Mast√®re universitaire dans le domaine des sciences informatiques que vous avez compl√©t√© par une exp√©rience significative en Data Science / Data Engineering.Votre stack technique :Requis :Connaissance des √©cosyst√®mes Data (NoSQL/DW/Hadoop) : ELK (ElasticSearch, Logstash, Kibana), MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS...Expertise en d√©veloppement Python ou Java Spring Boot.Expertise sur un des framework suivants : Spark, Kafka Connect&Streams, Apache Beam.Connaissance des architectures conteneurs : Docker, Kubernetes. Appr√©ci√© :Connaissance d'un des services manag√©s BigData de Google Cloud Platform / AWS / Microsoft Azure.Connaissance des approches Agile&DevOps.Comp√©tences ObligatoiresDocker, KubernetesSoft SkillsPassionn√©(e) d'informatique en progressant et en vous tenant √† jour sur toutes les technologies et architectures, vous √™tes cr√©atif(ve), autonome, rigoureux(se), curieux(se), motiv√©(e) et avez le sens du travail en √©quipe et du relationnel alors rejoignez-nous !Niveau De LangueAnglais : niveau interm√©diaire minimum recommand√© et Fran√ßais exig√©.Chez Atos, la diversit√©, l'inclusion et l'accessibilit√© num√©rique font partie int√©grante de notre ADN. D√©couvrez nos engagements en faveur d'un environnement de travail √©quitable pour toutes et tous. Atos est un leader reconnu dans son secteur pour les crit√®res environnementaux, sociaux et de gouvernance (ESG). Pour en savoir plus sur notre engagement en mati√®re de RSE.Chez Atos, la diversit√©, l'inclusion et l'accessibilit√© num√©rique font partie int√©grante de notre ADN. D√©couvrez nos engagements en faveur d'un environnement de travail √©quitable pour toutes et tous.Atos est un leader reconnu dans son secteur pour les crit√®res environnementaux, sociaux et de gouvernance (ESG). Pour en savoir plus sur notre engagement en mati√®re de RSE, cliquez ici .Choose your future. Choose Atos.buttontextdc9b8a99d9905f96 a{ border: 1px solid transparent; } .buttontextdc9b8a99d9905f96 a:focus{ border: 1px dashed #0596ff !important; outline: none !important; }Learn More About UsAt Atos, we embrace diversity as the ultimate engine of ingenuity for our clients, and we constantly strive to create a culture where people feel supported and encouraged. Read more about our commitment here .Whether it is fighting climate change, promoting digital inclusion, or ensuring trust in data management - tech for good sits at the core of our identity. With numerous global recognitions for our ESG practices, we are committed to building a better future for all by harnessing the power of technology. Learn more here
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data engineer (H/F),relevanC,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-relevanc-3795333022?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=gjoQXzhbr1IpBZdHpaZZ7w%3D%3D&position=5&pageNum=3&trk=public_jobs_jserp-result_search-card,"relevanC est une filiale du Groupe Casino et a √©t√© fond√©e en 2017.Nous avons des bureaux en France, au Br√©sil et en Colombie et op√©rons √† l'√©chelle mondiale.Nos solutions de Retail Media permettent √† nos clients de g√©n√©rer de nouvelles sources de revenus publicitaires gr√¢ce √† des annonces pertinentes et personnalis√©es.En tant que Data Engineer tu auras acc√®s aux donn√©es de nos clients internes (enseignes du groupe Casino) et externes √† traiter au sein de notre data warehouse. Tes missions seront les suivantes :travailler en √©troite collaboration avec tous les autres membres de la squad√©crire / relire du code en respectant les bonnes pratiques de d√©veloppement ainsi que les tests unitaires et participerassurer la co-responsabilit√© du d√©roulement des d√©ploiements, des mises en production et du bon fonctionnement des applications avec les autres membres de la squadr√©diger la documentation technique quand cela est n√©cessairemettre en ≈ìuvre les bonnes pratiques relatives au RGPD telles que d√©finies par le tech leadCe CDI bas√© √† Paris centre (1er arrondissement) d√©butera d√®s que possible.Faire partie de relevanC, qu‚Äôest-ce que √ßa signifie ?Travailler sur une stack technologique de pointe (Python, PySpark, Google BigQuery, Apache, Airflow‚Ä¶)√ätre membre √† part enti√®re d‚Äôune √©quipe dynamique et passionn√©e aux profils tr√®s vari√©s (chefs de projets, d√©veloppeurs, designers, animations commerciales)Travailler dans un environnement stimulant et relever des nouveaux d√©fis chaque jourRejoindre une entreprise en pleine expansion avec des opportunit√©s fortes de d√©veloppements et d‚ÄôinnovationProfil recherch√©Dipl√¥m√©(e) d‚Äôune grande √©cole d‚Äôing√©nieur ou profil universitaire sp√©cialis√© en Data / Informatique / Math / Stats.5 ans (et plus) d‚Äôexp√©rience en Data EngineeringApp√©tence forte pour le marketing digital et le retail, force de proposition, business oriented et moteur d‚ÄôinnovationUne maitrise parfaites des bonnes pratiques de d√©veloppementSolides comp√©tences en Python, Spark et SQLUne exp√©rience sur Google Cloud Platform est un plusLien vers notre politique de traitement des donn√©es : https://relevanc.com/fr/politique-de-protection-des-donn%C3%A9es-recrutemen


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Ing√©nieur data (H/F),LR TECHNOLOGIES - GROUPE,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-at-lr-technologies-groupe-3799954038?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=UIROaUnv39m8QY3mn1dGhA%3D%3D&position=6&pageNum=3&trk=public_jobs_jserp-result_search-card,"Chez notre client, tu interviendras au sein de la direction informatique, dans le service Data.Tu int√©greras une Squad Data en charge d'un p√©rim√®tre fonctionnel.Tu es garant de l'acc√®s qualitatif aux sources de donn√©es.Tu t'assures de la ma√Ætrise de la donn√©e et est garant de la qualit√© de son utilisation (r√©f√©rencement, normalisation, et qualification) afin d'en faciliter l'exploitation par les √©quipes (Data Analysts et Data Scientists).Tu contribues √©galement √† la d√©finition de la politique de la donn√©e et √† la structuration de son cycle de vie dans le respect des r√©glementations en vigueur, en collaboration avec le Chief Data Officer.Ton p√©rim√®tre d'intervention est ax√© sur les syst√®mes applicatifs autour de la gestion de la donn√©es et du traitement, et sur les plateformes Big Data, IoT,Tu assures la supervision et l'int√©gration des donn√©es de diverses natures qui proviennent de ces sources multiples et v√©rifie la qualit√© des donn√©es qui entrent dans le Data Lake (recetter de la donn√©e, supprimer les doublons).Qualification et gestion des donn√©es : Capter les donn√©es (structur√©es et non structur√©es) produites dans les diff√©rentes applications ou √† l'ext√©rieur de l'entit√© Int√©grer les √©l√©ments Structurer la donn√©e (s√©mantique, etc.) Cartographier les √©l√©ments √† disposition Nettoyer la donn√©e (√©limination des doublons, ) Valider la donn√©e Cr√©er le r√©f√©rentiel de donn√©esLes livrables : Data Lake appropri√© et partag√© et son dimensionnement Cartographie des donn√©es Les √©l√©ments permettant de garantir la qualit√© de la donn√©eAu cours de ta mission, tu : Participeras aux rituels agiles de l'√©quipe, Analyseras les besoins des utilisateurs et proposeras des solutions innovantes et en phase avec les drivers de l'entreprises, D√©velopperas les solutions data (Alimentation, stockage, mod√©lisation, restitution), Valideras la qualit√© des d√©veloppements de son √©quipe, Am√©lioreras et optimiseras le patrimoine actuel de son √©quipe, Maintiendras les solutions existantes (Run), Contribueras √† la construction du nouveau socle et des services sur la plateforme Google Cloud, Accompagneras et accultureras les m√©tiers sur les bonnes pratiques de l'exploitation de la DataEnvironnement technique :Expertise SQL/BigQuery, ETL/ELTCI/CD, github, TerraformMod√©lisation, UML / LookML, Business ObjectPower BI, Data Studio, Looker vizIng√©nieur ou Universitaire Bac +5, avec une sp√©cialisation en informatique, tu poss√®des une premi√®re exp√©rience professionnelle sur le m√™me type de poste.Tu es le/la candidat(e) id√©al(e) si :Tu as un bon relationnel et tu sais travailler en toute autonomieTu as un niveau professionnel en anglaisTes valeurs sont le partage et la coh√©sionViens rejoindre l'√©quipe lilloise de Laurie, compos√©e de Christelle, Raumane et Jordane ! Elles seront l√† pour toi, pour t'accompagner, t'√©couter, te soutenir dans tes moments de doute ou c√©l√©brer tes accomplissements !Elles organisent r√©guli√®rement des √©v√©nements o√π tu retrouveras toute la team de consultants pour des moments conviviaux (galette des rois, raclette, escape game, go√ªter de No√´l avec la famille ).En ce qui concerne nos petits avantages sympas : carte restaurant, t√©l√©travail, 10 jours de RTT...¬´ Toutes les Soci√©t√©s de Conseil se ressemblent ¬ª,Toutes ?LR TECHNOLOGIES GROUPE c‚Äôest 500 Libelliens qui nous ont √©lus Great Place To Work en 2016, 2018 et √† pr√©sent 3e France et Europe 2021. Nous sommes √©galement la 99e soci√©t√© fran√ßaise labellis√©e B CORP pour notre engagement RSE.Depuis 2014 nous avons cr√©√© 11 implantations et 5 p√¥les d'activit√©s compl√©mentaires :A√©ronautique / Spatial / D√©fense Drone / Robotique / IoT / Automobile/ Ferroviaire / Industries / Multim√©dia M√©dical / Pharmaceutique √ânergie / Environnement Syst√®mes d‚ÄôInformations / Banque / Finance / Assurance3 raisons de rejoindre : 500 Libelliens, sollicit√©s par tous comme vous devez l‚Äô√™tre, nous ont rencontr√©s et ont d√©cid√© de nous rejoindre. 94 % des Libelliens d√©clarent que nous sommes un Groupe o√π il fait vraiment bon travailler. Nous grandissons vite mais nous grandissons bien : B CORP | Great Place To Work | ISO 9001 | CIR.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirm√©,Rayn,"Biot, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-at-rayn-3799043076?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=KBKmFEh34AyMI0Vw%2FU6Q7g%3D%3D&position=7&pageNum=3&trk=public_jobs_jserp-result_search-card,"Automata, start-up en plein croissance dans le domaine de la Fintech, d√©veloppe l'application bancaire digitale ¬´ RAYN ¬ª r√©unissant l'univers de la finance d√©centralis√©e, les investissements innovants, un compte √©pargne r√©volutionnaire, la gestion de patrimoine et les solutions de paiement sur une seule et m√™me plateforme.Plus besoin de multiplier les comptes et de jongler entre un compte courant pour les d√©penses du quotidien, une application pour les cagnottes en ligne ou pour payer ses amis, une autre pour investir en bourse, et encore un compte diff√©rent pour acheter ses cryptos?C'est la premi√®re Fintech qui ne se focus pas sur les d√©penses mais sur le fait de faire travailler l'argent des clients pour eux, tout en √©tant disponible √† la d√©pense.C'est plus simple, plus rapide, et en un mot c'est moderne.Nos clients sortent de la pr√©histoire : ils √©conomisent du temps, du stress, et de l'argent.Responsabilit√©sMission 1 : Acheminement de la donn√©eRecueillir les besoins m√©tiers des diff√©rentes unit√©s demandeuses et utilisatrices de solutions de collecte et stockage de la donn√©e.D√©velopper les solutions techniques de collecte de la donn√©e via des API.D√©velopper des solutions techniques de stockage de la donn√©e.R√©aliser les tests unitaires et d‚Äôint√©gration.Mettre en place et maintenir les m√©canismes de synchronisation en production (jobs spark).Mission 2 : Mise √† disposition des donn√©es aux √©quipes utilisatricesIndustrialiser et automatiser le nettoyage de la donn√©e selon les sp√©cifications retenues.G√©rer, maintenir et documenter de multiples bases de donn√©es (via l‚Äôimportation de donn√©es externes en open data ou de donn√©es internes par exemple).G√©rer le cycle de vie de la donn√©e conform√©ment aux directives inscrites dans le RGPD.Assurer le suivi de production et la maintenance.Mission 3 : Mise en production de mod√®les statistiques dans les applicationsD√©velopper l‚Äôindustrialisation de mod√®les statistiques ou de machine learning.Impl√©mentation du suivi de la validit√© du mod√®le statistique.Assurer le suivi de production et la maintenance.Mission 4 : Suivi des projets de d√©veloppement√âtablir les sp√©cifications techniques √† partir de l‚Äôanalyse des besoins.Reporter l‚Äôactivit√© aupr√®s du chef de projet.Comp√©tences et aptitudesSavoirMaster 2 en informatique, en data science, ou en statistiques INDISPENSABLE√âcole d‚Äôing√©nieurs en informatique, en data science, ou en statistiques INDISPENSABLESavoir FaireMa√Ætrise de l‚Äôenvironnement Hive/Spark (que ce soit en local ou dans le cloud) INDISPENSABLEMa√Ætrise des bases de donn√©es et gestion de bases de donn√©es (SQL/NoSQL) INDISPENSABLEMa√Ætrise de langages de programmation (Scala, Java, Python‚Ä¶) INDISPENSABLEMa√Ætrise de l‚Äôinfrastructure cloud (AWS, EKS, Kube) INDISPENSABLEMa√Ætrise les m√©thodes de d√©veloppement agile INDISPENSABLEConnaissance de la r√©glementation concernant les donn√©es personnelles et des principes de cybers√©curit√© INDISPENSABLEMa√Ætrise des syst√®mes d‚Äôexploitation (Unix, Windows‚Ä¶) INDISPENSABLEConnaissance des solutions de manipulation des donn√©es  SOUHAIT√âSavoir √ätreForce de proposition INDISPENSABLEOrganisation INDISPENSABLEAutonomie INDISPENSABLERigueur INDISPENSABLECuriosit√© sectorielle et go√ªt pour l‚Äôinnovation INDISPENSABLE


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Microsoft Azure F/H,VISEO,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-microsoft-azure-f-h-at-viseo-3779392193?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=guRgox1cK6dEXtfkwE0V4A%3D%3D&position=8&pageNum=3&trk=public_jobs_jserp-result_search-card,"Vous avez de l‚Äôexp√©rience dans la mise en place des Modern Data Platform dans Microsoft Azure ?Vous √©tiez √† l‚Äôinitiative ou contributeur de projet de mise en place des plateformes de donn√©es dans Azure ?Vous √™tes familiaris√© avec les technologies de transformation de donn√©e √† grande √©chelle (Spark, Hadoop) ?Au sein‚ÄØde‚ÄØVISEO‚ÄØModern Data Platform,‚ÄØnous recherchons un‚ÄØData Engineer Cloud‚ÄØ- Microsoft Azure F/H pour intervenir‚ÄØau sein de notre centre d'excellence toulousain.Nous sommes des ‚ÄúPositive Digital Makers‚Äù, l‚Äôagilit√© fait partie int√©grante de notre ADN. VISEO a b√¢ti un partenariat fort et strat√©gique avec Microsoft depuis pr√®s de 20 ans. Nous avons massivement investi ces 10 derni√®res ann√©es pour que cette approche nous aide √† mieux d√©livrer nos projets et accompagner nos clients dans la gestion de leur produit tout en restant focus sur la valeur m√©tier apport√©e.‚ÄØ Vos missions‚ÄØ: Accompagner et conseiller le client dans son adoption des Modern Data Platform dans Azure (Etude d‚Äôarchitecture, pr√©paration des DAT, FinOps, DevOps) Concevoir des architectures Cloud‚ÄØData exploitant efficacement les services de donn√©es manag√©s de AzureConduire des projets de d√©ploiement des Modern Data Platform (Applications Cloud Native, Migration d‚Äôapplications‚ÄØexistantes) et participer √† la‚ÄØmise en ≈ìuvre‚ÄØ Etablir des relations de confiance avec les d√©cisionnaires techniques et m√©tiers afin de favoriser l‚Äôadoption du Cloud‚ÄØAzure‚ÄØ√† long terme au sein de l‚Äôentreprise.‚ÄØ Fournir une expertise technique approfondie aux √©quipes projets‚ÄØ Assister et former le client sur les usages et outils Data du Cloud Azure R√©aliser une veille technologique permanente sur les tendances du march√© et les perspectives concurrentielles‚ÄØ ‚ÄØVotre profil‚ÄØ: ‚ÄØVous √™tes dipl√¥m√© d‚Äôune formation Bac+5 en informatique. Vous justifiez d‚Äôune expertise reconnue et d'une exp√©rience‚ÄØde 2‚ÄØans dans un r√¥le‚ÄØde Data Engineer avec une exp√©rience significative sur‚ÄØAzure.‚ÄØ Vous poss√©dez une compr√©hension approfondie des technologies‚ÄØdu Cloud‚ÄØ‚ÄØ Vous avez plusieurs ann√©es d‚Äôexp√©rience dans la conception d‚Äôarchitecture, la mise en ≈ìuvre et/ou le support d‚Äôapplications hautement distribu√©es‚ÄØ Vous avez des comp√©tences approfondies dans un ou plusieurs de ces domaines‚ÄØ:‚ÄØOp√©rations /‚ÄØGestion des syst√®mes‚ÄØ Conception ou d√©veloppement de logiciels‚ÄØ Processus DevOps et outillage‚ÄØ Strat√©gie d'entreprise‚ÄØ Infrastructure Cloud (virtualisation, mise en r√©seau, stockage, base de donn√©es)‚ÄØ S√©curit√© et conformit√©‚ÄØ Vous √™tes sensibilis√© √† la d√©marche DevOps et connaissez au moins un outil pour la mise en ≈ìuvre de‚ÄØContinuous‚ÄØIntegration/Continuous‚ÄØDelivery‚ÄØ(CI-CD)‚ÄØ Vous √™tes reconnu(e) pour votre leadership, votre capacit√© √† pourvoir f√©d√©rer des √©quipes.‚ÄØ Vous avez une grande aisance dans la communication orale et √©crite alli√©e √† un esprit de synth√®se, de la rigueur et un tr√®s bon sens de la formalisation‚ÄØ La possession de certifications sur des services Azure est un plus.‚ÄØ Int√©grer nos √©quipes Cloud au quotidien, √ßa veut dire quoi ?‚ÄØ‚ÄØ Vous ferez partie‚ÄØde‚ÄØla communaut√© Cloud‚ÄØ: la proximit√© et la taille humaine de notre organisation vous permettront de rendre visible vos initiatives et d‚Äô√©voquer facilement vos projets. En parall√®le, le dynamisme de l‚Äôentreprise et sa croissance‚ÄØperp√©tuelle‚ÄØmultiplieront vos opportunit√©s d‚Äô√©volution.‚ÄØVous‚ÄØb√©n√©ficierez d‚Äôun management de proximit√©‚ÄØpar votre mentor tout au long de votre parcours chez VISEO‚ÄØ:‚ÄØVotre mentor, consultant exp√©riment√© de votre practice, viendra r√©guli√®rement √©changer avec vous sur les challenges de votre mission, faire chaque semestre le bilan de vos r√©alisations et √©voquer vos ambitions futures et les moyens de les r√©aliser.‚ÄØVous disposerez de multiples moyens pour‚ÄØmonter en comp√©tences‚ÄØet d√©couvrir de nouveaux domaines : formations, certifications, Brown Bag Lunchs, ateliers,‚ÄØmeet-ups, rencontre d‚Äôexperts, s√©minaires techniques‚Ä¶‚ÄØ‚ÄØ#VISEO SPIRIT‚ÄØ: Un management flat qui encourage la communication et la prise d'initiative‚ÄØ Des‚ÄØcentres‚ÄØd‚Äôexcellence‚ÄØen‚ÄØIoT / Cloud / Smart‚ÄØFactory‚ÄØ Des missions d‚Äôaudit, d‚Äôexpertise technique et des‚ÄØPOCs‚ÄØ Un‚ÄØprogramme d‚Äôapprentissage‚ÄØen e-learning‚ÄØ: acc√®s digital‚ÄØacademy‚ÄØet 7-speaking‚ÄØ Deux jours de t√©l√©travail par semaine‚ÄØ N‚Äôattendez plus, rejoignez VISEO. Devenez un #PositiveDigitalMaker GDPR MESSAGE: Our privacy policy has been updated to comply with the new regulations. We invite you to consult it by clicking here: https://www.viseo.com/fr/politique-de-confidentialite. The VISEO Group uses the data collected as part of your application to assess your suitability for the job in question. We use the Jazz HR tool to help us in our recruitment process. This tool complies with current regulations on the protection of personal data. The tool is hosted in the United States and is PrivacyShield certified for HR data. In all cases, we may keep your file for 5 years so that we can contact you again if another position matches your profile. You may, of course, object to this. To find out more about how your data is used and how you can exercise your rights, please consult our privacy policy https://www.viseo.com/fr/politique-de-confidentialite.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Exp√©riment√© - H/F,Devoteam G Cloud,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-exp%C3%A9riment%C3%A9-h-f-at-devoteam-g-cloud-3801924988?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=4eDfTEHPspuzVtu3VIL7Hw%3D%3D&position=9&pageNum=3&trk=public_jobs_jserp-result_search-card,"Tu auras pour mission d‚Äôaccompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place et l‚Äôencadrement de projets data avec Google Cloud Platform et l‚Äô√©cosyst√®me solutions open source associ√©.Int√©gr√©(e) √† une √©quipe d‚Äôexperts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d‚Äô√©tudier et cadrer les besoins clientsPr√©coniser les solutions et architectures ciblesD√©finir les m√©thodologies de d√©ploiement et plans de migrationR√©diger les dossiers d‚Äôarchitecture et sp√©cifications techniquesConstruire les architectures de donn√©esConcevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els)Construire et d√©ployer les pipelines de donn√©es (ETL / ELT)Assurer la migration des donn√©es vers les nouveaux environnementsAnalyser les donn√©esAnalyser les donn√©es sources afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, DataStudio‚Ä¶)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les √©quipes clients aux m√©thodes et concepts du cloudTu seras accompagn√©(e) en interne pour monter rapidement en comp√©tences sur GCP dans l‚Äôobjectif de devenir certifi√© Google sur ta practice.Ton Profil : Dipl√¥m√©(e) d'une √©cole d'ing√©nieurs, tu disposes d'une exp√©rience significative au sein de projets Data : architecture, traitement ou analyse de donn√©es. Tu as d√©j√† pilot√© un projet Data avec l‚Äôencadrement de d‚Äôune √©quipe de data engineers. Exp√©rience minimum souhait√©e :¬†5 ansTu ma√Ætrises au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (Scala, R, Python, Java).Tu as de bonnes comp√©tences dans l‚Äôarchitecture des syst√®mes, bases de donn√©es, m√©thodologies d‚Äôanalyse. Tu sais te rep√©rer dans le vaste √©cosyst√®me Data et tu sais notamment quelle brique utiliser en fonction des cas d‚Äôusages.¬†Tu es sensible √† la Business Intelligence, le Big Data, l‚ÄôInternet des objets (IoT) et le Machine LearningUne connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, ‚Ä¶) est un pre-requis.Tu as une solide compr√©hension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et √† l‚Äô√©coute, tu poss√®des un r√©el esprit d‚ÄôanalyseTa ma√Ætrise de l'anglais te permettra de g√©rer des projets en contexte internationalLe Groupe Devoteam ≈ìuvre pour l'√©galit√© des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m√©rite et lutte activement contre toute forme de discrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation.Tous nos postes sont ouverts aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-thales-3767964087?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=RHRxhMGnbOSJvj%2F5fAibZg%3D%3D&position=10&pageNum=3&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l‚Äôhumain au c≈ìur des d√©cisions. Thales propose des solutions, services et produits qui aident ses clients ‚Äì entreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport. QUI ETES-VOUS ?De formation Ing√©nieur ou Bac+5, Ecole d‚Äôing√©nieur ou Universit√© vous justifiez d'une exp√©rience professionnelle d‚Äôau moins 4 ans. Comp√©tences techniques :Comp√©tences en d√©veloppement (Shell unix, Perl, PHP, Python, git, github) PostGreSQL Python   CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :  L‚Äôacc√©l√©ration de la transformation digitale des m√©tiers du Groupe s‚Äôappuie sur les actions suivantes :Construire une infrastructure technique performante et s√ªreMieux mobiliser nos ressources ¬´ Tech & Data ¬ª pour g√©n√©rer de la valeurGagner en agilit√© et en efficacit√© dans notre mani√®re de servir les m√©tiersProposer √† nos clients une meilleure exp√©rience num√©riqueVous serez int√©gr√© au sein d‚Äôune √©quipe agile et √† ce titre vous r√©aliserez la mission en collaboration avec les membres de l‚Äô√©quipe et dans les standards de d√©veloppement du groupe.   A ce titre, vous serez en charge : ¬∑ Du d√©veloppement de nouvelles fonctionnalit√©s sur la plateforme¬∑ Du maintien en condition op√©rationnelle de l‚Äôapplication,¬∑ De la mise en ≈ìuvre et l‚Äô√©vang√©lisation des bonnes pratiques de d√©veloppement au sein de l‚Äô√©quipe,¬∑ De la r√©solution des recommandations d‚Äôarchitecture et de s√©curit√© sur la plateforme,¬∑ De la mise en ≈ìuvre de pipeline de build, tests, d√©ploiement   En nous rejoignant, vous vous verrez confier les missions suivantes :   ¬∑ Code pour en am√©liorer la qualit√©, la performance, la s√©curit√©, et la maintenabilit√©   ¬∑ Bonnes pratiques en mati√®re de d√©veloppement   ¬∑ Fonctionnalit√©s compl√©mentaires permettant d‚Äôam√©liorer l‚Äôexp√©rience des utilisateurs finaux, en fonction de leurs besoins et retours d‚Äôexp√©rience.   ¬∑ Recueil de l‚Äôexistant : r√©cup√©ration, tests et mise en repository des codes / scripts / donn√©es utilis√©s dans les prototypes   ¬∑ Documentation du fonctionnement des prototypes : cin√©matique globale, description des fonctions   ¬∑ Am√©liorations (qualit√©, performance, s√©curit√©) sur les parties qui seront reprises des prototypes   ¬∑ Evolutions fonctionnelles suite aux √©changes avec les utilisateurs finaux   ¬∑ Design de la solution tactique bas√©e sur les socles digitaux du groupe. Solutions de backup en cas de d√©lais sur la disponibilit√© des socles groupes.   ¬∑ Tests unitaires et globaux   ¬∑ Conduite du changement des entit√©s internes   ¬∑ Support aux entit√©s internes / utilisateurs finaux sur l'exploitation de la solution    Nous vous offrons :  - Une diversit√© de projets vouspermettant de d√©couvrir l‚Äôensemble de nos m√©tiers,- Des conditions de travail motivantes et un plan de carri√®re personnalis√© offrant de r√©elles perspectives d‚Äô√©volution,- La possibilit√© de vous investir dans une entreprise dont la r√©putation est mondiale avec des ambitions constantes d‚Äôinnovations techniques. Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer Fluxvision F/H,Orange Business,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-engineer-fluxvision-f-h-at-orange-business-3778381208?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=T832mEivH94jtrhxl%2FF4lA%3D%3D&position=11&pageNum=3&trk=public_jobs_jserp-result_search-card,"Votre mission consistera √† travailler sur les indicateurs m√©tier des clients de l‚Äôoffre Flux Vision, notamment dans les domaines du g√©omarketing, du transport et du tourisme.Vous aurez en tant que Data Engineer pour mission de travailler au sein d‚Äôune √©quipe Data sur les sujets suivants :Pr√©paration et qualification des donn√©es livr√©es aux clientsMise en place d‚Äôalgorithmes de data science pour la cr√©ation et la qualification de nouveaux indicateurs statistiquesParticipation √† l‚Äôam√©lioration de l‚Äôappareil de production en optimisant les mod√®les visant √† stocker et traiter les donn√©esVous participerez √©galement √† l‚Äô√©laboration et √† l‚Äôam√©lioration des livrables clients (rapport d‚Äôanalyse, tableaux de bord, int√©gration dans les outils de traitement de la donn√©e, ‚Ä¶)Vous travaillez en coordination avec les √©quipes de d√©veloppement et les √©quipes d‚Äôexploitation.Profil recherch√©Vous √™tes titulaire d‚Äôun Bac+5 master ou √©cole d‚Äôing√©nieur, vous justifiez d'une exp√©rience d‚Äôau moins 3 ans d‚Äôexp√©rience dans la mise en ≈ìuvre de projets Big Data et BI.Vous disposez:D‚Äôune bonne maitrise de Python et SQL,De comp√©tences en architecture de donn√©es dans des environnements big data / fast data.Des connaissances dans les environnements cloud big data (Azure, AWS, GCP)Une exp√©rience dans l‚Äôutilisation d‚Äôoutils de Data Science tel que Pandas serait un plus.Dynamique, dot√©(e) d'un bon relationnel, vous avez le sens de l'√©quipe, et vous aimez avoir de l'autonomie pour mener une activit√© de mani√®re longitudinale.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Database Engineer,Glocomms,"Mulhouse, Grand Est, France",https://fr.linkedin.com/jobs/view/database-engineer-at-glocomms-3801327476?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=s5tiNCl96OU4rMhCpBpdtw%3D%3D&position=12&pageNum=3&trk=public_jobs_jserp-result_search-card,"We have a current opportunity for a Database Administrator/ Engineer on a contract basis. The position will be based in Mulhouse, France. For further information about this position please apply.Job Title: Database Engineer/ AdministratorContract Length: 6 month extendable (3 year project)Location: Mulhouse, FranceRemote work: HybridContext:We are working with a Global Consultancy who have defined an ambitious Master Plan for Information Systems, the implementation of which requires a strong strengthening of the Information Systems Department.ResponsibilitiesResponsible for the optimal functioning of the tools and systems under his/her charge.Implement tools while ensuring data consistency.Operate and manages database servers (administration, automation, development of procedures, security and access authorisation, optimisation of processing and queries, etc.).Create, at the request of the studies or the operation, specific tools to support the operation.Validates the installation and integration of new tools into the production environment.Manages security and access to servers and applications based on profiles.Support:Participates in corrective maintenance actions by ensuring their qualityProposes improvements to optimise existing resources and their organisationCarries out the transfer of skills and technical assistance of procedures to the teamsHandles Tier 3 external supportProjects:Identifies technical needs and the financial consequences of technical needs.Leads the various infrastructure development projects in his/her area of expertise according to constraints. TechnologyOraclePostgreSQLLinux/ Unix


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data analyst,eXalt,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-at-exalt-3791765658?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=R6ChLheJ%2ByTSRN0ToRwNJw%3D%3D&position=13&pageNum=3&trk=public_jobs_jserp-result_search-card,"L‚Äôentreprise, qui sommes-nous ?Cabinet de conseil en Transformation Digitale, eXalt est avant tout une formidable aventure humaine, et une communaut√© de plus de 850 collaborateurs, bas√©s √† Paris (si√®ge social), mais √©galement √† Lyon, Lille, Nantes, Bordeaux, Aix-en-Provence, Bogota, New-York et Madrid. Fond√©e en juillet 2018 autour des valeurs d'intrapreneuriat, de co-apprentissage et de co-construction, eXalt inscrit son d√©veloppement dans un engagement fort aupr√®s de ses clients et de ses √©quipes. Multi-sp√©cialiste, le groupe d√©cline son mod√®le dans diff√©rents domaines √† travers ses filiales d√©di√©es :¬∑ Le Product Management & la Gestion de Projet au sein d‚ÄôeXalt P&P¬∑ La Finance de March√© au sein d'eXalt Fi,¬∑ La Tech au sein d'eXalt IT (D√©veloppeur)¬∑ La Cybers√©curit√© au sein d'eXalt Shield¬∑ La Data & IA au sein d'eXalt Value.Descriptif du posteeXalt Value, filiale du groupe sp√©cialis√©e sur les m√©tiers de la Data, et recherche son/ sa nouveau/elle Data Analyst pour aller √† la conqu√™te de nouveaux projets ! Vous √©voluerez dans un contexte multi soci√©t√©s et challengeant.Vous serez rattach√©(e) √† notre bureau parisien.Vos principales missions seront de :Comprendre les probl√©matiques m√©tiers et les traduire de mani√®res analytiquesExtraire les donn√©es n√©cessaires √† l‚Äôanalyse.D√©finir et r√©aliser le nettoyage de la base de donn√©es.S‚Äôassurer la qualit√© des donn√©es tout au long de leur traitementAnalyser et exploiter les donn√©esCr√©er des dashboards via des outils de visualisationsEffectuer une veille sur les nouvelles technologies et solutions logicielles d‚Äôanalyse des donn√©es.Profil recherch√©Nous recherchons avant tout une personne anim√©e par l‚Äôesprit et l‚ÄôADN d‚ÄôeXalt ‚òÄÔ∏è ayant l‚Äôenvie de prendre part √† un superbe challenge et √† notre aventure !Vous √™tes dipl√¥m√©(e) d‚Äôun Bac+5Vous b√©n√©ficiez d‚Äôune exp√©rience d‚Äôau moins 4 ans en tant que Data AnalystVous avez une expertise en base de donn√©es et gestion de base de donn√©es (SQL/ NoSQL)Vous maitrisez des outils de data visualisation (Tableau, Qlikview, PowerBI) et/ou des outils de fouille et analyse de donn√©es (Dataiku)Vous avez une aisance r√©dactionnelle & relationnelleVous avez une passion pour les chiffres et le go√ªt pour l‚ÄôinnovationVous √™tes reconnu(e) pour votre rigueur, votre organisation et votre adaptabilit√©.L‚Äôanglais professionnel est requisPourquoi nous rejoindre ? ¬∑ Une soci√©t√© en pleine croissance¬∑ Un mod√®le innovant, r√©unissant le meilleur du monde du Consulting et de la Tech !¬∑ Un espace de travail d√©di√© √† nos consultants dans nos locaux en plein centre de Paris !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),METEOJOB by CleverConnect,"Villeurbanne, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3807408356?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=A2L92Ouaz2qr%2Fg%2Fey8r4Dg%3D%3D&position=14&pageNum=3&trk=public_jobs_jserp-result_search-card,"EntrepriseAdsearch vous propose des milliers d''opportunit√©s de carri√®res dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Int√©rim et Freelance sur notre site internet !Description Du PosteEn bref : Data Engineer (H/F) - Aix en Provence - CDI - 45/50k‚Ç¨Notre client bas√© √† Aix-en-Provence recherche, dans le cadre du d√©veloppement de leur activit√©, un Data Engineer (H/F).Les donn√©es collect√©es gr√¢ce √† votre travail profiteront √† de nombreux services dans l'entreprise.Les MissionsAu sein de l'√©quipe DATA, vous travaillerez sur diff√©rents sujets en mode agile dont :Int√©grer, transformer et maintenir des donn√©esMettre en place et industrialiser les processus d'int√©gration des donn√©es : Orchestration, monitoring, API, tests unitaires et d'int√©grationIndustrialiser et automatiser le nettoyage de la donn√©e, mettre en ≈ìuvre le machine LearningG√©rer la donn√©e conform√©ment aux directives RGPDDescription Du ProfilLe profil :De Formation Informatique, Vous MaitrisezLangage : Python, R, ShellOutils et bases de donn√©es : GDAL, ETL, BDD Postgres/Postgis, NoSQLSyst√®mes : OS Linux Debian/Ubuntu, Docker, KubernetesGitlab et Jira sont un plus.Les AvantagesLe poste est √† pouvoir en CDI √† plein temps. R√©mun√©ration entre 45/50k selon profil.12 jours de RTT par anInt√©ressementCarte titre RestaurantPoste situ√© √† Aix-en-Provence.Processus De Recrutement1er entretien avec Romane, consultante en recrutement IT chez Adsearch2√®me entretien avec le RH sur Aix-en-provence3√®me entretien avec le N+1 du poste √† pourvoirVous √™tes de nature curieuse et rigoureuse et vous vous attachez √† rendre une solution de qualit√© ; postulez en ligne d√®s maintenant.Candidatez en contactant ************************* ou le **************.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['JIRA']}"
Data Engineer Paris/ Ile-de-France H/F,Jems Group,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-paris-ile-de-france-h-f-at-jems-3802349437?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=e7qqa5Z%2FDCpqg7NY58KFqg%3D%3D&position=15&pageNum=3&trk=public_jobs_jserp-result_search-card,"A propos de JEMSNous sommes le seul industriel de la donn√©e en Europe. Notre m√©tier est de cr√©er, manager et exploiter le patrimoine data de nos clients.Nous avons la conviction que chaque entreprise peut adopter une d√©marche innovante de gestion de la donn√©e et cr√©er des cas d‚Äôusage disruptifs en r√©duisant l'impact √©cologique et en diminuant la dette technique.Nous comptons plus de 840 collaborateurs en mission chez nos clients grands comptes dans tout secteur d‚Äôactivit√© : banque, assurance, sant√©, √©nergie, e-commerce, automobile, luxe, retail, transport, agritech‚Ä¶Vos missionsNous recherchons un(e) data engineer capable de trouver des solutions innovantes et robustes √† l'ensemble des probl√©matiques Data.Vous aurez la charge de :Participer √† la conception et r√©alisation d'une solution Data depuis l'acquisition jusqu'√† l'exploitation de la donn√©e en accompagnant la r√©flexion des directions m√©tiersIdentifier, collecter et int√©grer les donn√©es n√©cessaires √† la r√©solution de probl√©matiques m√©tier et op√©rationnellesGarantir la qualit√© des donn√©es en mettant en place les outils de mesure et de suivi ad√©quats en appliquant les r√®gles de Data Gouvernance et de Data ManagementTranscrire des besoins m√©tier en r√®gles de gestion dataIndustrialiser le d√©ploiement de vos r√©alisations √† travers l'impl√©mentation de tests unitaires, d'int√©gration et de non-r√©gressionVos comp√©tencesEn tant que Data Engineer vous ma√Ætrisez :Le langage SQLUn langage objet (Python, JAVA, Scala)Un framework de calcul distribu√©L'int√©gration continue (Git, JUnit, SonarQube, Jenkins)Un cloud provider (AWS, GCP, Azure) ou une distribution Big Data (Hortonworks, Cloudera, Datastax)Les concepts de la mod√©lisation relationnelle et non-relationnelleVotre profilDipl√¥m√©(e) d'une √©cole d'ing√©nieur ou d'une universit√©, vous justifiez d'une exp√©rience professionnelle dans un contexte projet Data. Rigoureux, proactif et autonome vous restez en veille technologique et √™tes force de proposition. Vous √™tes capable de prendre de la hauteur et vous adapter aux enjeux du projet.Avantages √† travailler chez JEMSUne JEMS Acad√©mie au service de votre mont√©e en comp√©tences (formations et certifications sur les technologies de pointe)Un accompagnement personnalis√© et un management de proximit√© pour vous proposer des √©volutions de carri√®reUne int√©gration dans des communaut√©s techniques et de pratiques JEMS (encadrement par des experts, √©changes sur les bonnes pratiques, favoriser l'innovation...) Une entreprise reconnue ""Great Place To Work""Des √©v√®nements et s√©minaires inoubliables, des soir√©es d'agence convivialesMobilit√©Une mobilit√© nationale et internationale pour vous accompagner dans vos projets de vie.Diversit√©Le Groupe JEMS porte fi√®rement sa valeur ""Diversit√©"" en se mobilisant pour l'inclusion et l'√©galit√© des chances et en luttant contre toutes formes de discrimination.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Azure,Visian,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-azure-at-visian-3796113770?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=%2FV3KqGHCMP%2Fv5yIkjqpVag%3D%3D&position=16&pageNum=3&trk=public_jobs_jserp-result_search-card,"Opportunit√© CDIPour le compte d'une soci√©t√© de conseil et en tant que Data Engineer avec une exp√©rience sur Azure pour un client dans le domaine des transports. Nous recherchons un Data Engineer talentueux et passionn√© pour rejoindre notre √©quipe dynamique. Le Data Engineer sera charg√© de la conception, du d√©veloppement et de la gestion de l'infrastructure de donn√©es de notre entreprise. Il ou elle jouera un r√¥le cl√© dans la transformation de donn√©es brutes en informations exploitables pour notre organisation.Missions :Cadrage en amont de la phase de d√©veloppement avec les m√©tiers.Mise en place de nouveaux flux de donn√©es sous Talend et Azure.Une migration de Talend √† Azure est en cours de r√©alisationD√©ploiement as code des pipelines (Cloud, CI/CD)D√©ploiement de nouvelle base de donn√©es as code ou pas.Analyse des couts de mise en place pour les nouvelles demandes.Stack :Les technos / m√©thodo / Logiciels Cloud / Data (Talend /GIT/BDD SQL/Azure/Python)Azure Data Factory, Azure DevopsProfil recherch√© :Vous √™tes √™tes dipl√¥m√©.e d‚Äôun Bac+5 (√©coles d‚Äôing√©nieur ou universit√©)Vous avez au moins 4 ans sur les stacks techniquesMa√Ætrise des langages de programmation tels que Python, SQL, TalendMa√Ætrise de AzureAnglais et Fran√ßais op√©rationnels exig√©s : vous √©voluerez dans un environnement international n√©cessitant de communiquer r√©guli√®rement en Anglais et en Fran√ßais avec les parties prenantes.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Ing√©nieur data / dataviz H/F,Lectra,"Cestas, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-dataviz-h-f-at-lectra-3804095667?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=AmbX11Us9BO3ahKGpJ4jAg%3D%3D&position=17&pageNum=3&trk=public_jobs_jserp-result_search-card,"Description du poste :Acteur majeur sur les march√©s de la mode, de l‚Äôautomobile et de l‚Äôameublement, Lectra contribue au d√©veloppement de l‚Äôindustrie 4.0 avec audace et passion.Dans un contexte en constante √©volution¬†: Industrie 4.0, D√©ploiement d‚Äôun ERP unique, moderne, avec une couverture mondiale. Nous recherchons un(e) Ing√©nieur(e) Data/Dataviz¬†pour notre direction digitale¬†qui assure le fonctionnement et l‚Äô√©volution du syst√®me d‚Äôinformation de l‚Äôensemble du Groupe Lectra et de ses filiales √† travers le monde¬†MissionsConcevoir et d√©velopper nos projets autour de notre nouvelle Data Platform (Power BI, Snowflake,‚Ä¶)Contribuer aux d√©veloppements de flux d‚ÄôalimentationMaintenir les d√©veloppements actuels (Power BI, Snowflake, SAP BI)Participer √† l‚Äôam√©lioration continue de l‚Äô√©quipe (pratiques de d√©veloppement, qualit√© de la donn√©e, organisation d‚Äô√©quipe, mont√©e en comp√©tence) ¬†Le poste est bas√© √† Cestas (23 chemin de Marticot) - pour nous rejoindre :Accessible par l'autoroute sortie 25 de l'A63 (parking voiture et deux-roues sur place)Depuis Bordeaux centre en 20-25 min : en TER 12 min Bordeaux St-Jean - Cestas-Gazinet et 10 min de v√©lo/trottinette pour acc√©der au campus sur piste cyclable hors route.Depuis Pessac - Arr√™t Unitec via le Transgironde 602 : arr√™t Marticot : 20min ¬†Ce que Lectra vous propose ?Travailler dans un environnement international, multiculturel (32 nationalit√©s) et agile,Des locaux refaits √† neuf r√©cemment sur un site bois√© de 12 hectares,Un CSE attractif proposant des subventions pour les voyages, de la location de mat√©riel (randonn√©e, surf, r√©ception‚Ä¶), activit√©s culturelles et sportives, une m√©diath√®que‚Ä¶Mise √† disposition du complexe sportif du Bouzet √† Cestas (badminton, court de tennis, piscine‚Ä¶),Un restaurant d‚Äôentreprise,70 jours de t√©l√©travail par an. ¬†Description du profil :Exp√©rience d‚ÄôIng√©nieur(e) BI ou exp√©rience significative dans le monde de la data, d‚Äôau moins 3 ans.Vous avez les comp√©tences techniques suivantes¬†:Dataviz,¬†sous PowerBI, une connaissance de SAP BI serait un plus,Mod√©lisation¬†de Base de donn√©es. La mod√©lisation en Etoile ou Flocons n‚Äôont pas de secret pour vous,Maitrise du langage¬†SQL,Ingestion/Transformation :¬†√† l‚Äôaide d‚Äôoutils ETL/ELT comme Talend ou Data Factory, ‚Ä¶ Et vous vous retrouvez dans ces valeurs¬†:Curiosit√©, recherche du sens de la valeur des fonctionnalit√©s qui vous sont demand√©es,Qualit√©s relationnelles, communication, partage, go√ªt pour le travail en √©quipeSensibilit√© aux contraintes li√©es aux traitements de donn√©es, N'h√©sitez pas √† postuler !Nous proposons :Ce que Lectra vous propose ?Travailler dans un environnement international, multiculturel (32 nationalit√©s) et agile,Des locaux refaits √† neuf r√©cemment sur un site bois√© de 12 hectares,Un CSE attractif proposant des subventions pour les voyages, de la location de mat√©riel (randonn√©e, surf, r√©ception‚Ä¶), activit√©s culturelles et sportives, une m√©diath√®que‚Ä¶Mise √† disposition du complexe sportif du Bouzet √† Cestas (badminton, court de tennis, piscine‚Ä¶),Un restaurant d‚Äôentreprise,70 jours de t√©l√©travail par an.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage - Data Engineer (H/F),Equancy |¬†Groupe EDG,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-h-f-at-equancy-%C2%A0groupe-edg-3797383036?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=%2FOpbDEg6WwoKXi2AwWTOTA%3D%3D&position=18&pageNum=3&trk=public_jobs_jserp-result_search-card,"Equancy est un cabinet de conseil international, bas√© √† Paris et Duba√Ø, sp√©cialis√© dans la transformation data des entreprises.Nous planifions, concevons et mettons en ≈ìuvre des solutions Big Data, Data Science et Intelligence Artificielle pour nos clients. Nos projets vont de la mise en ≈ìuvre d‚Äôinfrastructures sp√©cialis√©es dans le traitement de la donn√©e de nos clients, de lacs de donn√©es jusqu‚Äôau d√©veloppement de syst√®mes op√©rationnels int√©grant des algorithmes de machine learning ou de deep learning. Nous sommes experts dans l‚Äôindustrialisation de ces plates-formes, en appliquant les principes du devops √† nos infrastructures data.Nos clients sont de grands groupes fran√ßais et internationaux (LVMH, Picard, Chanel VINCI, Volkswagen). Ils nous font confiance autant dans l‚Äôaccompagnement au cadrage de leurs besoins que dans la r√©alisation des solutions data innovantesAfin d‚Äôaccompagner la croissance de son activit√©, Equancy recherche un Stagiaire Data Engineer Junior (H/F) pour int√©grer sa Practice data.Dans ce cadre :Vous √©voluez dans des √©quipes fonctionnant en m√©thode Agile;Vous r√©alisez les fonctions de collecte, de stockage et de traitement des donn√©es;Vous automatisez des t√¢ches de traitement et mettrez en place les outils permettant d'assurer leur supervision dans une vision industrielle;Vous documentez vos travaux et les processus de mise en production;Vous accompagnez vos coll√®gues dans l'usage et le transfert de vos travaux;Vous participez aux activit√©s de veille technologique dans le domaine Big Data (recherches, exp√©rimentations) ;Vous utilisez les outils DevOps d√©ploy√©s sur nos cha√Ænes d'int√©gration continue (Jenkins, Docker, Git).Profil recherch√©:Vous √™tes en Ecole d'ing√©nieur en Informatique, Syst√®me d'information, Master sp√©cialis√© Data;Capacit√© √† travailler en √©quipe (tests unitaires, revue de code, partage de code, sprints);Maitrise de Python (connaissance d‚Äôautres langages de scripting √©galement appr√©ci√©e);A l‚Äôaise (ou ayant envie de le devenir) dans des environnements cloud (Google Cloud Platform, Amazon Web Services, MS Azure);Bonnes notions en bases de donn√©es relationnelles (MySql, BigQuery) et non-relationnelles (MongoDB, ElasticSearch, Redis);R√©actif, avec le sens du service, vous justifiez de bonnes capacit√©s d'√©coute, d'un bon relationnel et d‚Äôune bonne gestion du stress;Curieux, autonome et proactif;Int√©r√™t pour le conseil, les syst√®mes d'informations et le secteur de l'automobile, le tourisme, la grande distribution et la finance.Equancy c'est aussi :Un cadre de travail :¬∑ Superbes locaux au c≈ìur de Paris : Espace WeWork Jules Lefebvre, √† cot√© de Saint Lazare, au sein d‚Äôun b√¢timent historique, avec de grands espaces et vue panoramique sur tout Paris;¬∑ Equilibre vie pro / vie perso;¬∑ Une politique de t√©l√©travail de deux jours par semaine;¬∑ √âquipement pour travailler en remote + participation aux frais du t√©l√©travail (allocation mensuelle);¬∑ Engagement environnemental;¬∑ Des activit√©s sportives propos√©es¬∑ Une conciergerie propos√©e par We Work.Environnement de travail stimulant, proximit√© forte avec les directeurs et les associ√©s ;√âquipe dynamique, passionn√©e et internationale.L‚Äôaventure vous tente ? √âcrivez-nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer/MLOps,Mauna Kea Technologies,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-mlops-at-mauna-kea-technologies-3799120531?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=6Z%2BhtCjyjPZjusjgBO9Png%3D%3D&position=19&pageNum=3&trk=public_jobs_jserp-result_search-card,"Mauna Kea Technologies, a leader in confocal laser endomicroscopy imaging, is seeking a highly skilled and motivated Data Engineer / MLOps to join its innovative R&D / SW and Imaging Team. The candidate will play a crucial role in managing and optimizing data and data systems, ensuring the integrity and accessibility of large sets of data crucial for advanced medical imaging analysis and decision support tool developments.KEY RESPONSIBILITIESData Infrastructure Architecture and MaintenanceDesign, construct, install, test, and maintain scalable data management systems.Ensure systems meet business requirements and industry practices for CLE imaging data.Design and implement efficient and secure data storage solutions for large-scale medical imaging data, particularly focusing on high-resolution CLE images.Regularly assess and upgrade data systems to accommodate evolving data needs and technology advancements in medical imaging.Help define, formalize, implement and maintain all GMLP-related processesData Management, Curation and annotationDevelop data schemas and models that are optimized for both performance and data integrity, while ensuring compliance with medical data regulations and standards.Perform data curationParticipate in the data annotation process, develop an expertise in annotating and being able to train the annotators on CLE images, working closely with product and clinical teams.Integrate new data in the data system and ensure compliance with existing processes and defines data schemasData Integration and Pipeline DevelopmentDevelop data set processes for data modeling, mining, and production.Recommend ways to improve data reliability, efficiency, and quality.Construct and maintain robust data pipelines for efficient extraction, transformation, and loading (ETL) of large datasets from various sources, including real-time CLE imaging devices.Automate data workflows and integrate AI and machine learning models into the data pipeline to enhance image analysis and diagnostic capabilities.Collaborate with IT and cybersecurity-related teams to ensure secure data transfer and storage, adhering to HIPAA, GDPR and other relevant regulations.Cloud-Based Infrastructure DevelopmentDesign and implement a robust, scalable cloud-based infrastructure tailored for machine learning workloads. Utilize cloud services (e.g., AWS, Azure, GCP) to set up and manage data processing and machine learning environments. Ensure that the infrastructure supports various machine learning frameworks and tools efficiently.Collaboration with Cross-Functional TeamsWork closely with product teams, data scientists, software developers, clinical teams and regulatory teams to understand and aid their data needs and ensure the data architecture supports clinical decision-making.Translate complex functional and technical requirements into detailed architecture, design, and high-performing software.Work directly with data scientists to understand their data requirements for algorithm development and image processing tasks.Assist software developers in creating and optimizing applications for data visualization and analysis of CLE images.Assist clinical and product teams to define proper collection protocols with external sitesData Analysis and ReportingUtilize data sets to address CLE imaging-related business challenges.Create analytics tools that utilize the data pipeline to provide actionable insights.Develop and implement tools for advanced analytics, enabling the extraction of meaningful insights from complex medical imaging data sets.Produce regular reports and dashboards that highlight key metrics and trends in imaging data, supporting clinical research and operational efficiency.Contribute to the continuous improvement of data quality through rigorous testing, validation, and refinement of analytics tools.REQUIRED QUALIFICATIONSBachelor‚Äôs/Master‚Äôs degree in Computer Science, Engineering, or a related field.Proven experience as a Data Engineer or similar role.Strong analytical skills with experience in software development and data architecture.Knowledge of data modeling, data access, and data storage techniques.Proficiency in SQL/NoSQL, Python, and other programming languages.Familiarity with data pipeline and workflow management tools (e.g., Spark, Kafka‚Ä¶).Experience with cloud services (e.g., AWS, Azure, GCP)Experience with containerization technologies (e.g., Docker, Kubernetes). PREFERRED QUALIFICATIONSExperience in medical imaging or a related field.Understanding of medical imaging technology and its data characteristics.Familiarity with machine learning frameworks (e.g., Tensorflow, Keras, Pytorch.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['TensorFlow', 'Keras', 'PyTorch'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer H/F,Amiltone,"Toulon, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-amiltone-3738884777?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=PNZPtaGzZekoslbc5N74Fg%3D%3D&position=20&pageNum=3&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?Nous sommes passionn√©s par les nouvelles technologies, et vous ?Rejoindre Amiltone, c‚Äôest int√©grer des √©quipes dynamiques et soud√©es dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.Pourquoi choisir Amiltone‚ÄØ?Amiltone, plus qu‚Äôune entreprise, un √©tat d‚Äôesprit !Notre objectif ? Votre √©panouissement professionnel !Nous Avons √† C≈ìur DeVous accompagner au mieux au travers d‚Äôun suivi personnalis√©Vous faire monter en comp√©tences en vous proposant des formations tout au long de votre carri√®reComprendre vos besoins et respecter nos engagementsVous proposer des missions de qualit√© avec des technologies innovantesCultivervotre potentiel gr√¢ce √† notre programme de d√©veloppement personnel Addvise Votre bien-√™tre passe aussi par des activit√©s extraprofessionnelles, c‚Äôest pourquoi nous vous proposons des s√©ances sportives anim√©es par nos coachs, soir√©es pour se retrouver et animations (√† l'agence ou en visio), Gaming nights‚Ä¶Les Missions D'un AmiltonienEn tant que Data Engineer (H/F), vous serez en charge des missions suivantes :‚Äì En lien avec l‚Äô√©quipe DevOps, construire, maintenir et faire √©voluer la plateforme de donn√©es;‚Äì D√©finir et piloter la coh√©rence de la collecte, la gestion et l‚Äôalimentation des donn√©es internes et externes, en diff√©rents modes : batch, streaming, API (architecture micro-services);‚Äì Pr√©parer et mettre en qualit√© les donn√©es pour les rendre disponibles dans les diff√©rents environnement de travail (datalake, datawarehouse, datamart);‚Äì V√©rifier la qualit√© des donn√©es, de leur bonne et r√©guli√®re ex√©cution ainsi que de leur utilisation ad√©quate (gestion des co√ªts);‚Äì Travailler en √©troite collaboration avec les data analysts, scientists et data stewards et business de l‚Äôentreprise ;‚Äì En lien avec l‚ÄôIT et la s√©curit√©, veiller aux r√®gles d'int√©grit√© et de s√©curit√© des donn√©es;‚Äì Veille technologique.La Stack TechniqueNifi pour Injestion Spark/Java pour le traitement/nettoyage Hadoop pour le stockage Le Profil D‚Äôun AmiltonienDipl√¥m√© Bac+4/5 (Ecole d'ing√©nieur/Master), vous disposez de 2 ann√©es d'exp√©rience dans le d√©veloppement de data.Toujours sur le qui-vive des nouveaut√©s technologiques, vous √™tes force de proposition sur des technos, des outils ou des process qui permettent d'am√©liorer la qualit√© du code et la stabilit√© de nos applications.Outre vos comp√©tences techniques, nous nous int√©ressons √©galement √† votre potentiel et votre motivation.Nos postes sont ouverts aux personnes en situation de handicap.Postuler
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data Engineer Junior F/H - Syst√®me, r√©seaux, donn√©es (H/F)",Visian,"Courbevoie, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-junior-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-visian-3806358145?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=bE8zJ8yCKfbZLmnSQETNjg%3D%3D&position=21&pageNum=3&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi DescriptionDescriptif du poste: Tu es un Data engineer dot√© d'une premi√®re exp√©rience professionnelle (stage, alternance, CDD, CDI) ? Visian, cabinet de conseil IT, recherche un DATA ENGINEER en r√©ponse aux nombreux besoins de nos clients ! R√¥les et responsabilit√©s : * Requ√™ter sous SQL. * D√©veloppement sous Python et Spark de gros volumes de donn√©es. * Participer aux ateliers de conception techniques ou fonctionnels. * Conception et mise en place de syst√®me de gestion des donn√©es en utilisant un processus ETL avanc√©. Ce que nous te proposons : * Un CDI dans une entreprise en pleine croissance * Un package : t√©l√©travail, RTT, mutuelle, tickets restaurants ... * Un environnement de travail convivial et stimulant * Des opportunit√©s d'√©volution Nous serons ravis de te rencontrer ;). Profil recherch√©: Pour ce poste, nous recherchons un Data Engineer avec les comp√©tences suivantes : * Maitrise du langage Python et SQL * Connaissance de diff√©rents frameworks Python (Pyspark, Pytorch, ...) * La connaissance d'API serait un plus * √ätre force de propositions techniques * Savoir travailler en √©quipe et en m√©thodes agiles * Avoir un niveau avanc√© en Anglais (lu, √©crit, parl√©)PROFIL SOUHAIT√âExp√©rienceExp√©rience exig√©e de 1 An(s)Source: Pole emploi (https://www.pole-emploi.fr)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': ['PyTorch'], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Shaw Daniels Solutions,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-at-shaw-daniels-solutions-3806181098?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=aDv8UjzF9%2FDpXMGvSPYMSQ%3D%3D&position=22&pageNum=3&trk=public_jobs_jserp-result_search-card,"Main ResponsibilitiesDevelop, maintain, and optimize ETL pipelines, specifically tailored to meet the data requirements of our clients systematic trading activities, with a focus on building robust data solutions that empower profitable trading algorithms.Responsible of structuring complex and large financial time series data (e.g. Futures contracts), ensuring that our clients trading strategies are backed by accurate and high-quality data.Design and implement robust software solutions in Python, focusing on scalability, performance, and reliability.Schedule and automate workflows, enhancing operational efficiency and accuracy.Collaborate in the development and maintenance of cloud-based infrastructure, applying best practices in DevOps to ensure high data availability and scalability.Work closely with data scientists, quantitative researchers, and trading teams to understand their data needs, providing technical solutions that enable effective data analysis and strategy implementation.Ensure code quality and maintainability by implementing strong CI/CD practices, code versioning, automated tests, and conducting thorough peer-reviews.Stay current with emerging trends and advancements in software development, data engineering, and cloud technologies, integrating new tools and techniques where beneficial.Play a key role in MLOps initiatives, facilitating seamless integration of machine learning models into production environments.Provide technical support and troubleshooting for the new systematic trading framework, ensuring timely and effective resolution. QualificationsBSc or MSc in Computer Science, Engineering, Information Systems, or a related field.Professional experience in data engineering and software development.Proficiency in Python programming and experience with software development best practices.Solid knowledge with ETL processes and familiarity with data modelling and warehousing.Experience with Jenkins or similar scheduling tools, and strong understanding of CI/CD principles.Hands-on experience with cloud technologies and services, preferably in Azure.Familiarity with MLOps principles and practices is advantageous.Strong problem-solver, attention to detail, and ability to work independently and collaboratively.Excellent communication skills, fluent in English, and strong at collaborating across diverse teams.Previous experience in financial services or trading environments, particularly in systematic trading or agricultural commodities sectors, is highly desirable.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Fid√©rim,"Annecy, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-fid%C3%A9rim-3799879358?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=u8%2BU6qy%2BloVRc8BO6hMNCw%3D%3D&position=23&pageNum=3&trk=public_jobs_jserp-result_search-card,"Fid√©rim Consulting est une √©quipe impliqu√©e, professionnelle et experte des recrutements tertiaires depuis plus de 18 ans sur les deux Savoies.Nous recrutons les meilleurs talents et les accompagnons pour int√©grer les entreprises dans lesquelles ils vont s'√©panouir.Nous recrutons notre futur talent : un Data Engineer (h/f), pour notre client, Bailleur social sur Annecy.En charge de la collecte et de l'int√©gration des donn√©es alimentant le SI, dont vous garantissez l'int√©grit√© et la qualit√©. Vous collaborez avec l'administrateur fonctionnel dans le cadre des transferts de donn√©es entre l'entreprise et les institutions, afin de r√©pondre aux obligations r√©glementaires. Vous √™tes amen√©(e) √† collaborer avec le contr√¥le de gestion dans les demandes d'extractions.Vous aurez pour principales missions :Int√©gration des donn√©es : Assurer la collecte et l'int√©gration des donn√©es de diverses natures, provenant de sources multiples (internes externes) V√©rifier et garantir la qualit√© des donn√©es qui entrent dans le SI : mettre en place des contr√¥les de coh√©rence, r√©aliser des tests unitaires et d'int√©gration Proc√©der aux apurements de donn√©es dans le SI : g√©rer le cycle de vie de la donn√©e conform√©ment au RGPD et aux r√®gles appliqu√©es au logement social Assister l'administrateur fonctionnel dans les demandes de transferts de donn√©es entre l'entreprise et les institutionsExtraction de donn√©es : R√©pondre aux demandes d'extractions formul√©es par les directions m√©tiers Accompagner le contr√¥le de gestion dans la mise en place de tableaux de bordGestion de la data : Cartographier et documenter les sources de donn√©es Contribuer √† la gestion des r√©f√©rentiels de donn√©es √ätre force de proposition aupr√®s des m√©tiers dans l'am√©lioration de la qualit√© de la donn√©e. Participation aux projets m√©tiers n√©cessitant une analyse d'impacts sur les donn√©es et/ou des int√©grationsContrat √† pourvoir en CDI sur la base de 35 heures sur 4.5 jours.Salaire fixe + 13.5√®me mois + tickets restaurant.Venez rejoindre une belle entreprise √† fortes valeurs humaines !Vous √™tes issu(e) de formation sup√©rieure en informatique et justifiez d'une exp√©rience r√©ussie d'au moins 2 ans, sur un poste similaire.Ma√Ætrise des concepts de la conception et de ta gestion de bases de donn√©es (SQL/NoSQL)Ma√Ætrise d'outils de gestion d'entrep√¥t de donn√©es type ETLConnaissance de langages de programmation (C++, Scala, Java, Python...)Connaissance des outils de gestion de flux ((Kafka, Flink...)Connaissance des principes de la r√©glementation concernant les donn√©es personnelles (RGPD)Vous correspondez au profil que nous recherchons : Alors postulez et venez rejoindre une √©quipe dynamique et motiv√©e !Pour plus d'information, vous pouvez nous joindre √† l'agence.19069463-55584
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Working In,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-at-working-in-3804259615?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=YPkBeF7xHjyWgUMCoU3esw%3D%3D&position=24&pageNum=3&trk=public_jobs_jserp-result_search-card,"Descriptionüíª Data EngineerüéØ Secteur : retailüíº CDIüìç Lyonüè° T√©l√©travail : 3j/semaineüíª √Ä propos du projet :Il s'agit de concevoir des solutions sur mesure pour accompagner la transformation digitale des entreprises et de leurs syst√®mes d'informations. Aujourd'hui nous cherchons √† renforcer une √©quipe dynamique Scrum (PO, D√©veloppeurs, QA et support) en charge d'un projet de centralisation de donn√©es m√©tier au sein d'un data lake unique. Ce projet a pour but d'aider un client du secteur du retail √† avoir une meilleure vision globale sur ses donn√©es.üéØ Tes missions en bref :En tant que data engineer, tu devras : Participer √† la r√©alisation des projets m√©tiers (usages) Prendre en charge les demandes de corrections provenant d‚Äôincidents ou d‚Äôanomalies Participer √† la mont√© en comp√©tences des √©quipes de d√©veloppement Mettre en pratique les m√©thodes ""DevOps"" Contribuer aux chiffrages des usages et √† la constitution des releasesExigencesü§© Ce poste est fait pour toi si : Tu es √† l'aise sur Spark et Scala (2-3 ans d'xp minimum sur ces technos en particulier) Tu connais les m√©thodes / technos DevOps ou tu d√©sires profond√©ment monter en comp√©tences sur cet aspect Tu aimes les projets Big Dataüß∞ Quelques d√©tails sur l'environnement technique :Spark, scala, java, Bitbucket, Cloud GCP, ElasticSearch, Jenkins, Kafka, Kubernetes, Ansible, BigQuery, Dataproc‚Ä¶AvantagesUne r√©mun√©ration avantageuse qui s'adapte √† ton r√©el niveau de comp√©tences  3 jours de t√©l√©travail par semaineEt... si tu le souhaites nous rejoindre c'est aussi la possibilit√© d'inclure le logement comme avantage en nature, ce qui signifie:üí≠ Partager des convictions communes au sein d‚Äôun mod√®le innovant te proposant un package de vie (comme une voiture de soci√©t√©, mais ici c‚Äôest un logement styl√© !)üßò‚Äç‚ôÇÔ∏è Dire ‚ÄúBye bye‚Äù √† l‚Äôadministratif, aux factures, aux loyers exorbitants! Place √† la tranquillit√© d‚Äôesprit (m√©nage included) avec un pouvoir d‚Äôachat redor√© !üé® D√©couvrir et apprendre ! Mais quoi ? De nouvelles visions, exp√©riences, langues, cultures, comp√©tences, etc. avec des autres membres de la Communaut√© !üß∞ Un accompagnement r√©gulier, du coaching, une bou√©e de secours pour t‚Äô√©pauler, t‚Äôencourager et soutenir ta r√©ussite !üåç Vivre l‚Äô√©conomie de partage, aller vers un mode de consommation plus responsable, durable et √©cologique, parce que m**** le temps presse pour notre belle Plan√®te !BREF NOUS REJOINDRE C‚ÄôEST ADOPTER UN #ARTDEVIVRE


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': ['Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Stage - Data Engineer F/H,Fnac Darty,"Ivry-sur-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-f-h-at-fnac-darty-3805369566?refId=IlunvUmp2OoAlNawpITd8w%3D%3D&trackingId=wh8EEfaASdYZsGnt0gkFZA%3D%3D&position=25&pageNum=3&trk=public_jobs_jserp-result_search-card,"Fnac Darty, un leader europ√©en de la distribution omnicanal. Acteur omnicanal et europ√©en, sp√©cialis√© dans la distribution de produits techniques et d'√©lectrom√©nager, de biens culturels et de loisirs, et leader du service apr√®s-vente : 975 magasins dans le monde, 27 Millions de visiteurs uniques cumul√©s par mois sur nos sites marchands. Nos 25 000 collaborateurs sont notre meilleur atout. Ils font vivre la raison d'√™tre du Groupe au quotidien, qui consiste √† ¬´ s'engager pour un choix √©clair√© et une consommation durable ¬ª, aupr√®s de nos clients. Fnac Darty recrute partout en France des talents aux profils, formations et exp√©riences tr√®s diverses, que ce soit pour ses magasins, mais aussi dans les domaines de la logistique, de la r√©paration et service apr√®s-vente, de la livraison, de la relation client ou encore pour ses fonctions support. Votre prochain emploi vous attend chez Fnac Darty !Envie de te perfectionner ? Int√®gre la Digital Factory !Fnac Darty, est le Leader europ√©en de la distribution sp√©cialis√©e et un acteur majeur du E-commerce : 24 millions de visiteurs uniques par mois sur nos sites marchands en France, avec 8 milliards d‚Äôeuros de CA Groupe, 987 magasins pr√©sents dans 12 pays et 25 000 collaborateurs.La Digital Factory est une organisation agile constitu√©e d‚Äôune vingtaine d‚Äô√©quipes Produits pluridisciplinaires (Orderpipe, Commercialit√©, CustomerCare‚Ä¶) ainsi que d‚Äô√©quipes support transverses (architecture, UX, Data‚Ä¶) sur le p√©rim√®tre e-commerce. L‚Äôagilit√© √† l‚Äô√©chelle permet de faire travailler les diff√©rentes √©quipes ensemble.Nous recherchons un.e Data Scientist pour rejoindre le p√¥le Data de la Digital Factory. Les missions du p√¥le Data sont la collecte de donn√©es de navigation et de donn√©es produits, leur traitement, consolidation et stockage et enfin leur exploitation via des visualisations et des algorithmes de machine learning √† forte valeur ajout√©e (par exemple le moteur de recherche interne du site fnac.com ou le moteur de recommandation de produits).¬´ La mission de la Direction Digitale est de proposer √† nos clients des parcours omnicanaux, sans couture online et offline. Notre ambition est tr√®s forte, on dirait une grosse startup √† l‚Äôint√©rieur d‚Äôun grand groupe, √ßa donne √©norm√©ment de moyens pour faire aboutir les projets, tout en ayant un esprit d‚Äô√©quipe et une agilit√© tr√®s forte ¬ª Jean. L Directeur Digital.Tes Missions Principales Seront Impl√©menter des pipelines data sur GCP : orchestration via Cloud Composer (Airflow) Participer √† la mise en place de DBT (Data Build Tool) sur le p√©rim√®tre de l‚Äô√©quipe Participer aux code reviews Mise en place et monitoring des pipelines de CI/CD (int√©gration et d√©ploiement continus) Participer au cadrage des nouveaux projets Participer aux rituels Agile d‚Äô√©quipeTu veux en savoir plus sur ta future √©quipe ? Bonne coh√©sion d‚Äô√©quipe et dynamique De la formation et de l‚Äôentraide en continue sur les bonnes pratiques de code Un cadre responsabilisant qui offre la possibilit√© de progresser Organisation d‚ÄôAfterwork Tous les jeudis midi foot Des coll√®gues qui appr√©cient travailler sur des projets chalengeant dans des environnements √† fortes contraintes techniques.Informations Compl√©mentairesStage de fin d'√©tudes de 6 mois √† partir d'avril 2024 base √† Ivry sur Seine.
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER ‚Äì TOTALENERGIES DIGITAL FACTORY,TotalEnergies,"Saint-Martin-d‚ÄôH√®res, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-totalenergies-digital-factory-at-totalenergies-3793494861?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=5mNfCgpiTjkE7voLtheGrg%3D%3D&position=1&pageNum=4&trk=public_jobs_jserp-result_search-card,"Profil du candidat Tu as une exp√©rience d‚Äôau moins 4 ans en data engineering, tu es dipl√¥m√© d‚Äôun master ou d‚Äôune √©cole d‚Äôing√©nieur sp√©cialis√©e en informatique ou math√©matiques.Les comp√©tences qui sont attendues de toi en tant que Data Engineer : La maitrise de Python, Spark et SQL.  Une bonne connaissance sur les bases de donn√©es relationnelles et non relationnelles.  La capacit√© √† concevoir et √† mettre en ≈ìuvre des solutions de chargement, de manipulation, de traitement, d'analyse et d'exploration de donn√©es √† grande √©chelle.  Une bonne compr√©hension du machine learning. Une premi√®re exp√©rience sur un provider de Cloud, AWS de pr√©f√©rence. Activit√©s En tant Data Engineer, nous attendons techniquement de toi que tu : Con√ßoives, construises et int√®gres des donn√©es au sein de la Squad et en collaboration avec les autres Squads.  Assures le stockage, la consommation, l‚Äôint√©gration et la gestion des donn√©es des cas d‚Äôutilisation.  Fasses l‚Äôanalyse de l‚Äôanalyse de l‚Äôaccessibilit√© des donn√©es et que tu recommandes des solutions pour leur int√©gration.  Coordonnes la mise en place, l‚Äôindustrialisation et la maintenance de l‚Äôarchitecture data : infrastructure, cloud, flux de donn√©es. Tu int√®gres √©galement les donn√©es dans le data lake.  Collabores avec les data scientists pour la r√©alisation des mod√®les de pr√©diction.  Produises un code de qualit√©, mettes en place des tests automatis√©s et syst√©matiques pour le contr√¥ler.  Interagisses avec les architectes et les autres Data Engineers pour s‚Äôassurer de l‚Äôefficacit√© des solutions et apporter des pr√©conisations techniques. En parall√®le, tu auras √©galement des missions transverse. Pour ce faire, nous attendons de toi que tu : Assures la veille technologique sur les architectures data et les nouvelles technologies.Coaches et accompagnes la communaut√© des Data Engineers de la Digital Factory en participant au Communities of Practice (CoP) par exemple. Contexte et environnement Rejoins-nous en plein c≈ìur de Paris en tant que Data Engineer et int√®gre une de nos 30 squads qui r√©unit 8 √† 10 personnes (data scientist, data engineer, software engineers‚Ä¶). Chacune des squads est d√©di√©e √† un projet m√©tier et intervient dans la production des Minimum Viable Products (MVPs).Tu √©volueras dans un contexte agile (scrum/scrumban), en mode it√©ratif et co-constructif, en t‚Äôappuyant sur l‚Äôintelligence collective.En tant que Data Engineer, tu garantis la qualit√© des pipelines data du produit, tu assures le d√©veloppement des programmes pour collecter, pr√©parer, transformer et diffuser les donn√©es.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst H/F,Valeuriad,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-valeuriad-3741219622?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=FcWHuVPYJgwb7kkuXorZ%2Fg%3D%3D&position=2&pageNum=4&trk=public_jobs_jserp-result_search-card,"Rejoins la Team Data cr√©√©e par Nicolas Greffard, Docteur en Intelligence Artificielle, d√©j√† compos√©e de 20 Data Scientists et Data Engineer talentueux üòçNous recherchons de nouvelles p√©pites pour rejoindre notre √©quipe de choc et r√©pondre aux multiples probl√©matiques Data science de nos clients nantais mais √©galement contribuer √† nos projets de R&D et travailler sur des conf√©rences incroyables (DevFest, Salon de la Data) ü§©Ta future mission si tu l'acceptes üòâNous te proposons d'intervenir au sein de nos grandes DSI clientes, sur des sujets de collecte, d'alimentation et de transformation de donn√©es autour de l‚Äôintelligence artificielle.Le job en d√©tail ü§©Toutes Les Missions Ne Sont Pas Identiques, Mais Voici Des Exemples De Choses Sur Lesquelles Nos Data Analyst Sont Intervenus Mettre en oeuvre des outils informatiques, des techniques et des m√©thodes statistiques pour permettre d'organiser, synth√©tiser et traduire efficacement des donn√©es ; Fournir un appui analytique √† la conduite d'exploration et √† l'analyse complexe de donn√©es ; Cr√©er des algorithmes de recherche de donn√©es qui permettent d'explorer les donn√©es utiles ; Proc√©der √† l'industrialisation du proc√©d√© pour les donn√©es les plus int√©ressantes. Et organiser, synth√©tiser et traduire les informations pour faciliter la prise de d√©cision ; G√©rer les op√©rations et l'administration, la mod√©lisation et l'architecture des sources de donn√©es. Et s'assurer que les bases de donn√©es existantes soient op√©rationnelles et int√®gres ; Donner un sens aux donn√©es √† l'aide de ses connaissances analytiques (SQL, analytics/BI, statistiques basiques) ; D‚Äôint√©grer de nouveaux jeux de donn√©es (Open Data, crowd sourcing, API, fichiers, etc.).Nous intervenons sur des donn√©es Big Data (Hadoop, Hive, Spark, etc...), NoSQL (Neo4j, Redis Graph, Redis, mongo) avec toujours quelques bases de donn√©es Oracle ind√©boulonnables. Mais aussi r√©guli√®rement sur des environnements Cloud (principalement AWS et GCP). C√¥t√© outillage et ETL, les missions r√©centes √©taient principalement sur Informatica, Dataiku et Dig Dash. A retenir : nous faisons de tout !Pourquoi choisir Valeuriad ? üòäEn plus d‚Äô√™tre aujourd‚Äôhui un acteur nantais reconnu de l‚Äôexpertise IT, nous nous inscrivons depuis notre cr√©ation dans une d√©marche d'entreprise Opale et Holacratique, o√π l'ensemble de nos prises de d√©cisions et projets sont r√©alis√©s par et avec l'ensemble de nos 120 co√©quipiers üí™Rejoindre Valeuriad, c'est pouvoir s'investir dans la co-construction de l'entreprise : Par un r√¥le, avec une fiche de poste et un temps d√©di√© (gestionnaire des Ci‚Äôs, porteur des partenariats √©coles, organisateur d‚Äô√©v√©nements, PO des projets internes, gestion de l'Acad√©mie Valeuriad‚Ä¶). Par les projets strat√©giques (200 jours mis √† disposition pour les co√©quipiers chaque ann√©e) pour cr√©er et faire grandir des projets structurants (cr√©ation de nouveaux avantages √† l'anciennet√©, cr√©ation d'indicateurs mensuels pour √™tre toujours plus transparents, m√©c√©nat de comp√©tences pour des associations caritatives...). Par les projets cagnottes (150‚Ç¨ par co√©quipiers et par an) pour r√©aliser des projets collaboratifs qui te tiennent √† c≈ìur avec d'autres Valeurieux (d√©couverte du c√©cifoot, challenge √©cologique, challenges sportifs pour des dons √† des associations humanitaires, borne photo...). Par les ateliers collaboratifs, chaque mois des brainstorming et ateliers de travail sont propos√©s par les diff√©rents porteurs de projets et sont ouverts √† tous les volontaires.Mais avant-tout nous sommes une √©quipe soud√©e, des coll√®gues qui appr√©cient passer du temps ensemble lors de nos soir√©es hebdomadaires et se cr√©er des souvenirs inoubliables ü§© C'est pour √ßa que chez Valeuriad, le plus important pour nous reste le savoir-√™tre : des passionn√©s, du dynamisme, des sourires, de l'√©coute et le sens de la f√™te üòâ
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'Neo4j'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (F/H),Aubay,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aubay-3573871076?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=9tDxl5oM6thoHA8dp0UgCg%3D%3D&position=3&pageNum=4&trk=public_jobs_jserp-result_search-card,"Passionn√© par la Data, tu souhaites rejoindre une communaut√© d‚Äôexperts dans le domaine afin de d√©velopper tes comp√©tences en Data Engineering. Aubay renforce ses √©quipes Data et recherche des Data Engineers pour int√©grer des dispositifs de projets pointus et vari√©s.Ton quotidien en tant que Data Engineer chez Aubay, :D√©finition de la strat√©gie de stockage et mise en ≈ìuvre des technologie appropri√©es (base de donn√©es SQL, NoSQL, stockage distribu√©,‚Ä¶)Ingestion des donn√©es (structur√©es, semi-structur√©es ou non-structur√©es) selon diff√©rentes fr√©quences : batch, micro-batch ou temps r√©elConception et mise en ≈ìuvre de pipelines de donn√©es afin de fournir des donn√©es pr√™tes √† l‚Äôemploi aux consommateurs : uniformisation, mise en qualit√©, enrichissement, calcul d‚Äôindicateurs,‚Ä¶Conception et d√©veloppement d‚ÄôAPI pour exposer les donn√©es aupr√®s d‚Äôapplications tiercesAppui aux Data Scientists pour industrialiser et optimiser les algorithmes de Machine LearningPr√©paration et animation d‚Äôateliers de travail avec des interlocuteurs vari√©s : recueil/approfondissement des besoins m√©tiers, avancement/restitution des travaux, transfert de comp√©tences,‚Ä¶Ton profil :Tu dispose d‚Äôune formation niveau BAC+5 (Master 2 ou √©cole d‚Äôing√©nieur) sp√©cialis√©e en informatiqueTu as d√©j√† une premi√®re exp√©rience significative (a minima 2 ans) en Data Engineering sur des technologies Big DataLes technologies telles que Hadoop, Spark ou Kafka sont tes technologies de pr√©dilectionLa programmation n‚Äôa plus de secret pour toi et tu maitrise parfaitement un ou plusieurs langages de programmation suivants : Java, Scala et PythonTu ma√Ætrises les tenants et aboutissants de la philosophie DevOps et des outils orient√©s CI/CDTu es soucieux de la qualit√© et de la performance de tes d√©veloppements et tu t'int√©resse √† l‚Äôinnovation frugaleTu es un expert technique dans ton domaine sans pour autant oublier l‚Äôimportance d‚Äôune communication orale et √©crite de qualit√© et adapt√©e √† chacun de tes interlocuteursTu travaille au quotidien en mode agile et tu en maitrise les fondementsCe qui nous caract√©rise :Des missions et projets dans le domaine du Data Engineering en nombre et dans des secteurs vari√©s (Banque, Assurance, Telecom, Industrie,‚Ä¶) qui permettent √† nos collaborateurs de monter en comp√©tences et de devenir des experts Data reconnusDe l‚Äôapprentissage en continu avec des formations et des certifications sur les technologies Data d‚Äôaujourd‚Äôhui et de demainDes experts Data mobilisables pour accompagner et soutenir techniquement les collaborateurs sur leurs projetsDes communaut√©s de savoir-faire Data proposant de mani√®re r√©guli√®re aux collaborateurs d‚ÄôAubay du contenu et des √©v√®nements de partage (webinar, meetup/afterwork, BBL,‚Ä¶) sur les th√©matiques suivantes : Data Engineering, Data Viz, Data Science/IA, Data Platform & Architecture,‚Ä¶Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.Ta carri√®re chez Aubay :Tu auras la possibilit√© de d√©velopper et certifier tes comp√©tences sur les derni√®res technologies Data avec un focus fort sur les plateformes Data Cloud telles qu‚ÄôAzure Synapse Analytics, Google Cloud Platform, Snowflake et DatabricksTu pourras rejoindre la BU d‚Äôexcellence Data et √©voluer au sein d‚Äôun environnement humain et professionnel de haut niveau. Tu profiteras d‚Äôun management sur-mesure pour t'accompagner dans ta trajectoire de carri√®reAu sein de la BU d‚Äôexcellence, de multiples perspectives s‚Äôoffriront √† toi :R√¥le de ¬´ Lead ¬ª : Vous pourrez gagner en responsabilit√© sur le plan technologique et devenir un r√©f√©rent aupr√®s de nos clients et des collaborateurs de la communaut√© Data EngineeringR√¥le de ¬´ Champion ¬ª : Vous repr√©senterez Aubay aupr√®s d‚Äôun ou plusieurs de nos partenaires √©diteurs strat√©giques et vous participerez activement √† l‚Äôanimation de la relation sur le plan technologiqueR√¥le de ¬´ Head ¬ª : Vous pourrez prendre la responsabilit√© du savoir-faire Data Engineering et de ses offres et en assurer le d√©veloppement au sens large (d√©veloppement business, recrutement, management de collaborateurs, d√©finition de la strat√©gie et animation de la communaut√© au sein du groupe Aubay,‚Ä¶)Besoin d‚Äôen savoir plus sur le processus de recrutement ?Un √©change macro au niveau RH avec DorianeUn entretien technique avec Marius ou Peter, deux de nos r√©f√©rents techniquesUn √©change manag√©rial avec le Directeur de la BU Modern BI & DataA savoir que l‚Äôordre des √©tapes peut varier selon tes envies (ex : √©change manag√©rial avec l‚Äô√©change technique)Aubay encourage la diversit√© sous toutes ses formes et garantit l'√©galit√© des chances √† tous les candidats. Tous nos postes sont ouverts aux personnes en situation de handicap et nous proposons tous les am√©nagements n√©cessaires.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure', 'Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Glocomms,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-at-glocomms-3805458336?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=zlPd9EonfeJDchWM%2F69pXw%3D%3D&position=4&pageNum=4&trk=public_jobs_jserp-result_search-card,"In collaboration with an established Financial Services client, we are searching for an experienced Data Engineer to work on designing and implementation data solutions on Microsoft Azure environment.Role: Data EngineerDuration: 12 months (2 year project)Location: ParisHybrid RemoteStart Date: Start of FebruaryThe Role:To develop and maintain data pipelinesParticipate in the build of the data models ensuring accuracy and reliabilityCollaborate with stakeholders to understand the requirements and meet the needs of the userMonitor and optimize the performance of Azure data solutionsDevelop scripts to improve and streamline deployment, monitoring and maintenance of data solutionsProfile:Proven experience with cloud-based data pipelines and SQLCloud knowledge with Azure and its servicesTechnical experience with Databricks with AzureExperience of CI/CD best practicesProficiency with traditional database SQL technologiesAdept proficiency in Python, Snowflake and DBTFintech experience appreciated


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Qlik (H/F),Link Consulting SAS,"Cr√©teil, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-qlik-h-f-at-link-consulting-sas-3802291610?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=DqpA%2FET2L12rxWXcf%2BRDHw%3D%3D&position=5&pageNum=4&trk=public_jobs_jserp-result_search-card,"Link Consulting est un partenaire fiable pour nos nombreux clients PME, ETI, Grands Comptes au niveau national.Avec nous, offrez √† votre carri√®re de nouvelles perspectives : √©volution, challenge, √©panouissement professionnel. Gr√¢ce √† sa structure dynamique et innovante, Link Consulting favorise l'initiative et la libert√© d'entreprendre.Avan√ßons ensemble vers l'aventure qui vous anime.Notre client, acteur ambitieux du march√© de service IT, est √† la recherche de son futur Data Engineer (H/F) pour intervenir sur l'ensemble de la cha√Æne Data (infrastructures, int√©gration de donn√©es et le MCO) jusqu'√† l'accompagnement des m√©tiers pour la conception de la Data visualisation.Vos MissionsConstituer et entretenir le dictionnaire des donn√©es du Groupe,D√©finir, concevoir et maintenir les pipelines d‚Äôalimentation de donn√©es,Organiser les donn√©es en √©tant garant de l'alignement et la coh√©rence des donn√©es,Intervenir sur les migrations d‚Äôoutils de l'on-premise vers le cloud pour ce qui est des bases de donn√©es,Assurer le MCO des cha√Ænes de datas par des diagnostics, du support et de la correction en phase de Run.Profil Recherch√©Vous avez au moins 5 ann√©es d'exp√©riences r√©ussi en tant que Data Engineer et √™tes dipl√¥m√© d'un Bac +5 en informatique.Vous Ma√Ætrisez L'environnement Technique Suivant Qlik View et Qlik Sense Cloud AWS et les technos associ√©es Les outils d'automatisationEn plus des comp√©tences techniques, vous devrez vous d√©marquer par votre capacit√© d'analyse, votre relationnel et votre capacit√© √† partir d'une feuille blanche pour mettre en place les meilleures solutions possibles.Vous avez un anglais vous permettant d'aborder de la documentation technique en anglais.T√©l√©travail2 jours sur site √† Cr√©teil - 3 jours de t√©l√©travailR√©mun√©ration selon profil.La pr√©sente annonce d'emploi a √©t√© r√©dig√©e sous la responsabilit√© de Matthias PINEAU, mandataire ind√©pendant, ing√©nieur commercial de la SAS Link Consulting.Retrouvez toutes nos offres sur notre site : https://link-consulting.frLink Consulting c'est la liberteÃÅ et le choix.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Thales,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3808500283?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=6hRHI3l2txJ6d4rKIU%2BW3A%3D%3D&position=6&pageNum=4&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales propose des syst√®mes d'information et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d'importance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d'information critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l'utilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l'activit√© Syst√®mes d'information critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d'information afin de faire face aux ruptures technologiques et aux cybermenaces.L‚Äô√©quipe recherche un(e) Data Engineer (H/F)QUI ETES-VOUS ?Int√©gr√©(e) au centre de comp√©tences ¬´ Augmented Data ¬ª de Brest, vous interviendrez sur des projets de d√©veloppement de syst√®mes d‚Äôinformation ¬´ Data oriented ¬ª.Au sein de ce centre, vous rejoindrez nos Data Engineers, Data Architects et Data Scientists.De formation Ing√©nieur ou Bac +5, Ecole d‚Äôing√©nieur ou Universit√© vous justifiez d'une exp√©rience professionnelle en mise en place de solutions Big Data d‚Äôau moins 2 ans et id√©alement d‚Äôune premi√®re exp√©rience r√©ussie en animation d‚Äô√©quipe et/ou pilotage de lots techniques.Plusieurs des affirmations suivantes vous caract√©risent :- Vous √™tes passionn√©(e) par le Digital, les donn√©es, les enjeux qu‚Äôelles repr√©sentent et les technologies Big Data avec lesquelles les manipuler (Hadoop, Nifi, Kafka, ElasticSearch, Spark, Storm, HBase, Cassandra, etc.).- Vous √™tes familiaris√©(e) avec les diff√©rentes plateformes et outils qui y sont reli√©s.- Vous savez et aimez coder avec des langages de programmation commun√©ment utilis√©s pour la manipulation de donn√©es (Python, Java, SQL) sur des architectures distribu√©es en production.- Vous savez impl√©menter des cha√Ænes de traitement optimis√©es.- Vous √™tes familiaris√©(e) avec les concepts et technologies d‚Äôint√©gration continue (Git) et les outils de d√©ploiement (Docker).- Vous √™tes familiaris√©(e) avec les frameworks Agile tels que Scrum ou Kanban.- Vous √™tes motiv√©(e), appliqu√©(e), organis√©(e) et curieux(se) dans votre travail au quotidien.- Vous √™tes titulaire d‚Äôun dipl√¥me d‚Äôing√©nieur ou Master, id√©alement avec une sp√©cialisation sur les m√©tiers de la donn√©e et du Big Data.- Vous parlez fran√ßais et, id√©alement, anglais (√©crit et oral)CE QUE NOUS POUVONS FAIRE ENSEMBLE:En tant que Data Engineer, vos missions seront les suivantes :- Comprendre les besoins et les enjeux du client autour de ses donn√©es.- Concevoir des solutions innovantes de traitement de donn√©es r√©pondant aux besoins, impl√©menter des cha√Ænes de traitements Big Data et les d√©ployer √† l‚Äô√©chelle dans des environnements de production.- Contribuer √† la d√©finition d‚Äôarchitecture de donn√©es et √† l‚Äôop√©rationnalisation de plateformes de donn√©es.- Pr√©senter vos propositions de conception et r√©sultats aupr√®s du client et de votre √©quipe.- Partager et √©changer vos connaissances et exp√©riences dans le Data Engineering avec votre √©quipe.- Contribuer √† la pr√©paration et √† l‚Äôanimation d‚Äôateliers avec les interlocuteurs requis.- Effectuer un reporting r√©gulier √† votre manager sur l‚Äôavancement de vos activit√©s ainsi que sur les risques potentiels identifi√©s.NOUS VOUS OFFRONS:- Une diversit√© de projets vous permettant de d√©couvrir plusieurs environnements techniques et fonctionnels ainsi que l‚Äôensemble de nos m√©tiers au sein du groupe Thales,- Des conditions de travail motivantes et un plan de carri√®re personnalis√© offrant de r√©elles perspectives d‚Äô√©volution,- La possibilit√© de vous investir dans une entreprise dont la r√©putation est mondiale avec des ambitions constantes d‚Äôinnovations techniques,- Un cadre de travail privil√©gi√© dans des bureaux situ√©s √† un endroit dynamique du port de commerce de Brest,- La possibilit√© de t√©l√©-travailler jusqu‚Äô√† 10 jours par mois.Alors n'attendez plus, rejoignez-nous !Thales reconna√Æt tous les talents : la diversit√© est notre meilleur atout.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer senior Spark / Scala,BI consulting,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-spark-scala-at-sibylone-3800210863?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=NXxOX2vqjsa2qAmRgKwRSg%3D%3D&position=7&pageNum=4&trk=public_jobs_jserp-result_search-card,"SIBYLONE, soci√©t√© de conseil sp√©cialis√©e dans les syst√®mes d‚Äôinformation de synth√®se et de pilotage, aide ses clients √† tirer toute la valeur de leur patrimoine de donn√©es, levier strat√©gique majeur de d√©veloppement et de rentabilit√©.Notre ambition : rendre les diff√©rents acteurs de l‚Äôentreprise autonomes dans l‚Äôexploitation des donn√©es, lib√©rer les usages M√©tier, pour qu‚Äôils soient en mesure de relever les d√©fis de performance, de couverture de risque, de financement, de conqu√™te client, de RSE‚Ä¶ qui s‚Äôimposent √† eux.Sp√©cialistes reconnus, nos consultants s‚Äôappuient pour cela sur une connaissance approfondie de l‚Äôactivit√© business de nos clients, en lien avec nos trois piliers que sont le M√©tier, la Data et le Projet.SIBYLONE emploie environ 250 salari√©s et r√©alise un CA de 30m‚Ç¨ dans la prestation de services aupr√®s de grandes entreprises (8 grands comptes repr√©sentant 80% du CA). SIBYLONE est une filiale du Groupe Smart 4 Engineering cr√©√© en 2020. Le groupe s‚Äôest constitu√© en proc√©dant √† l‚Äôacquisition de 12 soci√©t√©s en France (dont SIBYLONE), Italie, et en Espagne dans le domaine de l‚Äôing√©nierie. Le groupe est d√©tenu par Dzeta Conseil, acteur familial de l‚Äôinvestissement. Avec nos 3,000 ing√©nieurs / consultants hautement qualifi√©s, le Groupe offre ses services dans les domaines tr√®s porteurs du Digital, de la Data, de l‚ÄôIntelligence Artificielle, de la Cybers√©curit√©, du Cloud et des Logiciels.Dans le cadre du d√©veloppement de notre activit√© Data, nous recherchons plusieurs Data Engineer√† l'aise avec spark et scala!Le Data Engineer participe √† la conception, la construction, le d√©ploiement et le maintien en production d‚Äôarchitectures Big Data, ces derni√®res ayant pour objectif de permettre tant l‚Äô√©volution que l‚Äôoptimisation du syst√®me d‚Äôinformation d√©cisionnel existant en permettant de nouveaux usages Analytics et IA.Vous int√©grerez une √©quipe projet Big Data dont l‚Äôobjectif premier est de conduire des projets ayant traits √† des probl√©matiques d‚Äôarchitecture et de conception dans un contexte Big Data & Cloud.Vos missionsAnalyser, comprendre et cadrer une architecture permettant de r√©pondre aux besoins m√©tiers des clientsConcevoir et mettre en place des plateformes Data en tenant compte des contraintes tant techniques que fonctionnellesIntervenir sur la conception et le d√©ploiement d‚Äôenvironnements ¬´ clusteris√©s ¬ª (Hadoop sur des distributions telles que Cloudera ou Hortonworks) ou Cloud publicD√©veloppement de pipelines d‚Äôingestion et de pr√©parationGestion du stockage de donn√©es (syst√®mes de fichiers comme HDFS, bases SQL ou NoSQL)Alimentation d‚Äôentrep√¥ts de donn√©es (Hive, Impala, ‚Ä¶)D√©velopper des applications d‚Äôexploration et de manipulation de donn√©es (SPARK / pySpark, Scala) afin d‚Äôalimenter les flux sortants, les reporting et d‚Äôexposer les donn√©esEvoluer sur l‚Äôordonnancement des traitements de donn√©es (Oozie, Bash / Shell)Assurer le maintien en conditions op√©rationnelles des plateformes produitesEtablir, formaliser, et promouvoir les best practicesPourquoi pas vous ?Profil recherch√© :De formation sup√©rieure ing√©nieur en Informatique, vous justifiez d‚Äôune premi√®re exp√©rience r√©ussie en data engineering acquise dans un contexte projet au sein d‚Äôune start-up, d‚Äôun pure player, ou d‚Äôune ESN.Vous disposez d‚Äôune bonne maitrise des langages propres aux environnements Big Data tels que :Hadoop et ses distributionsLes solutions Cloud (Azure, AWS, GPC)Spark, Scala, Python, Unix, SQL.Une connaissance de : Docker, ELK, Kubernetes, Cassandra, Kafka, ‚Ä¶ serait un plus, de m√™me que des fondamentaux DevOps (CI / CD).Vous avez d√©j√† √©volu√© dans un contexte projet agile ou scrum et faites preuve de flexibilit√©, d‚Äôadaptabilit√© et savez √™tre force de proposition.Au-del√† de vos comp√©tences techniques, vous √™tes curieux, autonome, organis√©, dot√© d‚Äôun bon sens relationnel et d‚Äôun esprit de synth√®se.Les PLUS Sibylone !Evoluer au sein d‚Äôune soci√©t√© qui exige le meilleur de ses collaborateurs tout en cultivant la coh√©sion et l‚Äôesprit d‚Äô√©quipe !S‚Äôengager dans une politique RSE exigeante : labellisation EcovadisAvoir un Partenariat EcoTree France : 1 recrutement = 1 arbre plant√© !Contribuer activement au bien-√™tre de ses collaborateurs : participation aux frais d‚Äôabonnements activit√©s ou achat 2 rouesAvoir de nombreux moments de convivialit√©s : s√©minaires, afterworks, conf√©rences et petits d√©jeuners, sports en groupe via l‚Äôapplication United HeroesDonner une offre de formation innovante et √† la pointe des nouvelles technologiesAccord de t√©l√©travail en vigueurVous vous reconnaissez dans la description du poste ?Vous souhaitez travailler dans un environnement stimulant et dynamique ?Vous souhaitez rejoindre une soci√©t√© ambitieuse ?Vous souhaitez comprendre l‚Äôorigine de Sibylone ?Venez-nous rencontrer : L'√©quipe TA sera ravie d‚Äô√©changer avec vous !Ce poste est ouvert aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Bash'], 'DataBase': ['SQL', 'NoSQL', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Ing√©nieur (H/F) - CDI,SFR,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-h-f-cdi-at-sfr-3798354547?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=exaS%2F%2ByzRzDQBw91zfEeDQ%3D%3D&position=8&pageNum=4&trk=public_jobs_jserp-result_search-card,"SFR Business, groupe Altice France, est la marque Entreprise du deuxi√®me op√©rateur t√©l√©com fran√ßais.SFR Business d√©veloppe des solutions t√©l√©coms et des services ICT simples, fiables, adapt√©s aux enjeux de chaque entreprise, quels que soient leur m√©tier et l'usage de leurs collaborateurs o√π qu'ils soient.SFR Business propose et d√©ploie une palette unique de services alliant des offres convergentes fixe-mobile et des solutions sur-mesure : t√©l√©phonie, donn√©es, S√©curit√© informatique, R√©seaux d'entreprise, Infrastructure IT, Internet des Objets... D√©j√† adopt√©es par 140 000 entreprises clientes, ces solutions simples et performantes permettent aux entreprises, de la TPE √† la multinationale, en passant par les administrations, de faire de la transformation num√©rique un levier de d√©veloppement √† part enti√®reVous int√©grez la Direction Transformation, Risques & Pilotage en qualit√© de Data Ing√©nieur(e). Rattach√©(e) hi√©rarchiquement au manager du service ¬´ PRV & Pilotage ¬ª dont la mission est le pilotage de l'activit√© commerciale SFR Business et du Plan de R√©mun√©ration Variable des √©quipes commerciales et avant-vente.Vos missions sont les suivantes :Architecture projet des donn√©es : concevoir et d√©velopper des architectures projet de donn√©es robustes, √©volutives et performantes pour int√©grer et g√©rer de grandes quantit√©s de donn√©es provenant de sources multiples. Assurer la fiabilit√©, l'√©volutivit√© et la s√©curit√© des flux de donn√©es.Int√©gration des donn√©es : √©laborer des pipelines de donn√©es efficaces pour l'extraction, la transformation et le chargement des donn√©es provenant de diff√©rentes sources. Mettre en place des processus d'int√©gration automatis√©s et veiller √† la qualit√© des donn√©es.Gestion des bases de donn√©es : concevoir et optimiser des bases de donn√©es pour r√©pondre aux besoins d'analyse et de reporting. Assurer la performance, la disponibilit√© et la s√©curit√© des bases de donn√©es, ainsi que la gestion efficace des requ√™tes.Collaboration interfonctionnelle : en support des Data Scientists, travailler avec l'√©quipe pour comprendre leurs besoins et fournir des conseils et des recommandations bas√©s sur les donn√©es.Optimisation des performances : Surveiller et optimiser les performances des pipelines de donn√©es, des bases de donn√©es et des requ√™tes. Identifier les goulots d'√©tranglement et les points d'optimisation et proposer des am√©liorations pour garantir des performances optimales.S√©curit√© et conformit√© : Veiller √† ce que les donn√©es soient trait√©es et stock√©es conform√©ment aux normes de s√©curit√© et de confidentialit√©. Mettre en place des m√©canismes de s√©curit√© pour prot√©ger les donn√©es sensibles et garantir la conformit√© aux r√©glementations en vigueur.En tant qu'expert(e) de la donn√©e, vous serez aussi amen√©(e) √† :R√©aliser des simulations statistiques d'impact lors des demandes d'√©volutions de r√®gles PRV afin de permettre √† la Direction de prendre les d√©cisions,Etudier les impacts des nouvelles r√®gles sur l'efficacit√© op√©rationnelle du commerce,R√©aliser des √©tudes ad-hoc permettant de mettre en √©vidence les leviers business et faire des recommandations,Piloter pour le service les projets d'√©volutions SI d√©cisionnel afin d'am√©liorer la mise √† disposition des donn√©es commerce pour notre socle de donn√©es (Technologie SAS),Assurer l'expertise sur Tableau et SAS pour le service.Profil :Exp√©rience en entreprise de 5 ans minimum dans le domaine du traitement et de l'analyse de donn√©es.Tr√®s bonne Maitrise de SQL, SAS, TABLEAU, VBAComp√©tences Statistiques, Big Data, IA & machine learning.Comp√©tences transverses attendues : Gestion/coordination de projet, sens des priorit√©s, adaptabilit√©Capacit√© d'analyse et force de propositionM√©thode, organisation, autonomieCommunication √©crite/oraleSens client (interne et externe) et √©coute activeTravail en √©quipe et curiosit√©


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
(Senior) Data Engineer,Mirakl,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3707383397?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=TUvialYsQCp2GKKM33Bi%2BQ%3D%3D&position=9&pageNum=4&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.A propos de Mirakl LabsNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :contribuer √† l'enrichissement de la Data Platform (ETL)am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©.Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, AnsibleAu quotidien, vous allez :Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SREAssurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data EngineeringR√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platformPartager ses connaissances et pr√©senter les travaux devant toutes les √©quipes LabsCe qu‚Äôon peut vous apporter :Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de MiraklUne culture orient√©e sur la veille technologiqueDes projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingueQuelques exemples de sujets en cours :Enrichissement des donn√©es produit √† partir des images et des descriptionsMod√©ration automatique des produitsMapping automatique des donn√©es produitIdentification des produits √† fort potentielsD√©tection de comportements frauduleuxSentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuationsD√©termination de prix optimauxMonitoring de la qualit√© de service des vendeursDes applications d‚Äôinf√©rence en synchrone de nos mod√®les de MLVous aimerez ce job si :Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partieVous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine LearningVous avez un background en d√©veloppement et avez √©volu√© dans un environnement DataVous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou DataVous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©esVotre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWSVous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous pr√©sentez vos travaux de mani√®re simple et accessibleVous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et fran√ßaisLes plus pour le poste :Vous avez une exp√©rience significative dans le domaine du e-commerceVous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez d√©ploy√© des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autreVous ma√Ætrisez Java/ScalaMirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
üöÄ Data Engineer,BAO,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/%F0%9F%9A%80-data-engineer-at-bao-3806758472?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=PGfsUgV6W%2FL4CpL2OjBWkQ%3D%3D&position=10&pageNum=4&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une start-up en plein d√©veloppement qui s'est lanc√©e pour mission de r√©volutionner la m√©decine du travail ?L'entreprise en question est une Medtech cr√©√©e en 2016. C'est une plateforme collaborative de pr√©vention d√©di√©e √† la sant√© au travail qui propose des outils complets de convocation, gestion, pr√©vention et facturation.Destin√©e aux ""Services de Pr√©vention et de Sant√© au Travail"", aux employeurs et aux salari√©s, cette solution a pour but d'optimiser l'organisation de la sant√© au travail en rendant les √©changes plus efficaces et plus fluides. Cela permet √©galement de minimiser les potentiels risques & dangers li√©s au travail.Aujourd'hui, ce sont pr√®s de 2 millions de salari√©s suivis sur cette plateforme et ce chiffre doit bient√¥t atteindre les 5 millions !üí• Au sein d'une √©quipe de 20 personnes, vous serez amen√©.e √† travailler sur :La collecte, l'organisation et le traitement des donn√©esL'optimisation et l'automatisation des process & flux de donn√©esL'am√©lioration de la performance et de la qualit√© des donn√©esLa s√©curit√© des donn√©esLa Stack: Python, SQL, Javascriptüî• Les plus :Une start-up √† impact avec un projet ambitieux et utile pour la soci√©t√©Une entreprise avec un r√©el challenge technique (migration de donn√©es et volum√©trie importante)Une √©quipe jeune et un secteur d'avenir !üßë‚Äçüíª Vous avez le profil id√©al si :Vous avez au minimum 1 an d'exp√©rience en tant que Data EngineerMonter en comp√©tences sur Javascript ne vous effraie pasVous avez envie d'√©voluer au sein d'une entreprise √† c≈ìur de m√©tier techüí∞ R√©mun√©ration : 44k-48k selon exp√©rienceüè† Poste bas√© √† Paris (17√®me) - 2 jours de t√©l√©travail/semaineOn en discute ?‚úâÔ∏è louise@bao.jobs


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data Engineer - Clermont-Ferrand, France (H/F)",Astek,"Clermont-Ferrand, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-clermont-ferrand-france-h-f-at-astek-3792944763?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=fFWbXQVNZ0dK8Abf31zmVQ%3D%3D&position=11&pageNum=4&trk=public_jobs_jserp-result_search-card,"Le Groupe Astek Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 7000 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.Rejoignez un Groupe en fort d√©veloppement en France et ayant r√©alis√© un chiffre d‚Äôaffaires de 500 M‚Ç¨ en 2022.‚ú® Tous les d√©tails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog.Ce que nous pouvons accomplir ensemble :Dans le cadre du d√©veloppement de notre entit√©, nous recrutons un Data Engineer pour int√©grer nos √©quipes clermontoises !Votre mission (‚Ä¶si vous l‚Äôacceptez !) :La mission consiste √† renforcer l‚Äô√©quipe data products development en place pour supporter les ambitions de d√©ploiement de services bas√©s sur la data.La mission du Data Engineer consistera √† analyser des donn√©es de mobilit√© et d√©velopper des pipelines de traitement de donn√©es robustes et scalables afin de pouvoir mettre en ≈ìuvre des services pour des clients externes et internes. Il proc√©dera √©galement √† l‚Äôindustrialisation et la mise en exploitation de ses mod√®les.Vous ?Dipl√¥m√© d‚Äôune √©cole d‚Äôing√©nieurs, vous justifiez d‚Äôau moins 5 ans d'exp√©rience professionnelle dans un r√¥le similaire.Exp√©riences requises :D√©veloppement sur les environnements Microsoft AzureD√©veloppement R/Python, DataikuExp√©rience sur les bases de donn√©es MongoDB, SQLNotions de traitement de donn√©es g√©ographiques - g√©omatiquesVous vous √™tes reconnu sur l‚Äôannonce et Astek vous pla√Æt ? Rencontrons-nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Senior,Mobiskill | WEFY Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-at-mobiskill-wefy-group-3804041198?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=SpkLtq%2FwW7AmXH1prbwusQ%3D%3D&position=12&pageNum=4&trk=public_jobs_jserp-result_search-card,"La soci√©t√© ?Cette startup a √©t√© cr√©√©e en 2018 et vise √† aider la prise de d√©cision de ses clients qui sont principalement dans le secteur du retail ou de l'alimentaire.Ils permettent d'enrichir la donn√©e afin d'am√©liorer la strat√©gie de vente et marketing d'une entreprise gr√¢ce √† leur plateforme Saas bas√©e sur des algorithmes d'IA.Ils ont besoin de renforcer leur √©quipe en Data Engineering pour g√©rer au mieux leur volum√©trie.Les missions ?- Editer le cahier des charges des donn√©es √† collecter aupr√®s de nos partenaires distributeurs- Faire un √©tat des lieux du mod√®le de donn√©es de la soci√©t√©, qui int√®gre d√©j√† plusieurs types de donn√©es issues de diff√©rentes sources- Prendre en main la gestion de la donn√©e dans le cloud de la soci√©t√© pour optimiser les co√ªts et l‚Äôefficacit√© des analyses effectu√©es par l‚Äô√©quipe Analytics- Anticiper les √©volutions et participer aux choix structurants de la soci√©t√© li√©s √† la gestion de la data ainsi que la stack technique.Stack : Azure / SQL / Snowflake / Kafka / Pyspark / Airflow / DatabricksLe profil recherch√© ?- Au minimum 3/4 ans d'exp√©rience dans le Data Engineering- Avoir pu travaill√© en Python concernant le langage de programmation- La ma√Ætrise des outils tels Spark, Airflow, Kafka et Snowflake seraient un gros plus - Ma√Ætriser un des cloud providers et si possible avoir une exp√©rience sur AzurePetit bonus si tu as pu travailler par le pass√© dans le retail Pourquoi les rejoindre ?- Une soci√©t√© stable financi√®rement (fonds propres uniquement)- Une startup en pleine croissance- Une r√©mun√©ration en fonction de votre s√©niorit√©- Volum√©trie de donn√©es incroyable, il y a de quoi s'amuser !- Faire parti de l'unique retail-tech qui a un impact √©cologique positif (fin des prospectus, √©viter le g√¢chis alimentaire)H√¢te de vous en dire plus rapidement !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Lille H/F,Jems Group,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-lille-h-f-at-jems-3803363459?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=ohSOvjKn5sRyuTTHLtRDiQ%3D%3D&position=13&pageNum=4&trk=public_jobs_jserp-result_search-card,"A propos de JEMSNous sommes le seul industriel de la donn√©e en Europe. Notre m√©tier est de cr√©er, manager et exploiter le patrimoine data de nos clients.Nous avons la conviction que chaque entreprise peut adopter une d√©marche innovante de gestion de la donn√©e et cr√©er des cas d‚Äôusage disruptifs en r√©duisant l'impact √©cologique et en diminuant la dette technique.Nous comptons plus de 840 collaborateurs en mission chez nos clients grands comptes dans tout secteur d‚Äôactivit√© : banque, assurance, sant√©, √©nergie, e-commerce, automobile, luxe, retail, transport, agritech‚Ä¶Vos missionsNous recherchons un(e) data engineer capable de trouver des solutions innovantes et robustes √† l'ensemble des probl√©matiques Data.Vous aurez la charge de :Participer √† la conception et r√©alisation d'une solution Data depuis l'acquisition jusqu'√† l'exploitation de la donn√©e en accompagnant la r√©flexion des directions m√©tiersIdentifier, collecter et int√©grer les donn√©es n√©cessaires √† la r√©solution de probl√©matiques m√©tier et op√©rationnellesGarantir la qualit√© des donn√©es en mettant en place les outils de mesure et de suivi ad√©quats en appliquant les r√®gles de Data Gouvernance et de Data ManagementTranscrire des besoins m√©tier en r√®gles de gestion dataIndustrialiser le d√©ploiement de vos r√©alisations √† travers l'impl√©mentation de tests unitaires, d'int√©gration et de non-r√©gressionVos comp√©tencesEn tant que Data Engineer vous ma√Ætrisez :Le langage SQLUn langage objet (Python, JAVA, Scala)Un framework de calcul distribu√©L'int√©gration continue (Git, JUnit, SonarQube, Jenkins)Un cloud provider (AWS, GCP, Azure) ou une distribution Big Data (Hortonworks, Cloudera, Datastax)Les concepts de la mod√©lisation relationnelle et non-relationnelleVotre profilDipl√¥m√©(e) d'une √©cole d'ing√©nieur ou d'une universit√©, vous justifiez d'une exp√©rience professionnelle dans un contexte projet Data. Rigoureux, proactif et autonome vous restez en veille technologique et √™tes force de proposition. Vous √™tes capable de prendre de la hauteur et vous adapter aux enjeux du projet.Avantages √† travailler chez JEMSUne JEMS Acad√©mie au service de votre mont√©e en comp√©tences (formations et certifications sur les technologies de pointe)Un accompagnement personnalis√© et un management de proximit√© pour vous proposer des √©volutions de carri√®reUne int√©gration dans des communaut√©s techniques et de pratiques JEMS (encadrement par des experts, √©changes sur les bonnes pratiques, favoriser l'innovation...) Une entreprise reconnue ""Great Place To Work""Des √©v√®nements et s√©minaires inoubliables, des soir√©es d'agence convivialesMobilit√©Une mobilit√© nationale et internationale pour vous accompagner dans vos projets de vie.Diversit√©Le Groupe JEMS porte fi√®rement sa valeur ""Diversit√©"" en se mobilisant pour l'inclusion et l'√©galit√© des chances et en luttant contre toutes formes de discrimination.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
head of data engineer,Cl√©mentine,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/head-of-data-engineer-at-cl%C3%A9mentine-certified-search-selection-3797494377?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=uwtLodtIRbWFzAr0aqM%2BtA%3D%3D&position=14&pageNum=4&trk=public_jobs_jserp-result_search-card,"SOCI√âT√â‚ÄîCl√©mentine, cabinet de conseil en recrutement depuis 2000 et sp√©cialiste des m√©tiers du digital et de l'IT recherche un(e) Directeur(trice) data engineer pour son client HAVAS DBI.Havas DBi, est une agence de conseil en data marketing, en hyper croissance, op√©rant √† l'√©chelle internationale : ""donner du sens √† la data"".MISSION‚ÄîRattach√© au comex vous jouez un r√¥le cl√© dans l'agence : technique, projet, organisation, management, avant vente, innovation,... En collaboration avec les √©quipes conseils vous √™tes un des moteurs de cette croissance.Missions principales : - Management & innovationVous managez et animez une √©quipe de 5 √† 10 experts (data engineers, data architects)Vous contribuez au d√©veloppement de la cellule data engineering (formation, nouvelles offres, organisation interne, recrutement, etc.).- Leadership techniqueComprendre les besoins fonctionnels et techniques des projets ainsi que les d√©fis sp√©cifiques de nos clients.Concevoir, mettre en place et administrer des architectures de donn√©es.Pr√©parer l'industrialisation et le d√©ploiement de cas d'utilisation en data marketing et data science.Garantir la conformit√© et la s√©curit√© des donn√©es personnelles de nos clients.D√©velopper et maintenir les flux de donn√©es d'alimentation.Mettre en ≈ìuvre les meilleures pratiques DevOps (Infrastructure as Code (IAC), processus d'int√©gration continue,...)Animer des ateliers m√©tiers et proposer des solutions adapt√©es.- D√©veloppement :Maintenir et d√©velopper les partenariats (Cloud, IA,...)Soutenir le d√©veloppement de futurs projets (avant-vente).PROFIL‚Äî Minimum 8 ans d'exp√©rience, dont une exp√©rience dans le data marketing.Excellente ma√Ætrise des environnements techniques, notamment Google Cloud Platform (GCP), Amazon Web Services (AWS), Microsoft Azure.Solides comp√©tences en Big Data avec Spark, Kafka.Comp√©tences en langages de programmation, notamment Python, Scala et SQL.Connaissance des bases de donn√©es telles que BigQuery, SQL Server et MySQL.Exp√©rience avec des ETL tel qu'Airflow.Savoir √™treExp√©rience en management d‚Äô√©quipeLeadership av√©r√© et d√©sir de contribuer au d√©veloppement de la cellule data engineering.Ma√Ætrise de l'anglais √† un niveau courant.Rigueur, autonomie, gestion des priorit√©s, esprit d'√©quipe et sens de l'organisation.Compr√©hension approfondie des enjeux et des impacts des projets dans le secteur du marketing.  POURQUOI POSTULER‚ÄîUn environnement de travail dynamique et collaboratif.Contribuer √† des projets innovants en data science et en IA g√©n√©rative.Formation continue et d√©veloppement professionnel.Des possibilit√©s d‚Äô√©volutions de carri√®re dans un groupe international


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Tech Lead Data Engineer,AXA en France,"Nanterre, √éle-de-France, France",https://fr.linkedin.com/jobs/view/tech-lead-data-engineer-at-axa-en-france-3801991762?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=vKe4sIsCFeQiCsCA%2FdetVA%3D%3D&position=15&pageNum=4&trk=public_jobs_jserp-result_search-card,"EnvironnementEn tant que Tech Lead Data Engineer F/H, vous allez contribuer directement aux projets des directions m√©tier (ex : fraude sant√©, multi√©quipements, pricing IARD, optimisation du lead management, fragilit√© auto, ‚Ä¶) d‚ÄôAXA France et √† la construction du socle technique Big Data.Vous allez int√©grer une √©quipe d'une dizaine de personne compos√©e de Data Engineer et des Tech Lead travaillant en mode Feature Team au sein des tribus m√©tier de la Direction Transformation Digital Tech et DATA (DT2).La Direction Transformation Digital Tech et DATA d'AXA France en quelques mots :- Une organisation agile en feature teams : tribus, guildes, squads- Des projets sur des applications innovantes √† fort trafic (web, mobile‚Ä¶)- Des m√©thodologies craft (TDD, BDD, clean code, code review‚Ä¶) et DevOps- Une communaut√© de partage de bonnes pratiques (BBL, dojo, meetup, conf‚Ä¶)Votre r√¥le et vos missionsVous aurez pour missions principales de d√©velopper les projets Big Data demand√©s par le m√©tier, et notamment :D‚Äôaccompagner techniquement les Data Engineer de l‚Äô√©quipe (coaching, code review, pair programming‚Ä¶)Passer de la donn√©e brute √† de la donn√©e exploitable, expos√©e sous forme de tables requ√™tables dans le datalakeConsolider ces donn√©es au fur et √† mesure de leur alimentation r√©currente dans le data lakeLes exploiter pour atteindre la finalit√© business (exposition de business view, r√©int√©gration des r√©sultats dans le SI, service de scoring, ‚Ä¶)De travailler √† la cr√©ation du socle technique Big Data et industrialiser le cycle de d√©veloppement de l'√©quipeDe mettre en place et de garantir le respect dans la dur√©e d'un processus qualit√© sur l'ensemble du cycle de DEV (documents, tests unitaires / int√©gration / fonctionnels, commentaires, versionning, etc.)Votre profilD'une formation sup√©rieure en informatique ou scientifique (Master ou Dipl√¥me d'ing√©nieur), vous justifiez de plusieurs exp√©riences significatives (+ de 7 ans) sur du d√©veloppement big data, en particulier sur du PySpark.Comp√©tences techniques :Connaissances avanc√©es en d√©veloppement en PySpark (Spark avec le langage Python)Maitrise de l'environnement Microsoft AzureConnaissances avanc√©es d'outils de BI comme PowerBIComp√©tences transverses :Capacit√© √† interagir avec des parties prenantes diverses : Business analyst, Architectes, M√©tierExp√©rience en mode de delivery Agile (Scrum, Kanban, etc...)Driver et accompagner des Data Engineer sur le plan op√©rationnelEt Id√©alement :Avoir une exp√©rience en tant que leadDes Connaissances sur Azure DevOps, Azure Pipeline, GIT, JIRAMaitrise des Traitements Big Data en mode StreamingMaitrise des Bases de donn√©es relationnelles et NoSQLUne exp√©rience professionnelle avec des outils comme Azure Databricks, Azure Data Lake Storage ou encore Azure Data FactoryMais pourquoi AXA France ?Nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons √† nos salari√©s sont nombreux.Nous choisir, c‚Äôest b√©n√©ficier par exemple :D‚Äôun package de r√©mun√©ration complet comprenant un salaire fixe, un compl√©ment de r√©mun√©ration variable, des primes, de la participation et de l‚Äôint√©ressement, la possibilit√© d‚Äôacqu√©rir des actions AXA, ou encore des solutions d‚Äô√©pargne avantageuses ;Equilibre vie Pro / Perso. : D‚Äôun cadre de travail flexible jusqu‚Äô√† 3 jours de t√©l√©travail possible par semaine, des tickets restaurant pour les jours t√©l√©travaill√©s ou encore une participation √† l‚Äôachat d‚Äôun √©cran ou fauteuil ergonomique ;D‚Äôune politique visant √† concilier vie personnelle et vie professionnelle avec 28 jours de cong√©s pay√©s, entre 14 et 16 RTT selon les ann√©es, des formules de travail √† temps partiel ou encore des jours d‚Äôabsence r√©mun√©r√©es pour la rentr√©e scolaire ou un d√©m√©nagement par exemple ;De la possibilit√© de s‚Äôengager pour une cause qui vous tient √† c≈ìur gr√¢ce √† nos associations telles que AXA Atout C≈ìur, AXA Comp√©tences Solidaires ou encore AXA Pr√©vention ;Et bien plus encore ! Perspectives de d√©veloppement des comp√©tences et de carri√®res immenses, CE, conciergerie, offres privil√®ges, soutien en cas d‚Äô√©preuve personnelle‚Ä¶On s‚Äôarr√™te l√†, la liste est longueQui sommes nous ?AXA est un des leaders de l‚Äôassurance et de la gestion d‚Äôactifs dans le monde.Nous aidons nos 108 millions de clients √† traverser les petites et grandes difficult√©s de la vie.Chaque jour, nous agissons ensemble pour inventer la meilleure mani√®re de les prot√©ger et voulons donner √† chacun les moyens de vivre une vie meilleure.Un challenge qui donne le sourire et envie de se lever le matin !Chez AXA, nous sommes persuad√©s que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs. C‚Äôest pour cette raison que nous menons une politique RH engag√©e qui favorise la diversit√©, qui pr√©serve l‚Äô√©quilibre vie priv√©e-vie professionnelle et acc√©l√®re le d√©veloppement des comp√©tences et des carri√®res.Ainsi, en rejoignant AXA France vous travaillerez dans une entreprise responsable, offrant une v√©ritable culture d‚Äôexpertise, acc√©l√©rant le d√©veloppement des comp√©tences de chacun et proposant une r√©mun√©ration attractive.Pourquoi nous rejoindre ?Vous √™tes porteur d‚Äôid√©es et d‚Äôinitiatives innovantes ? Vous proposez des solutions et √™tes au service du client ? Faites partie de notre grande famille en rejoignantUn leader mondial offrant des opportunit√©s de carri√®res int√©ressantesUne entreprise qui donne une place de choix √† l‚Äôinnovation, √† l‚Äôinitiative et aux actions solidaires (notamment via l‚Äôassociation AXA Atout C≈ìur)Un environnement inclusif √† tous les niveaux (mixit√©, handicap, initiatives pour favoriser l‚Äôinsertion des jeunes, orientation sexuelle, etc.)Un acc√®s √† de multiples avantages (cong√©s, temps partiel, t√©l√©travail, etc.)Un cadre stimulant, qui permet de rencontrer des collaborateurs performants et d‚Äôenrichir ses comp√©tencesVictime ou t√©moin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination √† alerte.discrimination.harcelement@axa.fr


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA']}"
Data Engineer (H/F),MERITIS,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3799014094?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=UKYQvFyIXdgwG%2FfKvjzDbQ%3D%3D&position=16&pageNum=4&trk=public_jobs_jserp-result_search-card,"Descriptif de l‚Äôentreprise :‚ÄãMeritis est un cabinet de conseil, pilotage et d√©veloppement IT fond√© en 2007 pr√©sent √† Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bient√¥t sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d‚Äôavance.‚ÄãNous accompagnons nos clients dans l‚Äôint√©gralit√© de leurs besoins en transformation num√©rique √† travers de nombreux domaines d‚Äôexpertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybers√©curit√© ou encore Agilit√©.‚ÄãIntervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des T√©l√©communications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.‚ÄãFort de nos valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, nous comptons aujourd‚Äôhui plus de 900 collaborateurs.‚ÄãNous mettons un point d‚Äôhonneur √† √™tre proche de nos collaborateurs et √† les accompagner de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise.Certifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.‚ÄãAujourd'hui, nous recherchons un(e) Data Engineer pour intervenir sur plusieurs projets innovants et de grande envergure dans les secteurs de la Banque, de l'Assurances, du Transport, de l'Energie, de la T√©l√©communication ou encore du Retail !Vos missions :Conception de plateformes permettant de traiter une grosse volum√©tries de donn√©esAnalyse et transformation de donn√©esConception de solutions data adapt√©es pour les besoinsMise en place des bases de donn√©esD√©ploiement des pipelines de donn√©es Maintien et d√©ploiement de nouvelles fonctionnalit√©sSuivi de la qualit√© de donn√©esEnvironnement technique : Spark, Scala, Hadoop, Python, Kafka, Airflow, SQL, MySQLCe poste est-il fait pour vous ? :Vous √™tes dipl√¥m√© d'un Bac +5 et justifiez d'au moins 3 ans d'exp√©rienceVous avez d√©j√† travaill√© sur les environnements Spark, Scala , Hadoop, PythonVous parlez anglais courammentVous avez justifiez d'au moins une premi√®re exp√©rience r√©ussie ‚ÄãMeritis est engag√©e dans la Responsabilit√© Soci√©tale des Entreprises. Nous valorisons notre impact positif sur la soci√©t√© et l'environnement. Notre d√©marche RSE guide chacune de nos actions pour promouvoir l'√©quit√©, la durabilit√© et le bien-√™tre de nos collaborateurs. Rejoignez-nous pour √™tre partie prenante de cette d√©marche responsable, o√π chacun de nos talents contribue √† construire un avenir meilleur.Vos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis est engag√©e en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez √™tre victime ou t√©moin d‚Äôune discrimination, vous pouvez contacter ethiquegroup@meritis.fr. ¬ª


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
(Senior) Data Engineer,Mirakl,France,https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3734528433?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=5lbntimWDuk%2Bjs5%2BPMbXAQ%3D%3D&position=17&pageNum=4&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.A propos de Mirakl LabsNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :contribuer √† l'enrichissement de la Data Platform (ETL)am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©.Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, AnsibleAu quotidien, vous allez :Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SREAssurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data EngineeringR√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platformPartager ses connaissances et pr√©senter les travaux devant toutes les √©quipes LabsCe qu‚Äôon peut vous apporter :Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de MiraklUne culture orient√©e sur la veille technologiqueDes projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingueQuelques exemples de sujets en cours :Enrichissement des donn√©es produit √† partir des images et des descriptionsMod√©ration automatique des produitsMapping automatique des donn√©es produitIdentification des produits √† fort potentielsD√©tection de comportements frauduleuxSentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuationsD√©termination de prix optimauxMonitoring de la qualit√© de service des vendeursDes applications d‚Äôinf√©rence en synchrone de nos mod√®les de MLVous aimerez ce job si :Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partieVous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine LearningVous avez un background en d√©veloppement et avez √©volu√© dans un environnement DataVous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou DataVous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©esVotre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWSVous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous pr√©sentez vos travaux de mani√®re simple et accessibleVous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et fran√ßaisLes plus pour le poste :Vous avez une exp√©rience significative dans le domaine du e-commerceVous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez d√©ploy√© des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autreVous ma√Ætrisez Java/ScalaMirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
(Senior) Data Engineer,Mirakl,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3640038712?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=jAa%2F7RApzcYAoLTAsMNwUw%3D%3D&position=18&pageNum=4&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l‚Äô√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.A propos de Mirakl LabsNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l‚Äôergonomie‚Ä¶Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l‚Äôensemble des produits.Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.Et pour favoriser ce partage avec d‚Äôautres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).En tant que (Senior) Data Engineer au sein de l‚Äô√©quipe Data Mirakl, vos principales missions seront de :contribuer √† l'enrichissement de la Data Platform (ETL)am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©.Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, AnsibleAu quotidien, vous allez :Participer √† la d√©finition et √† l‚Äôimpl√©mentation d‚Äôune architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et am√©liorer la CI/CD de l‚Äô√©quipe en collaboration avec l‚Äô√©quipe SREAssurer la mont√©e en comp√©tence des membres de l‚Äô√©quipe sur les sujets de MLOps et Data EngineeringR√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platformPartager ses connaissances et pr√©senter les travaux devant toutes les √©quipes LabsCe qu‚Äôon peut vous apporter :Des projets data driven, divers et vari√©s (traitements massifs d‚Äôimages, de textes, time series etc.) pour des produits diff√©rents de MiraklUne culture orient√©e sur la veille technologiqueDes projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingueQuelques exemples de sujets en cours :Enrichissement des donn√©es produit √† partir des images et des descriptionsMod√©ration automatique des produitsMapping automatique des donn√©es produitIdentification des produits √† fort potentielsD√©tection de comportements frauduleuxSentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuationsD√©termination de prix optimauxMonitoring de la qualit√© de service des vendeursDes applications d‚Äôinf√©rence en synchrone de nos mod√®les de MLVous aimerez ce job si :Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partieVous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine LearningVous avez un background en d√©veloppement et avez √©volu√© dans un environnement DataVous avez a minima 4 ans d‚Äôexp√©rience en environnement Machine Learning et/ou DataVous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d‚Äôimages dans des projets d'envergure, √† fort volume de donn√©esVotre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWSVous ma√Ætrisez au moins un outil d‚Äôorchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous pr√©sentez vos travaux de mani√®re simple et accessibleVous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et fran√ßaisLes plus pour le poste :Vous avez une exp√©rience significative dans le domaine du e-commerceVous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez d√©ploy√© des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autreVous ma√Ætrisez Java/ScalaMirakl est engag√©e en faveur de la diversit√©, de l‚Äô√©galit√© des chances et de l‚Äôinclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d‚Äôinnovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Engineer Cloud (H/F) | POEI,DataScientest.com,"Puteaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-h-f-poei-at-datascientest-com-3484992663?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=kfF7%2B7W7enfJQ0RGNwH1fw%3D%3D&position=19&pageNum=4&trk=public_jobs_jserp-result_search-card,"Vous √™tes demandeur d‚Äôemploi et vivement int√©ress√©(e) par les m√©tiers de la Data ?Rejoignez DataScientest en int√©grant une formation 100% financ√©e par P√¥le Emploi afin d‚Äôacqu√©rir les comp√©tences cl√©s qui vous permettront de booster votre carri√®re en tant que Data Engineer Cloud, un m√©tier en tension et en plein essor.Cette formation est certifi√©e par l‚ÄôEcole des Mines ParisTech, et inclut le passage de certifications √©diteurs (AWS, Microsoft Azure ou encore GCP) qui garantissent votre employabilit√©.Apr√®s avoir suivi notre formation de Cloud Data Engineer, vous rejoindrez, en CDI , notre entreprise partenaire.Les candidats retenus b√©n√©ficieront d‚Äôune formation intensive, enti√®rement prise en charge par le dispositif POEI (Pr√©paration Op√©rationnelle √† l‚ÄôEmploi Individuel) avec P√¥le-Emploi.üìúMISSIONS : En tant que Cloud Data Engineer, vous aurez pour missions de proposer les meilleures solutions aux entreprises afin d‚Äôoptimiser leur activit√©, √† travers les missions suivantes :D√©veloppement de solutions permettant de traiter des volumes importants de donn√©esConception, collection et fabrication des donn√©es brutesCr√©ation d‚Äôoutils et algorithmes pour le traitement des donn√©esPr√©paration des donn√©es pour le Data Analyst,S√©curisation des Pipelines donn√©es pour les Data Analysts et Data ScientistsOrganisation de l‚Äôarchitecture du cloudüë®‚ÄçüéìPROFIL : Ce que nous vous offrons :Une certification de l‚ÄôEcole des Mines ParisTechUn CDI aupr√®s de notre partenaire JEMS Group, expert europ√©en dans le traitement et l‚Äôexploitation des donn√©esUn salaire attractif √† la cl√© : 35 000‚Ç¨ √† 48 000‚Ç¨ selon le profilVotre profil :Issu(e) d‚Äôune fili√®re scientifique ou informatique vous disposez d‚Äôun bac+5 ou d‚Äôun dipl√¥me d‚Äôing√©nieurVous disposez id√©alement d‚Äôune exp√©rience significative en d√©veloppement informatique, en architecture r√©seaux ou dans la DataVous ma√Ætrisez un langage objet type Java, Python, C++, etc.Vous √™tes inscrit(e) √† P√¥le Emploi


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
CDI - Data Engineer - F/H/X,CANAL+ Group,"Puteaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/cdi-data-engineer-f-h-x-at-canal%2B-group-3797457997?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=W07IHwR4wc0ISOcwpYeg%2BA%3D%3D&position=20&pageNum=4&trk=public_jobs_jserp-result_search-card,"üåü Nos super projets en cours ou √† venir¬†:Data quality : notre √©quipe collecte 1,3 milliard de donn√©es par jour et 400 gigas par heure en moyenne. Dans ce contexte nous devons veiller √† ce que les donn√©es soient de qualit√©, mais aussi disponibles en temps et en heure. La collecte de ces donn√©es va nous permettre, entre autres, de recommander du contenu √† nos abonn√©.es ainsi que la transmission de messages cibl√©s visant au renforcement de leur engagement.üåü Fun facts¬†:Ces donn√©es vont nous permettre de convertir les prospects en abonn√©.es et de les fid√©liser en personnalisant au maximum leurs exp√©riences, mais aussi d'analyser l'impact de certains √©v√©nements marquants (la signature d'un nouveau partenaire, la prolongation des droits de diffusion de la F1 ou encore la prolongation de Kylian MBAPPE au PSG) sur le comportement de nos abonn√©.es ! üéØ Votre r√¥le et vos missions¬†:Concevoir, impl√©menter et participer √† l'industrialisation des applications dataComprendre les probl√©matiques en jeu de chaque sujetTravailler en collaboration avec des profils DevOps, Tech Lead et POParticiper aux diff√©rentes guildes mises en place dans des processus d'am√©lioration continue autour de la Data Gouvernance, des normes et standards de d√©veloppements¬† ¬†üèÜ Et si on parlait de vous¬†?¬†Vous justifiez d'une exp√©rience de 3 ans minimum en tant que d√©veloppeur/d√©veloppeuse ou ing√©nieur.e dataVous maitrisez Scala (ou Java), Spark ou justifiez d'une exp√©rience de d√©veloppement dans un environnement distribu√©¬†Vous avez une exp√©rience sur AWS ou au moins sur un cloud providerUne exp√©rience sur Airflow ou en ""Infrastructure as Code"" avec Terraform serait appr√©ci√©eVous faites preuve d'autonomie, appr√©ciez le travail en √©quipe et √™tes force de propositionVous avez d√©j√† travaill√© dans un environnement agileVous √™tes sensible aux concepts de clean code, clean architecture et aux best practices pour la r√©alisation de projets Data fiables et robustesVous avez un bon niveau d'anglais (lu, √©crit, parl√©)Vous souhaitez rejoindre un grand acteur de l'univers des m√©dias ! Et le process¬†? Un 1er contact t√©l√©phonique avec la tech recruiter + 1 entretien avec le manager, le tech lead et la tech recruiter + 1 test technique + 1 entretien avec notre Directrice Data + 1 caf√© avec l‚Äô√©quipe, environ 3 semaines en tout, en visio ou en physique comme vous le souhaitez¬†!üéÅ Les +Un abonnement collaborateur CANAL+ pour √™tre incollable sur nos univers¬†!Des avant-premi√®res de films et s√©ries dans notre salle de cin√©maDes visites de nos plateaux et des participations √† nos √©missionsParticiper aux √©v√©nements de notre communaut√© CANAL+ TECH¬†: meetups suivi d‚Äôafterworks, tech week, ‚Ä¶Participation & Int√©ressementCSE attractif : ch√®ques vacances et no√´l, prime mariage / pacs / naissance, r√©duction billetterie sport / voyages / loisirs, prise en charge d‚Äôune partie de votre abonnement sportif, ‚Ä¶Disposer d‚Äô1 jour d‚Äôengagement solidaire par an au profit d‚Äôune s√©lection d‚ÄôassociationsDevenir intrapreneur ou intrapreneuse avec l‚ÄôHack‚Äôcelerator, notre programme d‚Äôincubation interneEt parce que nous voulons vous aider √† vous √©panouir et vous perfectionner : des formations r√©guli√®res, des participations √† des conf√©rences en interne ou en externe ‚Ä¶ ! ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†üè° ¬†Et le t√©l√©travail dans tout √ßa ? Vous pourrez en b√©n√©ficier jusqu‚Äô√† 3 jours par semaine¬†!¬†En tant que m√©dia, producteur et distributeur de contenus, le Groupe CANAL+ a une responsabilit√© particuli√®re. En interne ou √† l‚Äô√©cran, nous soutenons une cr√©ation ambitieuse, inclusive et respectueuse des limites plan√©taires.üëä On agit pour l‚Äô√©galit√© entre les femmes et les hommes, contre toute forme de discrimination ou harc√®lementü§ù On agit pour l‚Äô√©galit√© des chances et l‚Äôinclusion de tous et toutesüåç On agit pour r√©duire notre impact environnemental et √©co-concevoir nos produitsSi vous voyez cette annonce, c‚Äôest que vous avez votre chance et que nous n‚Äôavons pas encore trouv√© la perle rare¬†!üëâ Seulement chez CANAL+ √† Puteaux (92).¬†¬†


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst/Data Engineer (H/F),PROXIAD,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-analyst-data-engineer-h-f-at-proxiad-3810367611?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=Sysp%2B7%2BT9jFfwM3rvz8YkA%3D%3D&position=21&pageNum=4&trk=public_jobs_jserp-result_search-card,"Dans le cadre de notre d√©veloppement, nous recrutons pour int√©grer notre projet sur Lyon (69) un :Data Analyst/Data Engineer (H/F)Vos missions, si vous les acceptez :Apport de comp√©tences Data aux √©quipes produits et projets de la North Star Flawless Preparation & Delivery :Analyse de donn√©es pour les cadrages et Discovery.Construction de dashboards en vue de suivi de KPI Projets/r√©currents.Sur la partie pr√©paration de commandes en entrepot : appropriation du modele de donn√©es et des donn√©es disponibles dans bigquery, construction des dashboard demand√©s, transfert de Comp√©tences outil aux personnes m√©tier.Sur la partie prep magasin : d√©finition des donn√©es utiles pour les besoins de pilotage et reporting, aide aux √©quipes produit √† sourcer et agr√©ger ces donn√©es, construction des tableaux de bord.Technologies :JIRAMY SQLSQLLookestudio (maitrise), Google Analytics (maitrise), Big Query (maitrise), MongoDB.Le profil que nous recherchons :De formation informatique avec minimum 3 ans d‚Äôexp√©rience en tant que Data Analyst/Data Engineer.Vous √™tes reconnu/e pour avoir une exp√©rience similaire avec une connaissance dans le domaine de preparation e-commerce qui serait un vrai plus.Un bon niveau d‚Äôanglais et n√©cessaire pour ce poste.Vous avez une capacit√© √† communiquer avec des personnes qui sont dans le domaine de l‚ÄôIT.Vous avez une autonomie et vous √™tes force de proposition.Pour finir vous avez une maitrise de lookerstudio, google analytics et big query obligatoire.Vous vous reconnaissez dans cette description ? Echangeons !Prise de fonction : A d√©finir selon disponibilit√©Salaire : Selon profilPourquoi nous rejoindre ?L‚Äôinnovation, la qualit√© et l‚Äôagilit√© sont au c≈ìur du d√©veloppement de nos activit√©s IT, encadr√©es et assur√©es par nos 850 collaborateurs et collaboratrices fran√ßais(es) et bulgares !Notre savoir-faire ? Conseil, D√©veloppement, Analyse et Expertise Informatique pour accompagner nos clients dans l'√©volution et la transformation de leur SI.En plus de notre ma√Ætrise des technologies PHP, JavaEE et .Net qui sont des composantes fortes de notre savoir-faire, nous mettons en avant une expertise d√©di√©e aux applications mobiles et XNet (Inter, Intra et Extranet) et au d√©veloppement de notre offre infrastructure (syst√®mes, r√©seaux, cybers√©curit√©‚Ä¶).Nos valeurs ? L‚Äôengagement, le pragmatisme, la proximit√©, l‚Äô√©volution et le partage. Aussi bien avec nos clients qu‚Äôavec nos collaborateurs (F/H).R√©sultats ? Une entreprise en pleine croissance avec des collaborateurs (F/H) √©panouis et reconnus au quotidien ! Des clients fid√®les et reconnaissants de la qualit√© des prestations fournies !Nos collaborateurs ≈ìuvrent chaque jour √† satisfaire et concr√©tiser les id√©es les plus folles et innovantes de nos clients !... N‚Äôattendez plus et tentez l‚Äôexp√©rience PROXIAD !Proxiad recrute et reconna√Æt tous les talents.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['JIRA']}"
Data Engineer - Spark Scala Hadoop (H/F),DGTL Performance,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-spark-scala-hadoop-h-f-at-dgtl-performance-3785729011?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=GHA2pgLNmRDerRkq2UAndg%3D%3D&position=22&pageNum=4&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi DescriptionDGTL / Signe + est le facilitateur pour tous les acteurs qui recherchent des ressources ou des missions DATA. Sp√©cialiste du march√© Data et BI, nous intervenons dans toute la France comme √† l'√©tranger ; en sous-traitance, pr√©-embauche, recrutement, portage commercial, portage salarial, etc. Depuis 2018, nous accompagnons nos clients avec proximit√©, juste prix et pr√©occupation √©thique de tous les instants. https://www.dgtl-performance.com Le poste : Data Engineer - Spark Scala Hadoop - minimum 3 ans d'XP Entreprise fran√ßaise du secteur de l'√©nergie, au sein d'une direction de l'innovation. Recherche un profil Data science/Data analyse pour rejoindre une √©quipe de 6+ personnes √† terme Profil recherch√© : Comp√©tences clefs obligatoires : Spark Scala langage Java Big Data (environnement Hadoop) Bon relationnel (contact m√©tier/esprit d'√©quipe), bonne capacit√© d'analyse Localisation : Issy-les-MoulineauxPROFIL SOUHAIT√âExp√©rienceExp√©rience exig√©e de 2 An(s)Source: Pole emploi (https://www.pole-emploi.fr)
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer H/F,Devoteam G Cloud,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-h-f-at-devoteam-g-cloud-3801927760?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=fvRO2mXxSS6aWIS7wsw%2BfQ%3D%3D&position=23&pageNum=4&trk=public_jobs_jserp-result_search-card,"Tu auras pour mission d‚Äôaccompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l‚Äô√©cosyst√®me solutions open source associ√©.Int√©gr√©(e) √† une √©quipe d‚Äôexperts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d‚Äô√©tudier et cadrer les besoins clientsPr√©coniser les solutions et architectures ciblesD√©finir les m√©thodologies de d√©ploiement et plans de migrationR√©diger les dossiers d‚Äôarchitecture et sp√©cifications techniquesConstruire les architectures de donn√©esConcevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els)Construire et d√©ployer les pipelines de donn√©es (ETL / ELT)Assurer la migration des donn√©es vers les nouveaux environnementsAnalyser les donn√©esAnalyser les donn√©es sources afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, DataStudio‚Ä¶)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les √©quipes clients aux m√©thodes et concepts du cloudTu seras accompagn√©(e) en interne pour monter rapidement en comp√©tences sur GCP dans l‚Äôobjectif de devenir certifi√© Google sur ta practice.Ton profilDipl√¥m√©(e) d'une √©cole d'ing√©nieurs ou d'un Master 2 en Informatique, tu disposes d'une exp√©rience significative au sein de projets Data : architecture, traitement ou analyse de donn√©es.Tu ma√Ætrises au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (Scala, R, Python, Java).Tu as de bonnes comp√©tences dans de l‚Äôarchitecture des syst√®mes, bases de donn√©es, m√©thodologies d‚Äôanalyse.Tu sais te rep√©rer dans le vaste √©cosyst√®me Data et tu sais notamment quelle brique utiliser en fonction des cas d‚Äôusages. Tu es passionn√©(e) par la Business Intelligence, le Big Data, l‚ÄôInternet des objets (IoT) et le Machine LearningUne connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, ‚Ä¶) est un plus.Tu as une solide compr√©hension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et √† l‚Äô√©coute, tu poss√®des un r√©el esprit d‚ÄôanalyseTa ma√Ætrise de l'anglais te permettra de g√©rer des projets en contexte internationalLe Groupe Devoteam oeuvre pour l'√©galit√© des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m√©rite et lutte activement contre toute forme de discrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation.Tous nos postes sont ouverts aux personnes en situation de handicap


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer - F/M,SPARTEO,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-m-at-sparteo-3803665465?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=Ryw73OKCkkuc1QSZ9O88uA%3D%3D&position=24&pageNum=4&trk=public_jobs_jserp-result_search-card,"Sparteo - Suite of Solutions for Web PublishersSince 2016, we have been offering cutting-edge adtech solutions to help publishers generate more value on their websites. How? Thanks to our dedicated and passionate teams! We are committed to providing them with all the means necessary to contribute to realizing ours and our clients' ambitions.Since the inception of¬†Sparteo, four solutions have already been launched:¬†Viously¬†for video,¬†Voxeus¬†for audio,¬†Actirise¬†for display, and¬†FastCMP¬†our consent management platform.Discover our history, our products, and our culture on our¬†website!Your JobTo define, design, implement, and maintain tools and infrastructures for the analysis of data collected by various services and products of Sparteo. Ensure the creation of a solution for processing, storing, and querying large volumes of data while ensuring its security. Collaborate with data scientists, data analysts, and developers to facilitate their use of data.To specifyData Collection:Creation of endpoints.Establishment of pipelines.Configuration of tables.Data Aggregation:Creation and improvement of data marts.Data Governance:Management of access rights.Data Visualization:Development of dashboards.Documentation:Establishment and maintenance of a data catalog.Support:Assistance to teams.Your profile for this jobYou have expertise in data engineering, creation of endpoints, and pipeline management.You possess skills in data visualization, including dashboard creation.You document your work by establishing and maintaining a data catalog.Native-level proficiency in French, along with full proficiency in English (B2 level required).¬†¬†Your mind set to share our adventureYou want to make an impact and move things forward collectively. Does hearing phrases like ""Yes, but we've been doing it this way for years..."" make your hair stand on end? We feel the same way: progress is made by questioning what already exists.You solve problems pragmatically and analytically.You're looking for a fast-moving environment where your agility will be an asset. The 80-20 (Pareto) principle holds no secrets for you.Your ability to listen encourages you to challenge and improve yourself on an ongoing basis.Our working conditionsA convivial and flexible working environment, with our telecommuting culture integrated into the company's organization.A friendly and small-sized team that you can find in our offices near Lille or in Paris.Social gatherings and company events organized throughout the year.Sparteo is experiencing significant growth both in terms of business and workforce, especially internationally.Additional benefits include an advantageous compensation system with non-taxable and non-mandatory overtime hours, as well as a Swile restaurant ticket card.Ready to join Team Sparteo? Send us your CV and continue the recruitment process!Here are the stages in our recruitment processDiscussions about your driving forces, your ambitions and our¬†Sparteo mindsetAnalytical and business logic testsDiscussions with one or more members of the Sparteo team, including your future managerTaking up referencesOur recruitment process is mainly conducted by videoconference; however, certain stages may require a face-to-face meeting.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Data Engineer,Mobiskill | WEFY Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mobiskill-wefy-group-3804049709?refId=yvAtyUTd87hlkWa1jjHWAw%3D%3D&trackingId=5y7bzyewo3D15FMNv0pzpg%3D%3D&position=25&pageNum=4&trk=public_jobs_jserp-result_search-card,"La soci√©t√©: Soci√©t√© dans l'e-sant√© qui vise √† digitaliser un protocole de m√©decine pr√©ventive personnalis√©e pour soigner au mieux et en avance les personnes qui seraient √† risque sur le plan m√©dicalLes missions: Travailler sur le design de l'architecture dataD√©velopper de nouveaux pipelines de donn√©esCr√©er des tests d'unit√© et d'int√©grationD√©ployer avec la m√©thode CI/CD ces nouveaux pipelines de donn√©esLes pr√©-requis :Avoir au minimum 4/5 ans d'exp√©rience en tant que Data EngineerAvoir travaill√© plusieurs ann√©es avec Pyspark et Kafka√ätre familier avec AWS comme condition obligatoireConna√Ætre Airflow serait un plus√ätre pr√™t √† travailler avec une entreprise early-stage, qui souhaite r√©volutionner un domaine entier et avec de grandes ambitionsLes++:- Rejoindre une entreprise en plein essor qui a valid√© ses lev√©es de fonds- Travailler dans le domaine de la sant√©, b√©n√©fique pour tous- Faire partie d'une aventure humaine forte- Des bureaux dans Paris intra-muros- Rythme hybride de remote avec 3 jours de t√©l√©travail possibles- Une r√©mun√©ration pouvant aller jusqu'√† 80kH√¢te de vous en dire plus !


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data Engineer F/H - Syst√®me, r√©seaux, donn√©es (H/F)",UpMan Consulting,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-syst%C3%A8me-r%C3%A9seaux-donn%C3%A9es-h-f-at-upman-consulting-3803468769?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=S%2F0Oj7tIVmSdSy2zbfrXcA%3D%3D&position=1&pageNum=5&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi DescriptionDescriptif du poste: C est maintenant l occasion pour toi de rejoindre UpMan Consulting Notre ambition est de trouver les meilleurs profils Data Engineer pour intervenir chez nos clients grands comptes de la m√©tropole lilloise. On te propose une exp√©rience professionnelle en ad√©quation avec ce que tu souhaites r√©ellement. Tu d√©couvriras une ambiance de travail saine & bienveillante, tu participeras activement au d√©veloppement d une Happy StartUp, actuellement en forte croissance. O√π convivialit√© rime avec efficacit√© & o√π ta performance individuelle contribue √† notre r√©ussite globale. Tes missions / comp√©tences techniques Si tu l acceptes, ton r√¥le & tes missions seront les suivantes : * R√©aliser le processus d int√©gration de nouvelles donn√©es (r√©flexion sur la solution, mise en place d ETL, r√®gles de nettoyage, anonymisation ) * √ätre garant de l'acc√®s aux sources de donn√©es. * Ma√Ætrise de la donn√©e et √™tre le garant de sa qualit√© (r√©f√©rencement, normalisation et qualification) afin d'en faciliter l'exploitation par les √©quipes (Data Analysts et Data Scientists). * Ma√Ætrise de technologies Big Data et Cloud : Hadoop, Spark * Assurer la supervision et l'int√©gration de donn√©es structur√©es et non structur√©es venant de sources multiples, tout en veillant √† garder des donn√©es de qualit√©. * Assurer le suivi, la cartographie et la documentation des donn√©es int√©gr√©es * Afin de garantir une bonne ex√©cution de ta mission, nous recherchons les comp√©tences techniques suivantes : Langages de programmation : * SQL * Python / Pyspark * Java/Scala (plus rare, mais important) Diff√©rents types d ETL & orchestrateurs : * Airflow * Dagster * Prefect * SSIS/informatica * Talend Plateformes cloud : * GCP * Microsoft Azure * AWS Base de donn√©es relationnelles & NoSQL : * postgreSQL, MySQL,... * Redis, graphDB * Data warehouse/data transform : * Snowflake, Bigquery (tr√®s important) * DBT Qualit√© & comp√©tences n√©cessaires * Communiquant.e dans l √¢me * Avoir une bonne capacit√© de synth√®se & l esprit critique * Travail d √©quipe * Curiosit√© aigu√´ * Comprendre les objectifs & les besoins Nice to have * Anglais courant * Connaissance de la m√©thodologie DevOps * Notions en Data-science The office Pas de full remote (pour l instant) mais de l hybride dans la plupart des missions. En moyenne, 2 jours de t√©l√©travail par semaine. Cependant, les portes de nos bureaux √† Wambrechies sont toujours ouvertes pour accueillir nos collaborateurs pendant leurs journ√©es de t√©l√©travail & passer une bonne journ√©e tous ensemble ! Profil recherch√©: Ton Profil ÔøΩÔøΩÔøΩÔøΩ Tu es une personne passionn√©e & passionnante par ton domaine. Tu as envie d'√©voluer, de partager, de participer √† une mission collective & d√©couvre LA nouvelle fa√ßon de collaborer avec une ESN. Tu peux nous d√©montrer une exp√©rience significative avec en tant que Data Ing√©nieur, saches que l'alternance, c'est de l'exp√©rience ! Pas besoin d'avoir trop ou pas assez de dipl√¥mes, chez nous, ce sont les comp√©tences qui priment ‚ÄØ! On se rencontre, on discute, on √©change sur tes envies professionnelles & on laisse la magie op√©rer. L'envie de grandir & de monter en comp√©tences est ton moteur au quotidien. Tu aimes les probl√©matiques complexes et les d√©fis technologiques. On dit de toi que tu es un.e agiliste dans l'√¢me, qui effectue une veille constante, √† l'aff√ªt de tout ce qui √©volue autour de toi... Ne r√©fl√©chis plus, saute le pas & d√©couvre UpMan Consulting, tu ne seras pas d√©√ßu. Tu balances ta d√©mission ?PROFIL SOUHAIT√âExp√©rienceExp√©rience exig√©e de 2 An(s)Source: Pole emploi (https://www.pole-emploi.fr)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['MySQL', 'PostgreSQL', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer | Luxe - Retail (H/F),Cenova,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-luxe-retail-h-f-at-cenova-3796158092?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=62UxH0ZB%2By6%2FiuDRu2mBUg%3D%3D&position=2&pageNum=5&trk=public_jobs_jserp-result_search-card,"QUI SOMMES NOUS ET POURQUOI NOUS REJOINDRE ?Cabinet √† forte croissance, Cenova accompagne ses clients du #Luxe, du #Retail et du #Tourisme/Loisirs dans leurs projets de transformation Data et Digitale, et ce sur l‚Äôensemble des probl√©matiques m√©tiers (marketing, produit, supply, RSE, ‚Ä¶).VOTRE MISSIONVous travaillerez pour le compte de l‚Äôun de nos clients, au sein de l‚Äô√©quipe Data sur le d√©veloppement de solutions Data Analytics. Vos missions principales seront les suivantes :Concevoir et mettre en ≈ìuvre des solutions de traitement de donn√©es dans un environnement CloudMener des √©tudes de faisabilit√© et pr√©coniser les architectures data ciblesCr√©er, tester et d√©ployer des pipelines de donn√©es d'extraction, de transformation et de chargementMettre en application les concepts de CI/CD via les outils d√©di√©sParticiper √† la mise en ≈ìuvre de produits de Data visualisation : dashboard, reporting...Participer aux ateliers de collecte des besoins aupr√®s des √©quipes m√©tiersR√©diger la documentation (sp√©cification techniques, document d'exploitation, dossier d'architecture...) et analyser les solutions les plus adapt√©esAssister les phases de recette utilisateurs (identification ou mise en place de jeux de tests, recueil et traitement des demandes de changements)Accompagner et former les utilisateurs √† la prise en main des solutionsEnvironnement technique :Cloud : Azure, GCP, AWSLangages : SQL, Python, Spark, Scala, JavascriptBase de donn√©es : SQL Server/SQL Cloud, Google BigQuery, Oracle, MySQL, MongoDBDatamanagement : Azure Data Factory / Databricks/ Synapse (id√©alement), Google Cloud Data Fusion / Datafllow, DBT, Talend, SQL Server Integration Services.Datavisualisation : Power BI (id√©alement), Tableau, Qlik, DataStudio/LookerRepository : GIT, Azure DevOps, SVNSyst√®mes d‚Äôexploitation : Unix, Linux, WindowsVOTRE PROFILVous avez une exp√©rience minimale de 2 ans sur des missions de Data Engineering et vous disposez d‚Äôune grande app√©tence technique.Vous appr√©ciez comprendre le cycle de vie de la donn√©e et vous √™tes amateur de datavisualisation, notamment sur PowerBI.Vous avez, par ailleurs, le contact facile et vous comprenez les enjeux business et adaptez vos analyses en ce sens.Vous √™tes proactif(ve), autonome, bon(ne) communiquant(e) et vous √™tes √† l'aise en anglais.POURQUOI NOUS REJOINDRE ?Au-del√† de missions passionnantes dans des secteurs en pleine transformation, Cenova c'est avant tout un cabinet √† taille humaine avec :‚úÖ Un respect de vos attentes concernant vos missions et une r√©elle proximit√© manag√©riale pour vous accompagner‚úÖ La CenoAcademy pour vous former et nos CenoTalk pour partager nos expertises et connaissances‚úÖ La CenoLife pour vous apporter une vie de cabinet stimulante (afterworks, s√©minaires, √©v√®nements sportifs...)‚úÖ De multiples avantages en compl√©ment d‚Äôune r√©mun√©ration attractive : la mutuelle Alan, un CE, des titres restaurants, des primes vacances, le t√©l√©travail et plein d‚Äôautres jolis avantages‚Ä¶Ces quelques mots suscitent votre curiosit√© ? Candidatez ! Votre personnalit√© et votre savoir-faire feront le reste. Notre processus se d√©roule en 3 entretiens : RH, Manager et rencontre avec un associ√© !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': ['Linux', 'Windows'], 'SoftDB': ['MySQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,CGI,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-cgi-3805296774?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=ISE%2FVvbm%2BsvVa%2FpFBjJtBg%3D%3D&position=3&pageNum=5&trk=public_jobs_jserp-result_search-card,"Description de posteEn tant que Data Engineer, vous serez au c≈ìur de la transformation digitale des entreprises de la r√©gion Lyonnaise.D√©veloppement, traitement de haute volum√©trie, cloud transformation/ migration seront autant d‚Äôenjeux qui rythmeront votre quotidien aux c√¥t√©s de nos professionnels.Vous int√©grerez une √©quipe de taille humaine sp√©cialis√©e sur les domaines de l'Energie, de la chimie & des m√©tiers de la sant√©.Aux c√¥t√©s des autres membres de l‚Äô√©quipe et de communaut√© Data Grand-Est , vous perfectionnerez vos comp√©tences pour devenir un Data Engineer senior sur les technologies les plus modernes du march√© Data.Fonctions et responsabilit√©sAu sein de l‚Äô√©quipe, vous serez en interaction avec toutes les parties prenantes du projet, allant du business, aux √©quipes d‚Äôexpert et de d√©ploiement des solutions.Vous participerez au d√©veloppement strat√©gique d‚Äôun projet d‚Äôun client et vous √©voluerez dans un contexte international, et b√©n√©ficierez de l‚Äôexpertise de consultants CGI, en immersion chez le client.A ce titre vos principales responsabilit√©s seront : Appr√©hender le contexte et les enjeux M√©tier du client ; Comprendre et exp√©rimenter le cadre Agile et Lean ; Analyser les besoins fonctionnels et d√©terminer le mod√®le de donn√©es n√©cessaire avec l‚Äôaccompagnement de Consultant senior ; Participer au d√©veloppement de ces indicateurs au sein de la plateforme Cloud cible (AWS, GCP , Azure) et des outils de restitution (ex : Power BI, Qliksense) ; √âtablir et d√©rouler des sc√©narios de tests ; Participer √† la vie de la communaut√© Data.Qualit√©s requises pour r√©ussir dans ce r√¥le De formation bac+5 ou de formation sup√©rieure en informatique, vous disposez de 2 ans exp√©riences r√©ussie dans le d√©ploiement de plateforme de type Kafka , Datalake AWS , Datalake CGP ; Des connaissances m√©tiers dans le domaine de l'Energie, de la chimie & des m√©tiers de la sant√© , alli√©s √† des comp√©tences techniques fortes sont √©galement des atouts pour la r√©ussite de ce projet ; Votre capacit√© d'adaptation, votre autonomie, votre sens du service ainsi que vos qualit√©s relationnelles seront vos atouts pour r√©ussir et √©voluer ; Vous aimez √©voluer dans des contextes internationaux, avec une tr√®s bonne maitrise du fran√ßais et de l'anglais √† l‚Äô√©crit comme √† l‚Äôoral.CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+.Rejoindre CGI, c‚Äôest : Des suivis r√©guliers avec son manager ; Un acc√®s √† une plateforme avec de nombreuses formations disponibles d√®s son arriv√©e ; De nombreuses communaut√©s techniques et m√©tiers ; Une mobilit√© interne facilit√©e ; Un programme de buddy pour √™tre accompagn√©(e) durant la premi√®re ann√©e chez CGI ; Un √©quilibre vie professionnelle /vie personnelle respect√© (dont 0 √† 3 j de t√©l√©travail/semaine) ; Des √©v√©nements r√©guliers (sport, afterworks,‚Ä¶) ; De nombreux avantages sociaux (R√©gime d‚ÄôAchat d‚ÄôAction, forfait mobilit√© durable, mutuelle √† 100%...) ; Une politique RSE ambitieuse ; Un programme de M√©c√©nat de Comp√©tences ; Une Mission Emploi Handicap tr√®s d√©velopp√©e ;Allier savoir et faireAlors que la technologie s‚Äôinscrit au c≈ìur de la transformation num√©rique de nos clients, nous savons que les individus sont au c≈ìur du succ√®s en affaires.Lorsque vous rejoignez CGI, vous devenez un conseiller de confiance, collaborant avec vos coll√®gues et clients pour proposer des id√©es exploitables qui produisent des r√©sultats concrets et durables. Nous appelons nos employ√©s ""membres"" parce qu‚Äôils sont actionnaires et propri√©taires de CGI. Ils ont du plaisir √† travailler et √† grandir ensemble pour b√¢tir une entreprise dont nous sommes fiers. C‚Äôest notre r√™ve depuis 1976. Il nous a men√©s l√† o√π nous sommes aujourd‚Äôhui ‚Äì l‚Äôune des plus importantes entreprises ind√©pendantes de conseil en technologie de l‚Äôinformation (TI) et en management au monde.Chez CGI, nous reconnaissons la richesse que la diversit√© nous apporte. Nous aspirons √† cr√©er une culture √† laquelle nous appartenons tous et collaborons avec nos clients pour cr√©er des communaut√©s plus inclusives. En tant qu‚Äôemployeur qui pr√¥ne l‚Äô√©galit√© des chances pour tous, nous voulons donner √† tous nos membres les moyens de r√©ussir et de s‚Äô√©panouir. Si vous avez besoin d‚Äôun accompagnement sp√©cifique durant le processus de recrutement et d‚Äôint√©gration, veuillez nous en informer. Nous serons heureux de vous aider.Pr√™t √† faire partie d‚Äôune entreprise qui est gage d‚Äôexcellence? Rejoignez CGI ‚Äì o√π vos id√©es et vos actions changent la donne.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Software Engineer,Teads,"Montpellier, Occitanie, France",https://fr.linkedin.com/jobs/view/senior-software-engineer-at-teads-3799283693?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=r1vhwBLWAgLbCPB6Y7ZnCA%3D%3D&position=4&pageNum=5&trk=public_jobs_jserp-result_search-card,"Teads has an engineering team that brings together 200+ talented individuals in 3 main locations (Montpellier, Paris, and Bucharest). We are organized in agile and autonomous feature teams and share technical knowledge within several communities of practice.We promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.Our organization gives the possibility to work remotely part of the time and more flexibility is open to discussion. We also offer relocation packages if you prefer to settle down in one of our engineering offices.üëâ Join a team of passionate people who build quality and responsible advertising, at scale!Our main Engineering challenges at TeadsWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).Rich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.Management of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).Build efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.A fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.Bring a wide diversity of profiles to the same level of quality and knowledge.What will you do?As a Senior Software Engineer, your mission will be to:Collaborate with a variety of teams to develop complex services.Create, design, develop, test, and monitor your code in production autonomously and reliably.Work with the Engineering Manager to frame projects and be accountable for their execution.Obtain a good understanding of the business to provide relevant solutions to clients.Be a work facilitator and help communication inside and outside Teads.Stay up-to-date on new technologies and architectures. If they can solve a problem Teads has, propose ways to implement them into our current software engineering process.What will you bring to the team?Good programming abilities. Testing your code is second nature to you. You are very mindful of your application‚Äôs architecture, performance, maintainability, and overall quality.Good communication skills and ability to work collaboratively within a team. You are an active listener and a dialogue facilitator, you know how to explain your decision and like sharing your knowledge.Multiple shipped projects in Software Engineering.Strong problem-solving skills.Why work at Teads?At Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to scale our business while continuing to create new and exciting products.We value team spirit, pragmatism, listening and we encourage initiatives.We promote end-to-end development: ‚ÄúYou build it, you run it, you monitor it‚Äù.We share knowledge and support with each other beyond any organizational boundary.We fix issues during a blameless postmortem and learn from it so that it doesn‚Äôt happen twice.We are working together to create great engineering, but we are also supportive to promote a great work-life balance.We care about youSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).Career Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).Life Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.Wellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).Discover more about our culture and benefits on our Engineering website.What are our recruitment process steps?We want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!About TeadsTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.As an end-to-end solution, Teads‚Äô modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world‚Äôs best publishers and content providers.Through exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.Teads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.We're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,Mobilize Financial Services ‚Äì France,"Noisy-le-Grand, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-mobilize-financial-services-%E2%80%93-france-3790154028?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=eDv5abC%2FTccd%2FIoi5o4y7w%3D%3D&position=5&pageNum=5&trk=public_jobs_jserp-result_search-card,"üöó En route vers Mobilize ! A l‚Äô√©coute de tous nos clients, nous cr√©ons des services financiers innovants pour construire une mobilit√© durable pour tous.Rejoindre Mobilize Financial Services, c‚Äôest d‚Äôabord choisir d‚Äôint√©grer un groupe international, filiale de Renault Group, une banque de financement solide, partenaire des constructeurs Renault‚ÄìNissan‚ÄìMitsubishi. Nos 4 000 collaborateurs pr√©sents dans 35 pays, agissent ensemble au service de nos clients.Nous proposons √† nos clients - particuliers comme professionnels - les financements et les services les plus adapt√©s pour les v√©hicules neufs et d'occasion.Nous finan√ßons √©galement l'activit√© des r√©seaux de concessionnaires des marques de l'Alliance Renault-Nissan-Mitsubishi et nous veillons √† faciliter leur gestion au quotidien pour leur permettre de d√©velopper leurs ventes et assurer leur p√©rennit√© financi√®re.Notre entreprise se ""MOBILIZE"" en faveur de la diversit√© culturelle, l'√©galit√© hommes-femmes et l'int√©gration de personnes en situation de Handicap. Nous favorisons un environnement de travail o√π les diff√©rences individuelles sont reconnues, appr√©ci√©es, respect√©es et valoris√©es, de fa√ßon √† mettre √† profit les talents et les forces de chacun.üöòPrenez le volant ! Pas de routine, tous nos itin√©raires sont diff√©rents ! Au sein de la DSI, votre futur m√©tier consistera √† :Accompagner l‚Äô√©quipe dans la transformation du domaine d√©cisionnel construit sur une architecture type DWH et le porter sur la solution GCP (Google Cloud Platform) de Mobilize FSParticiper √† la construction du projet de transformation vers GCPParticiper aux projets d‚Äô√©volution de notre plateforme Suite Elastic (ELK - Kibana)Piloter des projets en √©troite collaboration avec les directions m√©tier et en accord avec le TBA (Tableau de Bord des Actions).Assurer la gestion du budget, du planning, de la tenue des jalons et du respect des engagements sur les projets en responsabilit√©Assurer la qualit√© et le bon fonctionnement du chargement des donn√©es.Assurer la mise √† disposition des donn√©es et des outils de reportings √† toutes les directions clientes dans le respect des contrats de service V√©ritable tout-terrain, vous nous int√©ressez ! L‚Äôesprit d‚Äô√©quipe et le sens du service client pour atteindre ensemble les diff√©rents objectifs ambitieux et satisfaire les diff√©rentes parties avec un haut niveau de qualit√©.Vous avez un bon relationnel, de l‚Äô√©coute et une excellente communication afin d‚Äôinteragir avec des interlocuteurs de diff√©rents niveaux (direction technique et m√©tier) et de travailler en transverse.Le sens de l‚Äôanalyse et de bonnes capacit√©s d‚Äôanticipation pour d√©celer les probl√®mes avant la naissance de ces derniers.Force de proposition : avec vous il n'y a pas de probl√®mes, que des solutionsVous avez un niveau d‚Äôanglais vous permettant de lire et de comprendre de la documentation techniqueüíªüñ± Environnement technique :Maitrise des langages Python - SQL / NoSQLExp√©rience significative sur PythonExp√©rience avec GitUne exp√©rience avec les outils Nifi, Airflow et GCP (BigQuery / Cloud Function / Cloud Storage ‚Ä¶) serait un plusGestion de projet, maintenance, √©volution, supportApp√©tence pour les sujets techniques et fonctionnels : outils de mod√©lisation, exploration de donn√©es, IA, machine learningPourquoi nous rejoindre ?Votre Pack confort est compos√© de nombreux avantages üòÄ :Rejoindre Mobilize Financial Services c‚Äôest int√©grer un grand groupe international qui offre des opportunit√©s de carri√®re.Un environnement de travail moderne et convivial : locaux agr√©ables, salle de sport, terrasse, restaurant d‚Äôentreprise, parking avec un CSE dynamique avec de nombreuses offres voyages, sport, famille,Nous sommes mobilis√©s pour d√©velopper la qualit√© de vie au travail de nos collaborateurs en faisant √©voluer nos fa√ßons de travailler (m√©thodes, outils, organisation du travail‚Ä¶) et nous sommes fiers d‚Äô√™tre certifi√©s ‚≠êGreat Place To Work ‚≠êPossibilit√© de t√©l√©travailler 2 jours par semaineNous proposons une r√©mun√©ration selon profil + Participation + Int√©ressement Locaux situ√©s au pied du RER A ‚Äì Noisy le Grand Mont d‚ÄôEst‚ùó Mobilize Financial Services d√©m√©nage ‚ùó Les postes √† pourvoir en r√©gion parisienne seront bas√©s √† Boulogne Billancourt √† horizon 2026Pour en savoir plus sur notre entreprise, suivez-nous sur LinkedIn !La route du recrutement ?üìû Un rapide entretien t√©l√©phonique,üõë un arr√™t au stand / un premier √©change avec Marie DE CARLI, Responsable du d√©partement DATA‚Ü™ et un dernier virage avec Tifaine GIBAUD, Responsale du d√©partement D√©veloppement des Comp√©tences L‚Äô√©quipe Mobilize FS a h√¢te de vous recevoir !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,INFOGENE,"Neuilly-sur-Seine, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-infogene-3809754535?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=C147VPkJ4vB7%2F1al%2BMcSJA%3D%3D&position=6&pageNum=5&trk=public_jobs_jserp-result_search-card,"Postuler √† cette offreSeul les CVs au format pdf sont accept√©sMessage d'erreur Partager sur : Neuilly-sur-Seine CDI Publi√©e il y a plus d'un jour+5ans d'exp√©rience demand√©eR√©mun√©ration :  50k √† 65k Description Du PosteEn tant que Data Engineer F/H vous aurez pour mission au sein de l'√©quipe technique de : Analyser les donn√©es (par origine, contrats, criticit√©s, ....) : fixer les priorit√©s et analyser les diff√©rents cas d'usage Etablir des TBB de suivi (par branche/usage/Typologie de clients) : Donner un reporting de suivi & un niveau de risque D√©tecter des doublons (pour √©viter de solliciter inutilement nos clients) : Baisser les couts, am√©liorer la performance Filtrer r√©guli√®rement les dataSets, de fa√ßon √† isoler les contrats r√©sili√©s : Ne pas solliciter nos ex-clientsIl/elle est aussi √† l'√©coute de nos interlocuteurs business avec qui il interagit constamment.Description Du ProfilDipl√¥m√©(e) d'une √âcole d'Ing√©nieur / Master Bac+5 en informatique, vous avez une exp√©rience significative en Data engineering / Data Science.Vous avez 5 ans d'exp√©rience minimum sur des projets en Data.Comp√©tencesDataTBBAgilit√©AssurancesCommunication
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer H/F,Devoteam Revolve,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-devoteam-revolve-3806790070?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=OXN3O1KwtZfFYKG30codmw%3D%3D&position=7&pageNum=5&trk=public_jobs_jserp-result_search-card,"About the jobEn constant mouvement, nous gravitons dans des √©cosyst√®mes hyper technologiques toujours en √©volution.Notre projet concr√©tise les r√©flexions sur le sens que nous souhaitons donner √† la technologie et notre volont√© de lutter contre les raccourcis intellectuels et de proposer des alternatives.Et pour cela, nous avons besoin de vous !Si vous √™tes int√©ress√©¬∑e d‚Äôint√©grer une √©quipe qui challenge ses pratiques et r√©v√®le les singularit√©s de chaque membre de notre collectif, alors cette annonce est faite pour vous !PROFIL RECHERCH√â :Envie de rejoindre une √©quipe de ‚Äúbuilders‚Äù qui travaillent sur de vrais projets de Data en production et √† l‚Äô√©chelle ? Vous √™tes au bon endroit !Vous avez au moins 2 ans d‚Äôexp√©rience sur des probl√©matiques de data engineering (construction de pipelines de donn√©es (batch/streaming), industrialisation d‚Äôapplications data science, mod√©lisation de base de donn√©es‚Ä¶) dans un context agileVous disposez de solides connaissances sur les architectures de donn√©es et les environnements cloud (GCP, Azure, AWS‚Ä¶)Vous disposez d‚Äôune exp√©rience en visualisation de donn√©es (PowerBI, Tableau, QlikView, D3.js‚Ä¶)Vous ma√Ætrisez au moins un langage de programmation sp√©cifique (Spark, Scala, Python, Java, SQL)Vous ma√Ætrisez des syst√®mes d‚Äôexploitation (UNIX, Linux, Solaris ) avec une expertise dans le stockage de donn√©es et les outils ETL.Vous avez une bonne culture DevOps, une bonne communication op√©rationnelle et une forte capacit√© d‚Äôadaptation.Vous √™tes conscient¬∑e de la valeur que peut apporter l'automatisation.Vous √™tes convaincue par la culture Data, Cloud, tech et souhaitez affirmer vos convictions.Vous cultivez votre savoir faire, et cherchez constamment de meilleures mani√®res de faire et votre volont√© de la partager avec les autres n‚Äôa pas de limite.L‚Äôorganisation, la rigueur, l‚Äôautonomie font partie de vos qualit√©s tout comme l‚Äô√©coute et le partage.Vous ma√Ætrisez √©galement l‚Äôanglais √† l‚Äôoral comme √† l‚Äô√©crit.DESCRIPTIFVoici une liste non exhaustive de vos missions au quotidien, nous vous faisons confiance pour les prendre en main et les enrichir √† votre fa√ßon :Participer √† des projets Cloud AWS (EC2, S3, Lambda, Redshift, EMR, Kinesis, DynamoDB, etc.) ou autres solutions h√©berg√©es sur une architecture AWS (Snowflake, Databricks, etc.)D√©velopper et automatiser des pipelines d‚Äôingestion de donn√©es avec des layers de traitement dans les technologies ad√©quates ( Python,, Spark, Kafka)Industrialiser des algorithmes de Data ScienceConcevoir des sch√©mas de donn√©es extensibles et g√©n√©riques pour r√©pondre √† des besoins de reporting ou autre (SQL)D√©velopper des applications custom sur la base de composants g√©n√©riques existants pour r√©pondre √† des besoins client (sc√©narisation, suivi d'entra√Ænement de mod√®les pr√©dictifs et d‚ÄôIA, reporting, etc.Encadrer et superviser les consultant(es) juniors i.e., peer code review, application des best practices.Accompagner notre √©quipe commerciale sur la r√©daction de propositions et des r√©unions d‚Äôavant-vente.Participer au d√©veloppement de notre communaut√© interne (REX, workshops, articles, hackerspace.Participer au recrutement de nos futurs talents.Comp√©tences techniques requises :La liste des technos sur lesquelles vous seriez amen√© √† travailler est la suivante :Python, PySpark ou Scala Spark. Scikit-learn, MLlib, Tensorflow, Keras, PyTorch ,LightGBM, XGBoost, Scikit-Learn et Spark (pour ne citer qu‚Äôeux)Les architectures Data et les environnements Hadoop, ElasticSearch, Kafka notamment.La stack AWS Big Data (Step Function, Lambda, ECR, S3, EC2, Code Build, Glue, outils d‚Äôautomatisation et Devops, EMR, Redshift, Athena)Mise en place des environnements DevOps et Infra As CodeUne bonne partie des outils Git, GitLab CI, Jenkins, Ansible, Terraform, Docker, Kubernetes, ML Flow, Airflow ou leurs √©quivalents dans les environnements Cloud.BON A SAVOIR :Revolve training est notre centre de formation permettant √† toutes et tous de pouvoir suivre des formations et monter en comp√©tence.Les Revolvers peuvent, au-del√† de leurs missions, contribuer √† Gravity, notre centre de recherche contributive qui explore les sujets li√©s √† la sobri√©t√© num√©rique, l‚Äô√©thique de la technologie, la souverainet√© num√©rique, le machine learning au service de l‚Äô√©cologie, ou tout autre projet susceptible de faire progresser la communaut√© et ses pratiques.Flexibilit√© : Le t√©l√©travail fait partie du quotidien des collaboratrices et collaborateurs.Une mutuelle attractiveLa possibilit√© de choisir son mat√©riel (mac, windows, linux, smartphone‚Ä¶).Une participation annuelle aux frais de transportsUne carte ticket restaurantOffre exclusive MeyclubCe qui fait la diff√©rence chez Devoteam Revolve, c'est notre fa√ßon de :Partager ouvertement, largement et d√©lib√©r√©ment les informations.Encourager les prises de d√©cision autonomes de la part des collaborateurs et collaboratrices.Ne collaborer sur le long terme qu'avec des collaborateurs et collaboratrices hautement comp√©tent¬∑es et ayant un impact positif sur le collectif.Toujours rechercher une ""meilleure fa√ßon"" de faire les choses.√ätre ouvert¬∑e d'esprit aux id√©es changeantes et aux approches nouvelles.Devoteam Revolve s‚Äôengage √† promouvoir la diversit√© et est fier de favoriser l‚Äô√©galit√© des chances au sein de l‚Äôentreprise. Chaque candidature est consid√©r√©e sans tenir compte de l‚Äôorigine, de la couleur de peau, de la religion, du genre, de l‚Äôidentit√© de genre, de l‚Äôorientation sexuelle, du handicap, des caract√©ristiques g√©n√©tiques ou de l‚Äô√¢ge.Parce que nous voulons que le savoir soit utile au plus grand nombre, nous croyons √† l‚Äôinclusion de toutes et tous.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': ['Scikit-Learn', 'TensorFlow', 'Keras', 'PyTorch', 'XGBoost', 'LightGBM'], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': ['Linux', 'Windows'], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer (H/F),METEOJOB by CleverConnect,"Nice, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3804860094?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=fpVpBgDE%2F3GV2bLUU30QsQ%3D%3D&position=8&pageNum=5&trk=public_jobs_jserp-result_search-card,"EntrepriseAdsearch vous propose des milliers d''opportunit√©s de carri√®res dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Int√©rim et Freelance sur notre site internet !Description Du PosteEn bref : Nice- CDI - Data Engineer Talend (F/H) - Salaire selon exp√©rience - T√©l√©travailAdsearch, cabinet de recrutement bas√© √† Nice vous accompagne dans votre carri√®re pour vous trouver LE poste id√©al.Je recrute pour un client un Data Engineer Talend (F/H) bas√© √† Nice.Vos MissionsCadre du besoin Impl√©mentation des solutions BI - TalendR√©daction des sp√©cifications techniques et fonctionnellesMod√©lisation des syst√®mes d√©cisionnelsOptimisation et monitoringDescription Du ProfilVotre profil ;Vous √™tes id√©alement titulaire d'un Bac+5 dans l'informatique Vous avez une premi√®re exp√©rience sur un poste similaire Talend n'a plus de secret pour vous ? Ce Que L'on Vous ProposeDes sujets challengeant Une super TeamLe Processus De RecrutementEtape 1 : Entretien de s√©lection avec Adsearch pour d√©finir vos objectifs de carri√®re et votre correspondance avec le posteEtape 2 : Entretien technique avec le clientEt c'est tout ! Pas d'entretien inutile, nous allons directement au but.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,Micropole,"Villeurbanne, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-micropole-3789104218?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=5kGYknX61p3tNBJZkR%2FMXg%3D%3D&position=9&pageNum=5&trk=public_jobs_jserp-result_search-card,"Rejoignez le Groupe Micropole. Devenez un(e) #InnovativePeople ! Mission En R√©sum√©Poste : Data Engineer F/H Secteur de l'entreprise : experts conseil dans les secteurs de la banque-assurance, le luxe-retail et l‚ÄôIndustrieLocalit√© : LyonType de contrat : CDI Niveau d‚Äôexp√©rience : au moins 3 ansVous √™tes passionn√©(e)s par la data ? Vous √™tes convaincus que l‚Äôoptimisation du patrimoine data des entreprises est la cl√© de leur performance ? Vous voulez rendre les entreprises data driven et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous √™tes au fait des derni√®res tendances et pr√™t √† explorer de nouveaux territoires ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?Si vous avez r√©pondu ¬´‚ÄØOui‚ÄØ¬ª √† chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l‚Äôindustrie/ services.Alors, pr√™t √† rejoindre l‚Äôaventure Micropole ? N‚Äôattendez plus !En Tant Que Data EngineerVous rejoignez notre entit√© Data Analytics bas√©e √† Lyon, o√π vous interviendrez sur l‚Äôint√©gralit√© de plusieurs projets avec une vision ¬´ Data 360¬∞ ¬ª, m√™lant Conseil, Architecture, Int√©gration et Data Science. En tant que Data Engineer, vous accompagnerez les directions m√©tiers dans l'√©valuation de l'efficacit√© de leur processus et dans leur strat√©gie pour optimiser leur performance. Vous serez rattach√©(e) √† l‚Äô√©quipe Data Analytics, compos√©e de 50 #InnovativePeople.Dans Vos Missions Quotidiennes, Vous Serez Amen√©sA comprendre le besoin de nos clients au travers de missions de type : aide aux choix d‚Äôoutils, cadrage des besoins, Proof Of Concept ;Accompagner les √©quipes commerciales sur des rendez-vous client et en phase d‚Äôavant-vente ;Recueillir et analyser les besoins et proposer une architecture technique adapt√©e aux cas d‚Äôusage des clients ;A r√©aliser nos projets de construction de Data Platform au travers des activit√©s : refonte, migration ou d√©veloppement de tableaux de bord dans le respect des exigences de qualit√© et s√©curit√© ; R√©diger la documentation des livrables pour rendre les utilisateurs autonomes et les former ;R√©diger la documentation permettant √† l'IT d'assurer la maintenance ;Accompagner les consultants moins exp√©riment√©s dans leur mont√©e en comp√©tence ;Capitaliser et partager les bonnes pratiques, connaissances et retours d‚Äôexp√©rience ; Profil Vos Comp√©tences TechniquesVous avez un minimum de 3 ann√©es d‚Äôexp√©rience sur des projets Data sur les outils ETL (Talend, SQL Server) et Reporting (Power BI, Tableau Software).Id√©alement au moins une premi√®re exp√©rience sur des projets Cloud AWS ou Azure Vous ma√Ætrisez au minimum un langage de programmation (Python, Spark, Scala, R)‚ÄØ; Vous avez une maitrise des th√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des concepts d‚Äôindustrialisation, Ia C, CI/CD et/ou gestion de version, Vos AtoutsV√©ritable co√©quipier, vous avez √† c≈ìur de contribuer √† la mont√©e en comp√©tence de votre √©quipe,Vous recherchez la vari√©t√© et l‚Äôexcellence dans votre travail. Autonome et impliqu√©(e), vous avez le go√ªt du challenge,Dot√©(e) d‚Äôun excellent relationnel et du sens du service, vous avez la capacit√© de g√©rer une relation client,Vous d√©velopperez votre cr√©ativit√© et votre curiosit√© gr√¢ce √† une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud et des solutions DataEnfin, vous disposez d‚Äôun bon niveau de fran√ßais et d‚Äôanglais, √† l‚Äôoral comme √† l‚Äô√©crit.Devenir #INNOVATIVE PEOPLE C‚Äôest :Int√©grer une communaut√© de 1100 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine.Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale.Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP.Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus.S‚Äôassurer d‚Äôune innovation continue gr√¢ce : notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients ; anagement par les talents naturels (regarder le mot de la DRH)Processus De RecrutementChez Micropole, le processus de recrutement est r√©actif et transparent.Etape 1 ‚Äì Si votre profil correspond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suivent votre candidature par Justine ou Nathan nos Talent Specialist d√©di√©s √† l'agence de Lyon pour une qualification t√©l√©phonique ;Etape 2 - Un premier entretien est programm√© avec Justine ou Nathan en physique ou visio ;Etape 3 ‚Äì Vous rencontrez Matthieu, un manager technique avec l‚Äôun de nos experts Data AnalyticsEn fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique)LA VIE CHEZ MICROPOLE, C‚ÄôestUne vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole ;Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles ;Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion ;Participation √† des projets internes sur la base du volontariat.√Ä PROPOS DU GROUPE MICROPOLEGroupe international de conseil et technologies innovantes, MICROPOLE est sp√©cialis√© dans les domaines de la Data & Digital. Depuis ses 14 agences situ√©es en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts m√©tiers, ing√©nieurs, UX designers‚Ä¶) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil √† leur r√©alisation, et sur la conduite du changement.MICROPOLE r√©alise 35% de son chiffre d‚Äôaffaires √† l‚Äôinternational et est cot√© sur le march√© Eurolist compartiment C d‚ÄôEuronext Paris, segment Next Economy.Pour en savoir plus :  https://www.linkedin.com/company/micropoleA PROPOS DE L'AGENCE MICROPOLE LYON L‚Äôagence Micropole Lyon s‚Äôappuie sur son implantation strat√©gique et son expertise technique pour porter et accompagner les ambitions de croissance du groupe Micropole. Sous l‚Äôimpulsion de notre Directrice d‚ÄôAgence, Armelle Descaillot, nous souhaitons cr√©er une synergie entre la data et le digital afin d‚Äôapporter une r√©elle valeur ajout√©e √† nos clients et les accompagner sur les d√©fis technologiques de demain.Les marques fortes du groupe telles que Wide (agence digitale int√©gr√©e au groupe Micropole) et Lucy in the Cloud (entit√© conseil du groupe Micropole d√©di√©e √† AWS) nous soutiennent et nous permettent de nous positionner comme acteur conseil de r√©f√©rence dans la r√©gion Centre-Est.V√©ritable agence √† taille humaine o√π r√®gnent esprit d‚Äô√©quipe et convivialit√©, nos talents allient savoir-faire et expertise pour r√©pondre aux besoins de transformation des entreprises.Mot du Manager En rejoignant notre agence Lyonnaise, vous b√©n√©ficiez de la puissance d‚Äôun groupe pionnier des grandes innovations data et digitales tout en int√©grant une √©quipe dynamique, bienveillante et √† taille humaine dont les valeurs de partage, le sens du service et de la convivialit√© sont les ma√Ætres mots. Qu‚Äôattendez-vous ?


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage - Data Engineer,Exotec,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-at-exotec-3764789933?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=xWF7OLR%2F73JXdpXS%2FcXHZw%3D%3D&position=10&pageNum=5&trk=public_jobs_jserp-result_search-card,"Chez Exotec, nous mettons l'excellence technologique au service de la red√©finition des relations entre humains et robots. A travers le monde, nos solutions r√©volutionnent la fa√ßon dont nos clients d√©livrent leurs produits aux consommateurs finaux. Nous contribuons au succ√®s des plus grandes marques du commerce et de l'industrie, tout en am√©liorant les conditions de travail de leurs salari√©s.Par l'alliance de l'intelligence artificielle et d'un hardware performant, nos robots sont d√©sormais d√©ploy√©s dans le monde entier et leur succ√®s a fait de nous la premi√®re licorne industrielle fran√ßaise.Rejoindre Exotec, c'est l'opportunit√© de donner du sens √† vos comp√©tences. Grandissez avec plus de 800 ExoPeople dans le monde entier pour faire de vos id√©es des r√©alit√©s.La r√©volution robotique port√©e par Exotec ne fait que commencer, vous en √™tes ?Au sein du p√¥le Data, de la DSI d'Exotec, votre r√¥le sera de participer au d√©veloppement de l'environnement et de l'infrastructure Data d'Exotec.Pour cela :Vous participez √† la mise en ≈ìuvre des composants techniques de la plateforme de donn√©es d'ExotecVous travaillez sur la collecte dans la plateforme de donn√©es provenant de sources multiples : Salesforce, ERP, logiciels d√©velopp√©s en interneVous nettoyez, mettez en qualit√© et pr√©parez les donn√©es afin de les rendre disponibles pour les diff√©rents cas d'usage qui en ont besoinVous migrez des reportings existants vers la plateforme de donn√©es et mettez en ≈ìuvre de nouveaux cas d'usage pour r√©pondre aux besoins de l'entrepriseVous travaillerez au sein de l'√©quipe data et en √©troite collaboration avec la software factory, ainsi qu'avec les utilisateurs des m√©tiers qui ont besoin de rendre intelligibles les donn√©es disponiblesRequirementsVous √™tes √©tudiant(e) d'une √©cole d'Ing√©nieur g√©n√©raliste avec une sp√©cialisation programmation ou informatiqueVous recherchez un stage de fin d'√©tudes d'une dur√©e de 4 √† 6 moisVous avez id√©alement une premi√®re exp√©rience en Data Engineering et le d√©veloppement de pipeline de donn√©esVous maitrisez Python, l'ETL et SQL,Curieux(se) et rigoureux(se), vous souhaitez rejoindre une √©quipe jeune et dynamique ainsi que vous investir dans des projets complexes et excitantsVous avez un niveau d'anglais courantChez Exotec, nous garantissons l'√©galit√© des chances dans notre processus de recrutement. L'ensemble des candidatures re√ßues sont √©tudi√©es ind√©pendamment de l'√¢ge, du genre, de l'origine, de la religion, de la couleur de peau, de la nationalit√©, du sexe, du handicap, de l'orientation sexuelle ou de toute autre distinction prot√©g√©e par la loi. Nous mettons en place un environnement de travail inclusif et respectueux de toutes les diff√©rences. En rejoignant le Pacte Parit√©, Exotec s'engage pour un √©cosyst√®me French Tech plus paritaire.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F (CDI ou Freelance),ATAWIZ,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-cdi-ou-freelance-at-atawiz-3807732290?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=EFQ0jRApwNKBUDDtFKiL6g%3D%3D&position=11&pageNum=5&trk=public_jobs_jserp-result_search-card,"Pour la petite histoire, Atawiz a √©t√© cr√©√© en 2016, pour devenir le cabinet d‚Äôexpertise que l‚Äôon conna√Æt aujourd‚Äôhui. Nous sommes Microsoft Solutions Partner dans plusieurs domaines de comp√©tences et partenaire Databricks. Les domaines d‚Äôexpertise d‚ÄôAtawiz s‚Äôadaptent aux nouveaux enjeux des entreprises : Time to Market, agilit√©, data, digitalisation des processus, ‚Ä¶Nos consultant¬∑e¬∑s combinent ainsi agilit√©, approche DevOps pour soutenir nos clients dans la r√©alisation de leurs objectifs, et ce, depuis 2016 !Au-del√† d‚Äôun groupe d‚Äôexpert¬∑e¬∑s, nous sommes des passionn√©¬∑e¬∑s qui collaborent dans diff√©rents domaines d‚Äôexpertise :Le Cloud, sp√©cialement AzureDevOpsLe Big DataLe d√©veloppement d‚Äôapplication mobile et webLes architectures micro-servicesAliment√©¬∑e par une forte culture d‚Äôentreprise, notre objectif est d‚Äôassurer la satisfaction de nos consultant¬∑e¬∑s autant que de celle de nos clients. Pour cela, nous s√©lectionnons avec attention nos projets pour que chacun de nos collaborateur¬∑rice¬∑s se sentent stimul√©(e)s et progressent rapidement.üìá Descriptif du posteNous avons de fortes demandes client et par cons√©quent besoin de renforcer notre √©quipe.L‚Äôaventure Atawiz, c‚Äôest aussi int√©grer une communaut√© d‚Äôune vingtaine d‚Äôexpert¬∑e¬∑s tous passionn√©¬∑e¬∑s. √Ä leurs c√¥t√©s, tu pourras √©voluer rapidement et d√©velopper de nouvelles comp√©tences.üéØMission propos√©e (longue dur√©e), en r√©gie chez notre client, grande entreprise du secteur de l‚Äô√©nergie (petite couronne ‚Äì proche Paris) :Freelance accept√©.En tant que Data Engineer H/F, tu seras rattach√©(e) au Responsable Data.üí° Enjeux du PosteAssurer le lead technique sur l‚Äôingestion, le chargement et la transformation des donn√©es dans la data plaform (Datalake, Datawarehouse)Mod√©liser et impl√©menter les diff√©rents flux de donn√©esParticiper √† l‚Äôurbanisation de l‚Äôarchitecture de la plateforme avec le Tech Leadüë©‚Äçüíª La r√©partition des t√¢ches :Pipelines de donn√©es :Mise en place et optimisation des processus.R√©f√©rent technique pour l'ingestion, le loading et la transformation de donn√©es.D√©finition technique du mod√®le de donn√©es.D√©veloppement :Pr√©paration des environnements techniques.D√©veloppement sur les assets selon les normes.Collaboration avec le support de la plateforme pour des expos en API.Ing√©nierie de donn√©es :Comp√©tences en mod√©lisation et cr√©ation de scripts.R√©flexions sur l'√©chelle, la disponibilit√© et l'optimisation des op√©rations.üíª Stack technique sur le projet :Cloud : AWS (id√©alement) ou AzureDEV : Python, API, Git, Docker,DevOps (Terraform, CI/CD),DATA (SQL, NoSQL, DBT), BIGDATA (HDFS, SPARK).Data Science (MLOPS),Notions : Scalabilit√©, Clustering, Data Mesh, Data Virt, Data Qualit√©, Analytique (Tableau, Dataiku).‚ú® Avantages de la mission :En acceptant cette mission, tu b√©n√©ficieras d‚Äôun environnement de travail motivant et coop√©ratif, o√π tu auras l‚Äôoccasion de t‚Äôimpliquer dans des projets diversifi√©s et challengeants.De plus, vous aurez des possibilit√©s d‚Äô√©volution de carri√®re.üîé Profil recherch√© :Passionn√©(e) de nouvelles technologies et proactif(ve), tu excelles en √©quipe dans un environnement dynamique. Ton engagement envers les meilleures pratiques et tes comp√©tences en communication font de toi la personne id√©ale pour cette mission.Tu as minimum 5 ans d‚Äôexp√©riences, une solide exp√©rience dans le domaine du data engineering en environnement cloud.Une exp√©rience sur le cloud AWS ou √©quivalent (Azure, GCP) est un plus.Ton esprit d'√©quipe, ta pro activit√© font de toi un(e) candidat(e) id√©al(e) pour renforcer l‚Äô√©quipe. Rejoins-nous ! üåüAvant d‚Äô√™tre en mission chez le client, tu es avant tout un(e) salari√©(e) d‚ÄôAtawiz üòä‚ú® La vie interne chez Atawiz:Chez Atawiz, les opportunit√©s sont nombreuses, nous valorisons ton expertise et ton savoir-faire. Tu auras la possibilit√© de :‚úÖ D√©velopper tes comp√©tences et pour √ßa, tu b√©n√©ficieras d'une formation approfondie, de coaching manag√©rial et technique, et d'un accompagnement pour obtenir des certifications. üìö‚úÖ Participer activement √† la vie interne de l'entreprise, en partageant tes connaissances et ton expertise au travers d'articles techniques publi√©s sur notre blog et √† notre page LinkedIn.üëâ notre blog : https://blog.atawiz.fr/üëâ page LinkedIn : https://www.linkedin.com/company/atawiz/‚úÖ Suivre en mission et √™tre garant de l‚Äô√©volution de carri√®re de consultants juniors.‚úÖ Participer au process de recrutement, pour tester techniquement les candidats ou proposer des cooptations de personnes de ton r√©seau.‚úÖ Profiter d'avantages attractifs, tels que des √©v√©nements Microsoft, des bootcamps et des workshops & tech coffees r√©guliers, un mat√©riel performant, et bien plus encore ! üéâBenefits:Salaire fixe entre 60k ‚Ç¨ et 65k ‚Ç¨ en fonction du profil pour un CDI Pour Freelance TJM entre 600 et 650 ‚Ç¨ / jourStatut cadreRTTTitre de transport pris en charge √† 100%Mutuelle Alan pris en charge √† 60 %La pr√©voyance prise en charge √† 100 %7 ‚Ç¨ de panier repas par jour travaill√©2 jours de T√©l√©travail /semaineBudget t√©l√©travailDe beaux locaux √† Paris 9e, proche de la gare Saint-LazareRejoins-nous d√®s maintenant dans nos bureaux situ√©s en plein c≈ìur de Paris üíº pour faire partie d'une √©quipe de passionn√©s, relever de nouveaux d√©fis et booster ta carri√®re. üöÄInt√©ress√©(e) ? Postule d√®s √† pr√©sent et d√©couvre notre processus de recrutement interactif. Tu auras l'occasion de rencontrer notre √©quipe, d'√©changer avec nos expert¬∑e¬∑s techniques, et m√™me de discuter avec notre CEO et notre Sales Director.ü§ù Notre processus de recrutement :1 - Postulez en ligne ! L‚Äô√©quipe Recrutement √©tudie avec attention ta candidature et te r√©pond dans les plus brefs d√©lais.2 - Premier √©change ! Tu √©changes avec notre Talent Acquisition Manager sur ton parcours, tes aspirations professionnelles ainsi que sur Atawiz et les opportunit√©s que nous proposons.3 - Un entretien technique avec l‚Äôun¬∑e de nos expert¬∑e¬∑s pour te challenger techniquement. C‚Äôest √©galement l‚Äôoccasion pour toi d‚Äôavoir son retour d‚Äôexp√©rience.4 - Dernier entretien : pour finir, tu rencontreras notre CEO. Tu pourras par ailleurs √©changer avec notre Sales Director.Pendant tout le processus de recrutement, tu as la possibilit√© de participer √† des √©v√©nements organis√©s par Atawiz et d‚Äô√©changer avec des collaborateurs afin d‚Äôen apprendre plus sur nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Stage - Data Engineer,Numberly,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-at-numberly-1000mercis-group-3800212725?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=Yi9RV2nuIE84TDXJ9oxlrQ%3D%3D&position=12&pageNum=5&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseNumberly est reconnu comme l‚Äôun des meilleurs sp√©cialistes mondiaux du Data Marketing avec pr√®s de 500 collaborateurs et 8 bureaux dans le monde au service de clients de premier plan (LVMH, BNP Paribas, Hill‚Äôs, Beneteau, L'Or√©al, Ipsen, Ouigo, Maje, HSBC...).En mettant la technologie au service des marques et des consommateurs, Numberly est au c≈ìur de la croissance des entreprises et de l‚Äôaspiration de chacun √† un marketing plus responsable et plus pertinent. Numberly s‚Äôappuie sur les avanc√©es les plus r√©centes en mati√®re de traitement, d‚Äôanalyse et d‚Äôactivation media et CRM des donn√©es, dans un contexte vertueux alliant comp√©titivit√© des entreprises et respect renforc√© de la vie priv√©e et de la protection des donn√©es.Nous analysons des sets de donn√©es comportementales, personnelles, contextuelles et transactionnelles, dans tous les environnements technologiques existants, et les articulons avec les enjeux business et digitaux de nos clients.Nous construisons chaque jour des strat√©gies data et marketing digital qui am√©liorent la pertinence et l‚Äôimpact des interactions de nos clients avec leurs audiences, en alimentant nos recommandations strat√©giques avec toute l‚Äôexpertise technologique, data, et op√©rationnelle du groupe.Description du posteNumberly recherche un(e) Data Engineer en stage pour rejoindre son √©quipe d√©di√©e aux probl√©matiques Data. Vous participerez aux traitements, transformations et restitutions des donn√©es aupr√®s des √©quipes internes afin d‚Äôam√©liorer les performances des campagnes et des strat√©gies marketing de nos clients.Vous :Aimez la donn√©e sous toutes ses formes : brute, travaill√©e et analys√©e ;Avez le d√©sir de la comprendre et de la faire parler ;Poss√©dez une formation ax√©e sur la big data, la fouille de donn√©es ou plus g√©n√©ralement en software engineering;Appr√©ciez le travail bien fait, avez le sens du d√©tail et vous aimez comprendre les probl√©matiques de vos clients ;Aspirez √† travailler pour des clients vari√©s et prestigieux sur des probl√©matiques pointues ;√ätes √† l‚Äôaff√ªt des nouveaux langages/technologies et des derni√®res tendances open source;√ätes spontan√©(e) et appr√©ciez le travail en √©quipe en collaborant avec diff√©rents m√©tiers de la data;Portez de l'int√©r√™t au Marketing et souhaitez d√©couvrir ce domaine.Stage de 6 mois d√©butant en f√©vrier 2024.R√©mun√©ration : 1400 ‚Ç¨ brut mensuel en M1 et 1700 ‚Ç¨ brut mensuel en M2.QualificationsVous connaissez :Mod√©lisationSQLPythonETLEncore mieux si vous connaissez :Workflows management platformsEnvironnement HadoopSyst√®mes et calculs distribu√©sAPI REST, Web ServicesRealtime / StreamingDockerCe que nous utilisons :UbuntuSuite Microsoft (SSMS, SSIS, SSRS, Power BI)HdfsSpark / HiveGit / CICDAirflowKafkaKubernetesInformations compl√©mentaires Chez Numberly, nous partageons une passion pour la transmission √† nos √©quipes comme √† nos clients : des talks internes hebdomadaires, des rencontres avec des professionnels experts dans leur domaine, un apprentissage permanent.Un onboarding rapide et puissant, notamment gr√¢ce aux Vis ma vie dans des √©quipes diff√©rentes ; aux Happy Meetings (des rendez-vous mensuels internes pour se retrouver avec toutes nos √©quipes dans le monde et partager l‚Äôactualit√© du groupe).Nous cultivons la libert√© de parole qui permet √† tous de participer au d√©veloppement du groupe.Nous agissons positivement sur notre √©cosyst√®me √† travers 1000mercis impacts et via nos activit√©s qui cr√©ent de la valeur dans l‚ÄôOpen Internet et participent √† l‚Äôenrichissement de l‚ÄôOpen Source : https://github.com/numberlyNumberly est acteur de la diversit√© et Gender Equal by design (certification WeConnect International et gender equity score de 97/100).Numberly propose un environnement international avec plus de 30 nationalit√©s.Des bureaux √† l‚Äôimage de chacune des √©quipes, une biblioth√®que g√©n√©reuse, un grand studio de musique tout √©quip√©, deux chats, du tri s√©lectif et du lombricompostage, la possibilit√© de venir avec votre animal de compagnie et de la place pour les v√©los ! Dans chaque cuisine : caf√©, th√©, infusions √† volont√© et aussi des mystery lunchs.Un abonnement Gymlib, des cours de sport et des soir√©es (souvent d√©guis√©es).Pour ceux qui en auraient besoin, possibilit√© de travailler en remote pendant la p√©riode des Jeux Olympiques.Carte Swile (titres-restaurants).Numberly accueille les personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer (H/F),Extia,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3627654825?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=kaSFdbhd%2By4s1xdiHx8BYA%3D%3D&position=13&pageNum=5&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez Extia !Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e depuis 2012 par le label Great Place to Work¬Æ.Chez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !D'abord quiVous √™tes habitu√© √† travailler aussi bien avec des m√©ta-donn√©es qu‚Äôavec des donn√©es non-structur√©es. A cet effet vous maitrisez un ou plusieurs des concepts comme l‚ÄôETL, le Data mining le Machine learning, les Big data ou encore la Th√©orie des graphes par exemple,Vous maitrisez les bases de l‚Äôanalyse statistique,Vous √™tes apte √† r√©diger des scripts en Python et/ou R, et une connaissance d'autres langages de programmation comme Java, Scala ou SAS est un plus,Vous √™tes familiaris√© avec l‚Äôenvironnement Linux,Une exp√©rience avec les outils de Stockage de fichiers volumineux (HDFS, Data Lake, S3, stockage Blob), la connaissance des infrastructures cloud AWS ou GCP et des bases en streaming temps r√©el seront aussi de r√©els atouts.Ensuite quoiVous serez en charge de :Participer √† la d√©finition des besoins et √† la r√©daction des User Stories,Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e,Concevoir et construire des architectures de donn√©es,Int√©grer des sources de donn√©es,Vous assurez que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives,Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Ops Data Engineer,Anywr,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/cloud-ops-data-engineer-at-anywr-3798641032?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=j325C70W6JcUQHgoxerblQ%3D%3D&position=14&pageNum=5&trk=public_jobs_jserp-result_search-card,"Notre client, acteur majeur mondial dans l'industrie, recherche un Cloud Ops Data Engineer pour la cr√©ation de leur Data Factory. Ce poste est bas√© √† Marcq-en-Bar≈ìul. T√©l√©travail 2 jours / semaine.Le Cloud Ops Data Engineer participera √† la construction et √† la maintenance d'une plateforme de services de donn√©es bas√©e sur une approche de maillage de donn√©es. Ce poste fera partie de la Data & Tech Factory et sera rattach√© au responsable de l'architecture et de l'ing√©nierie des donn√©es. Il/elle sera responsable de la conception, de l'architecture, du d√©veloppement et de la maintenance de notre plateforme de services de donn√©es en mettant l'accent sur l'automatisation, l'infrastructure en tant que code et les pratiques DevOps.Votre quotidien :Concevoir, d√©velopper et maintenir une plateforme de services de donn√©es qui prend en charge une approche de maillage des donn√©es en utilisant les principes de l'infrastructure en tant que code.Collaborer avec les √©quipes de d√©veloppement des donn√©es pour int√©grer les services num√©riques et de donn√©es dans la plateforme.Concevoir et mettre en ≈ìuvre des solutions d'automatisation pour la configuration, l'approvisionnement et la surveillance de la plateforme √† l'aide d'outils et de pratiques DevOps tels que Ansible, Terraform et GitOps.Mettre en ≈ìuvre des pipelines d'int√©gration et de d√©ploiement continus (CI/CD) pour les services de donn√©es.Identifier et r√©soudre les probl√®mes de performance de la plateforme √† l'aide d'une surveillance et d'alertes automatis√©esMettre en place des processus pour surveiller l'√©tat de la plateforme et avertir les √©quipes de support en cas de dysfonctionnementCollaborer avec les √©quipes de s√©curit√© informatique pour s'assurer que la plateforme r√©pond aux normes de s√©curit√© et mettre en ≈ìuvre les principes de s√©curit√© en tant que code.Cr√©er et maintenir la documentation et les manuels d'ex√©cution pour assurer la r√©silience de la plateforme et la reprise en cas de d√©faillance.Profil recherch√© :Baccalaur√©at ou ma√Ætrise en informatique, en g√©nie informatique, en science des donn√©es ou dans un domaine connexe.Au moins 4 ans d'exp√©rience professionnelle dans un environnement de donn√©es distribu√©es et Cloud native avec un fort accent sur l'automatisation, l'infrastructure en tant que code, et les pratiques DevOps.Bon niveau d'anglais souhait√©.Comp√©tences techniques :Connaissance approfondie des architectures de donn√©es distribu√©esSolide exp√©rience dans la conception et le d√©veloppement de solutions de donn√©es distribu√©es √† grande √©chelle en utilisant l'infrastructure en tant que code et les principes DevOps.Connaissance approfondie des technologies de donn√©es bas√©es sur le cloud (AWS est un plus).Exp√©rience de travail avec des outils de gestion de conteneurs tels que Kubernetes et Docker (EKS, ECS).Connaissance des technologies de stockage de donn√©es (Snowflake, NoSQL, S3)Solides comp√©tences en programmation dans un ou plusieurs langages de programmation, dont au moins Python.Exp√©rience de travail avec des bases de donn√©es relationnelles et non relationnelles (Postgresql, Cassandra, MongoDB, RDS, DynamoDB).Connaissance des pratiques de s√©curit√© des donn√©es et des normes de conformit√©Solides comp√©tences en mati√®re de d√©pannage et de r√©solution de probl√®mesCe poste est un CDI chez un client final.Vous int√©grerez une entreprise en croissance avec des projets ambitieux.Vous aurez l'occasion d'√™tre force de proposition, de construire votre poste.De plus, l'environnement de travail sera propice √† votre bien-√™tre : salle de sport, restaurant d'entreprise, conciergerie, cr√®cheSalaire fixe : 50 - 60K‚Ç¨Salaire variable : 5 √† 10% sur objectif personnel + 20% de participation


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Senior Data/SW Engineer | Up to 65k | Paris | IA | ML,Talent-R,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-sw-engineer-up-to-65k-paris-ia-ml-at-talent-r-3797676756?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=AWpZHFQP9qOvSV85ipsGSQ%3D%3D&position=15&pageNum=5&trk=public_jobs_jserp-result_search-card,"üìçLocalisation: Paris (20√®me) & Remote (2 jours sur site / semaine)üîç Seniorit√©: Interm√©diaire (+3 ans)üí∞ Salaire : Up to 65K‚Ç¨ fixe + Variable + BSPCEL'entreprise üíº Startup fran√ßaise de 30 personnes qui propose un produit SASS pour aider les commercants √† optimiser leur rentabilit√© en utilisant l‚ÄôIntelligence Artificielle et le Machine LearningVotre profil üëâEntre le data engineer et le d√©veloppeur, vous aimez d√©velopper en python et manipuler de la data, vous r√©vez de faire partie d'une entreprise en pleine croissance !Exp√©rience > 3 ans dans un environnement de haut niveauEnglish MandatoryPython (biblioth√®ques Pandas/Dask)Frameworks : FastAPIBases de donn√©es : PostgreSQL (base de donn√©es relationnelle)Containers et orchestration : Docker Les plus : Linux, AS3, bash, sparkLes avantages üòçBureaux en plein de coeur de Paris (20√®me)Remote : 3 jours par semaine au d√©but puis f√©xibilit√© totale ensuiteSalaire jusqu‚Äô√† 70k (+variable)BSPCEBien plus √† d√©couvrir...Si vous √™tes interess√©, je vous invite √† postuler et √† m'envoyer un message si vous avez des questions !Merci de ne pas postuler si vous avez -3 ans d'√©xperience professionnelle et si vous n'avez pas cette double comp√©tences Data / Software.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Bash'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Docker'], 'Os': ['Linux'], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Ing√©nieur Data H/F,LA BOITE IMMO,"Hy√®res, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-at-la-bo%C3%AEte-immo-3803477031?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=xuZLFuILcOiWWuVAu609qA%3D%3D&position=16&pageNum=5&trk=public_jobs_jserp-result_search-card,"√Ä propos de nousLa Boite Immo - le 1er partenaire des agents immobiliers ind√©pendants partout en France.Depuis 15 ans, nous d√©veloppons des applications web (logiciels, sites internet, solutions de visites virtuelles...) innovantes et modernes utilis√©es par plus de 59000 utilisateurs. Pionn√© dans notre secteur nous sommes constamment en qu√™te d'innovation pour garantir la satisfaction de nos clients.Notre √©quipe, compos√©e de plus de 200 personnes r√©parties entre nos sites de Hy√®res et Paris, travaille ardemment pour stimuler notre croissance. De nouveaux projets naissent constamment, ce qui fait de notre entreprise un lieu d'opportunit√©s et d'√©volution continue.Nous recherchons des collaborateurs qui veulent donner un v√©ritable sens √† leur travail, int√©grer une entreprise o√π l'aventure humaine est au c≈ìur de ses pr√©occupations.En 2023, nous avons obtenu le label Happy Index, avec une note de 4,6/5, d√©montrant l'importance que nous accordons au bien-√™tre de nos employ√©s.Si vous √™tes √† la recherche d'une mission enrichissante et d'une entreprise qui favorise votre progression, nous vous invitons √† d√©couvrir l'opportunit√© ci-dessous.MissionAu sein de notre service R&D et rattach√©(e) au Directeur de l'innovation, vous serez en charge du montage des architectures techniques sur nos donn√©es m√©tier et march√©.Vos missions si vous les acceptez seront les suivantes :Structurer, mod√©liser et organiser les donn√©es afin de r√©pondre aux diff√©rents use-cases m√©tiers : Vous mettez en ≈ìuvre les solutions techniques et les pipelines data n√©cessaires pour mod√©liser au mieux les donn√©es m√©tier et march√© de notre soci√©t√©R√©aliser les croisements, raffinages et structurations de donn√©es pour la construction et le maintien des data marts et et data warehouseParticiper avec l'√©quipe du data management √† la mise en place d'ETLProduire des DataViz pertinentes donnant du sens aux donn√©es r√©colt√©esR√©aliser des √©tudes et des analyses ponctuelles sur des donn√©es silot√©es des diff√©rents p√¥les m√©tiersProfilVous √™tes issu(e) d'une formation Bac+5 sp√©cialis√©(e) en informatique ou en data engineering et vous justifiez d'une exp√©rience de 5 ans sur un poste similaire.Vous √™tes d√©sireux de relever des d√©fis multiples autour de l'architecture de donn√©es dans un contexte technologique riche et innovant.Pour r√©ussir √† ce poste, nous recherchons les comp√©tences suivantes :Connaissances confirm√©es sur Azur, Python, Power Bi, Talend ETLExp√©rience significative dans la mod√©lisation de donn√©es, des entrep√¥ts de donn√©es et des processus ETLDes notions en PHP et S3 seront fortement appr√©ci√©esExcellentes comp√©tences en communication et capacit√© √† expliquer des concepts techniques complexes √† des parties prenantes non techniquesEn nous rejoignant, voici concr√®tement ce que nous vous proposons : Une r√©mun√©ration fixe comprise entre 40k‚Ç¨ et 50k‚Ç¨/an en fonction de votre exp√©rienceUn contrat de 35h sur 4.5 joursUne prime de participationUne formation et une int√©gration qui vous permettront de r√©ussirDes s√©minaires de dingue! des ap√©ros, des soir√©es guinguettes, de la p√©tanque, du miel de nos abeilles, des fruits de producteurs locaux, la salle de sport ton alli√© pendant la saison des raclettes et tartiflettes.. etcLes in√©vitables tickets restaurants, mutuelle, CE..Termin√© les process de recrutement √† rallonge, nous proposons des √©changes simples et efficaces :A r√©ception de votre CV, Charlyne notre charg√©e de recrutement prendra contact avec vous pour discuter de votre projetVous √™tes retenu(e) ? Un premier entretien visio avec Jull, Directeur du pole R&D est organis√©L'√©change est positif ? Un deuxi√®me et dernier entretien vous est propos√© dans nos locaux afin de rencontrer Arnaud DSI de la Boite Immo et Carine Responsable RHvous avez un retour rapide qu'il soit positif ou n√©gatif dans les jours qui suivent l'entretien !R√©f√©rence de l'offre : cdrwvujz9m
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Data Engineer (H/F),Believe,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-believe-3773594947?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=RXlw7c4uFupf9rhoAZSrHA%3D%3D&position=17&pageNum=5&trk=public_jobs_jserp-result_search-card,"Company DescriptionBelieve est l'un des leaders mondiaux du march√© de la musique num√©rique. Believe a pour mission d‚Äôaccompagner les artistes et les labels locaux dans l‚Äô√©cosyst√®me digital en leur offrant des solutions √† chaque √©tape de leur carri√®re et d√©veloppementCe sont plus de 1700 salari√©s dans 50 pays qui accompagnent artistes avec expertise, respect, √©quit√© et transparence.Afin de soutenir notre forte croissance sur tous les continents, nous sommes constamment √† l‚Äôaff√ªt de nouveaux Believers. Rejoignez-nous afin qu‚Äôensemble, nous ayons un impact fort et plus positif sur l‚Äôindustrie musicale‚ÄØ!Believe est cot√©e sur le compartiment A du march√© r√©glement√© d‚ÄôEuronext Paris (Ticker : BLV, ISIN : FR0014003FE9).www.believe.comReady to #setthetone with Believe?Job DescriptionContexte Le Tribe ¬´‚ÄØCustomer Finance‚ÄØ¬ª est compos√© de plusieurs Squad, parmi elles la squad‚ÄØFinance Ingestion qui a pour mission de d√©velopper des outils et des applications pour la collecte de royalties aupr√®s des plateformes de streaming de musique ainsi que pr√©parer les donn√©es afin de faire la distribution des royalties aupr√®s des producteurs de musiques.En tant que Data Engineer, tu int√©gras une √©quipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette √©quipe est compos√©e essentiellement de 5 Data Engineer et 1 Software Engineer. Nous avons un √©cosyst√®me qui se composeune socle de gestion des donn√©es (Delta Lake) plus d‚Äô1.5 milliard de lignes /mois data engineering avec du Scala Spark utilisant le runtime de Databricks orchestration de nos data pipelines avec Airflow manag√© des APIs avec les Lambda AWS pour faire interagir les utilisateurs avec notre interface front (PHP) RDS pour hoster la base de donn√©es back-end sous PostgreSQL versionning du code sous GitLab avec un environnement de dev, staging et production infrastructures sous AWS Les missions du Data Engineer au sein de l‚Äô√©quipe : ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Interagir avec le Product Owner, le m√©tier‚ÄØpour comprendre les besoins‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Interagir avec l‚Äôarchitecte, les √©quipes infrastructures et Cloud pour concevoir les solutions de data engineering‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ D√©velopper des flux de donn√©es (data pipelines) avec du Apache Spark et du Scala‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Faire de l‚Äôorchestration via Airflow avec du Python‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Maintenir et am√©liorer les modules existants de l‚Äôapplication‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Utiliser GitLab pour tester, builder et d√©ployer son code sur les diff√©rents environnements‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Effectuer des revues de codes des autres membres de l‚Äô√©quipe‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Interagir avec les membres de l‚Äô√©quipe pour atteindre l‚Äôobjectif du sprint‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Faire du support applicatif et fonctionnel de l‚Äôapplication aupr√®s des op√©rationnelQualificationsQualifications du Data Engineer  3-5 ans d‚Äôexp√©rience dans la pratique de d√©veloppement sous Scala une tr√®s bonne maitrise du framework Spark avec du Scala, nous ne faisons pas de PySpark une bonne maitrise de conception et d√©veloppement des data pipelines D√©velopper avec un √©tat d‚Äôesprit Keep it Simple, Stupid (KISS) une bonne maitrise d‚Äôun outil de versionning de code tel que Gitlab une bonne maitrise des APIs avec du Lambda une exp√©rience dans l‚Äô√©cosyst√®me AWSAdditional InformationSet the tone with us Chez Believe, nous avons deux c≈ìurs : nos collaborateurs et nos artistes.Nous croyons en la force de nos collaborateurs, qui s'√©panouissent chaque jour en d√©veloppant leur potentiel... Notre objectif est d'offrir √† nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'√©panouir.Rock the jobProgramme de formation et de coaching sur mesureUne politique de t√©l√©travailUn programme de bien-√™tre ""Pauses"" avec de nombreuses activit√©s et animations en interneAcc√®s √† Eutelmed, la plateforme num√©rique de sant√© mentale et de bien-√™tre qui permet de parler √† un psychologue exp√©riment√©Un restaurant d'entreprise sain et √©co-responsableUne assurance sant√© individuelle ou familialeAvantages CEUn rooftopUne salle de sport avec des cours gratuitsSing in harmonyDes groupes d'ambassadeurs pour s'engager sur la r√©duction de l'empreinte carbone et environnementale de Believe et l‚Äô√©quit√© professionnelle Femme/Homme.Mise en place du Forfait mobilit√© durable: remboursement jusqu‚Äô√† 600‚Ç¨ des frais de transport en commun/avec une faible empreinte carbone.Cong√© 2nd parent de 5 jours calendaires r√©mun√©r√©s √† 100% (en plus du cong√© l√©gal paternit√© ou du cong√© d‚Äôadoption, nous ne l‚Äôattribuons pas au cong√© maternit√©)Believe s‚Äôengage √† garantir l‚Äô√©galit√© des chances en mati√®re d‚Äôemploi, sans tenir compte de l‚Äôorigine, du sexe, des m≈ìurs, de l‚Äôorientation sexuelle, du genre, de l‚Äô√¢ge, de la situation de famille, de l‚Äô√©tat de grossesse, d‚Äôune pr√©tendue race, des opinions politiques, des activit√©s syndicales, des convictions religieuses, de l‚Äôapparence physique, du nom de famille, du lieu de r√©sidence, de l‚Äô√©tat de sant√©, ou en situation de handicap.D√©couvrez nos nouveaux locaux : bit.ly/believeoffice
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),METEOJOB by CleverConnect,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3805816901?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=JtSgG7DyhkyMe9nAiKb%2F0Q%3D%3D&position=18&pageNum=5&trk=public_jobs_jserp-result_search-card,"EntrepriseChez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L'intelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d'une centaine de disciplines, de l'optique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l'intelligence artificielle. Rejoindre Thales, c'est repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C'est donc √™tre au c≈ìur d'une formidable aventure technique. Une attention port√©e √† l'√©quilibre des collaborateurs au service de leur r√©ussite. C'est pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d'accorder la flexibilit√© n√©cessaire √† l'√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C'est aussi la possibilit√© d'√©voluer, de changer de fonction ou d'activit√©, voire de pays.Description Du PosteQUI SOMMES-NOUS ?Thales propose des syst√®mes d'information et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d'importance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d'information critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l'utilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l'activit√© Syst√®mes d'information critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d'information afin de faire face aux ruptures technologiques et aux cybermenaces.QUI ETES-VOUS ?Int√©gr√©(e) au centre de comp√©tences ¬´ Augmented Data ¬ª de Brest, vous interviendrez sur des projets de d√©veloppement de syst√®mes d'information ¬´ Data oriented ¬ª.Au sein de ce centre, vous rejoindrez nos Data Engineers, Data Architects et Data Scientists.De formation Ing√©nieur ou Bac +5, Ecole d'ing√©nieur ou Universit√© vous justifiez d'une exp√©rience professionnelle en mise en place de solutions Big Data d'au moins 2 ans et id√©alement d'une premi√®re exp√©rience r√©ussie en animation d'√©quipe et/ou pilotage de lots techniques.Comp√©tencesPlusieurs des affirmations suivantes vous caract√©risent : Vous √™tes passionn√©(e) par le Digital, les donn√©es, les enjeux qu'elles repr√©sentent et les technologies Big Data avec lesquelles les manipuler (Hadoop, Nifi, Kafka, ElasticSearch, Spark, Storm, HBase, Cassandra, etc.). Vous √™tes familiaris√©(e) avec les diff√©rentes plateformes et outils qui y sont reli√©s. Vous savez et aimez coder avec des langages de programmation commun√©ment utilis√©s pour la manipulation de donn√©es (Python, Java, SQL) sur des architectures distribu√©es en production. Vous savez impl√©menter des cha√Ænes de traitement optimis√©es. Vous √™tes familiaris√©(e) avec les concepts et technologies d'int√©gration continue (Git) et les outils de d√©ploiement (Docker). Vous √™tes familiaris√©(e) avec les frameworks Agile tels que Scrum ou Kanban. Vous √™tes motiv√©(e), appliqu√©(e), organis√©(e) et curieux(se) dans votre travail au quotidien. Vous √™tes titulaire d'un dipl√¥me d'ing√©nieur ou Master, id√©alement avec une sp√©cialisation sur les m√©tiers de la donn√©e et du Big Data. Vous parlez fran√ßais et, id√©alement, anglais (√©crit et oral)Ce Que Nous Pouvons Faire EnsembleEn tant que Data Engineer, vos missions seront les suivantes : Comprendre les besoins et les enjeux du client autour de ses donn√©es. Concevoir des solutions innovantes de traitement de donn√©es r√©pondant aux besoins, impl√©menter des cha√Ænes de traitements Big Data et les d√©ployer √† l'√©chelle dans des environnements de production. Contribuer √† la d√©finition d'architecture de donn√©es et √† l'op√©rationnalisation de plateformes de donn√©es. Pr√©senter vos propositions de conception et r√©sultats aupr√®s du client et de votre √©quipe. Partager et √©changer vos connaissances et exp√©riences dans le Data Engineering avec votre √©quipe. Contribuer √† la pr√©paration et √† l'animation d'ateliers avec les interlocuteurs requis. Effectuer un reporting r√©gulier √† votre manager sur l'avancement de vos activit√©s ainsi que sur les risques potentiels identifi√©s.Nous Vous Offrons Une diversit√© de projets vous permettant de d√©couvrir plusieurs environnements techniques et fonctionnels ainsi que l'ensemble de nos m√©tiers au sein du groupe Thales, Des conditions de travail motivantes et un plan de carri√®re personnalis√© offrant de r√©elles perspectives d'√©volution, La possibilit√© de vous investir dans une entreprise dont la r√©putation est mondiale avec des ambitions constantes d'innovations techniques, Un cadre de travail privil√©gi√© dans des bureaux situ√©s √† un endroit dynamique du port de commerce de Brest, La possibilit√© de t√©l√©-travailler jusqu'√† 10 jours par mois.Alors n'attendez plus, rejoignez-nous !Thales reconna√Æt tous les talents : la diversit√© est notre meilleur atout.Le poste pouvant n√©cessiter d'acc√©der √† des informations relevant du secret de la d√©fense nationale, la personne retenue fera l'objet d'une proc√©dure d'habilitation, conform√©ment aux dispositions des articles R.2311-1 et suivants du Code de la d√©fense et de l'IGI 1300 SGDSN/PSE du 09 ao√ªt 2021.Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd'hui.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer R&D (M/F),Atos,"√âchirolles, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-r-d-m-f-at-atos-3765788780?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=9wTDUoWPWzdGez20p%2B4q%2Fg%3D%3D&position=19&pageNum=5&trk=public_jobs_jserp-result_search-card,"Eviden is an Atos Group business with an annual revenue of circa ‚Ç¨ 5 billion and a global leader in data-driven, trusted and sustainable digital transformation. As a next generation digital business with worldwide leading positions in digital, cloud, data, advanced computing and security, it brings deep expertise for all industries in more than 47 countries. By uniting unique high-end technologies across the full digital continuum with 55,000 world-class talents, Eviden expands the possibilities of data and technology, now and for generations to come.Our team is building Eviden CVP (https //atos.net/fr/solutions/bullsequana-edge-fr/atos-computer-vision-platform) , a real-time video analytics platform for different verticals (security, retail, ‚Ä¶). We use AI technologies to design and develop the product, as well as Big Data software components to manage the related data. We currently recruit in our European AI lab in Grenoble a data engineer to complete our team on data governance, end-to-end data pipeline implementation and datalake operation.Key Responsibilities Contribute to data / model governance policies definition and implementation. Set up and develop our computer vision data management platform (implement full data pipeline including data collection, data proliferation, meta-data extraction leveraging AI models, integrate 3rd party tools such as labeling framework, ‚Ä¶) Operate the data platform Follow our internal quality & security standards for code development. Automatize everything (devops, mlops). Work with an international team.Required Skills MS in data science or computer science. Experience in data engineering and big data project Hand on experience in SQL/NoSQL database (eg. Elastic) and communication frameworks. Strong coding skills (Python). Deployment of machine learning based project Practice of agile methodology Practice of software engineering (devops, mlops) Practice of Linux environment. Excellent communication skills and the desire to work in a dynamic and collaborative environment Must be eager and able to learn quickly and to improve.Desirable Skills Appetite for AI & computer vision Experience in AI Engineering tool eg kubeflow, MLFlow, FiftyOne, Cvat etc Experience in docker, Restful API Experience in cloud platform (eg GCP)Location  EchirollesLet‚Äôs grow together.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer,DAHER,"Bouguenais, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-at-daher-3798420301?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=1qcB9168wZVmxHun1Ubnuw%3D%3D&position=20&pageNum=5&trk=public_jobs_jserp-result_search-card,"Vous avez envie de FAIRE DECOLLER votre carri√®re ?Nous recherchons notre futur(e)Data EngineerType de contratCDIPr√©sentation de l'emploiPour accompagner notre d√©veloppement et renforcer notre √©quipe, nous recherchons un(e) DATA ENGINEER, en CDI. Vous serez rattach√©(e) au Responsable de Centre Informatique DATA, √† Nantes sur le centre d'innovation Shap'IN. Vous serez garant de l‚Äôacc√®s qualitatif aux sources de donn√©es.Pr√©sentation de DaherNous sommes avionneur et √©quipementier pour l'industrie et le service et nous affirmons notre leadership dans 3 principaux m√©tiers - construction d'avions, √©quipements et syst√®mes a√©ronautiques, services logistiques et supply chain.Fiche de PostePlus pr√©cis√©ment, vous vous assurez de la ma√Ætrise de la donn√©e et √™tes garant de la qualit√© de son utilisation (r√©f√©rencement, normalisation, et qualification) afin d‚Äôen faciliter l‚Äôexploitation par les √©quipes (Data Analysts et Data Scientists).Vous contribuez √©galement √† la d√©finition de la politique de la donn√©e et √† la structuration de son cycle de vie dans le respect des r√©glementations en vigueur, en collaboration avec l'Architecte Data. Votre p√©rim√®tre d‚Äôintervention est ax√© sur les syst√®mes applicatifs autour de la gestion et traitement de la donn√©e sur les plateformes PAAS et on-premise (Azure, Snowflake, Databricks et SQL Server[SSIS])Enfin, vous assurez la supervision et l‚Äôint√©gration des donn√©es de diverse nature qui proviennent de ces sources multiples et v√©rifie la qualit√© des donn√©es qui entrent dans le Lakehouse.Pour r√©sumer, votre r√¥le cl√© au sein de l‚Äô√©quipe sera de :Construire des solutions d'int√©gration des donn√©es (structur√©es et non structur√©es).Travailler dans des √©quipes pluridisciplinaires informatiques et op√©rationnellesStructurer la donn√©e (s√©mantique, etc.)Cartographier et documenter les solutionsMaintenir / superviser les solutions (incidents, doublons, flux bloqu√©s...)Accompagner les key users dans l'exploitation de la plateformePoste ouvert √† un profil junior ou post-doc, pas √† l'alternance.Ce poste est pour vous l'opportunit√© de travailler au sein d'une √©quipe exp√©riment√©e en Data Engineering, avec des technologies de pointe (Snowflake, Databricks), sur des projets d'envergure et sur des th√©matiques diverses (Aircraft, Industrie a√©ronautique, Logistique et Service Industriel, transverses...), en recherche et d√©veloppement ou pour la production.Titulaire d'un Bac+5 en √©cole Informatique ou √©quivalent, vous justifiez d'une exp√©rience probante en tant que Data Engineer, id√©alement dans un environnement industriel.Vous maitrisez les technologies : SQL, ETL(s), d√©veloppement reporting PowerBI, SSIS, Microsoft Azure, SQL Server, Databricks, Snowflake, PySpark, analyse et mod√©lisation de donn√©es, m√©thodes de d√©veloppement Agile...Motiv√©(e), dynamique et dot√©(e) d'un grand sens de l'adaptabilit√© et de l'√©coute, vous vous int√©ressez autant au m√©tier de l'utilisateur final qu'√† la solution technique que vous devez lui produire. Vous maitrisez l'anglais (lu, parl√©, √©crit, nos documentations sont √† produire en Anglais).Postulez et rejoignez-nous chez DAHER Shap'IN √† proximit√© directe de Nantes, centre d'excellence et d'innovation Industrielle.Allez-vous OSER l'aventure avec nous ?Venez nous rejoindre et lib√©rez votre potentiel !


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Extia,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-extia-3675382393?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=0%2Be%2BPhtjW3o%2FVQv%2F1qPtwQ%3D%3D&position=21&pageNum=5&trk=public_jobs_jserp-result_search-card,"Vous souhaitez rejoindre une entreprise qui place l‚Äôhumain au c≈ìur de ses pr√©occupations ? On vous attend chez Extia !Soci√©t√© de conseil sp√©cialis√©e dans les m√©tiers de l‚ÄôIT, de l‚Äôing√©nierie et du digital, Extia privil√©gie depuis sa cr√©ation en 2007 une approche qui allie performance et bien-√™tre au travail. Une vision de l‚Äôentreprise partag√©e aujourd‚Äôhui par plus de 2 500 Extiens en France et √† l'international et r√©compens√©e depuis 2012 par le label Great Place to Work¬Æ.Chez Extia, c‚Äôest ¬´ D‚Äôabord qui, ensuite quoi ¬ª alors, allons-y !D'abord quiRigoureux, vous ne laissez rien au hasard,Efficace, vous ne remettez pas √† demain ce qui peut √™tre fait d√®s aujourd‚Äôhui,Autonome, vous savez mener vos missions √† bien sans aide.Ensuite quoiVous aurez le r√¥le de support technique aux √©quipes d‚Äôanalyse : structurer les donn√©es, r√©aliser des analyses ¬´ statistiques ¬ª ou ¬´ techniques ¬ª sur les donn√©es, d√©velopper des outils d‚Äôanalyse‚Ä¶Vous m√®nerez des √©tudes afin d‚Äô√©valuer les nouvelles technologies dans le domaine du Big Data, Data Mining ou Machine Learning afin d‚Äôidentifier les solutions les plus pertinentes.Vous serez en charge de :Participer √† la d√©finition des besoins et √† la r√©daction des User Stories,Collaborer avec les Data Scientists au d√©veloppement des modules d‚Äôanalyse de donn√©e,Concevoir et construire des architectures de donn√©es,Int√©grer des sources de donn√©es,S'assurer que les donn√©es sont facilement accessibles et que leur exploitation fonctionne comme demand√©, m√™me dans des circonstances hautement √©volutives,Ex√©cuter des processus ETL (extraire / transformer / charger) √† partir d'ensembles de donn√©es complexes et / ou volumineux.Profil recherch√© :Maitrise de l‚Äô√©cosyst√®me Microsoft Azure Data Factory, Azure Data Lake est un plusMaitrise Technologie autour de la data : Power BI, Spark, Airflow, Python, Scala‚Ä¶Maitrise des bonnes pratiques de d√©veloppement et m√©thodes agilesBase de donn√©es : SQL, Postgr√© SQL (Paas) et mod√©lisation de la donn√©eConnaissance des syst√®mes de gestionnaire de conteneur (Kubernetes,...)Connaissance des outils de d√©ploiements : Jenkins, Git, maven, AnsibleQualit√©s relationnelles et capacit√© √† g√©rer nombreuses interactionsDynamisme, autonomie et envie de d√©couvrir des mani√®res diff√©rentes/innovantes de faire


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Hub Python Data Engineer H/F,Jobs via eFinancialCareers,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-hub-python-data-engineer-h-f-at-jobs-via-efinancialcareers-3799927545?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=263T2FSwO58rO61nQxGszA%3D%3D&position=22&pageNum=5&trk=public_jobs_jserp-result_search-card,"M√©tier :Production et infrastructureExp√©rience :2 ans minimumA propos...ADD UP est une ESN (Entreprise de Services Num√©riques). Elle est n√©e en 2001 de la rencontre de jeunes entrepreneurs, issus de grandes √©coles fran√ßaises, dont Polytechnique et HEC, et form√©s dans les grands cabinets de consulting. N√©e d'une passion pour les nouvelles technologies, l'√©quipe d'ADD UP propose des prestations de conseil √† forte valeur ajout√©e √† ses clients. Ses domaines de comp√©tence : les services informatiques et le consulting pour la finance de march√©.Description :Au sein des √©quipes de notre client dans le secteur bancaire, vous devrez contribuer aux d√©veloppements de workflows en python au sein de l'√©quipe DataHub Core Platform.vos missions seront : Participer √† diff√©rents projets Data au sein de l'√©quipe Participation au projet DQF (Data Quality Framework) Participation au projet Data Lineage D√©veloppement des modules python communs qui seront utiles √† tous les projetsProfil recherch√© :De formation Bac+5, vous avez une premi√®re exp√©rience sur un poste similaire.Date de d√©marrage :Asap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Scientist - Machine Learning Engineer,Phealing,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-scientist-machine-learning-engineer-at-phealing-3802114905?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=j3nCSet%2FHWKxR1xyCAV%2F5Q%3D%3D&position=23&pageNum=5&trk=public_jobs_jserp-result_search-card,"Poste √† pourvoir : Data Scientist / ML EngineerExp√©rience demand√©e : 3 ans et +üìç Lyon (Part Dieu)üí¨ Qui sommes-nous¬†?CreÃÅeÃÅ en 2019, Phealing est le premier outil d‚Äôaide aÃÄ la dispensation en officine capable de preÃÅvenir instantaneÃÅment le pharmacien en cas de risque meÃÅdicamenteux pour son patient.Notre IA m√©dicale permet le croisement instantan√© des donn√©es de la dispensation avec le profil physiopathologique du patient et les informations du m√©dicament.Notre mission : mettre l‚Äôinnovation technologique au service du comptoir de l‚Äôofficine pour seÃÅcuriser le pharmacien et son patient face au risque pharmacologique et reÃÅglementaire de la dispensation.¬†‚öôÔ∏è Descriptif du poste : Au sein de l‚ÄôeÃÅquipe technique (5 ‚Äì 10 personnes), vous interviendrez sur des missions varieÃÅes depuis la conception de prototypes jusqu‚ÄôaÃÄ leur impleÃÅmentation et suivi en production.Apr√®s plusieurs ann√©es de R&D, Phealing a construit et exploite en production des mod√®les √† l‚Äô√©tat de l‚Äôart pour l‚Äôextraction d‚Äôinformation √† partir de documents m√©dicaux. Vous b√©n√©ficierez ainsi de cette expertise et √™tes amen√©(e) √† la renforcer afin d‚Äôenrichir les mod√®les actuels et en cr√©er de nouveaux.Fort(e) de votre maiÃÇtrise du langage PYTHON, vous travaillerez eÃÅgalement sur l‚ÄôameÃÅlioration ou la conception d‚Äôheuristiques.Pragmatique et arm√©(e) d‚Äôune solide connaissance en IA (NLP en particulier) vous serez capable d‚Äôexp√©rimenter des nouvelles id√©es innovantes !¬†üéØ Vos missions :Conception / am√©lioration des mod√®les de machine learning / deep learningContribution √† l‚Äô√©laboration des datasets, finetuning selon les besoinsImpl√©mentation et d√©ploiement des fonctionnalit√©s li√©es √† l‚ÄôIA ou la data, impl√©mentation Python dans le respect des bonnes pratiquesV√©rification des contraintes de mise en productionSuivi des indicateurs de performances, analyses des anomaliesPrototyping, √©tudes, ou collecte de donn√©esContribution √† la planification et la construction de la feuille de route¬†‚ùìInformations compl√©mentaires : > Poste bas√© √† Lyon (proche Gare Part Dieu) ; possibilit√© de t√©l√©travail partiel> Comp√©tences : NLP, Python, Prototyping> Exp√©rience en ML/DS : > 3ans> Disponibilit√© poste : d√®s Mars 2024Vous pouvez √©galement postuler √† : candidature@phealing.fr


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer H/F,MERITIS,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3775391196?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=EEm%2BiBUYZNs4cvU8J2xMuQ%3D%3D&position=24&pageNum=5&trk=public_jobs_jserp-result_search-card,"Descriptif de l‚Äôentreprise et du poste :Meritis est un cabinet de conseil, pilotage et d√©veloppement IT fond√© en 2007 pr√©sent √† Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bient√¥t sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d‚Äôavance.‚ÄãNous accompagnons nos clients dans l‚Äôint√©gralit√© de leurs besoins en transformation num√©rique √† travers de nombreux domaines d‚Äôexpertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybers√©curit√© ou encore Agilit√©.‚ÄãIntervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des T√©l√©communications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.‚ÄãFort de nos valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, nous comptons aujourd‚Äôhui plus de 900 collaborateurs.‚ÄãNous mettons un point d‚Äôhonneur √† √™tre proche de nos collaborateurs et √† les accompagner de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise. Certifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.‚ÄãLes missions qui vous attendent :Data Engineer pour la construction d‚Äôun entrep√¥t de donn√©es DatalakeLe DataHub est un centre d‚Äôexpertises de la donn√©e qui a vocation √† faciliter les usages de la donn√©e par les diff√©rentes fonctions m√©tiers (pilotage commercial, marketing, actuariat, finance et risque, etc.). Il est compos√© de deux √©quipes :‚Ä¢ Le DataLab regroupant les Data Scientists en charge des prototypes IA,‚Ä¢ Les Feature Team Data anim√©es par un Product Owner et regroupant les Data Analyst / Data Engineer travaillant en amont et en aval des prototypes sur la construction d‚Äôenablers data sur le Datalake et leur mise √† disposition via des vues m√©tiers. Il y a actuellement 2 FT et celles-ci travaillent en agile (Scrum).La prestation du Data Engineer contribuera √† d√©velopper sur notre Datalake les mod√®les de transformation de la donn√©e ; en partant des donn√©es brutes d√©vers√©es depuis nos silos de gestion il devra mettre en oeuvre l‚Äôensemble des r√®gles de transformation m√©tier pour raffiner la donn√©e et la rendre exploitable, compr√©hensible, reconnaissable par les diff√©rentes directions m√©tier.Ainsi, au sein de la FT, les principales activit√©s du Data Engineer seront les suivantes :‚Ä¢ Participe aux c√©r√©monies de la FT (daily, affinage, sprint planning),‚Ä¢ Assure les d√©veloppements sp√©cifiques pour contribuer √† la production du Datamart et des vues utilisateurs‚Ä¢ R√©alise des tests unitaires et d‚Äôint√©gration‚Ä¢ Garanti la maintenabilit√© et les performances des programmes d√©velopp√©s‚Ä¢ Maintien √† jour la documentation‚Ä¢ Apporte un regard critique sur la production du Datamart au regard du m√©tier de l‚ÄôassuranceComp√©tences techniques demand√©es :‚Ä¢ Langage SQL : Expertise‚Ä¢ Technologie HADOOP (Spark, Hive principalement) : Expertise‚Ä¢ D√©veloppement objet (JAVA) : Expertise‚Ä¢ Gestion de source (Git) : Expertise‚Ä¢ Connaissance en mod√©lisation de la donn√©eCe poste est uniquement ouvert √† du CDI.Devenir collaborateur Meritis c‚Äôest :‚Äã¬∑ Des parcours professionnels sur mesure (√©volution de carri√®re, formations adapt√©es, mentoring‚Ä¶) ;‚Äã¬∑ Avoir le choix de sa mission et un accompagnement personnalis√© tout au long de votre carri√®re ;‚Äã¬∑ Evoluer dans un environnement o√π l‚Äôapprentissage est favoris√© : formations certifiantes, e-learning, meetUp, concours de code, parcours d‚Äô√©volutions etc ;‚Äã¬∑ Faire partie de communaut√©s d‚Äôexperts qui partagent leurs savoirs et exp√©riences au sein de nos centres de comp√©tences ;‚Äã¬∑ Un environnement convivial avec de nombreux √©v√©nements festifs (soir√©e annuelle, s√©minaires & teambuiding, d√©jeuners et afterworks‚Ä¶) ;‚Äã‚ÄãMeritis est engag√©e dans la Responsabilit√© Soci√©tale des Entreprises. Nous valorisons notre impact positif sur la soci√©t√© et l'environnement. Notre d√©marche RSE guide chacune de nos actions pour promouvoir l'√©quit√©, la durabilit√© et le bien-√™tre de nos collaborateurs. Rejoignez-nous pour √™tre partie prenante de cette d√©marche responsable, o√π chacun de nos talents contribue √† construire un avenir meilleur.Nos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis s'implique en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - DUNKERQUE (H/F),Capgemini Engineering,Greater Dunkerque Area,https://fr.linkedin.com/jobs/view/data-engineer-dunkerque-h-f-at-capgemini-engineering-3806443084?refId=60y02oAIuhUjDjey0WxoLg%3D%3D&trackingId=hUP79CnCrH02JDvbdWFbKA%3D%3D&position=25&pageNum=5&trk=public_jobs_jserp-result_search-card,"CAPGEMINICapgemini, qu'est-ce que cela √©voque pour vous ? Pour nous, c'est une success story √† la fran√ßaise ! Celle d'une startup devenue une r√©f√©rence mondiale en mati√®re de conseil et de services informatiques.Leader de la convergence des mondes physique et virtuel, nous agissons en partenaire de nos clients industriels pour concevoir, mettre en ≈ìuvre, s√©curiser et d√©manteler des produits et infrastructures complexes. Nous participons √† la transformation et √† l‚Äôoptimisation des entreprises de demain.Capgemini Engineering est la marque du groupe Capgemini r√©unissant les services d‚Äôing√©nierie et de R&D. On accompagne la convergence des mondes physique et num√©rique. Conjugu√©e avec l‚Äôensemble des capacit√©s du Groupe, elle aide les entreprises √† acc√©l√©rer leur transformation vers l‚ÄôIntelligent Industry. Capgemini Engineering compte plus de 52 000 ing√©nieurs et scientifiques dans plus de 30 pays, dans des secteurs tels que l‚Äôa√©ronautique, l‚Äôautomobile, le ferroviaire, les communications, l‚Äô√©nergie, les sciences de la vie, les semi-conducteurs, les logiciels et l‚ÄôInternet, le spatial et la d√©fense, et les biens de consommation.VOTRE MISSIONVous int√©grez l‚Äô√©quipe Digital Engineering de Capgemini Engineering, en tant que Data Engineer, vous participez √† un projet chez notre client dans le secteur de la sid√©rurgie. Vous √™tes responsable de :Concevoir et d√©velopper des solutions pour la collecte, l'organisation, le stockage et la mod√©lisation des donn√©esGarantir l'acc√®s aux diff√©rentes sources de donn√©es et de maintenir la qualit√© des donn√©es. Veiller √† ce que les analystes de donn√©es et les data scientists de l'entreprise puissent acc√©der facilement aux donn√©es et les exploiter dans des conditions optimalesContribuer, sous la supervision op√©rationnelle de notre architecte, aux meilleures pratiques, aux normes, aux politiques, aux m√©thodes, aux outils et aux proc√©dures li√©s au Cluster Big DataContribuer √† la mise en place d'une politique de donn√©es conforme aux r√©glementations en vigueurAssurer une veille technologique, notamment sur les langages de programmation utilis√©s afin d‚Äôaider √† l'avancement des projetsCE QUE NOUS RECHERCHONSVous √™tes Ing√©nieur(e) ou titulaire d'un dipl√¥me √©quivalent de niveau bac+5 en informatique ou en sciences des donn√©es. Vous voulez commencez votre carri√®re dans les technologies du Big Data.Vous poss√©dez certaines de ces comp√©tences suivantes : Hive, HDFS, Kafka, Talend, SQL Server, Framework Spark, Datalake ‚Äì Cloudera. Vous avez une bonne compr√©hension des infrastructures et des outils n√©cessaires pour le traitement des donn√©es, ainsi qu'un esprit d'√©quipe associ√© √† d'excellentes comp√©tences en communication.Vous avez √©galement la capacit√© √† vous int√©grer dans des projets et des √©quipes existantes dans un contexte de transformation.Alors, rejoignez Capgemini et choisissez le futur qui vous ressemble !CAPGEMINI, entreprise handi accueillante, conform√©ment √† la norme AFNOR NF X50-783, est √©galement signataire de la charte de la diversit√© en entreprise


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer CDI H/F,Mediaperformances,"Courbevoie, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cdi-h-f-at-mediaperformances-3806468738?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=DuMN2HjZGEXvXkcznetB3Q%3D%3D&position=1&pageNum=6&trk=public_jobs_jserp-result_search-card,"Le leader de l‚ÄôActivation shopper omnicanal. Le premier partenaire de mon√©tisation de la data et des m√©dias de tous les retailers alimentaires fran√ßais.Depuis plus de 35 ans, nous aidons les marques de grande consommation √† d√©velopper leurs ventes dans les enseignes de la grande distribution alimentaire. Nous mettons en place des campagnes publicitaires √† destination des shoppers pour influencer leur comportement d‚Äôachat.Depuis plusieurs ann√©es, nous avons pris un r√©el virage sur le digital, √† travers des m√©dias shopper data centric et data driven. Nous avons un patrimoine data activable significatif sur ce march√© avec une part consid√©rable de cette data en propri√©taire.Suite √† diff√©rentes cr√©ations et acquisition, le groupe M√©diaperformances, couvre des m√©dias omnicanaux, aussi divers que la programmatic, les avis clients, l‚Äôactivation mobile, le drive ‚Ä¶ et bien entendu l‚Äôin store.VOTRE MISSION : Au c≈ìur de cette strat√©gie d‚Äôacc√©l√©ration digitale, le Data Engineer H/F aura un r√¥le central. Vos principales missions seront de : Participer √† la conception et √† la construction de notre plateforme de donn√©esConstruire des pipelines de donn√©es en ayant recours √† diff√©rentes technologies et langages (Python, Sql, Beam ‚Ä¶)Assurer la qualit√© des donn√©es collect√©es, pr√©parer et optimiser le stockage et le chargement,Travailler de pair avec nos data scientists pour optimiser la performance de nos projets et d√©velopper de nouveaux cas d‚ÄôusageAssurer et am√©liorer le monitoring des diff√©rents flux d√©j√† existants en mettant en place des processus d‚Äôautomatisation et d‚ÄôindustrialisationD√©finir des KPIs et cr√©er des tableaux de bord de co√ªt et d‚Äôutilisation Vous serez amen√© √† collaborer avec diff√©rents services dans l‚Äôentreprise : La DSI, les d√©veloppeurs de nos filiales, le trading desk, ainsi que des partenaires ext√©rieurs retailer et GAFAM‚Ä¶Vous serez sous la responsabilit√© du Data Engineer senior, direction Data & Etudes.   VENEZ RELEVER LE CHALLENGE D‚ÄôETRE LE PREMIER MAILLON D‚ÄôUNE EQUIPE DATA EN DEVENIR ! Votre profil :  Vous √™tes passionn√©(e) par le domaine de l‚Äôinformatique et la data et avez d√©j√† une premi√®re exp√©rience sur des enjeux data engineering et big data sur un environnement cloud. Les probl√©matiques retail, marketing client ne vous sont pas √©trang√®res. Vous √™tes dipl√¥m√©s d‚Äôun minimum BAC +5 d‚Äôune √©cole d‚Äôing√©nieur ou d‚Äôun master dans un domaine connexe √† la big data & informatique.Vous √™tes Automne et rigoureux.Vous savez vous adapter (notamment pour assurer la gestion multi projet) et faites preuve de curiosit√©.Votre exp√©rience :Vous justifiez d‚Äôau moins 2 ans d‚Äôexp√©rience sur des probl√©matiques de data engineering (construction de pipelines de donn√©es (batch/streaming), industrialisation d‚Äôapplications data science, mod√©lisation de base de donn√©es‚Ä¶)Vous √™tes certifi√© et/ou avez une premi√®re exp√©rience sur l‚Äôenvironnement cloud GCP (Bigquery, GCS, GCE, Cloud run, data proc, Pub/Sub‚Ä¶ )Vous avez de solides comp√©tences en Python, SQLVous avez une bonne connaissance des processus et outils de d√©veloppement modernes (DevOps, Git, CI/CD‚Ä¶) ;Vous pratiquez les m√©thodes agiles dont Scrum.Les plus : Vous ma√Ætrisez Javascript, le d√©veloppement d‚ÄôAPI,Vous utilisez les outils DBT ou Dataform,Une premi√®re exp√©rience en visualisation de donn√©es d√©montr√©e sur au moins un outil : Datastudio / Looker, PowerBI, Tableau‚Ä¶Vous avez travaill√© dans des contextes √† tr√®s forte volum√©trieM√©diaperformances s‚Äôengage dans l‚Äôinsertion des personnes en situation de handicap et traite l‚Äôensemble des candidatures dans le respect des grands principes de non-discrimination.Join the team !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer / GCP (H/F),Micropole,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-h-f-at-micropole-3706045967?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=i1HCgBjlH35yorj9iIf%2B7w%3D%3D&position=2&pageNum=6&trk=public_jobs_jserp-result_search-card,"Rejoignez le Groupe Micropole. Devenez un(e) #InnovativePeople ! Mission En R√©sum√©Poste : Data Engineer / GCPLocalit√© : Levallois-PerretType de contrat : CDINiveau d‚Äôexp√©rience : au moins 3 ansVous √™tes passionn√©(e)s par la data ? Vous √™tes convaincus que l‚Äôoptimisation du patrimoine data des entreprises est la cl√© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous √™tes au fait des derni√®res tendances et pr√™t √† explorer de nouveaux territoires ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?Si vous avez r√©pondu ¬´‚ÄØOui‚ÄØ¬ª √† chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.Alors, pr√™t √† rejoindre l‚Äôaventure Micropole ? N‚Äôattendez plus !Au sein de notre agence bas√©e √† levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions m√©tiers dans l'√©valuation de l'efficacit√© de leur processus et dans leur strat√©gie pour optimiser leur performance.Dans vos‚ÄØ missions quotidiennes , vous serez amen√©(e) √†‚ÄØ:D√©velopper et maintenir des cas d‚Äôusages clients avec les outils et les infrastructures Big Data / Cloud GCP. Mod√©liser et analyser des donn√©es dans le Cloud. Garantir la s√©curit√© / compliance des donn√©es‚ÄØ; Apporter votre r√©flexion sur des probl√©matiques m√©tiers √† travers l‚Äôexploitation et la compr√©hension des donn√©es. Identifier les sources de donn√©es les plus pertinentes et restituer des r√©sultats de fa√ßon concise et visuelle‚ÄØ; R√©aliser une veille technologique pour √™tre √† la pointe sur les solutions cloud & Data‚ÄØ; Participer au d√©veloppement de notre centre d‚Äôexcellence GCP.  Profil Vos Comp√©tences TechniquesVous avez un minimum de 3 ann√©es d‚Äôexp√©rience sur des projets Data dont au moins une sur des projets Cloud GCP (Compute, Stockage), ou √† d√©faut une certification GCP avec l‚Äôambition de vous pr√©parer √† d‚Äôautres. Vous ma√Ætrisez au minimum un langage de programmation (Spark, Scala, Python, Java ou R)‚ÄØ; Vous avez une maitrise des th√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des outils et framework d‚Äôindustrialisation, IaC, CI/CD et/ou gestion de version, Vos AtoutsVous √™tes passionn√©(e), rigoureux(se), curieux(se) et √† l‚Äô√©coute‚ÄØ; Vous avez un bon niveau d‚Äôanglais qui vous permet d‚Äôintervenir sur des projets √† dimension internationale‚ÄØ; Vous d√©velopperez votre cr√©ativit√© et votre curiosit√© gr√¢ce √† une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud GCP et des solutions Data. Devenir #INNOVATIVE PEOPLE C‚Äôest :Int√©grer une communaut√© de 1200 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine.Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale.Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP.Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus.S‚Äôassurer d‚Äôune innovation continue gr√¢ce √† : notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients ; notre management par les talents naturels.Processus De RecrutementChez Micropole, le processus de recrutement est r√©actif et transparent.Etape 1 ‚Äì si votre profil correspond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suivent votre candidature par Dimitri notre Talent Specialist. Une qualification t√©l√©phonique ou physique est organis√©e rapidement avec Dimitri ;Etape 2 - Un premier entretien est programm√© avec Dimitri en physique ou visioEtape 3 ‚Äì Vous rencontrez un manager technique avec l‚Äôun de nos experts.En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique)LA VIE CHEZ MICROPOLE, C‚ÄôestUne vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole ;Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles ;Une politique de formation attractive et √©clectique (certifications prises en charge) ;Un travail en √©quipe valoris√© pour une meilleure coh√©sion ;Participation √† des projets internes sur la base du volontariat.Comp√©tencesGCP Big Query


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,Aix-Marseille University,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-aix-marseille-universit%C3%A9-3784236181?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=Htc%2BBIsDTrNJO7CijPqZvQ%3D%3D&position=3&pageNum=6&trk=public_jobs_jserp-result_search-card,"Et si vous rejoigniez une structure en pleine mutation vers l‚Äôuniversit√© de demain ?Au premier rang des universit√©s fran√ßaises et francophones, Aix-Marseille Universit√© (AMU) regroupe 78 000 √©tudiants, 8 000 personnels, 122 structures de recherche en lien avec les plus grands organismes dans ce domaine et un budget de 720 M‚Ç¨. 5 grands campus accueillent les √©tudiants et tous les champs universitaires qu‚Äôil est possible d‚Äô√©tudier en France. La diversit√© des sites permet de proposer aujourd‚Äôhui des opportunit√©s de carri√®re uniques. Aix-Marseille Universit√© fait partie de l'alliance CIVIS pour la cr√©ation des ""Universit√©s Europ√©ennes"". Aix-Marseille Universit√© recrute et reconnait tous les talents, ses offres d'emplois sont handi-accessibles.AMU en vid√©o : https://youtu.be/7-Hrtn-l2QkMissionLe data Engineer travaillera au sein de la Direction du Num√©rique (DirNum) sous la responsabilit√© du directeur du p√¥le ¬´ Logiciels de gestion ¬ª. Il fera √©quipe avec les data analysts du service de la Direction du Pilotage et du Contr√¥le de Gestion (DPCG) pour l'installation, la mod√©lisation, la construction et la maintenance des entrep√¥ts de donn√©es.En Tant Qu'Ing√©nieur De Bases De Donn√©es, Il Sera En Charge De La Mise En Place Et Du D√©veloppement D'un Entrep√¥t De Donn√©es (projet SIROCCO)Extraction, uniformisation et structuration des donn√©es clientsCollecter, s√©lectionner et valider les donn√©es pertinentes pour l'analyse en collaboration avec les data analysts et les experts m√©tiers. D√©finir les solutions de stockage et la structuration des donn√©es.Convertir, coder et cartographier des donn√©es de consommation ou d'usage produit dans un format compr√©hensible par l'ensemble des utilisateurs.D√©terminer les outils et m√©thodes d'acquisition de donn√©es depuis un ensemble de bases techniquement h√©t√©rog√®nes.Concevoir l'architecture d'un entrep√¥t de donn√©es d√©cisionnels (Data Warehouse). Ma√Ætriser la qualit√© des donn√©es tout au long de leur traitement.D√©veloppement d'outils de support aux clients internesParticiper √† la mise en ≈ìuvre de la strat√©gie de pilotageParticiper au d√©veloppement des indicateurs de performance de l'universit√©.Animer les ateliers d'expression des besoins internes et r√©diger les cahiers des charges. √âcrire et r√©diger les sp√©cifications de besoinsFormer les utilisateurs aux outils informatiques et d√©cisionnels.Veille technologique sur les outils de dataminingEffectuer une veille sur les nouvelles et solutions logicielles d'analyse des donn√©es. Rechercher et exp√©rimenter de nouvelles m√©thodes de mod√©lisation et d'analyse des donn√©esS√©lectionner les nouveaux outils et techniques de data management.ProfilComp√©tences Cl√©sMa√Ætrise des outils d'ETL et notamment TalendExcellente ma√Ætrise des bases de donn√©es relationnelles (Oracle Database, Postgresql, Mariadb) et connaissance des bases de donn√©es no-SQL Maitrise du langage SQLTr√®s bonne connaissance de la conception d'entrep√¥ts de donn√©esVous avez l'esprit d'analyse, et faites preuve d'une grande rigueurVous avez le sens de la communication et du serviceLes Avantages AMU Participation aux frais de transports en commun sur l'ensemble du territoire d√©partemental T√©l√©travail possible jusqu'√† 2 jours/semaine, selon les n√©cessit√©s et l'organisation du service √† partir de 6 mois d‚Äôanciennet√© Une prime au-del√† des 12 mois d‚Äôanciennet√© pour les agents non titulaire Selon votre rythme de travail, b√©n√©ficiez jusqu‚Äô√† 50 jours de cong√©s d√®s la premi√®re ann√©e puis 58 jours au bout d‚Äôun an Participation Mutuelle √† hauteur de 15‚Ç¨ /mois Des offres loisirs, sport et culture pour tous les agents L‚Äô√©tablissement conventionn√© par le FIPHFP (Fonds pour l'Insertion des Personnes Handicap√©es dans la Fonction Publique) Possibilit√© d‚Äôacc√®s √† un emplacement parking √† proximit√© Forfait mobilit√© durable pour l‚Äôutilisation d‚Äôun cycle sur les trajets domicile-travail Parcours d‚Äôaccueil et d‚Äôint√©gration pour les nouveaux agents


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Analytics Data engineer - internship,Equativ,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/analytics-data-engineer-internship-at-equativ-3798611608?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=6IVyFmLVKnaNVsoROTv0uQ%3D%3D&position=4&pageNum=6&trk=public_jobs_jserp-result_search-card,"Your mission: Helping the company be fully data-driven is not just a buzzword, it is our mission at Equativ. We, the Data Analytics team at Equativ, maximize efficiency by enabling easy and permanent access to quality data, valuable insights & rigorous thinking. Our responsibility is to ensure our local and central teams, clients and partners, make informed business decisions. To do so, we leverage huge volumes of data (Equativ handles 150Bn Auctions per Day) in a state-of-the-art tech stack (AirFlow, Snowflake, Tableau‚Ä¶) in order to provide actionable insights to all teams at Equativ!What you'll do : Reporting to the manager of the Analytics team, your mission will be to maintain and upgrade our data pipeline.Day-to-day maintenance of our data pipeline: Ensure data pipeline ingestion accuracy in due timeFollow-up on data quality issues raised by internal customersImprovement of sourcing processes:Migrate from Talend data flows to Python scripts for our sourcing jobsDevelop resources to make Data Analysts autonomous in sourcing data in our Snowflake database (through ready-to-use scripts or small interfaces)Developing new projects on our main platforms (Tableau & Snowflake)Leverage new resources to make the most out of Snowflake (Streamlit, Snowpark‚Ä¶)Identify new ways to structure our data sources in Tableau while reducing the loading time for the userParticipate in the restructuring of our data marts (schemas, stages & permissions)Communication:Sync with Data Analysts to make sure that their requests are properly prioritizedSynchronize with other technical teams (Core-Data, Infra) to gather requirements of the migration and ensure a smooth transitionUnderstand business needs to suggest the most efficient technical solution.About you:Pragmatic & hands-on mindset is required: you‚Äôll have latitude to explore different options, but you need to go for the most effective solutionTechnical knowledge of Python & SQL is a must.Knowledge of collaboration platforms (Gitlab) & Agile processes is a plus.You can demonstrate your ability to solve problems end to end.You are fluent in English.üëã About us Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.Come and lead the charge with us in building a transparent ecosystem based on quality!----------------------Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Capital Fund Management (CFM),"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-capital-fund-management-cfm-3796580585?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=dcDCJdiQuEnUro9OfuL0kg%3D%3D&position=5&pageNum=6&trk=public_jobs_jserp-result_search-card,"ABOUT CFMFounded in 1991, we are a global quantitative and systematic asset management firm applying a scientific approach to finance to develop alternative investment strategies that create value for our clients.We value innovation, dedication, collaboration and the ability to make an impact and together we create an environment for talented and passionate experts in research, technology and business to explore new ideas and challenge assumptions.ABOUT THE ROLEThe context :Data is the fuel that powers our investment strategies: intraday price dynamics are used to better our investment decisions; buy/sell intents of market participants help to trade at the best available price‚Ä¶ CFM Data team is in charge of preparing the data to make quant research easier and trading more reliable.The positionAs a data engineer intern, you will build data pipelines to convert raw orderbook data into features.Those features are then used by our systems to improve the efficiency and the reliability of our trading processes. Examples of features: daily traded volume per security, imbalance of trading volume between opening & closing auctions, etc.Our data is both large and diverse, so we are looking for someone that has both an interest in technology and in understanding the data and the rules that govern it.The work will involve python coding as well as data exploration/visualization from the notebook.You will be able to leverage our proven technology & expertise as we have already taken care of the heavy lifting.SKILLSET REQUIREMENTS/QUALIFICATIONS- You are proficient in python; a real ability to work on Linux environments (C++ not required but is a plus),- You are curious, attentive to details,- You have an interest in Technology and Data.EQUAL OPPORTUNITIES STATEMENTWe are continuously striving to be an equal opportunity employer and we prohibit any discrimination based on sex, disability, origin, sexual orientation, gender identity, age, race, or religion. We believe that our diversity, breadth of experience, and multiple points of view are among the leading factors in our success.CFM is a signatory of the Women Empowerment PrinciplesFOLLOW USFollow us on Twitter and LinkedIn or visit our website to find out more about CFM.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800339372?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=ISck%2F3DVLmeDZO4GHQcVtw%3D%3D&position=6&pageNum=6&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence üöÄAnthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et d√©cident de cr√©er une solution SAAS ERP √† destination des ESN & soci√©t√©s de conseil, afin de ""travailler autrement"".BoondManager est ainsi n√© ü¶äAu c≈ìur de BoondManager, il y a l'id√©e que chacun(e) devrait avoir la possibilit√© de se r√©aliser dans son travail et sa carri√®re, de pouvoir ""les"" concilier avec sa vie personnelle. ü´∂Notre Mission ‚≠ê‚≠ê‚≠ê‚≠ê‚≠êF√©d√©rer sur un m√™me outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunit√©s, facturation, CRA) !Notre ADN ‚ù§Ô∏èNos 75 Boonders sont en full remote/100% t√©l√©travail dans toute la France.Le t√©l√©travail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'estü§ù 1500 clientsüë• 70.000 utilisateursüåç 21 paysüí∂ Rentable et autofinanc√©eü•∞ La Boondfamily est pass√©e de 30 √† 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? üëáLe PosteBoondManager ne cesse de grandir ! ü¶äAfin de r√©pondre √† notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'√©quipe BI/Performance ü¶äTout √ßa, c'est magnifique, mais on reste un peu sur notre faim‚Ä¶ nos plus grands r√™ves sont :Devenir le leader europ√©en des ERP pour les soci√©t√©s de conseils (on a de l'ambition).Et pour √ßa, on a besoin de toi !Nos Grands Principes üëå‚úÖ Mieux vaut s'excuser que de demander la permission. On encourage √† 300 % la prise d'initiative !‚úÖ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, √©coute !La (super) Team üèÜL'√©quipe Performance est compos√©e de talents pluridisciplinaires ! Fran√ßois s'occupe de la data (ton futur bin√¥me) Guillaume des projets de refactoring Manu de la stack ELK R√©mi c√¥t√© DevOps. Florens, ton futur managerLa performance touche l'ensemble des √©quipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plut√¥t sympa donc !Tes activit√©s : üëáOn Te Propose C√¥t√© Dataviz Cr√©ation dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Int√©gration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets n√©cessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de mani√®re transverse Sp√©cification et conception de dashboard de A √† ZC√¥t√© Data Analyst Cr√©ation de KPI via sql Challenger les perfs de nos Kpi (am√©liorer les temps de r√©sultats) R√©aliser les croisements de donn√©es pour la construction et le maintien du data warehouse Assurer la maintenance et l'√©volution des KPI du produit BoondC√¥t√© Engineering Suivi de l'int√©grit√© de la donn√©e (topologie, audit) Participer √† l'alimentation du Datawarehouse D√©veloppement, maintien et l'√©volution de l'architecture des donn√©es Recueillir les besoins des parties prenantes et sp√©cifier les besoins en dataNotre Stack Technique üåà Backend/Frontend : Java, Python (√† venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'√©quipe Perfs ü¶ä On se retrouve tous les lundis matin avec l'ensemble de l'√©quipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton √©volution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour √©changer avec le reste de la team Weekly avec toute l'√©quipe tech (les BB pour les intimes) le mercredi √† 14hTon Onboarding üöÄ1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Mont√©e en comp√©tence sur notre solution au travers de notre Boondgame Mont√©e en comp√©tence sur le m√©tier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des donn√©es qui permet de calculer cette valeur, r√©solution). √ätre capable de mettre les mains dans l'int√©gration √† boond des KPI (manipul√© le backend)6 Mois Capacit√© de cr√©er des nouveaux KPI √† partir des demandes de PO (requ√™te sql permettant de le calculer) Capable d'int√©grer de la dataviz. L'id√©e est que tu sois dans les meilleures dispositions en ma√Ætrisant notre environnement üí™ProfilEt toi, Qui es-tu ? ü§©üç∑ Tu adores pinot et je ne te parle pas de celui des charentesüí™ Tu as d√©j√† construit des tableaux de bords au travers d'un outil de Dataviz‚úçÔ∏è tu connais kafka et pas que l'√©crivainüòé Tu es capable d'√©crire des requ√™tes optimis√©s pour fabriquer la dataviz avec des exemples concrets en SQLüß† Python : Tu dois savoir d√©velopper des nouvelles fonctionnalit√©s, gestion des d√©pendances, challenger l'existant (qualit√© du code), compiler le projet.üöÄ Le + : Tu ma√Ætrises notre stack technique (on veut des projets significatifs)ü¶ä Le petit ++ : Tu connais le monde des ESNüôã‚Äç‚ôÄÔ∏è Mesdames, autorisez-vous √† candidater !Ce Qu'on T'offrira En Plus De Tout √áa üéÅüí∏ Un salaire entre 45k et 60Küè° 100% remote üá´üá∑ (plus de temps pour toi !)üå¥ 3 s√©minaires par an pour se retrouver et s'√©clater‚ÄØ!üòé 9 jours de cong√©s pay√©s suppl√©mentairesüè• Une mutuelle familiale (pas de suppl√©ments pour ta famille)üí∏ Une offre t√©l√©travail en plus de ton salaire !üéÅ Une offre mensuelle dans le coworking de ton choix !üßò Cours en ligne de m√©ditation, fitness et yoga chaque semaine !ü§ù Un plan d'√©pargne entreprise valoris√© √† hauteur de 300‚Äâ%üíª Une mise √† disposition d'un Macbook, 2 √©crans, casque, etc.ü¶ä On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !D√©roulement des entretiensüíª Un premier √©change avec Jean-Florian, notre Head Of TalentüöÄ Un entretien technique/culture fit avec Fran√ßois, ton futur bin√¥me c√¥t√© Dataü§ù Un √©change Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager ü§ìEt si tu as r√©ussi √† me lire jusqu'ici,voici ma derni√®re phrase pour qu'on ne passe pas √† c√¥t√© de toi : si demain cette offre venait √† √™tre cl√¥tur√©e et que tu penses regretter de ne pas avoir postul√©, c'est qu'elle t'a tap√© dans l'≈ìil.√áa serait dommage de d√©marrer 2024 avec un regret,Alors, n'h√©site pas, POSTULEüëá
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Equativ,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-equativ-3797587886?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=g%2B7s9qeVMd02B7CZwrS3%2Bw%3D%3D&position=7&pageNum=6&trk=public_jobs_jserp-result_search-card,"üë´ About the teamAt Equativ, we‚Äôre on a mission to develop advertising technologies that empower our customers to reach their digital business goals. This means that we rely on massively scalable, widely distributed, highly available, and efficient software systems; the platform deals with over 100 billions requests per day and above 40 Gbps of network traffic.Our innovation team based in Paris, Nantes, Limoges, Krak√≥w and Berlin is composed of 90 straightforward and energetic engineers working in an Agile environment and ready to tackle the most complex technical challenges.Our data engineering team is composed of 10 skilled engineers and is based in Paris. We are part of the R&D department which is composed of 140+ engineers spread across Paris, Nantes, Limoges, Krak√≥w and Berlin all working in an Agile environment and ready to tackle the most complex technical challenges.Our mission üëáData Engineering team is central to Equativ‚Äôs data centric business and is responsible to ingest, transform, model and redistribute all data coming from our adtech platform.We aim at building scalable and robust Big Data platforms from ingestion to business actionable consumption. Our Big Data ecosystem must handle massive log ingestion (tens of billions per day), short & long term data storage, complex data modelling, real-time and batch ELT as well as providing external access through dedicated APIs.Data Engineers serve Equativ data directly to our customers and throughout the company whether it is for BI analysis, data science algorithms (clustering and optimization), customer reporting, invoicing and more.Equativ Data Engineering team is engaged in an ambitious migration of its main data stack (Hadoop on-premise) to GCP with the objective to increase reporting features, lower maintenance time, improve performances and simplify the access to our raw data.What you'll do ‚úèÔ∏è As a Big Data Engineer, you‚Äôll primarily focus on maintaining and enhancing the operationality of our on-premise and cloud data pipelines which feed our warehouses and APIsDesign, develop, test, promote and industrialize all data components from data ingestion to datawarehouse delivery (ClickHouse, BigQuery):- Propose and develop innovative solutions to achieve the best levels of scalability and performance for our Big Data engines- Automate and streamline our real-time and batch data pipelines (on-premise and in the cloud) in order to simplify access to our data by other teams and lower amount of work spent by other teams on ETL processes- Perform end-to-end monitoring to ensure high availability of production data processing, data quality and reliability- Apply best in class Devops guidelines and secure deploymentsBrainstorm with other team members working on our data backend (datawarehouse modelling and data exposure through our reporting APIs) on optimizing our architecture and support them in the use of our pipelinesContribute to data roadmap definition in coordination with other R&D and product teams in order to build a best in class data infrastructure that will generate insights for Equativ‚Äôs analyticsTake part in improving and deploy data engineering standards, procedures, processes and operational guidelines around target data components at Equativüí™ About youMaster degree in Computer Science or similar technical field of study3+ years of software development with open source technologiesFluent in Java and/or in Scala. SQL masteryVery good understanding of Devops principles (Gitlab, Docker, Kubernetes, Gradle, ci/cd)Experience with large-scale data engineering technologies (ClickHouse, Flink, Kafka, Hadoop, Spark, Hbase)Experience on building data pipelines on Google Cloud Platform (BigQuery, Dataflow, GCS, Cloud Run, Airflow ‚Ä¶) would be a big plusExperience in working with high QPS Rest APIs is a plusEntrepreneurial spirit and know-how to identify opportunities of improvementWorking proficiency and communication skills in verbal and written EnglishPassion for playing with large volume of dataüöÄ How you'll growWithin 1 month:You'll be just finishing your onboarding. You'll probably have tackled a few small tasks in peer-codingWithin 4 months:You'll have an overview of 50% of the stack, CI/CD and team‚Äôs main processes. You‚Äôll be able to work on more complex developmentsYou'll now have enough knowledge to participate to deployments of chosen applicationsWithin 9 months:You'll be autonomous on most of our stack and will have participated to major projectsYou‚Äôll be helping the team on production mattersüëã About us Equativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.Come and lead the charge with us in building a transparent ecosystem based on quality!


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer Marseille H/F,Jems Group,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-marseille-h-f-at-jems-3802354030?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=acMkelMsh3%2FrteFOCUBHRg%3D%3D&position=8&pageNum=6&trk=public_jobs_jserp-result_search-card,"A propos de JEMSNous sommes le seul industriel de la donn√©e en Europe. Notre m√©tier est de cr√©er, manager et exploiter le patrimoine data de nos clients.Nous avons la conviction que chaque entreprise peut adopter une d√©marche innovante de gestion de la donn√©e et cr√©er des cas d‚Äôusage disruptifs en r√©duisant l'impact √©cologique et en diminuant la dette technique.Nous comptons plus de 840 collaborateurs en mission chez nos clients grands comptes dans tout secteur d‚Äôactivit√© : banque, assurance, sant√©, √©nergie, e-commerce, automobile, luxe, retail, transport, agritech‚Ä¶Vos missionsNous recherchons un(e) data engineer capable de trouver des solutions innovantes et robustes √† l'ensemble des probl√©matiques Data.Vous aurez la charge de :Participer √† la conception et r√©alisation d'une solution Data depuis l'acquisition jusqu'√† l'exploitation de la donn√©e en accompagnant la r√©flexion des directions m√©tiersIdentifier, collecter et int√©grer les donn√©es n√©cessaires √† la r√©solution de probl√©matiques m√©tier et op√©rationnellesGarantir la qualit√© des donn√©es en mettant en place les outils de mesure et de suivi ad√©quats en appliquant les r√®gles de Data Gouvernance et de Data ManagementTranscrire des besoins m√©tier en r√®gles de gestion dataIndustrialiser le d√©ploiement de vos r√©alisations √† travers l'impl√©mentation de tests unitaires, d'int√©gration et de non-r√©gressionVos comp√©tencesEn tant que Data Engineer vous ma√Ætrisez :Le langage SQLUn langage objet (Python, JAVA, Scala)Un framework de calcul distribu√© L'int√©gration continue (Git, JUnit, SonarQube, Jenkins)Un cloud provider (AWS, GCP, Azure) ou une distribution Big Data (Hortonworks, Cloudera, Datastax)Les concepts de la mod√©lisation relationnelle et non-relationnelleVotre profilDipl√¥m√©(e) d'une √©cole d'ing√©nieur ou d'une universit√©, vous justifiez d'une exp√©rience professionnelle dans un contexte projet Data. Rigoureux, proactif et autonome vous restez en veille technologique et √™tes force de proposition. Vous √™tes capable de prendre de la hauteur et vous adapter aux enjeux du projet.Avantages √† travailler chez JEMSUne JEMS Acad√©mie au service de votre mont√©e en comp√©tences (formations et certifications sur les technologies de pointe)Un accompagnement personnalis√© et un management de proximit√© pour vous proposer des √©volutions de carri√®reUne int√©gration dans des communaut√©s techniques et de pratiques JEMS (encadrement par des experts, √©changes sur les bonnes pratiques, favoriser l'innovation...) Une entreprise reconnue ""Great Place To Work""Des √©v√®nements et s√©minaires inoubliables, des soir√©es d'agence convivialesMobilit√©Une mobilit√© nationale et internationale pour vous accompagner dans vos projets de vie.Diversit√©Le Groupe JEMS porte fi√®rement sa valeur ""Diversit√©"" en se mobilisant pour l'inclusion et l'√©galit√© des chances et en luttant contre toutes formes de discrimination.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,ANFSI - Agence du num√©rique des forces de s√©curit√© int√©rieure,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-anfsi-agence-du-num%C3%A9rique-des-forces-de-s%C3%A9curit%C3%A9-int%C3%A9rieure-3792963686?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=O%2ByzyH%2B7zQkGfGYHLp9tYg%3D%3D&position=9&pageNum=6&trk=public_jobs_jserp-result_search-card,"Vos activit√©s principales : ACHEMINEMENT DE LA DONN√âE :‚Ä¢ Recueillir les besoins m√©tiers des diff√©rentes unit√©s demandeuses et utilisatrices de solutions de collecte et stockage de la donn√©e.‚Ä¢ D√©velopper les solutions techniques de collecte de la donn√©e via des API.‚Ä¢ D√©velopper des solutions techniques de stockage de la donn√©e‚Ä¢ R√©aliser les tests unitaires et d‚Äôint√©gration.‚Ä¢ Mettre en place et maintenir les batchs, c‚Äôest-√†-dire les automatisations d‚Äôune s√©rie de traitements.MISE √Ä DISPOSITION DES DONN√âES AUX √âQUIPES UTILISATRICES :‚Ä¢ Industrialiser et automatiser le nettoyage de la donn√©e selon les sp√©cifications retenues.‚Ä¢ G√©rer, maintenir et documenter de multiples bases de donn√©es (via l‚Äôimportation de donn√©es externes en open data ou de donn√©es internes par exemple).‚Ä¢ G√©rer le cycle de vie de la donn√©e conform√©ment aux directives inscrites dans le RGPD.‚Ä¢ Assurer le suivi de production et la maintenance.SUIVI DES PROJETS DE D√âVELOPPEMENT :‚Ä¢ √âtablir les sp√©cifications techniques √† partir de l‚Äôanalyse des besoins.‚Ä¢ Reporter l‚Äôactivit√© aupr√®s du chef de projet.ACTIVIT√âS √âVENTUELLES :‚Ä¢ Automatiser la cr√©ation de tableaux de bord aux √©quipes m√©tiers (envoi de fichiers via des applications d√©di√©es).‚Ä¢ Assurer une veille technologique sur les outils big data.‚Ä¢ √âcrire la documentation relative aux bases de donn√©es (r√®gles de gestion, dictionnaire des variables‚Ä¶).Votre environnement professionnel : Activit√©s du service L‚ÄôANFSI (agence du num√©rique des forces de s√©curit√© int√©rieure) est charg√©e de piloter et de conduire les projets de syst√®mes d‚Äôinformation, de communication, de commandement et des moyens technologiques connexes d√©di√©s aux utilisateurs de la s√©curit√© publique.Composition et effectifs du service L‚ÄôANFSI (agence du num√©rique des forces de s√©curit√© int√©rieure) est compos√© de six directions :la Direction des Supports Op√©rationnels, la Direction de la s√©curit√© et de l‚Äôarchitecture, la Direction de l‚Äôappui √† l‚Äôinvestigation, la Direction des applications d‚Äôappui au commandement, la Direction des communications tactiques, et la Direction de la proximit√© et de l‚Äôappui √† l‚Äôinnovation.L'effectif est compos√© de personnels de la police et de la gendarmerie nationales ainsi que de contractuels.La section de mise √† disposition des donn√©es, au sein de laquelle le poste est ouvert, est compos√©e de 9 postes. Son activit√© principale consiste √† r√©cup√©rer les donn√©es m√©tier des logiciels de r√©daction de proc√©dures des forces de s√©curit√© int√©rieure et les mettre √† disposition d‚Äôapplications tierces, comme le fichier des personnes recherch√©es, le fichier des objets et v√©hicules vol√©s, le traitement des ant√©c√©dents judiciaires et ce au travers d‚Äôoutils √† moderniser.Liaisons hi√©rarchiques Chef de section et chef de d√©partement et adjoint.Liaisons fonctionnellesToutes directions DGPN-DGGN-DNUMVos comp√©tences principales mises en ≈ìuvre :Connaissances techniquesAvoir des comp√©tences en informatique - bureautique niveau ma√Ætrise requisConna√Ætre l'environnement professionnel niveau ma√Ætrise √† acqu√©rir Savoir-faireSavoir analyser niveau expert requisSavoir manager niveau ma√Ætrise requisSavoir r√©diger niveau pratique requisAvoir l'esprit de synth√®se niveau ma√Ætrise requisSavoir s'organiser niveau ma√Ætrise requisSavoir travailler en √©quipe niveau ma√Ætrise requisSavoir-√™tre avoir le sens des relations humaines niveau ma√Ætrise requissavoir s'adapter niveau expert requissavoir communiquer niveau ma√Ætrise √† acqu√©rirsavoir s'exprimer oralement niveau ma√Ætrise √† acqu√©rirAutres : Conception des applications, Int√©gration des syst√®mes, Tests, D√©ploiement de solutions, Gestion de l‚Äôinformation et de la connaissance, Gestion des changements m√©tiers, D√©veloppement d‚Äôune strat√©gie et gestion de la s√©curit√© de l‚Äôinformation, D√©veloppement d‚Äôune strat√©gie et gestion de la qualit√© informatiqueVos perspectives :Dans un contexte d‚Äôacc√©l√©ration de l'√©volution du num√©rique et des besoins de r√©activit√© associ√©s : Enrichissement du r√©seau professionnel, approfondissement des connaissances et exp√©rience professionnelles, ma√Ætrise des proc√©dures et comp√©tences ¬´ m√©tier ¬ª de la GN/PN. Implication dans la mise en place de projets innovants (PN/GN) et transverses. S‚Äôouvrir aux nouvelles m√©thodologies de conduite de projet. Dur√©e attendue sur le poste : 3 ansSp√©cificit√©s du poste / Contraintes / Suj√©tions : R√©gime hebdomadaire 39 h ‚Äì 25 CA ‚Äì 22 RTT Les candidat.e.s pourront √™tre soumis √† une enqu√™te administrative de s√©curit√© sur le fondement de l'article L.114-1 du code de la s√©curit√© int√©rieure.Localisation g√©ographique : 4, rue Claude Bernard - 92130 Issy-les-Moulineaux


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - IDF H/F,Expleo Group,"Yvelines, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-idf-h-f-at-expleo-group-3732218304?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=a9g1nf29X81CzBeouLPefw%3D%3D&position=10&pageNum=6&trk=public_jobs_jserp-result_search-card,"En savoir plus  Soyez vous-m√™me.  Devenez qui vous voulez. Acteur mondial de l‚Äôing√©nierie, de la technologie et du conseil, Expleo accompagne des entreprises reconnues dans leur innovation afin d‚Äôacc√©l√©rer leur r√©ussite.Nous nous appuyons sur plus de 40 ans d‚Äôexp√©rience dans le d√©veloppement de produits complexes, l‚Äôoptimisation des processus de fabrication et la performance des syst√®mes d‚Äôinformation.Notre exp√©rience sectorielle nous permet d‚Äôapporter √† nos clients une expertise approfondie propre √† stimuler l‚Äôinnovation √† chaque √©tape de la cha√Æne de valeur.Le groupe r√©alise un chiffre d‚Äôaffaires annuel de plus d‚Äôun milliard d‚Äôeuros. Expleo  est un groupe responsable qui s‚Äôengage √† placer l‚Äô√©thique et la diversit√© au centre de ses pratiques, ainsi qu‚Äô√† ≈ìuvrer pour une soci√©t√© plus durable et plus s√ªre.Chez Expleo, √©panouissez-vous au c≈ìur d‚Äôune communaut√© de 19 000 collaborateurs hautement qualifi√©s qui fournissent des solutions √† forte valeur ajout√©e dans 30 pays.Nos postes sont accessibles aux personnes en situation de handicap.Pourquoi nous rejoindre ? Un accompagnement technique sur le terrain  Des formations continues via nos experts techniques  Des valeurs humaines entre nos collaborateurs  La diversit√© de nos √©quipes  Une mont√©e en comp√©tences tout au long de sa carri√®re  Travailler sur des projets de grandes ampleurs  Mission Notre offre ?Au sein du d√©partement Digital & Emerging Technologies, vous accompagnerez nos clients sur les enjeux li√©s √† la Data et √† la mise en production de solutions innovantes en travaillant en √©quipe selon la m√©thode Agile.Localisation ?L‚Äôopportunit√© se situe en Ile-de-France (75, 78, 92).Notre si√®ge se trouve √† Saint-Quentin-en-Yvelines (78).Votre r√¥le ?  Concevoir et optimiser des solutions de pipelines de donn√©es (On-Premise, Hybrid, Cloud)  R√©aliser des audits d‚Äôarchitecture data et des pr√©conisations d‚Äô√©volution  Participer aux d√©veloppements techniques  R√©pondre aux enjeux vari√©s autour de la donn√©e (cr√©ation/migration de datalakes, Move-to-cloud, industrialisation de produits de data science...)  Assurer le reporting technique du projet au client  R√©aliser une veille technologique afin de proposer des solutions innovantes  Accompagner des ing√©nieurs Data juniors dans leur mont√©e en comp√©tences  Profil Qui √™tes-vous ?Dipl√¥m√©(e) d‚Äôune formation sup√©rieure (Bac +5), vous avez une premi√®re exp√©rience significative (3 ans exp hors √©tudes).Vos comp√©tences ?  Expert(e) d'un ou de plusieurs langages suivants : Python, SQL, Java, Scala  Connaissance d'au moins un Cloud Provider : GCP, AWS, Azure, Snowflake, etc  Connaissance du management de bases de donn√©es (SQL, NoSQL) et de l'√©cosyst√®me BigData  Connaissance des principes et des √©l√©ments de Hadoop (HDFS, Hive, HBase), d'Apache Spark et/ou de Kafka  Connaissance des principes du CI/CD (ex : Git)  Connaissances des outils de virtualisation, de conteneurisation (Docker) et d'orchestration (Kubernetes)  Int√©r√™t pour les architectures microservices (REST API's)  Anglais courant Quels sont nos avantages ? Politique interne sur le t√©l√©travail  CSE  13 RTT  Tickets restaurant  Pr√©voyance Sant√©  Compte Epargne temps  Prime de vacances  Prime de cooptation Quel est notre process de recrutement ?Vous √™tes contact√© par un sp√©cialiste du recrutement lors d‚Äôun √©change t√©l√©phonique.√Ä la suite de cela, nous organisons un entretien √† la fois technique et RH.Une d√©cision peut √™tre prise d√®s cet entretien pour une embauche.Quoi qu‚Äôil arrive, vous aurez un retour de notre part.Vous souhaitez en savoir plus sur nos activit√©s =>  EXPLEOLa localisation des postes n‚Äôest qu‚Äôindicative, une mobilit√© g√©ographique sur le territoire national peut √™tre requise si la mission client le n√©cessite ou si une nouvelle mission est propos√©e . A bient√¥t dans nos √©quipes !  üòä


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer senior H/F,C2S,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-senior-h-f-at-c2s-bouygues-3804562963?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=28okjDhxrC8uIaByIVCRyw%3D%3D&position=11&pageNum=6&trk=public_jobs_jserp-result_search-card,"MissionsAu sein de la Direction Digital & Data Factory, vous int√®grerez le p√¥le Pilotage & Transformation. Vous aurez pour mission d‚Äôaider nos clients √† venir √† bout de leurs probl√®mes de qualit√© de donn√©es, de validation de la conformit√© de donn√©es aux r√®gles de gestion d√©finies par leurs directions m√©tiers.  En tant que Data Engineer, vous aurez notamment pour responsabilit√©s de :Construire des pipelines de donn√©es en ayant recours √† des technologies et langages vari√©s (TALEND, SnowFlake, Power BI, Python‚Ä¶),Participer √† l‚Äô√©tude de nouvelles solutions Data, Mener des √©tudes de faisabilit√©, Travailler √† l'am√©lioration continue des pipelines (Bonnes pratiques, optimisations,‚Ä¶), Challenger les √©quipes dans leurs r√©alisations et travailler √† l'am√©lioration des abaques, Participer et encadrer les exercices de Code Review, Accompagner des projets d'industrialisations Data Science (Dataiku,,...), Piloter des projets en lien avec les MOA, nos prestataires ou nos centres de d√©veloppement externes,Participer √† l'animation de l'√©quipe autour de son delivery et sa mont√©e en comp√©tence. D√©placements ponctuels en r√©gions √† pr√©voir.Profil  Vous √™tes dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou d'un autre dipl√¥me Bac+5 li√© √† l'informatique et la data et vous avez au moins 5 ans d‚Äôexp√©rience sur des probl√©matiques de data engineering (construction de pipelines de donn√©es (batch/streaming), industrialisation d‚Äôapplications data science, mod√©lisation de base de donn√©es‚Ä¶) ; ‚Ä¢ Anglais professionnel ‚Ä¢ Vous travaillez en ayant une culture projet en mode AGILE ‚Ä¢ Vous disposez de solides connaissances sur les architectures de donn√©es et le cloud. ‚Ä¢ Vous avez de l‚Äôexp√©rience sur un ou plusieurs environnements cloud (Azure, AWS‚Ä¶) ; ‚Ä¢ Vous disposez de bonnes comp√©tences en Python, SQL ‚Ä¢ Vous avez travaill√© √† l'industrialisation de projet Data et avez des connaissances Data OPS / QOS - QOD Toutes nos opportunit√©s professionnelles sont accessibles aux personnes en situation de handicap. Si vous n√©cessitez des am√©nagements sp√©cifiques, nous vous invitons √† nous en informer durant le processus de recrutement.En devenant membre de C2S, vous int√©grez √©galement la Communaut√© Informatique du Groupe Bouygues, BYTECH.Cette communaut√© dynamique favorise l'innovation, l'apprentissage et encourage le partage. Elle regroupe 3 200 collaborateurs issus de divers m√©tiers de l'informatique et du digital au sein du Groupe.üöÄ √ätes-vous pr√™t √† embarquer dans l'aventure C2S Bouygues ? Postulez d√®s maintenant !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Mailinblack,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mailinblack-3794178809?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=CRRgILD4unrvriC%2FQF%2Fm4A%3D%3D&position=12&pageNum=6&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?   Bas√©e √† Marseille, Mailinblack est une soci√©t√© fran√ßaise en pleine expansion, et la premi√®re en cybers√©curit√© de la r√©gion Sud √† int√©grer le palmar√®s Great Place to Work¬Æ ‚òÄÔ∏è ‚òÄÔ∏è Nous d√©veloppons et distribuons des solutions SaaS de cybers√©curit√© pour les professionnels depuis 20 ans. Notre mission consiste √† garantir la s√©curit√© des organisations en les prot√©geant contre les risques d'attaques par email, tout en formant et sensibilisant activement leurs collaborateurs √† la cybers√©curit√©.  Nous recrutons un(e) Data Engineer ! üöÄ   Ton r√¥le ? Rattach√©(e) √† l'√©quipe Lab R&D, tu travailleras en √©troite collaboration avec les Data Scientists, les √©quipes de d√©veloppement, infrastructure et produit. Ton r√¥le sera d'am√©liorer et de maintenir le socle de donn√©es Big Data aux sources de donn√©es vari√©es : emails (5 milliards par an !), pages web et bases de donn√©es Produit/CRM, afin de permettre aux Data Scientists d‚Äôam√©liorer nos syst√®mes de d√©tection des menaces. Tu apporteras aux Data Scientists et √† l‚Äô√©quipe Produit ton expertise en traitement et en analyse √† de la donn√©e √† grande √©chelle.  Tes missions ?   D√©terminer les structures de donn√©es n√©cessaires aux besoins de recherche du Lab en collaboration avec les Data Scientists et l‚Äô√©quipe infrastructure. D√©velopper, d√©ployer et maintenir les services et outils constituant le pipeline de collecte et d‚Äôenrichissement des donn√©es. Contribuer activement aux bonnes pratiques en mati√®re de s√©curit√©. Veiller au respect des r√®gles de traitement des donn√©es √† caract√®re personnel, en accord avec les normes et r√©gulations en vigueur. Mettre en place, industrialiser et maintenir les processus li√©s √† l'int√©gration de donn√©es, tels que l'orchestration, le monitoring, les API, ainsi que les tests unitaires et d'int√©gration.  Environnement technique : Python, Go, Spark, Databricks, Azure (VM, ADLS, Event Hubs, Service Bus, Synapse, Cosmos DB, DevOps pipeline), MySQL, Git, Jenkins, Docker, Kubernetes, ELK, API REST, SMTP.     Ton profil ?   ‚úÖ Exp√©rience de 2 ans minimum en Data Engineering sur de gros volumes de donn√©es et en d√©veloppement de pipeline bas√©es sur des micro-services ‚úÖ Bonne connaissance des technologies de Big Data : stockage (Data lakes, stockage distribu√©, bases de donn√©es) et traitement distribu√© √† grande √©chelle (Spark, Event Hubs, Service Bus, etc.) ‚úÖ Ma√Ætrise du d√©veloppement en Python et PySpark ‚úÖ Ma√Ætrise des processus de mise en production des mod√®les de Machine Learning ‚úÖ Connaissance des syst√®mes de bases de donn√©es SQL ‚úÖ Connaissances des approches d'int√©gration et de d√©ploiement continu (Jenkins, GitLab CI/CD, Azure DevOps Pipeline)  üåü Bonus : Connaissances dans les domaines de la messagerie (protocole SMTP et m√©thodes de filtrage) et web. Connaissance des environnements de micro-services (Docker, Kubernetes) et une exp√©rience sur Azure.  D√©roulement des entretiens  üì± Premier √©change de 20 minutes par t√©l√©phone avec Alexandre, notre Talent Acquisition üí¨ Entretien en visio avec Achraf, Manager de l‚Äô√©quipe IA/Data, et Alexandre üíª Test technique üëÄ Rencontre avec l‚Äô√©quipe Data   Les + chez Mailinblack :  Des bureaux sympas en plein centre de Marseille, au soleil et √† deux pas du Vieux Port et des Calanques ‚òÄÔ∏è ‚òÄÔ∏è 7 jours de cong√©s pay√©s suppl√©mentaires Une partie de la semaine en t√©l√©travail Une culture d‚Äôentreprise qui pr√¥ne l‚Äôautonomie, la responsabilit√© et la bienveillance Un plan de d√©veloppement de comp√©tences Et aussi : des ch√®ques vacances, des paniers de fruits dans la cuisine, des repas d‚Äô√©quipes, des journ√©es massage sur site et des √©v√©nements canons ! Et bien s√ªr une bonne mutuelle (Malakoff), une √©pargne salariale, une participation aux transports en commun (50%) Impatient(e) d'int√©grer une √©quipe soud√©e et une entreprise en pleine √©volution ?


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
DATA Engineer (H/F),METEOJOB by CleverConnect,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3805867739?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=QyoNs9%2FfrZs4lNKAIznhFA%3D%3D&position=13&pageNum=6&trk=public_jobs_jserp-result_search-card,"EntrepriseAdsearch vous propose des milliers d''opportunit√©s de carri√®res dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Int√©rim et Freelance sur notre site internet !Description Du PosteIntroduction !En Bref : CDI - DATA Engineer (H/F) - Nantes - 50K-55K - T√©l√©travail partiel - Editeur de logicielSolenn dAdsearch, Consultante sp√©cialis√©e IT (Infrastructure, Data, S√©curit√©), recrute pour lun de ses partenaires, Editeur de logiciel nantais, un DATA ENGINEER H/F.Vos missions √† r√©aliser !Dans un contexte de remplacement, vous devenez le nouveau DATA Engineer de lentreprise et endossez les responsabilit√©s suivantes : Construire des mod√®les et sch√©mas pour r√©pondre aux besoins Proc√©der √† de lanalyse DATA pour les clients Int√©grer un nouvel outil BI Cr√©ation de rapports personnalis√©s et r√©daction de documentation Cibler des opportunit√©s de communication DATA Contribuer √† lam√©lioration continue et les projets strat√©giques √† venirVotre process de recrutement (peut-√™tre r√©alis√© en 2 semaines!)! Entretien n¬∞1 en visio avec votre Consultante Adsearch Entretien n¬∞2 par t√©l√©phone avec le Service RH Entretien n¬∞3 en pr√©sentiel avec le Responsable Technique Entretien n¬∞4 en pr√©sentiel avec la Direction G√©n√©raleDescription Du ProfilVotre profil attendu ! Vos connaissances techniques : Outil BI, ETL, outils mod√®les et statistiques.SQL, SGBD, Looker, Vues et NoSQL. Vos comp√©tences acquises : Au minimum 2 ans d'exp√©rience sur l'ing√©nierie DATA. Aisance de compr√©hension et d'expression en Anglais. Votre posture professionnelle : Curieux, force de proposition, esprit d'analyse et d'√©quipe, guid√© par l'am√©lioration continue !Vos leviers de motivations !Poste en autonomie & responsabilit√© compl√®teCadre de travail convivialEntreprise √† taille humaine, dynamique et r√©put√©eT√©l√©travail partiel De nombreux avantagesCe poste est peut-√™tre LE VOTRE alors candidatez sans tarder pour vous positionner et √©changer avec Solenn d'ADSEARCH !
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer d√©butant - R√©alisation de use cases et √©valuation de plateforme No/Low code F/H,TotalEnergies,"Saint-Martin-d‚ÄôH√®res, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9butant-r%C3%A9alisation-de-use-cases-et-%C3%A9valuation-de-plateforme-no-low-code-f-h-at-totalenergies-3801952917?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=hyR7zwqJZWyDmkSyDRKcGQ%3D%3D&position=14&pageNum=6&trk=public_jobs_jserp-result_search-card,"Profil du candidat D√©butez votre carri√®re par une exp√©rience stimulante au c≈ìur d‚Äô√©quipes internationales, engag√©es dans la transition √©nerg√©tique !Nous recherchons pour une dur√©e de 12 mois au CSTJF √† PAU (64), un(e) Data Engineer d√©butant(e) - R√©alisation de use cases et √©valuation de plateforme No/Low code F/HVous √™tes r√©cemment dipl√¥m√©(e) d'un Master 2 ou d‚Äôun dipl√¥me d'ing√©nieur avec une sp√©cialisation en Data Engineering, et √™tes √† la recherche d'une opportunit√© dans un environnement international et innovant ?Vous avez des comp√©tences en programmation informatique  et en  Data Science ?Vous √™tes familier(e) avec l‚Äôenvironnement Linux ?Vous √™tes comp√©tent(e) en programmation Python et en langage SQL / BDD ?Vous avez de solides connaissances en Data processing, Distributed computing, Data ingestion et en int√©gration?Vous faites preuve d' autonomie , de rigueur , et √™tes force de proposition  ?Vous maitrisez l‚Äô anglais professionnel ?Nous vous proposons un Contrat de Professionnalisation Temps Plein qualifiant de 12 mois (100% en entreprise) incluant 15% de formation interne (m√©tier, linguistique, outils‚Ä¶) dispens√©e par des organismes s√©lectionn√©s par TotalEnergies. Ce contrat vous permettra d‚Äôacqu√©rir une ann√©e d‚Äôexp√©rience professionnelle tout en √©tant form√© aux sp√©cificit√©s de votre m√©tier en lien avec les activit√©s de la Compagnie. Un r√©el atout pour booster votre employabilit√©. Activit√©s A cette attention, voici les principales missions de votre activit√© : D√©velopper et industrialiser des solutions bas√©es sur l'intelligence artificielle pour le traitement des documents et des illustrations. Cela implique le d√©veloppement Python, le refactoring de code et la cr√©ation de packages. Vous participerez √©galement √† la phase exploratoire au c√¥t√© du Data Scientist et notamment √† la collecte, au traitement et √† l'analyse de donn√©es (principalement images et textes).  Accompagner les √©quipes du DataLab dans la r√©alisation de cas d'usage sur des plateforme de Data Science No/Low code et contribuer √† l'√©valuation de diff√©rentes plateformes. D'un point de vuetechnique, vous participerez √† : La cr√©ation et l'ex√©cution de cas de test sur la plateforme  Des tests d'appels API externes permettant l'inf√©rence de mod√®les IA  Tester la capacit√© √† int√©grer diff√©rentes sources de donn√©es dans la plateforme  √âvaluer l'interop√©rabilit√©  D√©velopper des cas d'usage en Data Science  La collecte et la pr√©paration de donn√©es au c√¥t√© de Data Scientists  Contribuer √† l'industrialisation de nos solutions  Contexte et environnement TotalEnergies est un acteur majeur de l'√©nergie dans le monde. Dans ce contexte, l‚Äôobjectif est de fournir une solution innovante sous la forme d'une plateforme de Data Science No/Low code, destin√©e √† des ing√©nieurs ayant une bonne connaissance de leurs donn√©es mais une moindre app√©tence pour la programmation. Cette plateforme vise √† faciliter et rendre autonomes les ing√©nieurs dans la r√©alisation de leurs propres cas d'usage et l'exploitation de leurs donn√©es, en offrant des fonctionnalit√©s intuitives et conviviales.Le poste de Data Engineer s'inscrit √©galement dans un contexte dynamique ax√© sur l'optimisation des processus de Data management et de contribution aux √©quipes en charge du d√©veloppement de moteurs de recherche intelligents.En tant que Data Engineer, vous travaillerez au sein d'une √©quipe dynamique et multidisciplinaire (Data Managers, Chefs de projets syst√®mes d'information, Sp√©cialistes IT, Product Owners, Data Scientists et Data Engineers exp√©riment√©s), collaborant √©troitement avec les utilisateurs finaux pour √©valuer les capacit√©s de la plateforme et r√©aliser des cas d'usage. Vous √©voluerez dans un environnement stimulant et ax√© sur l'innovation, contribuant ainsi √† renforcer les capacit√©s d'analyse de donn√©es au sein de la Compagnie, et serez invit√©(e) aux diff√©rents points de rencontres des √©quipes : avancements, arbitrages, partenaires...En cons√©quence, vous apporterez une v√©ritable valeur ajout√©e par votre analyse et vos r√©alisations. Vous b√©n√©ficierez de toute l'exp√©rience et l'accompagnement d'une √©quipe dynamique en mode ""start-up"", AGILE et flexible dans sa m√©thodologie.Alors, n'attendez plus... Postulez pour rejoindre les √©quipes TotalEnergies √† Pau ! Informations suppl√©mentaires Pour postuler √† cette offre, vous devez imp√©rativement poss√©der, √† la date d‚Äôembauche, un titre de s√©jour valide pour la p√©riode couverte par cette offre (minimum 13 mois). Attention, la conclusion de ce contrat de professionnalisation ne permet pas la d√©livrance d‚Äôun titre de s√©jour (article R.52221-6 du Code du travail). Ce poste ne s'adresse pas aux personnes recherchant une alternance avec une √©cole ou une formation dipl√¥mante, mais aux personnes r√©cemment dipl√¥m√©es √† la recherche d'un premi√®re exp√©rience.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software engineer (x/f/m),Doctolib,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-x-f-m-at-doctolib-3788675399?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=UH6Zp%2FcvP0yPMh%2BynL1qRg%3D%3D&position=15&pageNum=6&trk=public_jobs_jserp-result_search-card,"What We DoJoin a team of passionate and hard working entrepreneurs to transform healthcare!Working in the tech team at Doctolib involves building innovative products and features to improve the daily lives of care teams and patients. We work in feature teams in an agile environment, while collaborating with product , design, and business teams.What You‚Äôll DoWe are looking for a Software Engineer to join the Patient Identity Management team in the Patient Health Platform domain.As a Software Engineer, your mission will be to help Doctolib provide seamless access to healthcare for everyone. You will be working in a product team that develops foundational capabilities and services that enable patients and their relatives to access secure accounts at any time to manage their health, administrative and personal information.Your responsibilities include but are not limited to:Collaboratively design, implement and maintain high quality solutions delivering value to our users.Contribute to the modularization of the team‚Äôs domain enabling Doctolib to scale.Handle the day to day team operations (Improve monitoring, Fix bugs and security issues)Provide thoughtful and constructive feedback during pair programming sessions.Who You AreIf you don‚Äôt meet all the requirements below but believe this opportunity matches your expectations and experience, we still encourage you to apply!You have in-depth knowledge of Ruby on Rails.You have experience with React or similar Javascript frameworks.You have experience navigating technical debt, comfortably balancing between consciously incurring legacy and actively reducing it.You are product-oriented and can suggest tradeoffs to balance business needs with technical constraints.You have experience in monitoring the health of the system you are building and actively contribute to its improvement.We‚Äôll like you even more if:You are familiar with Domain Driven Design.You are an advocate for pair and mob programming.What We OfferA stock-option program for each DoctoliberA competitive health insurance paid 100% by the company A dedicated onboarding program - the Doctolib AcademyMental health and wellbeing offer in partnership with moka.careThe Doctolib Parent Care Program, including extended parental leave, meet-ups and inspiring conferencesA subsidy from the work council to refund part of the membership to a sport club or a creative class Subsidy for lunch and various food offers in our offices A flexible workplace policy offering both hybrid and office-based mode Flexibility days allowing to work in EU countries and the UK 10 days per year The interview process Recruiter InterviewFeature Building Interview System Design InterviewBehavioral InterviewOffer!If you would like to find out more about tech life at Doctolib, feel free to read our latest Medium blog articles!At Doctolib, we believe in improving access to healthcare for everyone - regardless of where you come from, what you look like. This translates into our recruitment process: Doctolib is an equal opportunity employer. We don't just accept diversity at Doctolib, we respect and celebrate it!The more diverse ideas are heard, the more our product will truly improve healthcare for all. You are welcome to apply to Doctolib, regardless of your gender, religion, age, sexual orientation, ethnicity, disability, or place of origin. If you have a disability, let us know if there's any way we can make the interview process smoother for you! All the information transmitted via this form is processed by Doctolib for the purpose of managing applications. For more information on how Doctolib processes your application data, click here.If you wish to exercise your rights or if you have any questions about the processing of your data, you can write to us at hr.dataprivacy@doctolib.com.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F/NB) - Paris,Keyrus,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-nb-paris-at-keyrus-3799373891?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=8FRBBXs%2BXfqxHQcmpJ9NTg%3D%3D&position=16&pageNum=6&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ? Une success story dans la Data et le Digital !Notre mission ? Des projets √† forte valeur ajout√©e pour accro√Ætre la performance et la comp√©titivit√© des entreprises, faciliter et acc√©l√©rer leur transformation.Notre Expertise Depuis Plus De 20 Ans ? Le Conseil Et L'int√©gration De Solutions Innovantes Autour De Trois DomainesData IntelligenceBusiness Intelligence, Big Data & Analytics, Intelligence ArtificielleDigital ExperienceConseil, Strat√©gie & Performance DigitalesConseil en Management & TransformationStrat√©gie & Innovation, Pilotage de la Performance & Accompagnement des ProjetsNous sommes plus de 3000 talents sur plus de 20 pays et 4 continents. Notre ADN ? Innover et entreprendre.Le JobLes principales missions qui vous seront confi√©es seront les suivantes:Mettre en ≈ìuvre divers outils de d√©veloppement, de test, d'automatisation et d'infrastructure informatique.D√©finir et param√©trer les processus de d√©veloppement, de test, de publication, de mise √† jour et de support pour les op√©rations DevOps.Avoir les comp√©tences techniques pour examiner, v√©rifier et valider le code logiciel d√©velopp√© dans le cadre du projet.Surveiller les processus tout au long du cycle de vie pour leur adh√©sion et mettre √† jour ou cr√©er de nouveaux processus pour l'am√©lioration et la minimisation du gaspillage.Encourager et cr√©er des processus automatis√©s dans la mesure du possible.Identifier et d√©ployer des mesures de cybers√©curit√© en effectuant en permanence une √©valuation des vuln√©rabilit√©s et une gestion des risques.S'efforcer d'am√©liorer continuellement et de construire une int√©gration continue, un d√©veloppement continu et un pipeline de d√©ploiement constant (CI/CD Pipeline)Gestion des rapports p√©riodiques sur les progr√®s √† la direction et au client.Le ProfilVous avez 5 ans d'exp√©rience.Vous parlez anglais couramment.Pourquoi nous rejoindre ? Pour int√©grer une communaut√© d‚Äôexperts curieux et passionn√©s et √©voluer dans un environnement multiculturel, formateur et favorisant la mobilit√© internationale.Parce que vous √™tes #DataGeek, #DigitalAddict, #InnovationLover !#KeyrusRocks #YouRockKeyrus est une entreprise o√π il fait bon vivre et travailler !D√©couvrezLa vie chez Keyrus en 60 secKeyrus en 3 motsNos animations pour nos collaborateurs sur Facebook et sur Instagram.Notre vid√©o par Welcome To The Jungle
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Onepoint,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-onepoint-3619446219?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=aI1C0TiXMmjXol9eCz2oAQ%3D%3D&position=17&pageNum=6&trk=public_jobs_jserp-result_search-card,"Rejoignez notre communaut√© TechStud.io qui repr√©sente un collectif passionn√© de technologies proposant la cr√©ation de solutions efficientes √† un monde en qu√™te de nouvelles exp√©riences et de services innovants.Nous apportons notre vision technique pour aider nos clients √† r√©aliser leur transformation num√©rique informatique vers des applications critiques √† grande √©chelle.Votre r√¥leVous avez au moins 2 ans sur la conception et la mise en ≈ìuvre de solutions Data, vous avez une sp√©cialisation sur l‚Äôune des stacks technologiques (Azure, AWS, GCP, Informatica, Talend, Spark, Databricks, Kakfa, ELK ‚Ä¶) et souhaitez continuer √† la d√©velopper, venez nous rejoindre dans le r√¥le de Data Engineer.Vous interviendrez sur nos projets de transformation en accompagnant des √©quipes de d√©veloppeurs, vous serez le garant de la bonne qualit√© du code et de l‚Äôefficacit√© des solutions choisies, le tout dans un environnement Agile.Vous contribuerez √©galement activement au d√©veloppement ambitieux de notre √©quipe Data.Notre accompagnementAu sein de onepoint, vous continuerez √† d√©velopper votre expertise technique gr√¢ce aux formations certifiantes que nous vous proposons tout au long de votre carri√®re, vous b√©n√©ficierez d'un √©cosyst√®me de partenaires technologiques de premier plan et partagerez continuellement avec nos communaut√©s d‚Äôexperts au travers des nombreux √©v√©nements que nous organisons r√©guli√®rement autour de la Data.Processus de recrutementOnepoint a mis en place un processus de recrutement √©tabli en fonction de vos comp√©tences, vos exp√©riences et votre s√©niorit√©.Selon votre exp√©rience, onepoint vous demandera de d√©montrer concr√®tement vos savoir-faire au cours des entretiens qu‚Äôil soit m√©thodologique, m√©tier, tech ou cr√©a.#TechInformations compl√©mentairesNous proposons :‚ÄØ‚ÄØ‚ÄØDes missions et projets passionnants ; Une communaut√© de consultants active ; Un cabinet de conseil diff√©rent (¬´ Startup spirit ¬ª), tr√®s qualitatif et √† taille moyenne ; Une opportunit√© unique de d√©veloppement et d‚Äô√©volution dans un esprit communautaire ; Des formations adapt√©es ainsi qu‚Äôune bonne dose de partage de connaissances, afin d‚Äôapprendre au quotidien ; Faire partie d‚Äôune communaut√© de technophiles souhaitant partager leurs connaissances via des √©v√©nements internes et externes.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
D√©veloppeur de big data/D√©veloppeuse de big data,GROUPE ALLIANCE,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/d%C3%A9veloppeur-de-big-data-d%C3%A9veloppeuse-de-big-data-at-groupe-alliance-3772574265?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=ewHKhEXnrcA9tIXZdVLXyQ%3D%3D&position=18&pageNum=6&trk=public_jobs_jserp-result_search-card,"Ce que tu recherches :Evoluer au sein d‚Äôune √©quipe dynamiqueParticiper √† des projets innovants d‚ÄôenvergureRelever des d√©fisDonner un nouveau souffle √† ta carri√®reAlors nous avons la mission id√©ale pour toi.Au sein d‚Äôacteurs majeurs du secteur Banque, Assurance, Retail ou Energie, tu participeras √† des projets d‚Äôenvergure, de refonte, de migration, et / ou √† des √©volutions majeures du SI du client : Analyse des besoins, tu ferasSp√©cifications techniques, tu r√©digerasL‚Äôarchitecture et/ou socle technique, tu d√©finirasBonnes pratiques, tu instaurerasDe nouvelles fonctionnalit√©s, tu d√©velopperasZ√©ro bug, tu laisserasTon √©quipe, tu accompagnerasAux instances de pilotage, tu participerasQui tu es :Dipl√¥m√©(e) de la formation qui va bienSurdou√©(e) ou d√¥t√©(e) d‚Äôune exp√©rience de 7 ans minimumExpert(e) sur des solutions BI : MS BI, Power BiHabile avec les outils de DatavizAu-del√† des comp√©tences techniques, tu es / as :Dynamique : tu n‚Äôaimes pas rester les deux pieds dans le m√™me sabotAutonome : un guide du Routard te suffiraEsprit de synth√®se : tu sais aller √† l‚ÄôessentielCapacit√© d‚Äôadaptation : tu es un vrai cam√©l√©onSens de la communication : les mots n‚Äôont pas de secret pour toiForce de proposition : tu es l‚ÄôAladdin de l‚ÄôinformatiqueEsprit d‚Äô√©quipe : un pour tous et tous pour un !


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER H/F,FRG Technology Consulting,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-frg-technology-consulting-3809885372?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=hC2WEzI0R3dRWbzNm2OUnA%3D%3D&position=19&pageNum=6&trk=public_jobs_jserp-result_search-card,"FRG Consulting recrute pour l'un de ses clients, un acteur majeur du secteur immobilier bas√© au c≈ìur de Lyon, un Data Engineer H/D comp√©tent pour renforcer son √©quipe dynamique. L'entreprise offre un environnement de travail stimulant, des opportunit√©s de croissance professionnelle et la possibilit√© de contribuer √† des projets innovants dans le domaine de l'immobilier.Responsabilit√©s: En tant que Data Engineer, vous jouerez un r√¥le cl√© dans la conception, le d√©veloppement et la maintenance des infrastructures de donn√©es. Vous collaborerez √©troitement avec les √©quipes m√©tier pour comprendre leurs besoins, et utiliserez les technologies suivantes :Concevoir, d√©velopper et maintenir des pipelines de donn√©es performants √† l'aide de process engines tels que Spark, Hadoop et Apache Airflow.Mettre en ≈ìuvre des solutions ETL avec un outil tel que Talend pour assurer la fiabilit√© des flux de donn√©es.Utiliser les langages de programmation SQL et Python pour le traitement et l'analyse des donn√©es.Exploiter les bases de donn√©es SQL/NoSQL, notamment PostGreSQL, et d√©ployer des solutions ELK (Elasticsearch, Logstash, Kibana) pour l'analyse des logs.Travailler avec des technologies Big Data telles que Hadoop, Spark et Hive pour g√©rer et analyser de grandes quantit√©s de donn√©es.Collaborer avec les services Cloud, en particulier Azure, AWS ou Cloud Souverain (OVH Cloud), en mettant en ≈ìuvre des notions de FinOps pour optimiser les co√ªts.Mettre en place la conteneurisation et l'orchestration avec Docker et Kubernetes.Utiliser des outils de d√©veloppement tels que Jupyter pour la cr√©ation et le partage de notebooks interactifs.Participer √† l'int√©gration continue avec Git et Jenkins.Travailler selon les m√©thodes agiles, notamment Scrum et Kanban, pour assurer une collaboration efficace au sein de l'√©quipe.Qualifications RequisesDipl√¥me en informatique, g√©nie logiciel, sciences des donn√©es ou domaine connexe.Exp√©rience pratique avec les technologies mentionn√©es ci-dessus.Comp√©tences approfondies en SQL, Python, DBT, et exp√©rience avec un ETL tel que Talend.Connaissance des bases de donn√©es SQL/NoSQL, des outils ELK, et des technologies Big Data (Hadoop, Spark, Hive).Exp√©rience dans le d√©ploiement sur des fournisseurs de cloud tels que Azure, AWS ou Cloud Souverain (OVH Cloud), avec des notions de FinOps.Ma√Ætrise de la conteneurisation et de l'orchestration avec Docker et Kubernetes.Utilisation d'outils de d√©veloppement tels que Jupyter.Exp√©rience de l'int√©gration continue avec Git et Jenkins.Familiarit√© avec les m√©thodologies agiles, notamment Scrum et Kanban.AvantagesEnvironnement de travail collaboratif et dynamique.Opportunit√©s de formation continue.Possibilit√© de contribuer √† des projets innovants dans le secteur de l'immobilier.Croissance professionnelle au sein d'une entreprise en pleine expansion.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Apache Airflow'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Senior Data Engineer,Vestiaire Collective,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-vestiaire-collective-3809825947?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=E8V4DQMHTlLwro6LUp5xOg%3D%3D&position=20&pageNum=6&trk=public_jobs_jserp-result_search-card,"Vestiaire Collective is the leading global online marketplace for desirable pre-loved fashion. Our mission is to transform the fashion industry for a more sustainable future by empowering our community to promote the circular fashion movement. Vestiaire was founded in 2009 and is headquartered in Paris with offices in London, Berlin, New York, Singapore and Hong Kong and warehouses in Tourcoing (France), Crawley (UK), Hong Kong and New York.We currently have a diverse global team of 1000 employees representing over 50 nationalities. Our values are community, activism, transparency, dedication and greatness. We are proud to be a BCorp.About The RoleVestiaire Collective is hiring a Senior Data Engineer on our data platform team, to play a crucial role in developing and enhancing our data infrastructure, driving Vestiaire Collective's mission towards a sustainable fashion industry.What You'll Do Data Platform Architecture:Design and evolve our data platform's architecture for scalable, efficient data processing and analytics. Participate in strategic planning for long-term alignment with business goalsData Integration and ModelingImplement robust, scalable data integration strategies. Optimize data models for efficient storage, retrieval, and analytics. Building ML Platform EcosystemCollaboratively develop a scalable, reliable ML platform, focusing on model serving, training, and essential MLOps features. Prioritize efficiency, automation, and best practices in MLOps. Workflow AutomationDevelop automated solutions to enhance data operations. Utilize Apache Airflow for effective data workflow management. Real-Time Data ProcessingCreate real-time data processing applications, leveraging Kafka for timely data availability. Ensure high throughput and low latency in data processing/serv. Continuous Learning and ImprovementStay abreast of the latest data engineering trends and technologies. Foster a culture of continuous learning and knowledge sharing. Required Skills PythonExpert in clean, efficient Python coding; proficient with data libraries and web frameworksSkilled in asynchronous programming. SQL: Strong in SQL syntax and query optimization. Kafka:Proficient in Kafka architecture and stream processing. ML Deployment / Optimization: Experienced in ML model deployment and MLOps principles. Required ToolingsApache Airflow: Expertise in workflow management. FastAPI/Robyn: Skilled in FastAPI/Robyn development and features. Git:Advanced knowledge in version control and CI/CD integration. Cloud Services: AWS or similar cloud experience. Data Visualization Tools: Proficient in tools like Tableau and Streamlit. Monitoring and Logging Tools: Experienced with tools like DataDog, Prometheus, and Grafana. Nice To Have SkillsTerraform/Ansible: Skills in infrastructure automation. Golang: Experience in Go programming and its ecosystem. DBT: Proficient in DBT for data warehousing. Spark/Flin: Experienced in distributed data processing. What We OfferA meaningful job with an impact on the way people consume fashion and promote sustainabilityFlexible work possibilitiesThe opportunity to do career-defining work in a fast-growing French-born scale upThe possibility to work as part of a globally diverse team with more than 50 nationalities Two days to help Project - reinforcing your activist journey and volunteer for an associationSignificant investment in your learning and growthCompetitive compensation and benefits packageAs full member of our entrepreneurial project, you will be eligible to free sharesVestiaire Collective is an equal opportunities employer


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Apache Airflow'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Atos,"Clermont-Ferrand, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-atos-3799329300?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=YEAZjnku7q2XAfSBWYJj4g%3D%3D&position=21&pageNum=6&trk=public_jobs_jserp-result_search-card,"Bienvenue chez Atos, o√π nous imaginons le futur de la tech.Leader international du num√©rique s√©curis√© et d√©carbon√©, Atos contribue √† fa√ßonner les nouvelles technologies avec ses clients.Dans un environnement multiculturel, collaboratif et agile, nous offrons des parcours de carri√®re valorisants bas√©s sur des programmes de formation, de certification et de mobilit√©.C‚Äôest pourquoi chez Atos, la diversit√© des comp√©tences et des exp√©riences de nos √©quipes nous permet, ensemble, de faire les bons choix avec nos clients, pour l‚Äôavenir de notre entreprise et de la soci√©t√©.LA MISSION QUE L‚ÄôON VOUS CONFIE Vous maintenir au top des nouvelles technologies les plus modernes, c‚Äôest essentiel pour vous ?Nous avons les projets ambitieux et les clients qui veulent prendre un temps d‚Äôavance.Vous aimez partager vos convictions en mati√®re de technos pour nous faire tous progresser ? Nous sommes preneurs !Au sein d'√©quipes dynamiques, vous aurez pour missions principalesConseiller en architecture en gouvernance de la donn√©e.Intervenir dans les aspects Data Ingestion, Data Analytiques et Data Science / IA.Mettre en place, int√©grer, d√©velopper et optimiser des solutions de pipeline sur des environnements Cloud pour les projets strat√©giques de nos clients.VOTRE PROFIL POUR R√âUSSIR De formation sup√©rieure BAC +5 en Informatique d‚Äôune Ecole d‚ÄôIng√©nieur ou d‚Äôun Mast√®re universitaire dans le domaine des sciences informatiques que vous avez compl√©t√© par une exp√©rience significative en Data Science / Data Engineering.Votre stack technique  Requis Connaissance des √©cosyst√®mes Data (NoSQL/DW/Hadoop) ELK (ElasticSearch, Logstash, Kibana), MongoDB, Cassandra, Redis, CouchBase, Teradata, SnowFlake, BigQuery, Redshift, Hive, Impala, Object storage, HDFS‚Ä¶Expertise en d√©veloppement Python ou Java Spring Boot.Expertise sur un des framework suivants Spark, Kafka Connect & Streams, Apache Beam.Connaissance des architectures conteneurs Docker, Kubernetes. Appr√©ci√© Connaissance d‚Äôun des services manag√©s BigData de Google Cloud Platform / AWS / Microsoft Azure.Connaissance des approches Agile & DevOps.Comp√©tences obligatoires Docker, KubernetesSoft SkillsPassionn√©(e) d‚Äôinformatique en progressant et en vous tenant √† jour sur toutes les technologies et architectures, vous √™tes cr√©atif(ve), autonome, rigoureux(se), curieux(se), motiv√©(e) et avez le sens du travail en √©quipe et du relationnel alors rejoignez-nous !Niveau de langue Anglais niveau interm√©diaire minimum recommand√© et Fran√ßais exig√©.Chez Atos, la diversit√©, l'inclusion et l‚Äôaccessibilit√© num√©rique font partie int√©grante de notre ADN. D√©couvrez nos engagements en faveur d'un environnement de travail √©quitable pour toutes et tous. Atos est un leader reconnu dans son secteur pour les crit√®res environnementaux, sociaux et de gouvernance (ESG). Pour en savoir plus sur notre engagement en mati√®re de RSE.Chez Atos, la diversit√©, l'inclusion et l‚Äôaccessibilit√© num√©rique font partie int√©grante de notre ADN. D√©couvrez‚ÄØnos engagements‚ÄØen faveur d'un environnement de travail √©quitable pour toutes et tous.‚ÄØ‚ÄØ‚ÄØAtos est un leader reconnu dans son secteur pour les crit√®res environnementaux, sociaux et de gouvernance (ESG). Pour en savoir plus sur notre engagement en mati√®re de RSE,‚ÄØcliquez ici.Choose your future. Choose Atos.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer,Mailinblack,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mailinblack-3794774027?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=r9jqop%2FZPOedibvTllD7fQ%3D%3D&position=22&pageNum=6&trk=public_jobs_jserp-result_search-card,"√Ä propos de nousQui sommes-nous‚ÄØ? Bas√©e √† Marseille, Mailinblack est une soci√©t√© fran√ßaise en pleine expansion, et la premi√®re en cybers√©curit√© de la r√©gion Sud √† int√©grer le palmar√®s‚ÄØGreat Place to Work¬Æ ‚òÄÔ∏è ‚òÄÔ∏èNous d√©veloppons et distribuons des solutions SaaS de cybers√©curit√© pour les professionnels depuis 20 ans. Notre mission consiste √† garantir la s√©curit√© des organisations en les prot√©geant contre les risques d'attaques par email, tout en formant et sensibilisant activement leurs collaborateurs √† la cybers√©curit√©.En pleine croissance, nous recrutons un(e) Data Engineer‚ÄØ! üöÄMissionTon r√¥le‚ÄØ?Rattach√©(e) √† l'√©quipe Lab R&D, tu travailleras en √©troite collaboration avec les Data Scientists, les √©quipes de d√©veloppement, infrastructure et produit. Ton r√¥le sera d'am√©liorer et de maintenir le socle de donn√©es Big Data aux sources de donn√©es vari√©es : emails (5 milliards par an !), pages web et bases de donn√©es Produit/CRM, afin de permettre aux Data Scientists d‚Äôam√©liorer nos syst√®mes de d√©tection des menaces. Tu apporteras aux Data Scientists et √† l‚Äô√©quipe Produit ton expertise en traitement et en analyse √† de la donn√©e √† grande √©chelle.Tes missions‚ÄØ? D√©terminer les structures de donn√©es n√©cessaires aux besoins de recherche du Lab en collaboration avec les Data Scientists et l‚Äô√©quipe infrastructure. D√©velopper, d√©ployer et maintenir les services et outils constituant le pipeline de collecte et d‚Äôenrichissement des donn√©es. Contribuer activement aux bonnes pratiques en mati√®re de s√©curit√©. Veiller au respect des r√®gles de traitement des donn√©es √† caract√®re personnel, en accord avec les normes et r√©gulations en vigueur. Mettre en place, industrialiser et maintenir les processus li√©s √† l'int√©gration de donn√©es, tels que l'orchestration, le monitoring, les API, ainsi que les tests unitaires et d'int√©gration. Environnement technique‚ÄØ: Python, Go, Spark, Databricks, Azure (VM, ADLS, Event Hubs, Service Bus, Synapse, Cosmos DB, DevOps pipeline), MySQL, Git, Jenkins, Docker, Kubernetes, ELK, API REST, SMTP.ProfilTon profil‚ÄØ? ‚úÖ Exp√©rience de 2 ans minimum en Data Engineering sur de gros volumes de donn√©es et en d√©veloppement de pipeline bas√©es sur des micro-services‚úÖ Bonne connaissance des technologies de Big Data‚ÄØ: stockage (Data lakes, stockage distribu√©, bases de donn√©es) et traitement distribu√© √† grande √©chelle (Spark, Event Hubs, Service Bus, etc.)‚úÖ Ma√Ætrise du d√©veloppement en Python et PySpark‚úÖ Ma√Ætrise des processus de mise en production des mod√®les de Machine Learning‚úÖ Connaissance des syst√®mes de bases de donn√©es SQL‚úÖ Connaissances des approches d'int√©gration et de d√©ploiement continu (Jenkins, GitLab CI/CD, Azure DevOps Pipeline)üåü Bonus‚ÄØ:‚ÄØConnaissances dans les domaines de la messagerie (protocole SMTP et m√©thodes de filtrage) et web. Connaissance des environnements de micro-services (Docker, Kubernetes) et une exp√©rience sur Azure. D√©roulement des entretiens‚ÄØ‚ÄØüì± Premier √©change de 20 minutes par t√©l√©phone avec Alexandre, notre Talent Acquisitionüí¨ Entretien en visio avec Achraf, Manager de l‚Äô√©quipe IA/Data, et Alexandre‚ÄØüíª Test technique ‚ÄØüëÄ Rencontre avec l‚Äô√©quipe‚ÄØDataLes + chez Mailinblack : Des bureaux sympas en plein centre de Marseille, au soleil et √† deux pas du Vieux Port et des Calanques ‚òÄÔ∏è ‚òÄÔ∏è 7 jours de cong√©s pay√©s suppl√©mentaires Une partie de la semaine en t√©l√©travail Une culture d‚Äôentreprise qui pr√¥ne l‚Äôautonomie, la responsabilit√© et la bienveillanceUn plan de d√©veloppement de comp√©tences Et aussi : des ch√®ques vacances, des paniers de fruits dans la cuisine, des repas d‚Äô√©quipes, des journ√©es massage sur site et des √©v√©nements canons !Et bien s√ªr une bonne mutuelle (Malakoff), une √©pargne salariale, une participation aux transports en commun (50%)Impatient(e) d'int√©grer une √©quipe soud√©e et une entreprise en pleine √©volution ?
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
(Senior) Data Engineer,Mirakl,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-mirakl-3698388646?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=RVVb%2B9npHdunN59bjkEkdg%3D%3D&position=23&pageNum=6&trk=public_jobs_jserp-result_search-card,"Mirakl, leader et pionnier de l'√©conomie de plateforme, propose aux entreprises une suite unique de solutions leur permettant de transformer significativement leur e-commerce afin d'acc√©l√©rer de fa√ßon durable et rentable leur croissance. Depuis 2012, Mirakl accompagne les entreprises B2C et B2B avec la technologie la plus avanc√©e, s√©curis√©e et √©volutive leur permettant de digitaliser leur activit√© et d'√©largir leur offre via la marketplace ou le dropship, faciliter la gestion des catalogues et des paiements de leurs fournisseurs pour plus d'efficacit√©, offrir une exp√©rience d'achat personnalis√©e √† leurs clients, et augmenter leurs profits gr√¢ce au retail media. Bas√©e √† Paris et Boston, Mirakl est certifi√©e Great Place to Work.A propos de Mirakl LabsNos √©quipes techniques et produits, nomm√©es Mirakl Labs, sont principalement r√©parties entre nos 2 hubs situ√©s √† Paris et √† Bordeaux. Elles collaborent au quotidien afin d'adresser les probl√©matiques de nos clients et utilisateurs en r√©pondant √† diff√©rents challenges li√©s aux nouvelles fonctionnalit√©s, √† la scalabilit√©, la s√©curit√© et l'ergonomie‚Ä¶Elles op√®rent en mode agile et s'organisent en Squads compos√©es d'un Squad Lead, de 5 d√©veloppeurs, d'un Product Manager et d'un QA. Chaque Squad est sp√©cialis√©e sur un scope fonctionnel afin de concevoir et r√©aliser de nouvelles features, leurs √©volutions et des APIs (avec un d√©coupage en micro-services). Nos √©quipes Infrastructure, Architecture, S√©curit√©, Documentation, Product Design, Data et Support op√®rent en transverse en apportant leur expertise et de la coh√©rence sur l'ensemble des produits.Toutes les √©quipes sont responsables de leur p√©rim√®tre et chacun des collaborateurs apporte son exp√©rience et ses id√©es. Innovation, feedback et implication dans les prises de d√©cision sont au c≈ìur de notre philosophie.Et pour favoriser ce partage avec d'autres passionn√©s, nous sommes sponsors, speakers, et h√¥tes de diff√©rents √©v√©nements, meetups, et associations de la sc√®ne Tech en France. Au cours des derni√®res ann√©es, nous avons particip√© √† des √©v√©nements tels que Devoxx, ReactEurope, ProductConf et Flupa UX Days.A propos du jobLa solution SaaS Mirakl est le moteur des marketplaces des plus importants e-commer√ßants √† travers le monde. Cette solution g√®re et produit de gros volumes de donn√©es qui pr√©sentent des challenges extr√™mement int√©ressants pour les sp√©cialistes de la donn√©e (produits, commandes, clients, niveaux de stock, prix, messages, appels API, donn√©es de navigation, s√©ries temporelles, donn√©es g√©olocalis√©es etc.).En tant que (Senior) Data Engineer au sein de l'√©quipe Data Mirakl, vos principales missions seront de :contribuer √† l'enrichissement de la Data Platform (ETL)am√©liorer la robustesse de nos pipelines de production pour nos applications Machine Learning (inf√©rence real time etc.)Int√©gr√©(e) dans une √©quipe de sp√©cialistes de la donn√©e (data engineers, machine learning engineers, data scientists, data analysts), vous √™tes un des acteurs cl√©s pour garantir la place de Mirakl comme solution dominante sur son march√©.Notre stack et nos outilsApache Spark, Kafka, AWS, Databricks, Python, Airflow, Mlflow, Tensorflow, Delta lake, Superset, Kubernetes, Redshift, SQL, Terraform, AnsibleAu quotidien, vous allez :Participer √† la d√©finition et √† l'impl√©mentation d'une architecture performante, robuste, scalable et aux co√ªts ma√Ætris√©s pour nos applications Spark ainsi que pour nos pipelines de production de Machine Learning (√©valuation des feature stores, refactoring de DAG Airflow)Accompagner les Data Scientists lors de leur mise en production (relecture de code, pair programming) et mettre en place les best practicesOptimiser et am√©liorer la CI/CD de l'√©quipe en collaboration avec l'√©quipe SREAssurer la mont√©e en comp√©tence des membres de l'√©quipe sur les sujets de MLOps et Data EngineeringR√©fl√©chir √† la meilleure fa√ßon d'int√©grer les donn√©es Google Analytics dans la data platformPartager ses connaissances et pr√©senter les travaux devant toutes les √©quipes LabsCe qu'on peut vous apporter :Des projets data driven, divers et vari√©s (traitements massifs d'images, de textes, time series etc.) pour des produits diff√©rents de MiraklUne culture orient√©e sur la veille technologiqueDes projets qui ont un vrai impact business devant √™tre d√©ploy√©s sur des centaines de clients dans un contexte multilingueQuelques exemples de sujets en cours :Enrichissement des donn√©es produit √† partir des images et des descriptionsMod√©ration automatique des produitsMapping automatique des donn√©es produitIdentification des produits √† fort potentielsD√©tection de comportements frauduleuxSentiment analysis sur les messages √©chang√©s entre clients et vendeurs et dans les √©valuationsD√©termination de prix optimauxMonitoring de la qualit√© de service des vendeursDes applications d'inf√©rence en synchrone de nos mod√®les de MLVous aimerez ce job si :Vous √™tes passionn√©(e) par la data et les technologies modernes permettant d'en tirer partieVous vous int√©ressez √† la data science et avez des connaissances g√©n√©rales sur les algorithmes de Machine LearningVous avez un background en d√©veloppement et avez √©volu√© dans un environnement DataVous avez a minima 4 ans d'exp√©rience en environnement Machine Learning et/ou DataVous avez mis en production avec succ√®s des applications Big Data faisant appel √† du Machine Learning, du NLP, du traitement d'images dans des projets d'envergure, √† fort volume de donn√©esVotre ma√Ætrisez Python, √™tes un pro des frameworks data de la fondation Apache et √™tes √† l'aise dans un environnement AWSVous ma√Ætrisez au moins un outil d'orchestration (Airflow, Data Pipeline ou tout autre outil similaire)Vous pr√©sentez vos travaux de mani√®re simple et accessibleVous fa√Ætes preuve d'un bon relationnel et vous aimez mentorer des collaborateursVous parlez couramment anglais et fran√ßaisLes plus pour le poste :Vous avez une exp√©rience significative dans le domaine du e-commerceVous avez d√©j√† mis en place un Data Lake, Data Warehouse ou une Data PlatformVous avez d√©ploy√© des applicatifs en environnement KubernetesVous avez mis en place des pipelines d'ingestion de donn√©es avec une approche CDC √† l'aide de Debezium ou autreVous ma√Ætrisez Java/ScalaMirakl est engag√©e en faveur de la diversit√©, de l'√©galit√© des chances et de l'inclusion. Nous c√©l√©brons nos diff√©rences car nous sommes convaincus que les qualit√©s visibles et invisibles de chaque Mirakl Worker sont une source de force et d'innovation. Dans le cadre de cet engagement, nous √©tudions toutes les candidatures sans distinction de : genre, ethnicit√©, religion, orientation sexuelle, handicap, √¢ge ou toute autre caract√©ristique prot√©g√©e par la loi.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
"Data Engineer | Python, Airflow, Sql | Start up dans la medtech",Octopus IT - Expert du recrutement tech,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-python-airflow-sql-start-up-dans-la-medtech-at-octopus-it-expert-du-recrutement-tech-3664564642?refId=F6x8NWTUQ%2ByO7t%2BKNUXG7g%3D%3D&trackingId=yVcjTHbUQf6pScB4pYVDOg%3D%3D&position=24&pageNum=6&trk=public_jobs_jserp-result_search-card,"La soci√©t√©Cette startup de la MedTech est d√©di√©e √† la valorisation de la donn√©e de sant√© bas√©e √† Paris. Spin-off d'un c√©l√®bre institut de recherche en maladies g√©n√©tiques, ils ont d√©velopp√© diff√©rentes solutions pour l'h√¥pital (entrep√¥t de donn√©es de sant√© int√©grant du NLP, algorithmes d'anonymisation, ou encore une plateforme s√©curis√©e de recueil des consentements).Leurs solutions sont aujourd'hui d√©ploy√©es dans plusieurs h√¥pitaux permettant defaciliter la recherche clinique, guider les d√©cideurs avec de la donn√©e dans leurpilotage m√©dico-√©conomique, mais aussi d'identifier des patients en errancediagnostique.Depuis Leur cr√©ation fin 2017, leur produit-phare (Dr. Warehouse) a √©t√© cit√© dansplus de 70 publications scientifiques comme solution cl√© pour le data miningpermettant de transformer les donn√©es de vie r√©elle (RWD) en preuves (RWE).Ils s'attachent particuli√®rement au d√©veloppement de solutions innovantesqui sont r√©ellement utiles pour les chercheurs ainsi que le personnel soignant. Etrendre utile la donn√©e pour le soin est une qu√™te pour chaque personne de l‚Äô√©quipe.Le posteAfin d'accompagner cette start up dans le d√©ploiement de la solution Dr. Warehouse dans les h√¥pitaux pour acc√©l√©rer la recherche clinique et aider les praticiens √† mieux soigner leurs patients, nous recherchons un Data Engineer. Ses missions seront de : Participer au d√©veloppement (mapping des donn√©es, d√©veloppement des connecteurs) et au maintien (validation de l‚Äôexhaustivit√© et de l‚Äôint√©grit√© des donn√©es) des ETLs pour int√©grer les donn√©es m√©dicales dans un entrep√¥t de donn√©es Dr Warehouse  Am√©liorer les performances, la maintenabilit√© et le monitoring des ETLs existants Cr√©er des dashboards (missions ponctuelles en fonction de la demande)  D√©finir et d√©velopper notre architecture data en liaison avec les autres √©quipes Participer √† l‚Äôam√©lioration du traitement automatique du langage des compte-rendus m√©dicaux poursuivant les objectifs suivants:Extraction automatique d'informations pr√©sente dans les textes Enrichissement s√©mantique pour extraction de contexte automatique et similarit√© de corpusLa soci√©t√© est sans silo ! Les √©quipes d√©veloppement, commerciales, marketing et produit s‚Äôentraident pour mettre en place une gestion plus efficace et humaine des donneÃÅes de santeÃÅ et acc√©l√©rer les progreÃÄs meÃÅdicaux !La stack actuelleVotre profil2 ans d‚Äôexp√©rience en tant que Data Engineer alternance inclueDipl√¥me d‚Äôing√©nieur ou √©cole d‚ÄôInformatique BAC+5 (id√©alement) Avoir d√©j√† travaill√© sur des pipelines de donn√©es complexes (ETLs, mapping,...) Tu as con√ßu, d√©ploy√© et maintenu une architecture complexe en production : sp√©cifications, conception, monitoring, alerting, gestion des incidents etc. Gestion de projet en Agile (sprint planning, r√©trospective) Gitlab/GitHub workflow (branch feature, developpement, master) (Bonus) Sensibilit√© aux probl√©matiques de la donn√©es de sant√©Vos comp√©tences: Requises:PythonAirflowETLPandasSQLImportantesDjango RESTOracle / PostgreSQLLe salaire & avantages39-45 K‚Ç¨ selon exp√©rienceRTTCarte Swile (ex-Lunchr) cr√©dit√©e mensuellementMutuelle et transport3 jours de t√©l√©travail par semaineIncentives organis√©s par la directionCe poste a √©t√© soigneusement choisi par votre coach. Powered by Octopus IT, cabinet d‚ÄôExperts en Recrutement Tech (CDI et clients finaux uniquement) ‚Äì Visitez nous pour plus d‚Äôopportunit√©s : www.octopusit.fr


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800339373?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=C%2BLACoqk65VitIqJxsgV6g%3D%3D&position=1&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence üöÄAnthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et d√©cident de cr√©er une solution SAAS ERP √† destination des ESN & soci√©t√©s de conseil, afin de ""travailler autrement"".BoondManager est ainsi n√© ü¶äAu c≈ìur de BoondManager, il y a l'id√©e que chacun(e) devrait avoir la possibilit√© de se r√©aliser dans son travail et sa carri√®re, de pouvoir ""les"" concilier avec sa vie personnelle. ü´∂Notre Mission ‚≠ê‚≠ê‚≠ê‚≠ê‚≠êF√©d√©rer sur un m√™me outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunit√©s, facturation, CRA) !Notre ADN ‚ù§Ô∏èNos 75 Boonders sont en full remote/100% t√©l√©travail dans toute la France.Le t√©l√©travail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'estü§ù 1500 clientsüë• 70.000 utilisateursüåç 21 paysüí∂ Rentable et autofinanc√©eü•∞ La Boondfamily est pass√©e de 30 √† 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? üëáLe PosteBoondManager ne cesse de grandir ! ü¶äAfin de r√©pondre √† notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'√©quipe BI/Performance ü¶äTout √ßa, c'est magnifique, mais on reste un peu sur notre faim‚Ä¶ nos plus grands r√™ves sont :Devenir le leader europ√©en des ERP pour les soci√©t√©s de conseils (on a de l'ambition).Et pour √ßa, on a besoin de toi !Nos Grands Principes üëå‚úÖ Mieux vaut s'excuser que de demander la permission. On encourage √† 300 % la prise d'initiative !‚úÖ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, √©coute !La (super) Team üèÜL'√©quipe Performance est compos√©e de talents pluridisciplinaires ! Fran√ßois s'occupe de la data (ton futur bin√¥me) Guillaume des projets de refactoring Manu de la stack ELK R√©mi c√¥t√© DevOps. Florens, ton futur managerLa performance touche l'ensemble des √©quipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plut√¥t sympa donc !Tes activit√©s : üëáOn Te Propose C√¥t√© Dataviz Cr√©ation dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Int√©gration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets n√©cessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de mani√®re transverse Sp√©cification et conception de dashboard de A √† ZC√¥t√© Data Analyst Cr√©ation de KPI via sql Challenger les perfs de nos Kpi (am√©liorer les temps de r√©sultats) R√©aliser les croisements de donn√©es pour la construction et le maintien du data warehouse Assurer la maintenance et l'√©volution des KPI du produit BoondC√¥t√© Engineering Suivi de l'int√©grit√© de la donn√©e (topologie, audit) Participer √† l'alimentation du Datawarehouse D√©veloppement, maintien et l'√©volution de l'architecture des donn√©es Recueillir les besoins des parties prenantes et sp√©cifier les besoins en dataNotre Stack Technique üåà Backend/Frontend : Java, Python (√† venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'√©quipe Perfs ü¶ä On se retrouve tous les lundis matin avec l'ensemble de l'√©quipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton √©volution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour √©changer avec le reste de la team Weekly avec toute l'√©quipe tech (les BB pour les intimes) le mercredi √† 14hTon Onboarding üöÄ1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Mont√©e en comp√©tence sur notre solution au travers de notre Boondgame Mont√©e en comp√©tence sur le m√©tier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des donn√©es qui permet de calculer cette valeur, r√©solution). √ätre capable de mettre les mains dans l'int√©gration √† boond des KPI (manipul√© le backend)6 Mois Capacit√© de cr√©er des nouveaux KPI √† partir des demandes de PO (requ√™te sql permettant de le calculer) Capable d'int√©grer de la dataviz. L'id√©e est que tu sois dans les meilleures dispositions en ma√Ætrisant notre environnement üí™ProfilEt toi, Qui es-tu ? ü§©üç∑ Tu adores pinot et je ne te parle pas de celui des charentesüí™ Tu as d√©j√† construit des tableaux de bords au travers d'un outil de Dataviz‚úçÔ∏è tu connais kafka et pas que l'√©crivainüòé Tu es capable d'√©crire des requ√™tes optimis√©s pour fabriquer la dataviz avec des exemples concrets en SQLüß† Python : Tu dois savoir d√©velopper des nouvelles fonctionnalit√©s, gestion des d√©pendances, challenger l'existant (qualit√© du code), compiler le projet.üöÄ Le + : Tu ma√Ætrises notre stack technique (on veut des projets significatifs)ü¶ä Le petit ++ : Tu connais le monde des ESNüôã‚Äç‚ôÄÔ∏è Mesdames, autorisez-vous √† candidater !Ce Qu'on T'offrira En Plus De Tout √áa üéÅüí∏ Un salaire entre 45k et 60Küè° 100% remote üá´üá∑ (plus de temps pour toi !)üå¥ 3 s√©minaires par an pour se retrouver et s'√©clater‚ÄØ!üòé 9 jours de cong√©s pay√©s suppl√©mentairesüè• Une mutuelle familiale (pas de suppl√©ments pour ta famille)üí∏ Une offre t√©l√©travail en plus de ton salaire !üéÅ Une offre mensuelle dans le coworking de ton choix !üßò Cours en ligne de m√©ditation, fitness et yoga chaque semaine !ü§ù Un plan d'√©pargne entreprise valoris√© √† hauteur de 300‚Äâ%üíª Une mise √† disposition d'un Macbook, 2 √©crans, casque, etc.ü¶ä On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !D√©roulement des entretiensüíª Un premier √©change avec Jean-Florian, notre Head Of TalentüöÄ Un entretien technique/culture fit avec Fran√ßois, ton futur bin√¥me c√¥t√© Dataü§ù Un √©change Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager ü§ìEt si tu as r√©ussi √† me lire jusqu'ici,voici ma derni√®re phrase pour qu'on ne passe pas √† c√¥t√© de toi : si demain cette offre venait √† √™tre cl√¥tur√©e et que tu penses regretter de ne pas avoir postul√©, c'est qu'elle t'a tap√© dans l'≈ìil.√áa serait dommage de d√©marrer 2024 avec un regret,Alors, n'h√©site pas, POSTULEüëá
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Embedded System Engineer,Le Bureau des Talents,"Royan, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/embedded-system-engineer-at-le-bureau-des-talents-3798663587?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=in3wjbvWjCsKm%2FPNXaf%2BbA%3D%3D&position=2&pageNum=7&trk=public_jobs_jserp-result_search-card,"Le Bureau des Talents est un cabinet de recrutement sp√©cialis√© dans la chasse, l‚Äôaccompagnement et le coaching des talents pour les startups, les scale-ups et les entreprises √† impact.üöÄNotre client est une scale up d√©veloppant des avions hybrides √©lectriques de pointe qui recherche un ing√©nieur syst√®mes pour rejoindre son bureau d'√©tudes syst√®mes bas√© √† Royan. Si vous souhaitez contribuer √† la r√©duction des √©missions de carbone dans le secteur de l'aviation et fa√ßonner l'avenir de l'aviation durable, postulez ici üëâ‚öíÔ∏èMissionsD√©finir l‚Äôarchitecture de syst√®me a√©ronautique, les modes op√©ratoires et les fonctions selon les exigences internes et externesG√©rer les exigences provenant des documents M√©tiers, Standards, S√©curit√©, et cahier des charges client durant toute la vie des syst√®mesDimensionner les syst√®mes et √©quipements pour assurer l‚Äôatteinte des performances.R√©diger les sp√©cifications des sous-syst√®mes et √©quipements d√©velopp√©s en interne ou externe.Coordonner, assurer et garantir la coh√©rence et compatibilit√© des syst√®mes entre les fournisseurs, les m√©tiers interne pour les interfaces, et les performances attendues.Collaborer avec les sp√©cialistes des disciplines transverses (certification, safety).Maintenir et garantir les r√©f√©rentiels et configurations techniques applicables.R√©diger la documentation √† destination du client ou des sous-traitants et, sur demande, participer aux revues techniques avec le clientR√©diger les rapports de tests de niveau syst√®mes et assurer la mise au point et l‚Äôint√©gration des fonctionsD√©finir et r√©aliser les v√©rifications fonctionnelles et de performances en collaboration avec les m√©tiers et l‚Äô√©quipe flight testR√©soudre les anomalies et probl√®mes techniques.Reporting technique aupr√®s de la Direction Technique.Assurer et piloter le bon avancement du d√©veloppement technique et supporter le projet sur la gestion des risques et optimisation.üë©üèªüë®üèΩProfilFormation Ing√©nieur Syst√®mes Embarqu√©s (ou g√©n√©raliste) ‚Äì Niveau Master 25 √† 10 ans d‚Äôexp√©rience professionnelle dans le domaine des syst√®mesExp√©rience CS25/CS23 fortement appr√©ci√©eBonne connaissance des normes DO-178C, DO-254 et DO-160Exp√©rience pratique souhait√©e en mati√®re de conception, d'int√©gration et de testBonne capacit√© √† travailler en √©quipe sur des projets complexes avec des contraintes calendaires fortesRigueur, force de proposition et aisance relationnelleEsprit d'analyse et de synth√®seForte autonomie, r√©activit√©, bon esprit d‚Äô√©quipeAdaptation √† un environnement start-up.Ma√Ætrise parfaite du Fran√ßais et de l‚ÄôAnglais, √©crit et oralBrevet ULM/Licence pilote priv√© avion/h√©licopt√®re appr√©ci√©


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800338540?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=LrlRSaMO5hk4llRUlffiTA%3D%3D&position=3&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence üöÄAnthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et d√©cident de cr√©er une solution SAAS ERP √† destination des ESN & soci√©t√©s de conseil, afin de ""travailler autrement"".BoondManager est ainsi n√© ü¶äAu c≈ìur de BoondManager, il y a l'id√©e que chacun(e) devrait avoir la possibilit√© de se r√©aliser dans son travail et sa carri√®re, de pouvoir ""les"" concilier avec sa vie personnelle. ü´∂Notre Mission ‚≠ê‚≠ê‚≠ê‚≠ê‚≠êF√©d√©rer sur un m√™me outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunit√©s, facturation, CRA) !Notre ADN ‚ù§Ô∏èNos 75 Boonders sont en full remote/100% t√©l√©travail dans toute la France.Le t√©l√©travail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'estü§ù 1500 clientsüë• 70.000 utilisateursüåç 21 paysüí∂ Rentable et autofinanc√©eü•∞ La Boondfamily est pass√©e de 30 √† 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? üëáLe PosteBoondManager ne cesse de grandir ! ü¶äAfin de r√©pondre √† notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'√©quipe BI/Performance ü¶äTout √ßa, c'est magnifique, mais on reste un peu sur notre faim‚Ä¶ nos plus grands r√™ves sont :Devenir le leader europ√©en des ERP pour les soci√©t√©s de conseils (on a de l'ambition).Et pour √ßa, on a besoin de toi !Nos Grands Principes üëå‚úÖ Mieux vaut s'excuser que de demander la permission. On encourage √† 300 % la prise d'initiative !‚úÖ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, √©coute !La (super) Team üèÜL'√©quipe Performance est compos√©e de talents pluridisciplinaires ! Fran√ßois s'occupe de la data (ton futur bin√¥me) Guillaume des projets de refactoring Manu de la stack ELK R√©mi c√¥t√© DevOps. Florens, ton futur managerLa performance touche l'ensemble des √©quipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plut√¥t sympa donc !Tes activit√©s : üëáOn Te Propose C√¥t√© Dataviz Cr√©ation dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Int√©gration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets n√©cessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de mani√®re transverse Sp√©cification et conception de dashboard de A √† ZC√¥t√© Data Analyst Cr√©ation de KPI via sql Challenger les perfs de nos Kpi (am√©liorer les temps de r√©sultats) R√©aliser les croisements de donn√©es pour la construction et le maintien du data warehouse Assurer la maintenance et l'√©volution des KPI du produit BoondC√¥t√© Engineering Suivi de l'int√©grit√© de la donn√©e (topologie, audit) Participer √† l'alimentation du Datawarehouse D√©veloppement, maintien et l'√©volution de l'architecture des donn√©es Recueillir les besoins des parties prenantes et sp√©cifier les besoins en dataNotre Stack Technique üåà Backend/Frontend : Java, Python (√† venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'√©quipe Perfs ü¶ä On se retrouve tous les lundis matin avec l'ensemble de l'√©quipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton √©volution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour √©changer avec le reste de la team Weekly avec toute l'√©quipe tech (les BB pour les intimes) le mercredi √† 14hTon Onboarding üöÄ1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Mont√©e en comp√©tence sur notre solution au travers de notre Boondgame Mont√©e en comp√©tence sur le m√©tier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des donn√©es qui permet de calculer cette valeur, r√©solution). √ätre capable de mettre les mains dans l'int√©gration √† boond des KPI (manipul√© le backend)6 Mois Capacit√© de cr√©er des nouveaux KPI √† partir des demandes de PO (requ√™te sql permettant de le calculer) Capable d'int√©grer de la dataviz. L'id√©e est que tu sois dans les meilleures dispositions en ma√Ætrisant notre environnement üí™ProfilEt toi, Qui es-tu ? ü§©üç∑ Tu adores pinot et je ne te parle pas de celui des charentesüí™ Tu as d√©j√† construit des tableaux de bords au travers d'un outil de Dataviz‚úçÔ∏è tu connais kafka et pas que l'√©crivainüòé Tu es capable d'√©crire des requ√™tes optimis√©s pour fabriquer la dataviz avec des exemples concrets en SQLüß† Python : Tu dois savoir d√©velopper des nouvelles fonctionnalit√©s, gestion des d√©pendances, challenger l'existant (qualit√© du code), compiler le projet.üöÄ Le + : Tu ma√Ætrises notre stack technique (on veut des projets significatifs)ü¶ä Le petit ++ : Tu connais le monde des ESNüôã‚Äç‚ôÄÔ∏è Mesdames, autorisez-vous √† candidater !Ce Qu'on T'offrira En Plus De Tout √áa üéÅüí∏ Un salaire entre 45k et 60Küè° 100% remote üá´üá∑ (plus de temps pour toi !)üå¥ 3 s√©minaires par an pour se retrouver et s'√©clater‚ÄØ!üòé 9 jours de cong√©s pay√©s suppl√©mentairesüè• Une mutuelle familiale (pas de suppl√©ments pour ta famille)üí∏ Une offre t√©l√©travail en plus de ton salaire !üéÅ Une offre mensuelle dans le coworking de ton choix !üßò Cours en ligne de m√©ditation, fitness et yoga chaque semaine !ü§ù Un plan d'√©pargne entreprise valoris√© √† hauteur de 300‚Äâ%üíª Une mise √† disposition d'un Macbook, 2 √©crans, casque, etc.ü¶ä On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !D√©roulement des entretiensüíª Un premier √©change avec Jean-Florian, notre Head Of TalentüöÄ Un entretien technique/culture fit avec Fran√ßois, ton futur bin√¥me c√¥t√© Dataü§ù Un √©change Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager ü§ìEt si tu as r√©ussi √† me lire jusqu'ici,voici ma derni√®re phrase pour qu'on ne passe pas √† c√¥t√© de toi : si demain cette offre venait √† √™tre cl√¥tur√©e et que tu penses regretter de ne pas avoir postul√©, c'est qu'elle t'a tap√© dans l'≈ìil.√áa serait dommage de d√©marrer 2024 avec un regret,Alors, n'h√©site pas, POSTULEüëá
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Groupe Karavel - Promovacances,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-karavel-promovacances-3802118837?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=JwBhIW28J%2Fe%2BCbrw3FcOMw%3D%3D&position=4&pageNum=7&trk=public_jobs_jserp-result_search-card,"Lanc√© en 2000, le Groupe KARAVEL est aujourd‚Äôhui le leader fran√ßais dans la vente de s√©jours sur Internet via ses deux marques phares, PROMOVACANCES, le sp√©cialiste des bons plans implant√©s au c≈ìur de Paris, et FRAM, fleuron toulousain du tourisme hexagonal r√©put√© pour ses labels Framissima et Jumbo.Avec plus de 5 millions de visiteurs uniques par mois sur ses diff√©rents sites, le Groupe d√©veloppe √©galement un r√©seau de 143 agences en France. KARAVEL s'appuie √©galement sur une √©quipe de plus de 900 collaborateurs dont plus de 100 d√©di√©s √† la recherche et la fabrication de voyages et 30 au seul service Qualit√©. Sa relation-client est assur√©e quant √† elle, outre ses agences, par une centaine de Conseillers en centre d'appels bas√©s √† Paris et Nice.En tant que Data Engineer, vous interviendrez sur la totalit√© de la chaine d√©cisionnelle au sein du p√¥le DATA, et serez charg√©, entre autres de : La participation au projet d‚Äôimpl√©mentation de notre nouvelle plateforme BI AZURE / SnowFlake / Power BI,Analyse de l‚Äôexistant et des nouveaux besoins m√©tiers,R√©alisation des sp√©cifications fonctionnelles et techniques,Mod√©lisation,Cr√©ation de package sous SSIS,Impl√©mentation des chargements de donn√©es vers SnowFlake,D√©veloppement sous cube Tabulaire (service AS Azure),R√©alisation de rapports sous Excel, et mod√®les de donn√©es Power BI,Recette et mise en production. Profil :Vous disposez de : De 3 √† 5 ann√©es d‚Äôexp√©rience sur la suite Microsoft BI (SSIS, SQLSERVER, SSAS, SSRS) avec une solide comp√©tence en SQL,De comp√©tences sur Snowflake (architecture, d√©veloppement, administration),D‚Äôune exp√©rience sur Power BI (jusqu‚Äô√† la conception du mod√®le de donn√©es, hors visualisations). Vous avez d√©montr√© un forte capacit√© d‚Äôadaptation et d‚Äôautonomie √† travailler au sein d‚Äôenvironnements complexes et h√©t√©rog√®nes en termes de syst√®mes d‚Äôinformation et de domaines fonctionnels couverts. Vous √™tes dot√© d'une forte culture de l'engagement et du r√©sultat, vous √™tes autonome, r√©actif et aimez relever les challenges. Vous avez d√©j√† une exp√©rience dans le secteur du digital et vous avez √©t√© confront√©s aux probl√®mes de qualit√© de donn√©es et de volum√©tries.A vos claviers !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800341290?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=v7v8nORRdaVgEdTjDdbMAQ%3D%3D&position=5&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence üöÄAnthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et d√©cident de cr√©er une solution SAAS ERP √† destination des ESN & soci√©t√©s de conseil, afin de ""travailler autrement"".BoondManager est ainsi n√© ü¶äAu c≈ìur de BoondManager, il y a l'id√©e que chacun(e) devrait avoir la possibilit√© de se r√©aliser dans son travail et sa carri√®re, de pouvoir ""les"" concilier avec sa vie personnelle. ü´∂Notre Mission ‚≠ê‚≠ê‚≠ê‚≠ê‚≠êF√©d√©rer sur un m√™me outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunit√©s, facturation, CRA) !Notre ADN ‚ù§Ô∏èNos 75 Boonders sont en full remote/100% t√©l√©travail dans toute la France.Le t√©l√©travail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'estü§ù 1500 clientsüë• 70.000 utilisateursüåç 21 paysüí∂ Rentable et autofinanc√©eü•∞ La Boondfamily est pass√©e de 30 √† 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? üëáLe PosteBoondManager ne cesse de grandir ! ü¶äAfin de r√©pondre √† notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'√©quipe BI/Performance ü¶äTout √ßa, c'est magnifique, mais on reste un peu sur notre faim‚Ä¶ nos plus grands r√™ves sont :Devenir le leader europ√©en des ERP pour les soci√©t√©s de conseils (on a de l'ambition).Et pour √ßa, on a besoin de toi !Nos Grands Principes üëå‚úÖ Mieux vaut s'excuser que de demander la permission. On encourage √† 300 % la prise d'initiative !‚úÖ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, √©coute !La (super) Team üèÜL'√©quipe Performance est compos√©e de talents pluridisciplinaires ! Fran√ßois s'occupe de la data (ton futur bin√¥me) Guillaume des projets de refactoring Manu de la stack ELK R√©mi c√¥t√© DevOps. Florens, ton futur managerLa performance touche l'ensemble des √©quipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plut√¥t sympa donc !Tes activit√©s : üëáOn Te Propose C√¥t√© Dataviz Cr√©ation dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Int√©gration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets n√©cessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de mani√®re transverse Sp√©cification et conception de dashboard de A √† ZC√¥t√© Data Analyst Cr√©ation de KPI via sql Challenger les perfs de nos Kpi (am√©liorer les temps de r√©sultats) R√©aliser les croisements de donn√©es pour la construction et le maintien du data warehouse Assurer la maintenance et l'√©volution des KPI du produit BoondC√¥t√© Engineering Suivi de l'int√©grit√© de la donn√©e (topologie, audit) Participer √† l'alimentation du Datawarehouse D√©veloppement, maintien et l'√©volution de l'architecture des donn√©es Recueillir les besoins des parties prenantes et sp√©cifier les besoins en dataNotre Stack Technique üåà Backend/Frontend : Java, Python (√† venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'√©quipe Perfs ü¶ä On se retrouve tous les lundis matin avec l'ensemble de l'√©quipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton √©volution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour √©changer avec le reste de la team Weekly avec toute l'√©quipe tech (les BB pour les intimes) le mercredi √† 14hTon Onboarding üöÄ1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Mont√©e en comp√©tence sur notre solution au travers de notre Boondgame Mont√©e en comp√©tence sur le m√©tier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des donn√©es qui permet de calculer cette valeur, r√©solution). √ätre capable de mettre les mains dans l'int√©gration √† boond des KPI (manipul√© le backend)6 Mois Capacit√© de cr√©er des nouveaux KPI √† partir des demandes de PO (requ√™te sql permettant de le calculer) Capable d'int√©grer de la dataviz. L'id√©e est que tu sois dans les meilleures dispositions en ma√Ætrisant notre environnement üí™ProfilEt toi, Qui es-tu ? ü§©üç∑ Tu adores pinot et je ne te parle pas de celui des charentesüí™ Tu as d√©j√† construit des tableaux de bords au travers d'un outil de Dataviz‚úçÔ∏è tu connais kafka et pas que l'√©crivainüòé Tu es capable d'√©crire des requ√™tes optimis√©s pour fabriquer la dataviz avec des exemples concrets en SQLüß† Python : Tu dois savoir d√©velopper des nouvelles fonctionnalit√©s, gestion des d√©pendances, challenger l'existant (qualit√© du code), compiler le projet.üöÄ Le + : Tu ma√Ætrises notre stack technique (on veut des projets significatifs)ü¶ä Le petit ++ : Tu connais le monde des ESNüôã‚Äç‚ôÄÔ∏è Mesdames, autorisez-vous √† candidater !Ce Qu'on T'offrira En Plus De Tout √áa üéÅüí∏ Un salaire entre 45k et 60Küè° 100% remote üá´üá∑ (plus de temps pour toi !)üå¥ 3 s√©minaires par an pour se retrouver et s'√©clater‚ÄØ!üòé 9 jours de cong√©s pay√©s suppl√©mentairesüè• Une mutuelle familiale (pas de suppl√©ments pour ta famille)üí∏ Une offre t√©l√©travail en plus de ton salaire !üéÅ Une offre mensuelle dans le coworking de ton choix !üßò Cours en ligne de m√©ditation, fitness et yoga chaque semaine !ü§ù Un plan d'√©pargne entreprise valoris√© √† hauteur de 300‚Äâ%üíª Une mise √† disposition d'un Macbook, 2 √©crans, casque, etc.ü¶ä On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !D√©roulement des entretiensüíª Un premier √©change avec Jean-Florian, notre Head Of TalentüöÄ Un entretien technique/culture fit avec Fran√ßois, ton futur bin√¥me c√¥t√© Dataü§ù Un √©change Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager ü§ìEt si tu as r√©ussi √† me lire jusqu'ici,voici ma derni√®re phrase pour qu'on ne passe pas √† c√¥t√© de toi : si demain cette offre venait √† √™tre cl√¥tur√©e et que tu penses regretter de ne pas avoir postul√©, c'est qu'elle t'a tap√© dans l'≈ìil.√áa serait dommage de d√©marrer 2024 avec un regret,Alors, n'h√©site pas, POSTULEüëá
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Analytics Engineer,MYM,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/analytics-engineer-at-mym-3799459109?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=NHLu4y0GD4mPAuVx9NCHDA%3D%3D&position=6&pageNum=7&trk=public_jobs_jserp-result_search-card,"Poste :Tu int√©greras la Team DATA et tu seras sous la responsabilit√© de notre super Data Expert üöÄ.Il s‚Äôagit d‚Äôune cr√©ation de poste pour lequel, tu vas exprimer toute ta cr√©ativit√© en analyse DATA !Ton r√¥le consistera √† contribuer √† d√©velopper les usages DATA de nos 50 employ√©s r√©partis dans les diff√©rentes Team : Product, Customer, Growth, Finance,‚Ä¶..La data platform est en pleine construction et tu participeras √† sa cr√©ation, tant sur l‚Äôanalyse et la compr√©hension de MYM que sur la construction d‚Äôun Datawarehouse efficace et pertinent.Tes principales t√¢ches day-to-day üíº:En √©troite collaboration avec Pierre, notre Head of Data au sein de l'√©quipe, tes responsabilit√©s incluent de :Construire des mod√®les de donn√©es efficaces et robustes depuis de nombreuses sourcesParticiper au d√©ploiement de nouvelles solutions (tracking, self service analytics, real time analytics)Mettre en ≈ìuvre des solutions pour am√©liorer la qualit√© des donn√©es.Travailler sur des projets end to end : ingestion, transformation, usage (visualisation et reverse ETL)Profil üèó:Exp√©rience de l'utilisation de SQL (toute exp√©rience avec des moteurs SQL est appr√©ci√©e )Une forte app√©tence pour le DATA ModelingUne premi√®re exp√©rience r√©ussie en tant que Data Analyst, avec la ma√Ætrise d‚Äôun langage de programmation type PythonConnaissance de base d'UNIX et de GIT.Exp√©rience avec un fournisseur de cloud (nous utilisons AWS).Tu as un 1 √† 3 ans d‚Äôexp√©rience en DATAId√©alement, tu as une exp√©rience d‚Äôau moins 3 ans en tant qu'Analytics Engineer.Ma√Ætrise de l'anglaisNotre Stack technique üõ†Ô∏è:Datawarehouse : AWS Redshift / SpectrumIngestion : Airbyte / RudderstackData Transformation : DBTOrchestration : DagsterCDP / Reverse ETL : RudderstackSi tu te retrouves dans cette annonce, alors rejoins la Team MYM!Les avantages √† travailler chez MYM :Travailler chez MYM, c‚Äôest rejoindre une entreprise qui comprend les enjeux des salari√©s d‚Äôaujourd‚Äôhui :Une Work-Life BalanceTu disposes d‚Äôun pass Gymlib üö¥ ü§∫2 jours de T√©l√©travail possible par semaine üë©üèª‚Äçüíªüë®üèæ‚ÄçüíªDes bureaux design et moderne en plein coeur de la Silicon IX√®me √† ParisUn √©quipement informatique dernier criBien √©videmment, nous disposons de :Tickets Restaurant SwileMutuelle BenefizNous proposons √©galement:Des moments partag√©s entre coll√®gues, en visio et en pr√©sentiel üçªUn management √† l‚Äô√©coute et ouvert aux suggestions et propositions salari√©s ü¶∏üèæ‚Äç‚ôÇÔ∏èü¶∏‚Äç‚ôÄÔ∏èProcess de recrutement : Entretien avec Omar, notre Chief People (45 minutes)Entretien avec Pierre, notre Head of DATA (60 minutes)Echange avec Gauthier et Quentin, respectivement, le COO et le CTO.Rencontre avec Gaspard et Pierre, les fondateurs de MYM (30 minutes)


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer m√©dia,MP DATA,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-m%C3%A9dia-at-mp-data-3806329502?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=CmDtQw%2Fp4lqZfnOfNo3uUg%3D%3D&position=7&pageNum=7&trk=public_jobs_jserp-result_search-card,"MP DATA est une soci√©t√© sp√©cialis√©e dans l‚Äôacquisition, le traitement, et la valorisation des donn√©es. Depuis sa cr√©ation en 2015, MP DATA accompagne ses clients, majoritairement industriels, dans le management de leur performance et l‚Äôexploitation de leurs donn√©es.MP DATA accompagne ses clients sur toute la chaine au travers de 3 p√¥les d‚Äôexpertise : Conseil et Strat√©gie, Infrastructure & CloudOPS, Data Science.Rejoindre MP DATA, c‚Äôest la garantie de travailler sur des sujets passionnants avec un cadre technique fort. MP DATA, recrute un Data Engineer afin de travailler pour notre client dans le secteur des M√©dias :Vos missions seront les suivantes :Renforcer notre connaissance 360 de nos clients/utilisateurs (segmentation, enrichissement, activation de la donn√©e‚Ä¶),Superviser les alimentations de production gr√¢ce aux outils (AirFlow‚Ä¶),D√©velopper l'offre de ciblage publicitaire en TV segment√©e,Gestion et maintenance de l'offre,‚Å†Apport d'une expertise sur l'offre de ciblage afin d'am√©liorer les recommandations,annonceurs/agences,Travailler avec les Data Scientists √† la mise en ≈ìuvre des mod√®les statistiques et algorithmiques,Profil recherch√© :De formation Bac+5 (ou plus) en d√©veloppement informatique / Data Engineering, vous justifiez d‚Äôune exp√©rience professionnelle significative dans le secteur de la Publicit√© au cours de laquelle vous avez pu d√©velopper les comp√©tences techniques suivantes :PythonSQLPysparkStreaming Process de recrutement :Pr√©-qualification t√©l√©phonique de 30 minEntretien technique√âchange avec l'√©quipe


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - ILM - F/H,Niji,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-ilm-f-h-at-niji-3804561156?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=vsvuELSodBwGR1%2BVEmeITA%3D%3D&position=8&pageNum=7&trk=public_jobs_jserp-result_search-card,"Nous sommes plus qu‚Äôun simple cabinet de conseil, qu'une agence de design et qu'une soci√©t√© de mise en ≈ìuvre technologique. Nous sommes le partenaire de la transformation digitale de nos clients grands-comptes et ETI, que nous accompagnons de l‚Äôid√©e √† la r√©alit√©.Nous associons, dans une m√™me cha√Æne de valeur, conseil en strat√©gie, design de service et design √©motionnel, management et valorisation de la donn√©e, ing√©nierie et conseil technologique, r√©alisation logicielle et expertise en cybers√©curit√©.Notre singularit√© repose sur les talents pluriels de nos √©quipes, au service de la satisfaction et de la performance de nos clients.Le P√¥le Data De Niji C'est Avant Tout Une √âquipe √† Taille Humaine Et Pluridisciplinaire, Compos√©e De Consultants Et Experts Qui Conseillent Et Appuient Nos Clients Sur Toutes Les √âtapes Du Cycle Des Donn√©esde la collecte √† la valorisation dans des services innovants,en passant par les architectures de stockage et de services.Nos consultants sont bas√©s en Ile-de-France et en r√©gions (Nantes, Rennes, Lille, Lyon et Bordeaux).Nos 3 directeurs : experts confirm√©s de la gouvernance des donn√©es, de la data science de l'IA et des m√©thodologies d'industrialisation de l'IA (MLOps, DataOps), recherchent de nouveaux talents tous compl√©mentaires avec plusieurs niveaux de qualification et s√©niorit√©, qui travailleront en synergie avec la large palette de comp√©tences de Niji en d√©veloppement, communication, cybers√©curit√© et en conseil.Int√©grer le P√¥le Data de Niji c'est avoir l'assurance d'√™tre accompagn√© dans sa progression et le d√©veloppement rapide de ses comp√©tences ,vous suivez un parcours de formation riche et diversifi√©, visant √† vous faire rapidement monter en expertise et √† vous certifier.En tant que Data Engineer, vos principales missions seront les suivantes : D√©velopper et maintenir une architecture de donn√©es robuste, √©volutive et s√©curis√©e, en tenant compte des besoins sp√©cifiques des clients.  G√©rer et optimiser les pipelines de donn√©es, en assurant la collecte, le stockage, le traitement et la mise √† disposition des donn√©es de mani√®re fiable et performante.  Assurer la qualit√© des donn√©es en mettant en place des contr√¥les de qualit√©, des tests et des processus de validation, conform√©ment aux exigences des clients.  Participer au maintien de la documentation technique, les bonnes pratiques et les standards de d√©veloppement au sein de l'√©quipe.Profil recherch√©Si VousAvez obtenu un dipl√¥me en universit√©, √©cole de commerce ou √©quivalent type bac +5 Ma√Ætrisez l'anglais √† l'√©crit comme √† l'oral Avez de solides connaissances en architecture et en mod√©lisation des donn√©es Ma√Ætrisez des technologies et des outils li√©s au Big Data (Hadoop, Spark, Hive, etc.) Ma√Ætrisez les outils d‚Äôindustrialisation des pipelines data tel que Docker, Kubernetes, Dataiku, Jenkins‚Ä¶ Avez une exp√©rience avec les langages de programmation utilis√©s dans le domaine des donn√©es, tels que : Python,R, Scala, SQL, etc. Avez une exp√©rience dans la conception et la mise en ≈ìuvre de pipelines de donn√©esAlors‚Ä¶ Venez participer au dynamisme de notre site en rejoignant notre Team Data Niji !L'aventure NijiProcess de recrutement : premier contact RH puis rencontre avec nos op√©rationnels.Rejoindre l'exp√©rience Niji c'est avoir l'assurance de participer √† une aventure humaine dans un environnement de travail motivant, challengeant et innovant.NijiU: notre plateforme de formation digital learning contenant pr√®s de 3 000 modules en acc√®s libre.Nos valeurs : Audace - Bienveillance - Performance ‚Äì Talent. Si ces mots vous parlent, venez faire la diff√©rence chez Niji !En rejoignant Niji, vous int√©grez une entreprise dont la politique RSE contribue √† la promotion de la diversit√© et de l‚Äô√©galit√© des chances, notamment pour les personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
"Software Engineer, Android",amo,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-android-at-amo-3802326561?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=B15khhCzRgqhNvOyNaFfXQ%3D%3D&position=9&pageNum=7&trk=public_jobs_jserp-result_search-card,"Looking for someone to join us as one of the first members of the Android team. This means participating in all design and product decisions of the early days of product centric company.In the initial months, you'll be working closely with the founding team, gradually taking ownership of central components and features. Given our early stage, we're seeking a versatile engineers comfortable contributing to various aspects of the company's foundation.We value team members who delve deep into their respective domains, aiming to cultivate a team of subject matter experts. This commitment to expertise is an expectation for every team member.As an Android engineer, your day-to-day will include:Feature DevelopmentYou‚Äôll be responsible for delivering unique, high-quality UI and features in a fast-moving environment. We like to push the push the limits of what‚Äôs possible, so be ready to use low-level APIs and go beyond what‚Äôs provide by the Android frameworks: building shaders to create dynamic effects in various media, writing a custom 2D scrolling rendering system with almost infinite zooming, etc.Platform DevelopmentYou‚Äôll participate in the creation and improvements of the platform, in order to increase the velocity and quality of the work of the whole development team. That will include things like synchronizing a code-generated library for reading/writing config settings between the server and the client (like feature configuration, feature flags, etc.) or implementing a cross-platform realtime type-safe analytics system.Roadmap Creation and IdeationYou‚Äôll also be an active participant of a the roadmap creation and ideation. You‚Äôll be expected to help identify the right tradeoffs and bring ideas from a product and engineering perspective.Knowledge SharingWe love learning from each other, so we push ourselves to stay up to date with the latest trends and best practices in backend engineering. So we‚Äôll be highly encouraging you to attend conferences, participate in online communities, and share your learnings internally.Your Skills & Experience5+ years of overall developer experience, with ideally at least 2 years of professional experience in native Android development using Kotlin or Java. Good understanding of computer systems fundamentals (Program execution, Linking, Multithreading, etc.). Professional or academic experience in low-level languages like C, C++ or Rust is a plus!Experience in Graphics Programming using APIs such as OpenGL, Vulkan or Metal. Passion and experience building consumer-facing products - we‚Äôd love to hear about apps you've made!Life at amoTo ensure that everyone is set up for success within our way of working, we work together onsite 5 days a week.We wanted to make sure coming to the office is as comfortable as possible for you:We chose a location in central Paris, near Opera (Metro lines 3,8,9 and RER A). We have a beautiful Parisian-style office with high ceilings, balconies, and huge windows. So a lot of natural light!We reimburse your commuting expenses 100%. Because life outside of work should also be stress-free, we cover:Health care (100% coverage). Maternity Leave, Paternity Leave, Second Parent Leave (salary maintained at 100%). We shut down entirely twice a year ‚Äî two weeks in the summer and one week in the winter to allow everyone to truly recharge and to avoid prolonged slowdowns (especially in the summer). This enables everyone to actually disconnect and enjoy their vacation. No Slack, no email, no FOMO. Per French standard, we also offer another 4 weeks to allow team members to choose when they want to take time off. We love the diverse perspectives we get from having people from all over the world join us, and so we of course support relocation to Paris with:Help and sponsored visa process. 1 month of Airbnb 100% covered by amo upon arrival. Assistance from Settlesweet to find your permanent home. Help with french paperwork like opening a french social security account, tax forms and more. French lessons to be fully set with your new Parisian life.


        Show more

        


        Show less","{'ProgLanguage': ['Java', 'C++', 'R', 'Go', 'Kotlin'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Slack']}"
Data Engineer / D√©veloppeur BI BigData # H/F,Air France,"Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur-bi-bigdata-%23-h-f-at-air-france-3728524792?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=BBoGFA9lsmQrGxDm%2BqCVcg%3D%3D&position=10&pageNum=7&trk=public_jobs_jserp-result_search-card,"Description du poste Intitul√© du poste Data Engineer / D√©veloppeur BI BigData # H/F M√©tier Syst√®mes d'informations - D√©veloppement Cat√©gorie socio-professionnelle Cadre Pr√©sentation du contexte Vous avez peut-√™tre d√©j√† voyag√© avec nous, mais que connaissez-vous de nos m√©tiers et de la richesse des donn√©es qu‚Äôils g√©n√®rent au quotidien ? Comment le traitement et l‚Äôexploitation de ces donn√©es peut contribuer √† notre strat√©gie de Revenue Management, ou encore aux multiples op√©rations √† r√©aliser pour permettre √† un vol de partir √† l‚Äôheure ?Air France-KLM fait r√™ver 104 millions de passagers par an, en les emmenant vers plus de 250 destinations, gr√¢ce √† une flotte de plus de 500 appareils. Le Groupe emploie 80 000 collaborateurs partout dans le monde :les opportunit√©s sont vastes pour mettre √† profit ses comp√©tences, apprendre et se d√©velopper !Le d√©partement de d√©veloppement DATA, OR & AI d‚ÄôAir France, au sein de la direction des Syst√®mes d‚ÄôInformation, intervient dans toute la cha√Æne de captation et de traitement des donn√©es du groupe pour d√©livrer √† nos m√©tiers des solutions applicatives cl√©s en main.Le d√©partement est √©galement en charge de l‚Äôensemble des outils techniques (ETL, DataLakes, DataWarehouses, Data visualisation) et du d√©veloppement des talents et comp√©tences de Data Engineering.Notre mission ? Transformer la donn√©e brute en d√©cision intelligente, pour mieux optimiser les m√©tiers d‚ÄôAir France ‚Äì KLM !Pour cela, nous avons chacun un r√¥le essentiel √† jouer, pourquoi le v√¥tre ne serait pas celui de Data Engineer ?Description De La MissionAu sein de notre d√©partement, vous travaillerez main dans la main avec d‚Äôautres Data Engineers ainsi qu‚Äôavec des sp√©cialistes des m√©tiers.Int√©gr√© au sein d‚Äôune product team agile passionn√©e et dynamique : Vous participez √† l‚Äôanalyse des besoins m√©tiers du commercial, des op√©rations a√©riennes, de l‚Äôexploitation sol en a√©roport, de la maintenance a√©ronautique ou encore du Cargo. Vous contribuez √† la d√©finition, au d√©veloppement, √† l‚Äôindustrialisation et √† la maintenance d‚Äôapplications Big Data ou en Business Intelligence Vous pr√©sentez la restitution de vos travaux et accompagnez les utilisateurs d‚Äôun point de vue fonctionnel ou m√©thodologiqueVous serez en contact avec les directions m√©tier du groupe Air France KLM.Nous attachons beaucoup d'importance au d√©veloppement des comp√©tences de nos collaborateurs ainsi qu‚Äô√† leur offrir des conditions de travail favorables √† l‚Äôautonomie et aux missions √† forte valeur ajout√©e. L'ouverture, le respect, la bienveillance et le partage sont des valeurs humaines port√©es par l'entreprise. Profil recherch√© Vous √™tes dipl√¥m√© de niveau Master ou Ing√©nieur dans les domaines informatiques, vous avez acquis une exp√©rience professionnelle dans le d√©veloppement d‚Äôapplications. Vous disposez d‚Äôune exp√©rience du d√©veloppement indispensable en Backend / Java Vous ma√Ætrisez les bases de donn√©es relationnelles et le langage SQLEn Compl√©ment, Vous Avez Une Connaissance Ou Une Exp√©rience Dans Tout Ou Partie Des Concepts Ou Outils Suivants Base de donn√©es noSQL (MongoDB, HBase, REDIS) ou Data Warehouse Teradata Environnement Big Data (Spark, Hadoop, Elasticsearch, Kafka, ...) Outil de Datavisualisation (Spotfire, PowerBI, Qlik ou Kibana) Solutions de Cloud hybride(Ces comp√©tences compl√©mentaires ou manquantes pouvant aussi s'acqu√©rir √† travers un parcours de reskilling et de formations aux outils du data engineering dispens√© en interne).Vous avez particip√© √† des projets organis√©s en Scrum ou Kanban, et avez peut-√™tre m√™me ≈ìuvr√© comme Scrum-Master, ce qui vous permettra de vous int√©grer ais√©ment au sein d‚Äôune Product Team. Votre esprit de synth√®se, votre force de conviction et votre ma√Ætrise de la communication facilitent les d√©cisions avec l‚Äôensemble des collaborateurs de l‚Äô√©quipe, √©ventuellement en langue anglaise, √† l‚Äô√©crit comme √† l‚Äôoral.Vous √™tes autonome, rigoureux(se), responsable et curieux(se), vous aimez travailler en √©quipe. Vous poss√©dez de bonnes capacit√©s d'√©coute, d'analyse, de synth√®se et de communication.Et bien s√ªr, vous √™tes passionn√©(e), enthousiaste et ing√©nieux(se)Ce que nous vous offrons De la cr√©ation de valeur pour l‚Äôensemble des m√©tiers d‚ÄôAir France KLM Des challenges et probl√©matiques complexes √† r√©soudre L‚Äôopportunit√© de d√©ployer des solutions Data industrielles √† l‚Äô√©chelle ! Une grande part de responsabilit√© dans une structure hi√©rarchique horizontale Un important degr√© de libert√© pour apprendre et d√©velopper son expertise au sein de l‚Äô√©quipeOn vous attend le plus rapidement possible ! Et pour une dur√©e ind√©termin√©e ;) Type de contrat CDI Date de prise de poste souhait√©e 02/11/2023 Temps partiel possible Non Type d'horaires AdministratifProfil candidat Niveau d'√©tudes min. requis Bac + 5 et plus / 3√®me ann√©e grande √©cole Langue Anglais (4 - Confirm√© / C1)Localisation du poste Localisation du poste France, Provence-Alpes-C√¥te d'Azur, Alpes Maritimes (06) Site Valbonne
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - 100% remote,BoondManager,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800335850?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=Kn2p9pqhoyVwFDryPfAbOA%3D%3D&position=11&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence üöÄAnthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et d√©cident de cr√©er une solution SAAS ERP √† destination des ESN & soci√©t√©s de conseil, afin de ""travailler autrement"".BoondManager est ainsi n√© ü¶äAu c≈ìur de BoondManager, il y a l'id√©e que chacun(e) devrait avoir la possibilit√© de se r√©aliser dans son travail et sa carri√®re, de pouvoir ""les"" concilier avec sa vie personnelle. ü´∂Notre Mission ‚≠ê‚≠ê‚≠ê‚≠ê‚≠êF√©d√©rer sur un m√™me outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunit√©s, facturation, CRA) !Notre ADN ‚ù§Ô∏èNos 75 Boonders sont en full remote/100% t√©l√©travail dans toute la France.Le t√©l√©travail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'estü§ù 1500 clientsüë• 70.000 utilisateursüåç 21 paysüí∂ Rentable et autofinanc√©eü•∞ La Boondfamily est pass√©e de 30 √† 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? üëáLe PosteBoondManager ne cesse de grandir ! ü¶äAfin de r√©pondre √† notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'√©quipe BI/Performance ü¶äTout √ßa, c'est magnifique, mais on reste un peu sur notre faim‚Ä¶ nos plus grands r√™ves sont :Devenir le leader europ√©en des ERP pour les soci√©t√©s de conseils (on a de l'ambition).Et pour √ßa, on a besoin de toi !Nos Grands Principes üëå‚úÖ Mieux vaut s'excuser que de demander la permission. On encourage √† 300 % la prise d'initiative !‚úÖ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, √©coute !La (super) Team üèÜL'√©quipe Performance est compos√©e de talents pluridisciplinaires ! Fran√ßois s'occupe de la data (ton futur bin√¥me) Guillaume des projets de refactoring Manu de la stack ELK R√©mi c√¥t√© DevOps. Florens, ton futur managerLa performance touche l'ensemble des √©quipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plut√¥t sympa donc !Tes activit√©s : üëáOn Te Propose C√¥t√© Dataviz Cr√©ation dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Int√©gration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets n√©cessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de mani√®re transverse Sp√©cification et conception de dashboard de A √† ZC√¥t√© Data Analyst Cr√©ation de KPI via sql Challenger les perfs de nos Kpi (am√©liorer les temps de r√©sultats) R√©aliser les croisements de donn√©es pour la construction et le maintien du data warehouse Assurer la maintenance et l'√©volution des KPI du produit BoondC√¥t√© Engineering Suivi de l'int√©grit√© de la donn√©e (topologie, audit) Participer √† l'alimentation du Datawarehouse D√©veloppement, maintien et l'√©volution de l'architecture des donn√©es Recueillir les besoins des parties prenantes et sp√©cifier les besoins en dataNotre Stack Technique üåà Backend/Frontend : Java, Python (√† venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'√©quipe Perfs ü¶ä On se retrouve tous les lundis matin avec l'ensemble de l'√©quipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton √©volution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour √©changer avec le reste de la team Weekly avec toute l'√©quipe tech (les BB pour les intimes) le mercredi √† 14hTon Onboarding üöÄ1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Mont√©e en comp√©tence sur notre solution au travers de notre Boondgame Mont√©e en comp√©tence sur le m√©tier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des donn√©es qui permet de calculer cette valeur, r√©solution). √ätre capable de mettre les mains dans l'int√©gration √† boond des KPI (manipul√© le backend)6 Mois Capacit√© de cr√©er des nouveaux KPI √† partir des demandes de PO (requ√™te sql permettant de le calculer) Capable d'int√©grer de la dataviz. L'id√©e est que tu sois dans les meilleures dispositions en ma√Ætrisant notre environnement üí™ProfilEt toi, Qui es-tu ? ü§©üç∑ Tu adores pinot et je ne te parle pas de celui des charentesüí™ Tu as d√©j√† construit des tableaux de bords au travers d'un outil de Dataviz‚úçÔ∏è tu connais kafka et pas que l'√©crivainüòé Tu es capable d'√©crire des requ√™tes optimis√©s pour fabriquer la dataviz avec des exemples concrets en SQLüß† Python : Tu dois savoir d√©velopper des nouvelles fonctionnalit√©s, gestion des d√©pendances, challenger l'existant (qualit√© du code), compiler le projet.üöÄ Le + : Tu ma√Ætrises notre stack technique (on veut des projets significatifs)ü¶ä Le petit ++ : Tu connais le monde des ESNüôã‚Äç‚ôÄÔ∏è Mesdames, autorisez-vous √† candidater !Ce Qu'on T'offrira En Plus De Tout √áa üéÅüí∏ Un salaire entre 45k et 60Küè° 100% remote üá´üá∑ (plus de temps pour toi !)üå¥ 3 s√©minaires par an pour se retrouver et s'√©clater‚ÄØ!üòé 9 jours de cong√©s pay√©s suppl√©mentairesüè• Une mutuelle familiale (pas de suppl√©ments pour ta famille)üí∏ Une offre t√©l√©travail en plus de ton salaire !üéÅ Une offre mensuelle dans le coworking de ton choix !üßò Cours en ligne de m√©ditation, fitness et yoga chaque semaine !ü§ù Un plan d'√©pargne entreprise valoris√© √† hauteur de 300‚Äâ%üíª Une mise √† disposition d'un Macbook, 2 √©crans, casque, etc.ü¶ä On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !D√©roulement des entretiensüíª Un premier √©change avec Jean-Florian, notre Head Of TalentüöÄ Un entretien technique/culture fit avec Fran√ßois, ton futur bin√¥me c√¥t√© Dataü§ù Un √©change Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager ü§ìEt si tu as r√©ussi √† me lire jusqu'ici,voici ma derni√®re phrase pour qu'on ne passe pas √† c√¥t√© de toi : si demain cette offre venait √† √™tre cl√¥tur√©e et que tu penses regretter de ne pas avoir postul√©, c'est qu'elle t'a tap√© dans l'≈ìil.√áa serait dommage de d√©marrer 2024 avec un regret,Alors, n'h√©site pas, POSTULEüëá
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Madonne Core (H/F),Natixis Corporate & Investment Banking,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-madonne-core-h-f-at-natixis-corporate-investment-banking-3794007401?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=49FelUpEzMM66BeHGNHnsg%3D%3D&position=12&pageNum=7&trk=public_jobs_jserp-result_search-card,"Acteur financier d'envergure internationale, Natixis Corporate & Investment Banking met √† disposition des entreprises, institutions financi√®res, sponsors financiers, souverains et supranationaux une palette de services en conseil, investment banking, financements, banque commerciale et sur les march√©s de capitaux.  Ses √©quipes d'experts, pr√©sentes dans 30 pays, conseillent les clients sur leur d√©veloppement strat√©gique en les accompagnant dans la croissance et la transformation de leurs activit√©s tout en maximisant leur impact positif. Natixis Corporate & Investment Banking s'est engag√©e √† soutenir la transition environnementale en alignant son bilan financier sur une trajectoire de +1,5 ¬∞C d'ici √† 2050.  Natixis Corporate & Investment Banking fait partie du p√¥le Global Financial Services du Groupe BPCE, 5e √©tablissement financier europ√©en et 2e acteur bancaire en France √† travers ses r√©seaux Banque Populaire et Caisse d'Epargne.  Si vous √™tes enthousiaste √† l'id√©e de relever des d√©fis passionnants, d'avoir un impact et de contribuer √† la construction du monde de demain, rejoignez-nous et faites bien plus qu'un simple job.Vous rejoignez l'√©quipe Core en charge de la maintenance √©volutive des applications Madonne (R√©colte, Explication et Validation du PnL) et BOP (Base transactionnelle unifi√©e au coeur de l'IT Risque). Au quotidien vous avez pour missions de :Participer √† l'adaptation de nos applications en ad√©quation avec les besoins m√©tiers (nouveaux produits, nouvelles r√®glementations, nouveaux SI Front) ;Participer activement √† la modernisation de nos outils, modernisation de notre cha√Æne CI/CD, bascule des process Legacy vers notre stack technique cible (Hadoop, Spark/Scala, SingleStore) ;Monter en comp√©tences sur le domaine fonctionnel de l'analyse et de la certification du PL. Vous d√©velopperez une compr√©hension globale des cha√Ænes de traitements ;Participer √† tous les travaux de modernisation de notre SI, et √™tre donc engag√© dans la migration de nombreux process vers le DataLake Risk. #TransformativeFinanceCe poste est bas√© √† Paris avec la possibilit√© de t√©l√©travailler.En tant que Top Employer, nous pla√ßons nos collaborateurs au centre de nos attentions. Des dispositifs de mobilit√© interne, d√©veloppement de carri√®re et de formation vous permettent de grandir et de vous √©panouir tout au long de votre parcours.Vous √©voluez dans un environnement de travail hybride, inclusif et favorisant le collaboratif.Vous avez √©galement la possibilit√© de vous engager en faveur de la soci√©t√© et de causes qui vous tiennent √† c≈ìur via notre fondation d'entreprise.  A propos du processus de recrutementVous serez contact√© par l'un de nos recruteurs avant de rencontrer nos experts m√©tier (manager, membre de l'√©quipe ou de la fili√®re m√©tier).Qui √™tes-vous ? Si vous vous reconnaissez dans la description suivante vous √™tes fait pour travailler avec nous :  Vous souhaitez b√©n√©ficier d'une premi√®re exp√©rience significative en d√©veloppement Spark et Scala.  Vous maitrisez : * Les m√©thodes agiles, notamment SCRUM ; * Le langage C#, en vous permettant de comprendre et intervenir sur du code legacy ; * Le langage SQL et vous avez une app√©tence pour la manipulation de la data.  Vous √™tes : * Reconnu par votre esprit d'√©quipe ; * Capable de communiquer avec des publics diff√©rents, notamment avec le m√©tier ; * Autonome et nt√©ress√© par l'environnement finance de march√©.  Vous maitrisez l'anglais avec un niveau B1.  Dites-nous que vous √™tes int√©ress√© en r√©pondant √† cette annonce.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst,Web Transition,"Marcq-en-Bar≈ìul, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-at-web-transition-3798106460?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=0WGSeAkrGK40s2dO7uyUAQ%3D%3D&position=13&pageNum=7&trk=public_jobs_jserp-result_search-card,"Web Transition, c‚Äôest qui ?   Fond√©e en 2011, Web transition est une entreprise de services num√©riques op√©rant sur le march√© de l‚ÄôIT/Digital !  Constituant une part essentielle de MoOngy Digital Lab, Web Transition accompagne ses clients grands comptes sur leurs projets de Webmarketing, de Design, Gestion de projet et √©galement en Data !  Notre objectif : nous implanter comme un acteur principal sur le march√© de la Transformation Digitale en accompagnant et valorisant les comp√©tences de nos collaborateurs ! Nous sommes convaincus que le succ√®s de MoOngy Digital Lab r√©side dans la somme des potentiels de nos √©quipes ü§ù  Ton √©quipe : La tribu Data  Parce qu‚Äôil est indispensable que tu puisses partager tes connaissances mais aussi en acqu√©rir de nouvelles, tu feras partie de l‚Äôune de nos tribus : celle de la Data. De plus, cela te permettra d‚Äô√™tre acteur dans le d√©veloppement et la strat√©gie de Web Transition. Ce syst√®me de co-r√©flexion et co-construction est un fondement essentiel chez nous !  Dans cette aventure, tu : Optimises les requ√™tes SQL ;Construis les mod√®les de r√©gression ;Analyses la rentabilit√© des actions marketing ;R√©alises des √©tudes ad hoc sur les comportements clients ;Produits et automatise le reporting. Rejoins-nous si tu as : Un BAC+5 en √©cole de commerce ou web,ainsi que d'une exp√©rience de 3 √† 5 ans dans l‚Äôanimation digitale retail, avec une connaissance des sp√©cificit√©s du digital. Une connaissance approfondie des √©cosyst√®mes web et E-Commerce.Une aisance avec les indicateurs et tu as une bonne capacit√© d'analyse.Maitrises POWER BI.  Ton savoir-√™tre : ¬∑ Ouvert d‚Äôesprit ¬∑ Respectueux des diff√©rences de chacun ¬∑ Curieux ¬∑ Proactif  Par o√π on commence ? ¬∑ Un premier entretien RH d‚Äô1h pour comprendre ton parcours et tes aspirations ¬∑ Un second entretien de 45 minutes avec l‚Äôun de nos Business Manager afin de valider tes comp√©tences et qu‚Äôil se projette sur l‚Äôune des missions qu‚Äôil pourrait te proposer ¬∑ Un troisi√®me entretien de quelques minutes avec notre responsable d‚Äôagence pour te proposer d‚Äôint√©grer notre superbe Team Web ! ¬∑ 3 entretiens en peu de temps, si ton profil correspond tu int√®greras tr√®s vite nos √©quipes üòâ  Pr√™t pour embarquer dans notre grande aventure humaine ? Deviens notre futur Weber en postulant √† cette offre ! Voici les avantages qui t‚Äôattendent en tant que Weber :  ü§© Des coll√®gues incroyables üèÜ Certifi√©e Great Place to Work  üéÆ Des bureaux sympas (o√π vous serez toujours les bienvenus)  üéâ Des teambuilding et √©vents tous les moisüíª Des tributs m√©tiers pour √©changer entre Weber du m√™me m√©tier Des missions chez le client qui sont accompagn√©es et coach√©es par ton manager Un accompagnement dans ton plan de carri√®re et tes envies de re skilling ü§ì Un catalogue de formations certifiantes ouvert √† tous les salari√©s üçΩÔ∏è Une carte tickets restaurant MyEdenred   ‚ù§Ô∏è Une mutuelle GrasSavoye   üöé Une prise en charge des frais de transport √† 100%


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Software Engineer - Branding Team,Teads,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-software-engineer-branding-team-at-teads-3776629218?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=Tfa7daI7dMRYR%2B9zQi9ipQ%3D%3D&position=14&pageNum=7&trk=public_jobs_jserp-result_search-card,"Teads has an engineering team that brings together 200+ talented individuals in 3 main locations (Montpellier, Paris, and Bucharest). We are organized in agile and autonomous feature teams and share technical knowledge within several communities of practice.We promote diversity and are committed to creating an inclusive environment to enable all employees to feel valued and respected, which fosters creativity and innovation by allowing constructive collaboration and open exchange of ideas.Our organization gives the possibility to work remotely part of the time and more flexibility is open to discussion. We also offer relocation packages if you prefer to settle down in one of our engineering offices.üëâ Join a team of passionate people who build quality and responsible advertising, at scale!Our Branding TeamThe Branding team is responsible for developing components and features that empower advertisers and agencies to craft compelling Branding campaigns, within an omnichannel framework (spanning in-article, in-stream, and CTV mediums).Our team works across the whole chain of campaign setup and delivery, covering both backend and frontend aspects. Our primary contribution is directed towards enhancing the usability of Teads Ad Manager, our campaign management system, while improving the code base.Our main Engineering challenges at TeadsWorking in a very high-traffic environment (1.9 billion users per month, 100 billion events per day) with low latency and high availability constraints (2 million requests per second, responses in less than 150 milliseconds).Rich and diverse tech stack and system architecture to optimize for performance, scalability, resiliency, and cost efficiency. We use mostly Scala and TypeScript, among others.Management of large datasets with milliseconds order of magnitude access time, to compute in a near real-time complex auction resolution algorithm (18 million predictions per second).Build efficient and easy-to-use web products used by thousands of users working for the world's most premium publishers, advertisers, and agencies.A fast-changing environment where we continuously collaborate with Product teams and constantly adapt our Cloud infrastructure for new features and Products.Bring a wide diversity of profiles to the same level of quality and knowledge.What will you do?As a Senior Software Engineer, your mission will be to:Collaborate with a variety of teams to develop complex services.Create, design, develop, test, and monitor your code in production autonomously and reliably.Work with the Engineering Manager to frame projects and be accountable for their execution.Obtain a good understanding of the business to provide relevant solutions to clients.Be a work facilitator and help communication inside and outside Teads.Stay up-to-date on new technologies and architectures. If they can solve a problem Teads has, propose ways to implement them into our current software engineering process.What will you bring to the team?Good programming abilities. Testing your code is second nature to you. You are very mindful of your application‚Äôs architecture, performance, maintainability, and overall quality.Good communication skills and ability to work collaboratively within a team. You are an active listener and a dialogue facilitator, you know how to explain your decision and like sharing your knowledge.Multiple shipped projects in Software Engineering.Strong problem-solving skills.Why work at Teads?At Teads, Product and Engineering work hand in hand and are aligned towards the same goal: to scale our business while continuing to create new and exciting products.We value team spirit, pragmatism, listening and we encourage initiatives.We promote end-to-end development: ‚ÄúYou build it, you run it, you monitor it‚Äù.We share knowledge and support with each other beyond any organizational boundary.We fix issues during a blameless postmortem and learn from it so that it doesn‚Äôt happen twice.We are working together to create great engineering, but we are also supportive to promote a great work-life balance.We Care About YouSecurity & Savings: Attractive package providing financial peace of mind, including competitive compensation, profit-sharing, daily meal vouchers (Swile), family health insurance (Alan), and a personalized relocation package (if needed).Career Development: Continuous investment in our employees' skills: in-house and external training, tech conference opportunities, internal mobility (individual contributor or management career ladder).Life Balance: A well-balanced work-life for our employees is one of our top priorities: 35+ days off per year, hybrid work (2-3 days remote work per week, more is open to discussion), fully covered parental leave, and reserved daycare places.Wellness: Prioritizing employee well-being through premium work equipment, enjoyable work environment (work-life balance, team building events, summits), remote work subsidy, promoting Diversity & Inclusion with internal & external initiatives (women speaking groups, dedicated school partnerships), dedicated charitable time and sustainability actions (Eco Tree, subsidy for eco-mobility).Discover more about our culture and benefits on our Engineering website.What are our recruitment process steps?We want to get to know you and we try to give you the insight you need to make an informed decision to join us. For that, you can find all the information in our Engineering hiring process article!About TeadsTeads operates a leading, cloud-based, omnichannel platform that enables programmatic digital advertising across a global ecosystem of quality digital media.As an end-to-end solution, Teads‚Äô modular platform allows partners to leverage buy-side, sell-side, creative, data and AI optimization technologies. For advertisers and their agencies, Teads offers a single access point to buy the inventory of many of the world‚Äôs best publishers and content providers.Through exclusive global media partnerships, Teads enables advertisers and agencies to reach billions of unique monthly users in brand safe, responsible advertising environments, while improving the effectiveness and efficiency of digital ad transactions.Teads partners with the leading marketers, agencies and publishers through a team of 1,200+ people in 50 offices across more than 30 countries.We're committed to creating a dynamic work environment that values diversity and inclusion, and represents employees across a variety of skill sets. We embrace contributions from all ages, sexes, races, ethnicities, religions, sexual orientations and gender identities.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Data Engineer,Ryte,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-at-ryte-3727247165?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=j7uZCwrTWoptoadkkxHOog%3D%3D&position=15&pageNum=7&trk=public_jobs_jserp-result_search-card,"DescriptionAbout Us:We're a team of physicians, healthcare executives, data scientists and Tech experts committed to empowering anyone, anywhere with the insights they need to make well-informed healthcare decisions. Through the combined power of AI and big data, we have created the first all-in-one solution that provides our users with everything they need to know about medical professionals and facilities. RYTE transforms the comprehensive data we collect on millions of healthcare providers and medical experts worldwide into knowledge that helps individuals and organizations navigate healthcare systems. Headquartered in Toronto (Canada) and having operations in Canada, USA, France, Kazakhstan, and the Philippines, you will join a truly international, multicultural, and dynamic workforce driven toward building something unique that affects Life and Healthcare on a global scale. For more information about us, please contact us at www.ryte.ai.The Position: Senior Data EngineerWe are looking for a Senior level Data Engineer (Azure) who will be responsible for expanding and optimizing our data and data pipeline architecture, as well as optimizing data flow and collection for use across existing products. The ideal candidate is an experienced data pipeline builder and data wrangler who enjoys optimizing and designing data systems. The Data Engineer will work alongside our international team of data stewards, data scientists, business and data analysts on data and integration initiatives and will ensure optimal data delivery architecture is consistent throughout ongoing projects. He/she must be self-directed and comfortable supporting multiple systems, products and data flows.This is a full-time position, working at Paris office (or Nice with frequent travel to Paris) | France. You will be working full-time for the Ryte team under the supervision of the Ryte Solution Architect.This is a CDI (Full time) position.The Role:As a successful candidate, you will bring extensive expertise in the design, framework & methodology of data warehousing, and possess experience in the full data life cycle. Additionally, you must possess a unique blend of healthcare business and industry savvy; a big-picture vision, and the drive to make that vision a reality. You must enjoy spending time in all healthcare SAAS business areas to understand their problems and find innovative solutions for the organization.Responsibilities:Understand complex Healthcare business requirements and provide solutions to business problems. Defining data engineering best practice and sharing across the organization. Understand modern data architecture approach including event-driven, data streaming and data mesh. Understand HealthCare compliance requirements (HIPAA, GDPR) and its applicability to Data Engineering. Create and maintain optimal data pipeline architecture. Set technical direction by designing solutions to complex problems. Improve the performance, observability, and reliability of our data pipelines. Implement data governance best practices in term of data cataloguing, lineage and metadata management. Work with large, complex financial data sets that require sophisticated processing and transformation. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build resilient and maintainable infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources. Work as part of an Agile development team with stakeholders to develop new features to support their data infrastructure needs. Work with data and analytics experts to strive for greater functionality in our data systems. Mentor less experienced team members by providing counsel and constructive oversight. Requirements Bachelor's degree in Engineering/Computer ScienceStrong experience using modern Data Warehousing solutions, preferably cloud solutionsAgile methodology experience essentialExperience applying modern data management frameworks and methodsExcellent documentation skillsTechnical project/change managementStrong understanding of RDBMS and NoSQL databasesExperience working with Graph databases is a plusOne or more in each of these categories:ETL: Spark, Azure Data Factory, DBT, pandas, Kafka StreamsQueues and Stream processing: Spark Streaming; Event Hub; Kafka. NoSQL: Cassandra, Azure Cosmos, Elasticsearch, MongoDBProgramming Languages: Python, SQL, Spark (Scala/PySpark)API Development: GraphQL, Rest, Thrift3+ years of experience as a Senior Data Engineer with Azure data components eg: Spark/Databricks, Data Lake, Data Factory, Synapse Analytics3+ years of data architecture, data analysis, ETL and/or data modeling experience3+ years current and deep experience with implementing large engagements. Proven experience managing projects through the entire project lifecycle. This includes managing multi-phase/multi-dimensional/multi-resource projects to conclusion while maintaining high customer satisfaction2+ years of experience and advanced domain knowledge in one or more vertical industries: manufacturing, financial services, government, legal, healthcare, property managementHighly proficient in spoken and written EnglishWe would like to thank all Applicants for their interest in this position. Please note that only Applicants selected for an interview will be contacted. Ryte Corp. is an equal opportunity employer. If selected for an interview, please advise our Human Resources team if you require accommodation during the interview and assessment process. We will work with Applicants to accommodate all accessibility needs.BenefitsFeatured Benefits:We provide Medical, Dental & Vision Insurance. Flexible Personal Time off (PTO). Fix + BonusFlexible remote work policy.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'Elasticsearch'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,RSight¬Æ,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-rsight%C2%AE-3801029508?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=5slywsiBSfT4hpDs5OO5kQ%3D%3D&position=16&pageNum=7&trk=public_jobs_jserp-result_search-card,"Nous recherchons pour notre client, un leader mondial des services et conseils en technologies, un ing√©nieur Databricks et Data Factory qui rejoindra une √©quipe qui combine des comp√©tences m√©tiers avec une forte expertise data, analytique et d‚Äôintelligence artificielle pour mettre en ≈ìuvre des solutions qui visent √† am√©liorer la gestion et la valorisation des donn√©es.Descriptif des missions:Vous √™tes int√©ress√© √† travailler sur une solution ayant un impact direct sur les ambitions de notre client en mati√®re de data (datadriven, data d√©mocratisation) ? Alors devenez membre de l‚Äô√©quipe Corporate Data Lake de notre client ! Comme tout autre membre de l'√©quipe, vous :Participer √† la d√©finition des composants informatiques supportant la fourniture de servicesD√©velopper, tester, industrialiser et d√©ployer des composants en minimisant les impacts sur les utilisateurs (automatisation, 0 temps d'arr√™t,...)Documenter la bonne utilisation des servicesD√©ployer et supporter nos fonctionnalit√©s sur la plateformeApporter assistance et conseils aux utilisateurs m√©tiersOp√©rer la solution en op√©ration courante (incluant le suivi de la qualit√© des services) et intervenir dans la r√©solution des incidentsParticiper activement √† l'am√©lioration continue des activit√©s de l'√©quipeExpliquer aux collaborateurs ce que le Corporate Data Lake peut faire pour euxConfigurer des espaces de travail pour euxFournir du coaching et de l'expertise lors de r√©unions en face √† face ou sur les canaux communautairesParticiper √† l'effort de support de la plateforme dans une approche ""vous la construisez, vous l'ex√©cutez""Contribuer aux premi√®res phases de conception d√©finissant l'avenir du Corporate Data LakeComp√©tences:1er exp√©rience Azure (PaaS et IaaS)Connaissance de Databricks et Data FactoryMa√Ætrise d'un ou plusieurs langages parmi : Python, Scala, Spark, PowerShellInt√©gration et livraison continues (Jenkins, Azure Devops, GIT Lab CI, ‚Ä¶)Pratique des fondamentaux du g√©nie logiciel (Gestion de Configuration, Tests,...)Anglais : √† l'aise pour assister √† une r√©union et r√©diger de la documentation techniqueBonne capacit√© d'√©coute, orientation client/utilisateurExpression orale et √©crite adapt√©e √† l'interlocuteurCuriosit√© et adaptation aux changements technologiquesB√©n√©fices:Un processus de recrutement court, un accompagnement personnalis√©, une √©volution qui s'adapte √† votre trajectoire de carri√®re.En plus de votre quotidien li√© √† votre mission, vous pourrez entreprendre, √™tre form√©, passer des certifications.Plan d'√©pargne pour la retraite collectif, mutuelle, tickets restaurant, des cong√©s d'anciennet√©, un catalogue CE, des accords d‚Äôentreprise relatifs au t√©l√©travail et √† la parentalit√© et autres avantages.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer (F/H),ACENSI,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-acensi-3747766862?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=sqezcwiQVfRess182ed3Ew%3D%3D&position=17&pageNum=7&trk=public_jobs_jserp-result_search-card,"Description de l'offre   LE POSTE ACENSI SUD-OUEST et ses √©quipes, ouvrent actuellement un poste de Data Engineer pour le bureau de Bordeaux !Contexte : Rattach√©(e) √† une √©quipe Data & IT, vous aiderez √† concevoir, d√©velopper, exploiter les donn√©es et solutions Data √† destination d‚Äôutilisateurs internes de p√¥les Supply Chain, Finance, Performance, RH et Marketing. LES MISSIONS Les Activit√©s Qui Animeront Vos Journ√©esConcevoir et d√©velopper des solutions Data/IA √† des fins analytics & dashboardingAccompagner les M√©tiers dans la compr√©hension des AnalyticsMettre en ≈ìuvre des solutions ""data driven""Mettre en ≈ìuvre des solutions industrielles exploitables, mesurables et op√©rablesCommuniquer et traduire les r√©sultats aux parties prenantes de l'entrepriseCapitaliser sur les solutions pour cr√©er de nouveaux produits, de nouveaux services et de nouvelles opportunit√©s de digitalisation, de valorisation de la donn√©eParticiper activement √† la communaut√© de Data Scientist et de Data EngineerG√©rer un √©cosyst√®me de partenaires data science et assurer un haut niveau d'expertiseAssurer un r√¥le de veille technologique sur tous les outils autour de la Data, IA et BISecteurs possibles : Telecom, Banque, E-Commerce, Assurances, ‚Ä¶Un dernier point pour vous convaincre ?Un salaire positionn√© sur la fourchette haute du march√© du num√©rique, avec un d√©roul√© de carri√®re individualis√© et le plus int√©ressant possible.Fini la ¬´ grille de salaires √† respecter ¬ª, et si on l'enjambait ensemble ?Vous pensez m√©riter ce salaire, avec votre niveau de comp√©tences ? On peut se le permettre ? Et bien, allons-y !Fourchette de Salaire n√©gociable : 45K √† 60kDes Avantages Sociaux Personnalis√©süéÇ Acensi Sud-Ouest souhaite vous remercier chaque ann√©e pour votre engagement et votre fid√©lit√©. De nombreuses surprises et cadeaux vous attendent pour vos anniversaires au sein de la soci√©t√©, mais aussi lorsque vos retours de missions sont positifs sur la dur√©e.üé® Besoin de vous a√©rer l‚Äôesprit : loisir, art, sport ? C'est le moment de vous accompagner financi√®rement dans votre √©quilibre vie priv√©e-vie pro !ü§∏‚Äç‚ôÄÔ∏è On ne r√©invente pas la roue, mais vous aurez le droit bien √©videmment aux : ticket restaurant, 50% sur les transports en commun, 50% prise en charge de la mutuelle, ch√®ques cadeaux, primes vacances, RTT ‚Ä¶üè† 2/3 jours de t√©l√©travailü§ù Cooptation : 2000 √† 3000 ‚Ç¨ brut / personne coopt√©e (selon conditions)Une entreprise o√π vous serez toujours bienvenupour partager un moment convivial (afterworks, soir√©es d‚Äôint√©gration‚Ä¶). LE PROFILPlus que des comp√©tences, qui s‚Äôacqui√®rent avec de la motivation, du temps et de la formation, nous recherchons une personne avec un √©tat d‚Äôesprit et qui sera capable d'√™tre ambassadeur d'ACENSI !Pas de panique si vous ne cochez pas toutes les cases‚ÄØ! Nous √©changerons ensemble sur vos comp√©tences et nous mettrons en place un plan de formation adapt√©.De formation Bac+2 √† Bac+5 en √©cole d‚Äôing√©nieur/universit√©, vous avez au minimum 2 ans d‚Äôexp√©rience dans le m√©tier de l‚Äôing√©nierie DATA ?Vous √™tes √† l‚Äôaise sur l‚Äôutilisation de la technologie Spark ?Vous connaissez des langages informatiques (Sql, Scala, Python, Java, Shell, ‚Ä¶) vous permettant d'√™tre autonome sur la manipulation des donn√©es ?Vous avez acquis une exp√©rience dans les outils BI et data visualisation ?Vous avez des comp√©tences statistiques et ma√Ætrisez les mod√®les pr√©dictifs ?Alors n'attendez plus pour nous envoyer une candidature !Recruteur en charge de l'offre: Florian AWANA
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer/BI (H/F),Eur√©cia,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-h-f-at-eur%C3%A9cia-3806360580?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=Nkl%2BxVrVTY6u1%2FQM7C%2FhAw%3D%3D&position=18&pageNum=7&trk=public_jobs_jserp-result_search-card,"√Ä propos d'Eur√©ciaEnvie de vivre une exp√©rience diff√©rente ?Envie de retrouver du bon sens, de la simplicit√©, de l‚Äôefficacit√© ?Eur√©cia , c‚Äôest une solution RH made in Toulouse, 190 collaborateurs passionn√©s, 300 000 clients-utilisateurs, une pr√©sence dans 66 pays et des chocolatines (‚Ä¶√î Toulouse) tous les matins ! Eur√©cia c‚Äôest aussi du management bienveillant, de l‚Äô√©panouissement, de la confiance‚Ä¶Notre moteur ? Oser et Grandir ensemble en Confiance. √ätre Simple et Efficace !Si vous aussi vous voulez contribuer √† construire un monde meilleur (ouais, on assume !), alors faites-nous un signe !Le posteüéØ Vos Missions, Votre QuotidienPour accompagner notre croissance, nous souhaitons renforcer le p√¥le data transverse qui soutient toutes les √©quipes. Dans ce cadre, nous cherchons notre nouveau Data Engineer/BI.Son r√¥le ? Participer √† la mise en ≈ìuvre d‚Äôune plateforme data fiable et √©volutive permettant de r√©pondre aux diff√©rents besoins de KPI et de dashboard m√©tiers.Concr√®tement, Vous Serez Amen√©(e) √†Mettre en ≈ìuvre et maintenir la plateforme data (airbyte, dataform, airflow, GCP)Concevoir, d√©velopper et maintenir des pipelines de donn√©es fiablesAnalyser les besoins des m√©tiers en termes de data et mettre en ≈ìuvre les solutionsProposer et tester de nouvelles technos/outils pouvant am√©liorer la plateforme dataG√©rer la documentation technique et fonctionnelle des outilsG√©rer les probl√®mes techniquesProfil recherch√©ü§ì On Est Fait Pour Travailler Ensemble SiVous disposez d'au moins 4 ans d'exp√©rience dans un poste similaireVous avez une solide connaissance en Python, SQLVous avez une exp√©rience en conception et mise en ≈ìuvre de pipelines de donn√©esVous ma√Ætrisez les concepts de BI traditionnels (datawarehouse, historisation‚Ä¶)Vous ma√Ætriser un outil de data visualisation (Metabase, Tableau, power BI...)Vous √™tes curieux(se) et pugnace pour trouver les solutions les plus efficaces et vous cherchez √† progresser continuellementVous aimez relever des d√©fis au quotidien, vous savez travailler en autonomie (et en √©quipe !) et √™tre force de proposition afin d‚Äôapporter une valeur ajout√©e √† vos projetsVous avez une app√©tence pour la satisfaction clientVous √™tes agile et capable de travailler sur plusieurs projets en m√™me tempsüöÄ Pourquoi nous rejoindre ?Si nos valeurs vous font √©cho : ¬´Oser et grandir ensemble en confiance. √ätre simple et efficace.¬ªPour s‚Äô√©panouir et performer, Eur√©cia offre un cadre de travail de qualit√© √† tous ses collaborateurs :Une team bienveillante, et un management de proximit√©Des opportunit√©s d‚Äôapprendre des uns et des autres : il n‚Äôy a pas d‚Äô√©chec, seulement des it√©rations et des occasions d‚ÄôapprendreUne formation au cours de laquelle vous serez amen√©(e) √† d√©couvrir l‚Äôensemble des √©quipes internes, nos offres, notre march√© et nos process de d√©veloppement produitsUn Campus de 1300m2 et 20 500m2 de parc au bord du canal du midi, pens√© et r√©alis√© pour r√©pondre au bien-√™tre quotidien des √©quipes, tout en pr√©servant le patrimoine et l‚Äô√¢me du lieu‚òÄÔ∏è Les Autres Avantages7 semaines de cong√©s pay√©s : soit 2 semaines suppl√©mentaires par an !Des jours de cong√©s suppl√©mentaires : anciennet√©, journ√©e pour le m√©c√©nat et la journ√©e de solidarit√© est offerte !Un accord de participation, qui peut √™tre plac√© sur une √©pargne salarialeDes moments fun et gourmands : Eur√©ciades, Stand up, gouter ou ap√©ro üòâUn Kit T√©l√©travail pour √™tre bien install√©(e) chez soi + une prime annuelle de 150‚Ç¨ netUne mutuelle prise en charge √† 60%Des titres restaurants (d√©mat√©rialis√©s) d‚Äôune valeur de 9.5‚Ç¨Une prise en charge de 50% des frais de transports en communUne prime mobilit√© annuelle de 400‚Ç¨ netDes fruits frais, massages, cours de sport et yoga‚Ä¶Notre Process De RecrutementUn premier √©change avec C√©lia, Talent Acquisition Manager.Un second entretien, sera organis√© avec Vincent, Data Manager.Si vous √™tes retenu(e) parmi les candidats finaux, vous aurez l'occasion de faire connaissance avec toute l'√©quipe autour d‚Äôun moment convivial et gourmand ! üç¨üç´üçµChez Eur√©cia nous croyons que la diversit√© est une chance et nous nous engageons √† traiter les candidatures sans consid√©ration de sexe, d‚Äô√¢ge, d‚Äôorigine, de handicap ou de conviction.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer H/F,LesJeudis,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3788256076?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=mRmeZG7HM%2FVsk0xkOH594g%3D%3D&position=19&pageNum=7&trk=public_jobs_jserp-result_search-card,"MissionDans le cadre de son d√©veloppement, Inetum recrute un Data Engineer (H/F) pour sa branche Applications Services.Vous interviendrez chez l'un de nos clients sur des projets BI et/ou Big Data en m√©thode agile.Le Data Engineer Sera En Charge DeApporter une expertise en Data permettant la manipulation de donn√©esAccompagner nos clients dans la r√©alisation de projets dans un contexte Big Data et CloudParticiper √† r√©unions permettant de valider les principes techniques et algorithmiques pour des projetsProfilDe formation Bac +5, vous justifiez d'une exp√©rience d'au moins 4 ans dans le domaine de la Data. Vous avez √©volu√© dans le monde du d√©veloppement (Python, Spark, Aws...)Vous √™tes capable de prendre des initiatives, autonome, rigoureux(se) et vous savez vous adaptez √† de nouveaux environnements.Vous appr√©ciez le travail en √©quipe dans un contexte agile, et aimez relever des d√©fis.La ma√Ætrise de l'anglais est un vrai plusOrganisationNous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer / D√©veloppeur¬∑euse Big Data F/H,Onepoint,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-d%C3%A9veloppeur%C2%B7euse-big-data-f-h-at-onepoint-3612029460?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=xPfVnZG7Rehg1IxS4ymEdg%3D%3D&position=20&pageNum=7&trk=public_jobs_jserp-result_search-card,"Un¬∑e data engineer est en charge de concevoir et de construire des pipelines de traitement de donn√©es. Curieux¬∑se, il / elle est √† l‚Äôaise avec du batch et du temps r√©el, de l‚Äôon premise et du cloud, des datalakes ou des data warehouses modernes. Ses traitements sont robustes, s√©curis√©s, et performants, et il / elle n‚Äôh√©site pas √† les factoriser et les automatiser.Vos Missions Seront Les Suivantes√âtudier les syst√®mes sources‚ÄØ; Choisir et impl√©menter les solutions de stockage et les mod√®les de donn√©es ad√©quats‚ÄØ; Extraire et charger les donn√©es des syst√®mes sources‚ÄØ; Uniformiser, structurer et transformer les donn√©es‚ÄØ; Exposer ces donn√©es (API, Web services ‚Ä¶) ; Planifier et orchestrer ces traitements‚ÄØ; Industrialiser selon les pratiques CI/CD ; Mettre en place des solutions de monitoring‚ÄØ; Documenter le code‚ÄØ; Exp√©rimenter, √©valuer, faire de la veille technologique. #techVous √™tes dipl√¥m√©¬∑e d'une Grande √âcole d'Ing√©nieur g√©n√©raliste, informatique ou d‚Äôun Master sp√©cialis√© en Big Data, et avez une exp√©rience minimum de 3 ans dans ce domaine.Vous Maitrisez Une Ou Plusieurs Des Solutions SuivantesL‚Äô√©cosyst√®me Hadoop : Spark, HDFS, Hive, HBase, ‚Ä¶ Les distributions Cloudera (Hortonworks), MapR SQL, Scala, Java, Python, ‚Ä¶ Les services Data des principaux fournisseurs Cloud (AWS, Azure, GCP, ‚Ä¶) Airflow, Luigi, ‚Ä¶ Kafka, RabbitMQ, ‚Ä¶ ElasticSearch (et la Suite ELK), Cassandra, MongoDB, Neo4J, ‚Ä¶ Docker, Kubernetes ‚Ä¶ Vous avez une ou plusieurs certifications en cours de validit√© sur l‚Äôune des technologies cit√©es ci-dessus,Vous disposez d‚Äôun tr√®s bon relationnel, d‚Äôun bon sens de l‚Äô√©coute et d‚Äôempathie,Vous faites preuve d‚Äôinitiative, vous √™tes naturellement force de propositions, vous avez envie de partager tes connaissances et savoir-faire et d‚Äôapprendre de vos pairs.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', ' MongoDB', 'Cassandra', 'Neo4j', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer  H/F,Groupe INGENA,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-ingena-3788281977?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=zCiwalD0PwPEQAAW4VLAAQ%3D%3D&position=21&pageNum=7&trk=public_jobs_jserp-result_search-card,"Le groupe INGENA promeut la transition num√©rique en √©tant acteur d‚Äôun monde souhaitable.Votre mission :Concevoir, d√©velopper et tester des algorithmes de collecte et de traitement de gros volumes de donn√©es sous Scala, Python ou JavaAutomatiser et optimiser les flux de donn√©es et leurs visualisations en dashboardsIndustrialiser les traitements, la qualit√© et l‚Äôint√©grit√© des donn√©esParticiper √† la Mod√©lisation et √† la Gouvernance des donn√©es (process, normalisation, r√©f√©rentiel,‚Ä¶)Contribuer √† la scalabilit√©, la s√©curit√©, la stabilit√© et la disponibilit√© des donn√©es de la plateformeAnalyser les donn√©es pour r√©pondre aux questions m√©tiers et participer √† l‚Äô√©volution de l‚Äôarchitecture Big DataConcevoir, D√©velopper et Industrialiser des mod√®les de Machine Learning, Deep Learning, en collaboration avec les Data ScientistsAppliquer une d√©marche CI/CD (Git, Jira, Jenkins)Les comp√©tences techniques n√©cessaires sont :Exp√©rience de 5 ans minimum en d√©veloppements Scala, Python ou JavaExp√©rience de 2 ans minimum sur SPARK et sur le traitement des flux en streamingExpertise sur Hadoop (Hive, HBase, HDFS) sous distributions MapR ou HortonworksExp√©rience souhait√©e sur ELK, Terraform, NoSQL,‚Ä¶Fort background en Mod√©lisation de donn√©es ou ETLMa√Ætrise des briques analytiques des clouds AWS, GCP ou AzureSensibilisation √† la d√©marche CI/CD tools (Git, Jenkins)La connaissance de Docker, Kubernetes et Ansible est un plusMise en ≈ìuvre des m√©thodes Agile (Scrum, Kanban,‚Ä¶)Anglais souhait√©Groupe INGENA :Le Groupe INGENA est sp√©cialis√© en Conseil M√©tier et en Int√©gration pour les march√©s de l‚Äôassurance, de la banque et de la Finance. INGENA intervient notamment sur les projets associ√©s √† la Data, aux Risques et √† la Distribution.Le groupe comprend √©galement la soci√©t√© DRiMS sp√©cialis√©e en Finance de March√©.Nos valeurs : Engagement, Int√©grit√© et Bienveillance.La mise en pratique du monde souhaitable, c‚Äôest pour nous une entreprise √©co-responsable, √©thique, inclusive, sociale, soucieuse du bien-√™tre, de l‚Äô√©volution et de l‚Äô√©panouissement de ses √©quipes. Ce sont aussi des offres pour un monde durable comme la ma√Ætrise des risques ou l‚ÄôESG.Dans un esprit convivial et engag√©, nous faisons en sorte que chacun puisse √™tre acteur de l‚ÄôINGENA souhaitable.Bureau √† Paris 9√®me (M√©tro Le Peletier). Clients √† Paris ou tr√®s proche banlieue.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['JIRA']}"
Data Analyst - 100% remote,BoondManager,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-analyst-100%25-remote-at-boondmanager-3800335849?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=wGyR8mNsCDLVGMhKqfpaLA%3D%3D&position=22&pageNum=7&trk=public_jobs_jserp-result_search-card,"C'est en 2009 que l'aventure commence üöÄAnthony et Tanguy se lancent dans l'aventure dans l'entrepreneuriat et d√©cident de cr√©er une solution SAAS ERP √† destination des ESN & soci√©t√©s de conseil, afin de ""travailler autrement"".BoondManager est ainsi n√© ü¶äAu c≈ìur de BoondManager, il y a l'id√©e que chacun(e) devrait avoir la possibilit√© de se r√©aliser dans son travail et sa carri√®re, de pouvoir ""les"" concilier avec sa vie personnelle. ü´∂Notre Mission ‚≠ê‚≠ê‚≠ê‚≠ê‚≠êF√©d√©rer sur un m√™me outil aussi bien les consultants, les recruteurs, les commerciaux, les administratifs et les dirigeants autour de divers modules (Recrutement, RH, CRM, gestion des opportunit√©s, facturation, CRA) !Notre ADN ‚ù§Ô∏èNos 75 Boonders sont en full remote/100% t√©l√©travail dans toute la France.Le t√©l√©travail, on connait bien, on le pratique depuis 13 ans.En Quelques Chiffres, BoondManager C'estü§ù 1500 clientsüë• 70.000 utilisateursüåç 21 paysüí∂ Rentable et autofinanc√©eü•∞ La Boondfamily est pass√©e de 30 √† 75 personnes en 2 ans.Liens UtilesNotre culture d'entreprise : https://urlr.me/8gtjVNotre solution : https://bit.ly/41WfKZ5Ce que nos clients pensent de Boond : https://bit.ly/3l7TvPbEt toi,partant.e pour l'aventure ? üëáLe PosteBoondManager ne cesse de grandir ! ü¶äAfin de r√©pondre √† notre roadmap ambitieuse,Nous ouvrons notre 1er poste de Data Analyst au sein de l'√©quipe BI/Performance ü¶äTout √ßa, c'est magnifique, mais on reste un peu sur notre faim‚Ä¶ nos plus grands r√™ves sont :Devenir le leader europ√©en des ERP pour les soci√©t√©s de conseils (on a de l'ambition).Et pour √ßa, on a besoin de toi !Nos Grands Principes üëå‚úÖ Mieux vaut s'excuser que de demander la permission. On encourage √† 300 % la prise d'initiative !‚úÖ Ne sois jamais satisfait de ton niveau de connaissance actuel. Apprends, cultive-toi, lis, √©coute !La (super) Team üèÜL'√©quipe Performance est compos√©e de talents pluridisciplinaires ! Fran√ßois s'occupe de la data (ton futur bin√¥me) Guillaume des projets de refactoring Manu de la stack ELK R√©mi c√¥t√© DevOps. Florens, ton futur managerLa performance touche l'ensemble des √©quipes tech, tu travailles donc avec l'ensemble des BoondBuilders, soit 35 personnes autour de sujets Features, Mobile, Support N3, QA, Infra. Plut√¥t sympa donc !Tes activit√©s : üëáOn Te Propose C√¥t√© Dataviz Cr√©ation dashboard via superset (ou autre outil) R&D autour des outils Dataviz (on adore l'open source) Int√©gration des dashboards dans boondmanager en marque blanche et gestion des interactions avec l'application existante Accompagnement des diverses parties prenantes sur les sujets n√©cessitant de la dataviz (Sales, RH & - Recrutement, CSM, PO, Market et nos clients) Conduite et aide au changement pour faire adopter l'outil de mani√®re transverse Sp√©cification et conception de dashboard de A √† ZC√¥t√© Data Analyst Cr√©ation de KPI via sql Challenger les perfs de nos Kpi (am√©liorer les temps de r√©sultats) R√©aliser les croisements de donn√©es pour la construction et le maintien du data warehouse Assurer la maintenance et l'√©volution des KPI du produit BoondC√¥t√© Engineering Suivi de l'int√©grit√© de la donn√©e (topologie, audit) Participer √† l'alimentation du Datawarehouse D√©veloppement, maintien et l'√©volution de l'architecture des donn√©es Recueillir les besoins des parties prenantes et sp√©cifier les besoins en dataNotre Stack Technique üåà Backend/Frontend : Java, Python (√† venir), PHP Data : Trino, Pinot, Kafka, Outil DatavizComment Travaille L'√©quipe Perfs ü¶ä On se retrouve tous les lundis matin avec l'ensemble de l'√©quipe Perfs Un One/one avec Florens toutes les semaines pour suivre ton √©volution et te faire grandir Coworking virtuel 2x par semaine (non obligatoire) pour √©changer avec le reste de la team Weekly avec toute l'√©quipe tech (les BB pour les intimes) le mercredi √† 14hTon Onboarding üöÄ1 mois : Prise en main de l'infra, de la data, notre architecture et le cycle d'alimentation Mont√©e en comp√©tence sur notre solution au travers de notre Boondgame Mont√©e en comp√©tence sur le m√©tier/secteur de nos clients3 Mois Autonomie dans l'analyse d'un KPI (debug prod d'un client sur son environnement, analyse et calcul valeur, enrichissement des donn√©es qui permet de calculer cette valeur, r√©solution). √ätre capable de mettre les mains dans l'int√©gration √† boond des KPI (manipul√© le backend)6 Mois Capacit√© de cr√©er des nouveaux KPI √† partir des demandes de PO (requ√™te sql permettant de le calculer) Capable d'int√©grer de la dataviz. L'id√©e est que tu sois dans les meilleures dispositions en ma√Ætrisant notre environnement üí™ProfilEt toi, Qui es-tu ? ü§©üç∑ Tu adores pinot et je ne te parle pas de celui des charentesüí™ Tu as d√©j√† construit des tableaux de bords au travers d'un outil de Dataviz‚úçÔ∏è tu connais kafka et pas que l'√©crivainüòé Tu es capable d'√©crire des requ√™tes optimis√©s pour fabriquer la dataviz avec des exemples concrets en SQLüß† Python : Tu dois savoir d√©velopper des nouvelles fonctionnalit√©s, gestion des d√©pendances, challenger l'existant (qualit√© du code), compiler le projet.üöÄ Le + : Tu ma√Ætrises notre stack technique (on veut des projets significatifs)ü¶ä Le petit ++ : Tu connais le monde des ESNüôã‚Äç‚ôÄÔ∏è Mesdames, autorisez-vous √† candidater !Ce Qu'on T'offrira En Plus De Tout √áa üéÅüí∏ Un salaire entre 45k et 60Küè° 100% remote üá´üá∑ (plus de temps pour toi !)üå¥ 3 s√©minaires par an pour se retrouver et s'√©clater‚ÄØ!üòé 9 jours de cong√©s pay√©s suppl√©mentairesüè• Une mutuelle familiale (pas de suppl√©ments pour ta famille)üí∏ Une offre t√©l√©travail en plus de ton salaire !üéÅ Une offre mensuelle dans le coworking de ton choix !üßò Cours en ligne de m√©ditation, fitness et yoga chaque semaine !ü§ù Un plan d'√©pargne entreprise valoris√© √† hauteur de 300‚Äâ%üíª Une mise √† disposition d'un Macbook, 2 √©crans, casque, etc.ü¶ä On peut travailler avec son chat sur les genoux chez Boond mais l'animal de compagnie officiel, c'est un renard !D√©roulement des entretiensüíª Un premier √©change avec Jean-Florian, notre Head Of TalentüöÄ Un entretien technique/culture fit avec Fran√ßois, ton futur bin√¥me c√¥t√© Dataü§ù Un √©change Culture fit avec Tanguy (fondateur de Boond) et Florens, ton futur manager ü§ìEt si tu as r√©ussi √† me lire jusqu'ici,voici ma derni√®re phrase pour qu'on ne passe pas √† c√¥t√© de toi : si demain cette offre venait √† √™tre cl√¥tur√©e et que tu penses regretter de ne pas avoir postul√©, c'est qu'elle t'a tap√© dans l'≈ìil.√áa serait dommage de d√©marrer 2024 avec un regret,Alors, n'h√©site pas, POSTULEüëá
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),MERITIS,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meritis-3805423899?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=vIJA%2Bn6XU11S%2BL1rtgoS6Q%3D%3D&position=23&pageNum=7&trk=public_jobs_jserp-result_search-card,"Descriptif de l'entrepriseMeritis est un cabinet de conseil, pilotage et d√©veloppement IT fond√© en 2007 pr√©sent √† Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bient√¥t sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d‚Äôavance.‚ÄãNous accompagnons nos clients dans l‚Äôint√©gralit√© de leurs besoins en transformation num√©rique √† travers de nombreux domaines d‚Äôexpertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybers√©curit√© ou encore Agilit√©.‚ÄãIntervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des T√©l√©communications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.‚ÄãFort de nos valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, nous comptons aujourd‚Äôhui plus de 900 collaborateurs.‚ÄãNous mettons un point d‚Äôhonneur √† √™tre proche de nos collaborateurs et √† les accompagner de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise. Certifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.‚ÄãDescriptif du posteEn collaboration avec l‚Äôarchitecte data, les experts data et le gestionnaire/propri√©taire produit, vous serez amen√© √† participer aux op√©rations et √† l‚Äôimpl√©mentation de la roadmap technique de la plateforme d‚Äôorchestration. Voici vos missions :Participer au cycle de d√©veloppement du produit Airflow,Assurer l‚Äôimpl√©mentation/d√©veloppement de l‚Äôoutillage et des fonctionnalit√©s de la plateforme n√©cessaires avec accord de l‚ÄôArchitecte Data et les experts Data du groupe,Contribuer au d√©veloppement des graphes orient√©s acycliques (DAG) n√©cessaires √† la bonne op√©rabilit√© des plateformes datalake et datamart (AWS et Snowflake),Assurer le r√¥le de support technique aupr√®s des end-users lors de leur usage de la plateforme,Assurer les livraisons et d√©ploiement du code,Assurer le mode run de la plateforme,Support niveau 2 expertise de la production et participation aux situations de crises,Reporter au gestionnaire de la plateforme Airflow, les performances IT, l‚Äô√©tat de sant√© temps r√©el et principaux risques op√©rationnels de la plateforme,Contribuer √† la communaut√© Data Orchestration,Produire la documentation n√©cessaire √† ce passage de connaissance : tuto, document d‚Äôexploitation, etc‚Ä¶Assurer et animer les sessions de transfert de connaissances au travers de d√©mos produit.QualificationsVous avez un dipl√¥me d‚Äôing√©nieur ou un Bac+5 √©quivalentVous avez 3 ans d'exp√©rience en tant que Data EngineerVous avez une bonne conne connaissance de l'environnement cloud AWSVous avez une bonne maitrise de l'Orchestration des processus, notamment avec AirflowVous √™tes familier avec les principes ETL/ELTVous avez d√©j√† travaill√© avec la m√©thodologie Agile Scrum/KanbanInformations compl√©mentaires :Des parcours professionnels sur mesure (√©volution de carri√®re, formations adapt√©es, mentoring‚Ä¶) ;‚ÄãAvoir le choix de sa mission et un accompagnement personnalis√© tout au long de votre carri√®re ;‚ÄãEvoluer dans un environnement o√π l‚Äôapprentissage est favoris√© : formations certifiantes, e-learning, meetUp, concours de code, parcours d‚Äô√©volutions etc ;‚ÄãFaire partie de communaut√©s d‚Äôexperts qui partagent leurs savoirs et exp√©riences au sein de nos centres de comp√©tences ;‚ÄãUn environnement convivial avec de nombreux √©v√©nements festifs (soir√©e annuelle, s√©minaires & teambuiding, d√©jeuners et afterworks‚Ä¶) ;‚Äã""Meritis est engag√©e dans la Responsabilit√© Soci√©tale des Entreprises. Nous valorisons notre impact positif sur la soci√©t√© et l'environnement. Notre d√©marche RSE guide chacune de nos actions pour promouvoir l'√©quit√©, la durabilit√© et le bien-√™tre de nos collaborateurs. Rejoignez-nous pour √™tre partie prenante de cette d√©marche responsable, o√π chacun de nos talents contribue √† construire un avenir meilleur.Nos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis s'implique en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap.""


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (h/f),METEOJOB by CleverConnect,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3786129236?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=UZaP4Dasr%2BgVHJ9RAQpdlQ%3D%3D&position=24&pageNum=7&trk=public_jobs_jserp-result_search-card,"EntrepriseACTIVUS c'est un groupe fond√© par des passionn√©s de l'innovation au service de ses clients et de ses √©quipes.Ecoute, proximit√©, r√©activit√© et efficacit√© se retrouvent dans notre management quotidien : b√©n√©ficiez d'un accompagnement personnalis√© tout au long de votre carri√®re.Parce que nous remportons en permanence de nouveaux projets, nous saurons vous trouver LE poste que vous recherchez.Description Du PosteNous recherchons un(e) Data Engineer (H/F) avec une expertise av√©r√©e dans la construction et le maintien des infrastructures de donn√©es, ainsi qu'une solide exp√©rience en d√©veloppement de logiciels dans un environnement Python (architecture orient√©e microservices et API).Le/la Data Engineer aura pour mission d'accompagner les √©quipes dans le choix des technologies n√©cessaires √† cette infrastructure, ainsi que de participer activement √† sa mise en ≈ìuvre et √† son bon fonctionnement.A Ce Titre, Ses Missions Seront Les SuivantesConcevoir les Data Models et Data Pipelines Concevoir les processus Elaborer la strat√©gie de validation des solutionsEtudier collaborativement et concevoir, en fonction des domaines et exigences non fonctionnellesConcevoir et sp√©cifier l infrastructure pour la mise en place de Data Pipelines Sp√©cifier les solutions d acquisition en fonction des flux Sp√©cifier les solutions de traitement adapt√©es aux mod√®les, bas√©s sur Python Estimer les besoins et co√ªtsSp√©cifier les solutions de gestion des donn√©es pour la mise en place des processus et politiques de gestionAccompagner et guider les √©quipesPr√©sentations des √©tudes et solutionsAccompagnement dans les expertisesAccompagnement dans les parcours de formationPr√©sentation et formations internesRevue de conception des solutions sur l ensemble de la cha√Æne de valeurMettre en ≈ìuvre et maintenirParticiper activement √† la mise en ≈ìuvre de l infrastructureD√©velopper et maintenir, avec les √©quipes de d√©veloppement, les services de traitement de donn√©es en Python Supervision / monitoring des infrastructuresLanguesDescription du profil :Fran√ßais courantAnglais professionnelCapacit√© √† travailler en √©quipeRigueur et organisationAccompagnement du changementCapacit√© de vulgarisation et de d√©monstrationMotivation pour les grands projets d infrastructure (moyen/long terme)App√©tence pour la m√©t√©orologie et le monde scientifique en g√©n√©ra
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
R&D Data Engineer,Exotec,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/r-d-data-engineer-at-exotec-3806138743?refId=kb7yivXUJ9hWrit4MWaaZQ%3D%3D&trackingId=LSp1H0WzAR9Tel2%2B2jJi2A%3D%3D&position=25&pageNum=7&trk=public_jobs_jserp-result_search-card,"Exotec is at the forefront of technological excellence, redefining the relationship between humans and robots. Our solutions are contributing to the success of some of the largest brands in retail and e-Commerce by revolutionizing the way they fulfill their orders to the end consumers, all while mitigating labor constraints and increasing workplace safety.Through the unification of artificial intelligence and high-performance hardware, our robotic solutions are now deployed across the globe and our exponential growth has led us to become the first industrial unicorn in France.Working at Exotec is an exciting opportunity to give purpose to your skills. Learn and grow with over 600 ExoPeople around the world to help turn your ideas into a reality.The robotics revolution is just the beginning at Exotec. Will you be part of it?We are seeking a talented and experienced Data Engineer to join our team in the Product Department.As a Data Engineer at Exotec, you will play a key role in designing, developing and maintaining our data infrastructure.ResponsibilitiesCollaborate with cross-functional teams to understand data requirements and design scalable data solutions. Collect data coming from our different client sitesDesign and implement an event driven data lakeProvide the data to applications and end userRequirementsIT/Software Engineer or related field. Proven experience as a Data Engineer or similar roleStrong proficiency in PythonHands-on experience with Terraform for Infrastructure as CodeKnowledge of containerization and orchestration tools like Docker and KubernetesFamiliarity with AWSStrong problem-solving and analytical skillsExcellent communication and collaboration skillsNice to have:Familiarity with Kafka or other message queuing systemHands-on experience with Apache Airflow or DagsterFamiliarity with machine learning frameworks and concepts


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Consultant¬∑e Cloud Data Engineer GCP/Azure,Saegus,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/consultant%C2%B7e-cloud-data-engineer-gcp-azure-at-saegus-3769067736?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=tjPtpGd6a8%2B%2BlOehVWdP5w%3D%3D&position=1&pageNum=8&trk=public_jobs_jserp-result_search-card,"Qui est Saegus ?Saegus est la ConsulTech qui accompagne ses clients (grands groupes du CAC 40 / SBF 120) dans leur transition vers l'entreprise intelligente et responsable de demain, le Smart Shift.Le Smart Shift repr√©sente bien plus qu'une simple transition num√©rique. C'est une vision strat√©gique compl√®te qui int√®gre les technologies √©mergentes, telles que l'intelligence artificielle et l'utilisation performante et raisonn√©e de la Data, √† des changements culturels, organisationnels et de gouvernance.Nous appliquons √©galement l‚Äôapproche Smart Shift pour offrir √† nos consultants un environnement propice √† leur d√©veloppement professionnel et √† leur √©panouissement : The Best Place To Grow. Au-del√† de pouvoir vivre l'exp√©rience d'un Smart Consultant (par l'IA), en rejoignant notre √©quipe, vous b√©n√©ficierez d'une culture d'entreprise ax√©e sur l'agilit√©, l'innovation et l'adaptabilit√©. Nous accompagnons nos Saegusien¬∑ne¬∑s √† d√©velopper de nouvelles comp√©tences, √† explorer les nouvelles technologies et √† cultiver un esprit entrepreneurial, le tout accompagn√© par une √©cole du conseil (parcours de formation propre √† Saegus), un catalogue de formations et de certifications et un coach interne.Smart Shift. For Real.Saegus est incarn√© par ses quatre d√©partements :Shift Acceleration, pour acc√©l√©rer le passage d‚Äôune id√©e en un produit ou service au sein de grandes entreprises gr√¢ce √† des outils et m√©thodologies agiles ;Smart Data, pour rendre compr√©hensibles, exploitables et valorisables les donn√©es des entreprises ;Smart Workplace, pour cr√©er un environnement humain, physique et technologique optimal pour l‚Äôensemble des collaborateur¬∑rice¬∑s ;Smart Experience Factory, pour designer et d√©velopper des applications sur-mesure gr√¢ce √† une m√©thode centr√©e utilisateurs.Ainsi, nous recrutons un.e Consultant¬∑e Cloud Data Engineer.Concr√®tement, quelle sera la mission et les r√©alisations attendues ‚ùìEn tant que Consultant¬∑e Data Engineer, tu seras int√©gr√©¬∑e √† l‚Äô√©quipe Smart Data dont la mission est d‚Äôaider ses clients √† tirer profit des technologies les plus innovantes pour valoriser leurs donn√©es. De l‚Äôacquisition √† la restitution, tu interviens sur chaque √©tape du processus d‚Äôaide √† la d√©cision.Tu participeras aux missions de conseil et d‚Äôexpertise afin de contribuer √† l‚Äôatteinte des objectifs majeurs de nos clients et contribueras √† la r√©alisation de projets tels que :‚ö°Ô∏è Le design d‚Äôune plateforme Azure Cloud et la mise en place de pipeline d‚Äôingestion et exposition de donn√©es pour la mise √† disposition de donn√©es m√©tiers, rafra√Æchies toutes les 30mn‚ö°Ô∏è La mise en place des bonnes pratiques et l‚Äôinitialisation du Datalab pour un grand groupe d‚Äôassurance, et l‚Äôaccompagnement √† l‚Äôindustrialisation des algorithmes pour les usages m√©tiers‚ö°Ô∏è L‚Äôensemble des traitements d‚Äôingestion et pr√©paration des datasets afin d‚Äôalimenter des Dashboard de monitoring de l‚Äôactivit√© digitale Worldwide d‚Äôun grand groupe cosm√©tique afin de mesurer l‚Äôempreinte des marques sur les m√©dias et r√©seaux sociaux‚ö°Ô∏è L‚Äôaccompagnement √† la cr√©ation et l‚Äôactivit√© d‚Äôune Data Factory pour traiter l‚Äôensemble des donn√©es d‚Äôun grand groupe de distribution et mettre √† disposition des donn√©es qualifi√©es pour les diff√©rents use cases m√©tiersNous recherchons un.e passionn√©.e poss√©dant une envie de de f√©d√©rer et faire monter en valeur les consultants autour des th√©matiques Data Engineering recouvrant la mise en place de Plateforme de donn√©es, des bonnes pratiques de d√©veloppements et des process DataOps, l‚Äôindustrialisation de pipeline de traitements de donn√©es pouvant aller jusqu‚Äô√† la Data Visualisation.‚ûú Dans quel environnement ?En fonction de tes missions et r√©alisations projet, tu seras amen√©¬∑e √† int√©grer des √©quipes compos√©es de Data Engineer, Data Scientist, Data Architects, organis√©es en mode agile. Tes activit√©s s‚Äôappuieront sur les m√©thodes et savoir-faire de Saegus et sur son catalogue d‚Äôoutils et technologies sur lesquels tu as une ma√Ætrise sur plusieurs d‚Äôentre eux :‚úÖ Bonnes connaissances sur les architectures data et cloud (connaissance d‚Äôun environnement Cloud) :Azure (Data Factory, Synapse, ADLS, Databricks)Google GCP (BigQuery, Composer, Data Studio)‚úÖ SQL, Python‚úÖ Spark, PySpark‚úÖ Airflow, Kafka, Jenkins‚úÖ Solides connaissances des processus collaboratifs et outils de d√©veloppement (DevOps, Git, CI/CD‚Ä¶)Les connaissances suivantes seraient un plus ‚§µÔ∏èOpenShift, Docker, KubernetesData visualisationBases NoSQLCertification Data Engineer (Azure Data Engineer, Google Professional Data Engineer ou Snowflake SnowPro)Ce que nous t‚Äôapportonsüí´ FORMATIONS ET D√âVELOPPEMENT DE CARRI√àREUne journ√©e de formation incluse dans ton parcours d‚Äôonboarding lors de ton premier mois d‚Äôarriv√©e pour partager sur les fondamentaux et r√©pondre √† tes questionsAcc√®s √† un coach interne et consultant comme toi pour t‚Äôaccompagner dans ton quotidien (questions en particulier, aide, mont√©e en comp√©tences)Un plan de formations et de certifications ambitieux (minimum 1 certification offerte par an)‚≠êÔ∏è AVANTAGESRemboursement de tes frais de transports (remboursement √† 100% de ton pass navigo ou forfait mobilit√© durable jusqu‚Äô√† 700‚Ç¨ par an pour l‚Äôutilisation et l‚Äôaide √† l‚Äôachat de mat√©riel de mobilit√© douce)Titres restaurant √† hauteur de 216‚Ç¨/mois pris en charge √† 60% par Saegus (Carte Swile)Prime vacances (vers√©e en juin)Prime t√©l√©phone 25‚Ç¨/moisPrime d‚Äôint√©ressement aux r√©sultats de l‚ÄôentreprisePrise en charge par Saegus de la mutuelle √† la hauteur de 75%üëã COH√âSION ET CONVIVIALIT√âOrganisation de deux activit√©s par mois (fun, solidaire ou excellence) par notre Team AnimUn s√©minaire annuel pour favoriser la coh√©sion entre SaegusiensAcc√®s aux locaux de Saegus, tr√®s accueillants dans le centre de Paris notamment lors de nos SaegUp mensuelProfil recherch√©üéØ Id√©alement, en termes de comp√©tences, nous recherchons :Un profil de formation sup√©rieure (Bac + 5 minimum), ing√©nieur ou √©quivalent, avec une exp√©rience d‚Äôau moins 3 ou 4 ans minimum dans le domaine du Big Data.Tu as d√©j√† men√© avec succ√®s plusieurs projets Big Data avec des r√©f√©rences significatives dans la mise en place de flux de donn√©es et de traitement de l‚Äôinformation.Tu interviens en autonomie sur tes projets et as une premi√®re exp√©rience d‚Äôencadrement technique.Tu es motiv√©.e pour int√©grer une structure alliant l‚Äôexigence d‚Äôun cabinet de conseil et le dynamisme et l‚Äôagilit√© d‚Äôune start-up.Tu es un¬∑e tr√®s bon¬∑ne communiquant¬∑e et as un fort esprit d‚Äôinitiative, un go√ªt prononc√© pour les nouvelles technologies et un bon esprit de synth√®se.Ton sens du service et ton √©coute client te permettront de t‚Äôinscrire parfaitement dans la culture de notre cabinet de conseil.La ma√Ætrise de l‚Äôanglais et du fran√ßais √† l‚Äô√©crit et √† l‚Äôoral est indispensable.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes', 'OpenShift'], 'Collaboration': []}"
Data Quant Developer / Python - Hedge Fund - CDI - 100/180K‚Ç¨ - Paris,MR SEARCH,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-quant-developer-python-hedge-fund-cdi-100-180k%E2%82%AC-paris-at-mr-search-3804058753?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=yLkQC4BhDP2xnvt7uRg%2F8w%3D%3D&position=2&pageNum=8&trk=public_jobs_jserp-result_search-card,"Data Quant Developer Python ‚Äì Hedge Fund ‚Äì CDI ‚Äì 75 ‚Äì 100/180 K‚Ç¨ La soci√©t√© : Fond g√©rant plus 10 milliards dollars. Les 450 collaborateurs sont r√©partis dans les bureaux en plein centre de Paris ainsi qu‚Äô√† Londres, Hong Kong et New York.En croissance permanente, la soci√©t√© pr√¥ne des valeurs fortes tels que l‚Äôinvestissement et l‚Äôengagement. Le poste : Vous rejoignez les √©quipes Tech avec pour objectifs d‚Äô√©valuer les nouvelles sources de donn√©es √† int√©grer dans la plateforme en lien avec les √©quipes de chercheurs quantitatifs :Analyser les sources de donn√©esMettre en place des solutions de Machine Learning pour extraire les donn√©es cibl√©esG√©rer les diff√©rentes phases de traitement de la donn√©e : exploration, acquisition, engineeringValider les choix technologiquesAssurer la mise en production et la maintenabilit√© des flux de donn√©esProfil recherch√© : Ecole d‚Äôing√©nieurPlus de 3 ans d‚Äôexp√©rience dans le domaine de la Data : Data Engineer, Data Quant ou Data ScientistExpert Python, Python ML, numpy, pandasConnaissance du NLPUne premi√®re exp√©rience en banque d‚Äôinvestissement ou en Hedge Fund est appr√©ci√©eAnglais : courantVous avez la volont√© et les capacit√©s pour travailler dans un environnement exigeantPackage : Salaire fixe : selon exp√©rience et sup√©rieure √† la moyenne du march√©Bonus discr√©tionnaire : il peut d√©passer 100% du fixeParticipation : √©lev√©e Si ce poste vous int√©resse, envoyez-moi votre CV.Matthieu RicourMR Search


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Viz Engineer (H/F),Thales,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-viz-engineer-h-f-at-thales-3808500017?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=10g76wnsvYBx4yPXJpnh1Q%3D%3D&position=3&pageNum=8&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales propose des syst√®mes d'information et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d'importance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d'information critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l'utilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l'activit√© Syst√®mes d'information critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d'information afin de faire face aux ruptures technologiques et aux cybermenacesL‚Äô√©quipe de la BI Factory recherche un(e) Data Viz Engineer (H/F)QUI ETES-VOUS ?De formation Ing√©nieur ou Bac +5 (√©cole d‚Äôing√©nieur ou Universit√©), vous justifiez d'une exp√©rience professionnelle dans le monde de la DataViz / BI d‚Äôau moins 3 ans autour des solutions Qlik ou Power BI.Vous souhaitez mettre √† disposition votre expertise dans le monde de la Data et continuer √† d√©velopper vos comp√©tences dans les aspects : Big Data, Data valorisation, Data Vizualisation, Data engineering et/ou Data Science et √™tes dot√© d‚Äôun bon relationnel.Vous √™tes pragmatique, curieux et organis√© et aimez le travail bien fait.Vous √™tes autonome, capable de travailler dans un environnement en √©volution permanente et avez le sens du service (engagement et livraison)Vous √™tes familier avec les pratiques agiles.Votre niveau d'anglais vous permet de r√©diger des documents ou d'animer des r√©unions en anglais par t√©l√©phone/visio dans un contexte international.Vous vous reconnaissez ?CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :Le domaine de la Data est devenu aujourd'hui un enjeu majeur dans la strat√©gie des entreprises et leur transformation digitale. C‚Äôest pourquoi nous r√©pondons aux besoins de nos client en leur offrant des solutions high-tech reposant d‚Äôune part sur notre connaissance des m√©tiers, et d‚Äôautre part sur notre capacit√© d‚Äôinnovation et notre savoir-faire autour de la Data (collecte, traitement, analyse, valorisation).Vous serez int√©gr√©(e) dans le centre de comp√©tences ¬´ Augmented Data ¬ª de Brest, au sein de l‚Äô√©quipe BI Factory.La BI Factory, c‚Äôest une √©quipe d√©di√©e agile √† taille humaine qui adresse les besoins Data Vizualisation & Business Intelligence au sein du Groupe Thales et √©galement pour nos clients hors Groupe.Vous interviendrez sur une diversit√© de projets de d√©veloppement de syst√®mes d‚Äôinformation de nos clients locaux, mais aussi nationaux (domaines D√©fense, Banque, Assurance, Energie).Au sein de ce centre, vous rejoindrez notre √©quipe de Data Engineers, Data Architects et Data Scientistes install√©e √† Brest. Data Viz Engineer, vous vous verrez confier les missions principales suivante :- Mener des ateliers de cadrage avec les utilisateurs finaux afin de recueillir tout d‚Äôabord leurs besoins puis ensuite leur pr√©senter votre travail,- Participer √† la conception de l‚Äôarchitecture g√©n√©rale des syst√®mes d√©cisionnels de nos clients,- √ätre force de proposition et orienter les choix techniques en fonction de votre exp√©rience et de la politique technique du groupe,- Impl√©menter les solutions valid√©es par nos clients,- Etre le garant de la qualit√© technique des solutions produites et du respect de l'architecture initiale,- Contribuer au sein du d√©partement √† l'effort d'animation technique, de veille technologique et d'innovation au sein des groupes de travail mis en place,- Partager vos connaissances au sein de la communaut√© BI Thales en pr√©sentant vos exp√©riences sur vos travaux r√©cents et approches innovantes.NOUS VOUS OFFRONS:- Une diversit√© de projets vous permettant de d√©couvrir plusieurs environnements techniques et fonctionnels ainsi que l‚Äôensemble de nos m√©tiers au sein du groupe Thales,- Des conditions de travail motivantes et un plan de carri√®re personnalis√© offrant de r√©elles perspectives d‚Äô√©volution,- La possibilit√© de vous investir dans une entreprise dont la r√©putation est mondiale avec des ambitions constantes d‚Äôinnovations techniques,- Un cadre de travail privil√©gi√© dans des bureaux situ√©s √† un endroit dynamique du port de commerce de Brest,- La possibilit√© de t√©l√©-travailler jusqu‚Äô√† 10 jours par mois. Alors n'attendez plus, rejoignez-nous ! Thales reconna√Æt tous les talents : la diversit√© est notre meilleur atout. Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd'hui


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Paris H/F,Inventiv IT,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-paris-h-f-at-inventiv-it-3802092413?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=1OaelfvzhoupYpjj9Bc3bQ%3D%3D&position=4&pageNum=8&trk=public_jobs_jserp-result_search-card,"Imaginez comment vos comp√©tences et votre vision pourraient enrichir notre dynamisme üöÄVotre √©nergie entrepreneuriale est le moteur de vos ambitions : vous visez toujours plus haut, d√©sireux(se) de porter l'entreprise vers des sommets inexplor√©s. R√©unir et inspirer les √©quipes fait naturellement partie de qui vous √™tes, tout comme votre in√©branlable expertise et votre passion pour chaque projet.La porte est ouverte pour discuter de l'impact que vous pourriez avoir ici‚¨áÔ∏èEt si vous d√©couvriez une entreprise cr√©√©e en 2008 autour de‚ÄØl‚Äôhumain et l‚Äôenvie d‚Äôaccompagner diff√©remment ses‚ÄØclients :‚û°Ô∏è Nous sommes une tribu de 100 esprits dynamiques et passionn√©s, une entreprise √† taille humaine o√π chaque voix compte. Notre cabinet de conseil en constante √©volution incarne l'agilit√© et une flexibilit√© qui nous permet d'explorer des approches nouvelles et innovantes, centr√© sur le collaborateur..Nos consultants ont des responsabilit√©s au sein de nos‚ÄØ 4 p√¥les centraux : DIGITAL, DATA, CLOUD et FACTORY.Dans le cadre de son d√©veloppement,¬†Inventiv IT recrute un DATA Engineer avec une exp√©rience de 4 ans au minimum.Le Poste est bas√© √† Paris. Rythme de Travail HybrideüéØInventifs Wanted Vous participerez au d√©veloppement des projets ou des services data en d√©veloppant une cha√Æne de traitement de donn√©es robuste et automatis√©e :Sp√©cifications techniquesRelease plan des diff√©rents livrablesIngestion et mise en qualit√© des donn√©es selon les bonnes pratiques de la FactoryTraitement, agr√©gation et sauvegarde des donn√©esInt√©gration continue (versioning, packaging, tests et d√©ploiement)√âtroite collaboration avec le chef de projet, OPS et architectesParticipation aux activit√©s d‚Äôarchitecture, conception et d√©veloppementRecette et mise en productionContribuer pro activement √† la veille scientifique et technique, aux projets R&D, et √† la construction d‚Äôassets et de services techniques orient√©s data ;Participer aux autres activit√©s du p√¥le Data Science & Engineering (reporting d‚Äôactivit√©, communication interne et externe, collaboration avec les universit√©s et laboratoires associ√©s)En mode agile : ScrumComp√©tences :Maitrise de Microsoft Azure Data Lake StorageMaitrise de Spark / ScalaConnaissances Git / Azure DevOpsConnaissances Airflow / DataDog / NifiPour vous aider √† affronter nos d√©fis,¬†¬†vous disposez d‚Äôau moins 5 ans d‚Äôexp√©rience dans les Big Data.Vous avez un esprit entrepreneurial et souhaitez vous investir pour faire grandir l‚Äôentreprise dans laquelle vous travaillez. Vous savez f√©d√©rer les √©quipes autour de vous et avez une r√©elle expertise et rigueur dans ce domaine.Vous poss√©dez un bon niveau d‚Äôanglais.ü§© Inventiv OffersOn comprend bien que pour vous, un job ne se limite pas √† √™tre ""juste"" un job. On aimerait vous d√©voiler ces petits d√©tails qui font battre le c≈ìur et font toute la diff√©rence:Vous √™tes au c≈ìur de nos priorit√©s, nos actions en sont le reflet‚ÄØ: Culture d'entreprise : partage des connaissances et esprit novateur Equilibre vie professionnelle / Perso: une‚ÄØflexibilit√© d‚Äôhoraires‚ÄØet du t√©l√©travailOpportunit√©s de d√©veloppement professionnel : des d√©fis stimulants pour grandirDes s√©minaires et √©v√©nements m√©morables, accompagn√©s de soir√©es d'entreprise chaleureuses.R√©mun√©ration : 52 000 - 58 000 ‚Ç¨Sans n√©gliger les avantages essentiels :Mat√©riel au choix : ordinateur (PC ou Mac) recycl√© ou neuf12 Jours de RTT / an - Et des jours en plus pour les moments de vie : mariage, naissance, paternit√©T√©l√©travail friendly (2 jours TT)Et bien s√ªr: Pass Navigo (100%) , carte Swile (10 ‚Ç¨ /Jour), Forfait t√©l√©phonique, Mutuelle Axa, primes diverses (participation, vacances, cooptation)Processus de recrutement :Entretien RH  avec une personne de notre Team RH : Discussion approfondie sur les motivations et l'ad√©quation avec la culture d'entreprise.Entretien Manager : √âvaluation approfondie des comp√©tences sp√©cifiques au poste avec l'un de nos managers√âchanger avec vos pairs : opportunit√© de sentir l'ambiance, et l'environnement de travail.Envoi de la proposition : Bienvenue chez Inventiv-IT ü§∏‚Äç‚ôÄÔ∏èChez nous, chaque voix, chaque talent compte, sans aucun pr√©jug√©. Que vous soyez jeune ou plus exp√©riment√©(e), peu importe votre origine, identit√©, religion ou orientation, nous valorisons chaque candidature. Nous nous engageons √† r√©pondre √† toutes les candidatures dans les 72 heures.De plus, nous nous engageons fermement √† l'inclusion, ouvrant tous nos postes aux personnes en situation de handicap.Rejoignez nous pour faire partie d'une √©quipe o√π l'√©galit√© des chances est une r√©alit√©, o√π votre collaboration sera votre plus grand atout !


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer  H/F,Amiltone,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-amiltone-3701770014?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=PBUx5bmhjgIPHKJpw%2BaNIQ%3D%3D&position=5&pageNum=8&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?Nous sommes passionn√©s par les nouvelles technologies, et vous ?Rejoindre Amiltone, c‚Äôest int√©grer des √©quipes dynamiques et soud√©es dans le cadre de projets novateurs et ambitieux. Nous relevons les challenges techniques de nos clients et les accompagnons dans leur transformation digitale.Pourquoi choisir Amiltone‚ÄØ?Amiltone, plus qu‚Äôune entreprise, un √©tat d‚Äôesprit !Notre objectif ? Votre √©panouissement professionnel !Nous Avons √† C≈ìur DeVous accompagner au mieux au travers d‚Äôun suivi personnalis√© Vous faire monter en comp√©tences en vous proposant des formations tout au long de votre carri√®re Comprendre vos besoins et respecter nos engagements Vous proposer des missions de qualit√© avec des technologies innovantes Cultivervotre potentiel gr√¢ce √† notre programme de d√©veloppement personnel Addvise Votre bien-√™tre passe aussi par des activit√©s extraprofessionnelles, c‚Äôest pourquoi nous vous proposons des s√©ances sportives anim√©es par nos coachs, soir√©es pour se retrouver et animations (√† l'agence ou en visio), Gaming nights‚Ä¶Les Missions D'un AmiltonienEn tant que Data Engineer (H/F), vous serez en charge des missions suivantes :‚Äì Concevoir et d√©velopper les futures fonctionnalit√©s de la plateforme Big Data sous Google Cloud Platform.‚Äì Concevoir les flux d'alimentation et les tables (structure de donn√©e).‚Äì Automatiser et industrialiser les flux.‚Äì Assurer le run applicatif, le cas √©ch√©ant.La Stack TechniqueMa√Ætrise des langages suivants : SQL, Talend, BigQueryConnaissances de Google (GCP)Notion de programmation fonctionnelleLe Profil D‚Äôun AmiltonienDipl√¥m√© Bac+4/5 (Ecole d'ing√©nieur/Master), vous disposez de 2 ann√©es d'exp√©rience dans le d√©veloppement de data.Toujours sur le qui-vive des nouveaut√©s technologiques, vous √™tes force de proposition sur des technos, des outils ou des process qui permettent d'am√©liorer la qualit√© du code et la stabilit√© de nos applications.Outre vos comp√©tences techniques, nous nous int√©ressons √©galement √† votre potentiel et votre motivation.Nos postes sont ouverts aux personnes en situation de handicap.Postuler
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,ALFI : Financial Markets Consultancy Services,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-alfi-financial-markets-consultancy-services-3799072485?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=i4jqJ9fH4MDGgq%2BZzgCMYQ%3D%3D&position=6&pageNum=8&trk=public_jobs_jserp-result_search-card,"ALFI est une soci√©t√© de conseil et services sp√©cialis√©e en syst√®mes d‚Äôinformation. Depuis plus de 20 ans, ALFI est un acteur unique qui m√™le technologie et humain pour accompagner les transformations num√©riques sur les march√©s de l‚ÄôAsset Management, la banque d‚ÄôInvestissement et les Services aux Investisseurs.Avec plus de 46 r√©f√©rencements de rang un, ALFI est reconnu comme incontournable sur le secteur BFA. Nous avons plus de 35 clients grands comptes actifs tels que HSBC, Soci√©t√© G√©n√©rale, BNP Paribas, Cr√©dit Agricole, Axa‚Ä¶Depuis 2015, ALFI a int√©gr√© le groupe MoOngy, qui compte plus de 6000 salari√©s dans toute l‚ÄôEuropeMissions : Pour l'un de nos clients grands comptes, nous vous proposons d'intervenir sur une fonction de Consultant Data engineer.Les principales missions sont :Comprendre les besoins des utilisateurs et les traduire de mani√®re analytiqueD√©veloppement de solutions permettant de traiter des volumes importants de donn√©esConception, collection et fabrication des donn√©es brutesD√©velopper des algorithmes permettant de r√©pondre aux probl√®mes pos√©s et veiller √† leur industrialisationS√©curisation des Pipelines donn√©es pour les Data Scientists et les Data AnalystsConstruire des bases de donn√©es robustesOrganisation de l‚Äôarchitecture du cloudProfil recherch√© :Vous √™tes issu d'une formation Bac +5 Ecole scientifique ou informatique.Vous disposez d'une premi√®re exp√©rience en d√©veloppement et dans la data.Vous disposez d'un niveau d'anglais op√©rationnel.Java, Python, C++SQLDevops (Jenkins, Kubernetes, Docker)Conform√©ment √† la r√®glementation, et √† notre politique d‚Äô√©galit√© professionnelle, tous nos postes sont ouverts aux personnes en situation de handicap;


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Stage Data Engineer (F/H),Capgemini,"Aix-en-Provence, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-f-h-at-capgemini-3806599442?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=Cd3gmcdXcYTUe3VupkcEiA%3D%3D&position=7&pageNum=8&trk=public_jobs_jserp-result_search-card,"DESCRIPTION DU POSTE Vous serez int√©gr√© au sein de notre Service Line Data Value et vous interviendrez sur les diff√©rentes phases d'un projet BI/Big Data: ‚Ä¢Acquisition des donn√©es ‚Ä¢Stockage optimis√© ‚Ä¢Traitements et analyses ‚Ä¢Mise en forme et d√©veloppement de rapports/dashboards Vous proposerez des nouvelles lectures de donn√©es via un travail de fouille sur les gisements d‚Äôinformation, notamment client. Dans votre quotidien, vous contribuerez au partage et √† la capitalisation des savoirs et des pratiques au sein de la communaut√© data de Capgemini. Environnement techniqueETL (Talend, Informatica, SSIS), Spark, Python, Scala, Qlik, Tableau, Power BIBase de donn√©esOracle, SQL Server, PostgresVotre profil : En derni√®re ann√©e d‚Äô√©cole d‚Äôing√©nieur ou de M2, vous cherchez un stage de fin d‚Äô√©tudes en vue d‚Äôint√©grer durablement une entreprise de services du num√©rique. Dynamique, vous avez l‚Äôesprit d‚Äô√©quipe et de fortes app√©tences pour le domaine de la Data. Vous disposez d‚Äôun premier stage dans la data. Motiv√©, vous souhaitez vous investir dans une soci√©t√© qui vous offrira de belles perspectives de carri√®re, un accompagnement sur mesure manag√©rial et RH et de beaux projets techniques. Bon niveau d‚Äôanglais (√©quivalent B2+ minimum)


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Betclic Group,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-betclic-group-3193434928?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=ORxSM5zs%2BtN%2BxhEDd1bQ1Q%3D%3D&position=8&pageNum=8&trk=public_jobs_jserp-result_search-card,"WE ARE BETCLICBetclic est une soci√©t√© tech de jeu en ligne et leader du pari sportif dans plusieurs pays Europ√©ens. Tous les jours Betclic s‚Äôengage √† satisfaire la passion du sport en fournissant la meilleure exp√©rience de divertissement √† ses joueurs gr√¢ce √† des technologies de pointe innovantes qui leur assurent un environnement de jeu s√ªr et sain.Betclic, dont le si√®ge fran√ßais est √† Bordeaux, est une entreprise multiculturelle et internationale comptant pr√®s de 950 collaborateurs r√©partis dans 5 pays d‚ÄôEurope‚ÄØ: France, Italie, Malte, Pologne, et Portugal.L‚Äôunivers du sport et du jeu te fait vibrer ? Tu aimes les d√©fis, tu es passionn√© par la tech et participer √† l‚Äôeffort collectif‚ÄØ? Rejoins l‚Äôaventure‚ÄØ!NO TECH NO GAME Betclic place la performance technologique au c≈ìur de ses activit√©s :Des applications enti√®rement d√©velopp√©es en interne pour une ma√Ætrise optimale de la cha√Æne de valeur : segmentation en temps r√©el, sensibilisation et int√©gration de r√®gles pour prot√©ger les joueurs, d√©tection des risques ‚Ä¶ Des interfaces con√ßues pour une exp√©rience joueur immersive : hautement s√©curis√©es, capables de g√©rer de forts pics de connexion et d‚Äôint√©grer les √©v√©nements sportifs en streaming. Des √©quipes Tech organis√©es en squads et tribus autonomes, chacune responsable d'un domaine‚ÄØfonctionnel‚ÄØet technique qui permettent de g√©rer des projets de A √† Z‚ÄØ: d√©veloppement, test de charge, livraison, suivi de production (monitoring, alerting). ENTER THE GAMEEn tant que Data Engineer, tu int√©greras une √©quipe agile IT afin de construire les pipelines de transformation data. Dans ce cadre, tu travailleras √©troitement avec les d√©veloppeurs et le PO de l'√©quipe ainsi que les Data Architect sur la partie mod√©lisation.YOUR ROLE WITHIN BETCLICAu sein d‚Äôune tribe Betclic et accompagn√© par une guild de data engineers DBT, tes missions principales seront de‚ÄØ:Participer aux phases de conception et de d√©veloppement des projets de transformation data D√©velopper l‚Äôensemble de la cha√Æne de transformation (Extract Load Transform / Extract Transform Load) au sein du Data Lake (Snowflake). Construction du Lake House et des couches Silver/Gold √† partir de la couche Bronze du Lake. Automatiser le d√©ploiement des pipelines data (DBT cloud, CICD Jenkins) G√©rer l‚Äô√©volution des solutions propos√©es, et en assurer la maintenance R√©diger la documentation relative aux projets TECHNICAL ENVIRONMENTSnowflakeDBT Core / DBT Cloud AWSJenkins GithubWHO WE ARE LOOKING FOR?Des collaborateurs avec une bonne dose d‚Äôhumour, du respect et de la bienveillance, un amour pour la tech, un peu de z√®le et une r√©elle passion pour leur m√©tier !Ce job est fait pour toi si :Tu es dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur, √©cole informatique, MIAGETu disposes d‚Äôune exp√©rience professionnelle r√©ussie de 3 ans minimum en tant que Data Engineer / Data Ops / ML Ops dans un environnement Cloud PublicTu es dot√©(e) de fortes comp√©tences en d√©veloppement, d‚Äôune app√©tence pour l‚Äôautomatisation (CI/CD) et le scripting et tu souhaites rejoindre un environnement professionnel challengeant. Tu es sensible √† la performance, la fiabilit√©, la maintenabilit√© et la scalabilit√© de votre code et des architectures que tu con√ßoisTu ma√Ætrises imp√©rativement un des langages de d√©veloppement Python, Scala, Java et tu as une exp√©rience r√©ussie avec l‚ÄôInfrastructure As CodeEt enfin, tu parles anglais courammentWHAT ARE THE RECRUITMENT STEPS?Si ta candidature est s√©lectionn√©e, tu seras contact√© par Maxime sous une semaine pour une pr√©qualification RH (30 minutes) Nous te demanderons ensuite de r√©aliser le Test AssessFirst (personnalit√©, motivations et r√©flexion) Tu rencontreras ensuite ton futur manager puis Laurent le manager de la Data Platform qui t'√©valuera techniquement.Enfin, Maxime te recevra en entretien final RH et vous d√©brieferez ensemble ton Test AssessFirst Afin d‚Äôoffrir une exp√©rience candidat id√©ale, le processus de recrutement Betclic dure, en moyenne, 4 √† 6 semaines.WHAT CAN YOU EXPECT?25 jours de cong√©s pay√©s et 10 jours de ¬´‚ÄØRTT‚ÄØ¬ª Une carte Ticket Restaurant¬Æ cr√©dit√©e de 10‚Ç¨ par jour (financ√©e √† hauteur de 50%) Une mutuelle prise en charge √† 100% pour toi et tes enfants Un abonnement de transport pris en charge √† hauteur de 50% ou une prime annuelle de mobilit√© durable (200‚Ç¨ pour les trajets domicile ‚Äì travail en transport durable) Un accord de t√©l√©travail avantageux Un programme de formation annuel personnalis√© Des locaux hors du commun avec un rooftop pour profiter de pauses et de d√©jeuners au soleil face √† la Cit√© du Vin Des animations internes pour pimenter ton quotidien Des cours de sports gratuits dans nos locaux Et surtout, l‚Äôopportunit√© de travailler dans une atmosph√®re jeune, conviviale et fun‚ÄØ!Poste en CDI √† pourvoir d√®s que possible √† BordeauxBetclic Group - 117 quai de Bacalan 33300 BORDEAUXTous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F/X,Verisure,"Antony, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-x-at-verisure-3798322567?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=yT4XSOMq52p3W4OXPuQXrQ%3D%3D&position=9&pageNum=8&trk=public_jobs_jserp-result_search-card,"Verisure c‚Äôest l‚Äôalarme de votre voisin mais c‚Äôest aussi le N¬∞1 en France et en Europe ! Depuis plus de 30 ans, les √©quipes de Verisure partagent la m√™me mission : ¬´ Nous sommes des personnes qui prot√©geons des personnes ¬ª.Les femmes et les hommes de Verisure ont toutes et tous un parcours de vie unique. Nos diff√©rences sont notre force et nous offrent une √©nergie singuli√®re. Entreprise handi-accueillante et handi-bienveillante, nos postes sont √©videmment ouverts aux personnes en situation de handicap.En recherche permanente de nouveaux talents, nous avons besoin de VOUS en qualit√© de Data Engineer !Rattach√©(e) au Responsable Data, le/la Data Engineer sera le trait d‚Äôunion entre les √©quipes internationales du groupe Verisure et la France.Sa capacit√© √† apporter une connaissance et compr√©hension technique solide, nous permettra d‚Äôaccroitre nos expertises crois√©es.Enthousiaste et passionn√©(e), vous √™tes tr√®s √™tes √† l'aise avec les outils d‚Äôacquisition et de transformation de la donn√©e et avez une app√©tence toute particuli√®re pour toutes les probl√©matiques de flux temps r√©els et √©v√©nementiels.Vous faites preuve d‚Äôune grande compr√©hension des flux de donn√©es et intervenez en tant que ma√Ætrise d‚Äô≈ìuvre afin de garantir la bonne impl√©mentation des solutions informatiques d√©cisionnelles de l‚Äôentreprise. Vous √™tes rigoureux(se), structur√©(e) et vous savez vous adapter selon vos interlocuteurs. Vous avez √©galement le souci du d√©tail ainsi qu‚Äôun esprit d'analyse.Vos principales missions seront les suivantes :Cr√©er, maintenir et migrer les flux d‚Äôint√©gration de la plateforme internationaleImpl√©menter toutes les solutions techniques et/ou logicielles permettant d‚Äôam√©liorer la fiabilit√©.Administrer et monitorer les solutions communes multi-country (Data Viz ‚Äì Sharing).D√©velopper la connaissance technique de nos Data Engineer sur les technologies groupe.Accompagner le/la Product Owner dans le suivi des solutions Data multi-country.Collaborer avec notre Data Owner sur les travaux de normalisation de donn√©es.Maintenir nos r√©f√©rentiels techniques (cartographies, sp√©cifications) et dictionnaire de KPIs √† jour.√ätes-vous pr√™t √† rejoindre nos √©quipes Data & Analytics engag√©es et passionn√©es ?Vous justifiez d‚Äôune premi√®re exp√©rience de 2 ann√©e sur un poste de Data EngineerVotre app√©tence et curiosit√© autour des solutions Data ne fait aucun douteVous maitrisez le datamining, le SQL n‚Äôa aucun secret pour vousVous comprenez les flux informatiques anciens (BI classique) et modernes (temps r√©el et √©v√©nementiel)Vous appr√©ciez partager votre savoir-faire et faire grandir ceux qui vous entourentVotre niveau d‚Äôanglais est tr√®s avanc√©.Et votre savoir √™tre s‚Äôinscrit dans l‚ÄôADN de nos Data Lovers(euses), humilit√©, simplicit√© et bienveillance.A nos c√¥t√©s vous pourrez :B√©n√©ficier d‚Äôun accompagnement personnalis√© tout au long de votre parcours ;Profiter d‚Äôun tremplin de carri√®re gr√¢ce √† notre parcours d‚Äô√©volution ;Contribuer √† la croissance d‚Äôune entreprise qui s‚Äôengage au quotidien pour un monde plus s√ªr, plus juste et plus durable ;Evoluer dans un environnement de travail innovant gr√¢ce √† nos d√©veloppements technologiques et √† des projets ambitieux ;Travailler aux c√¥t√©s d‚Äô√©quipes engag√©es et passionn√©es ;Profiter des avantages suivants :Un dispositif d‚Äô√©pargne salariale adapt√© selon votre √©ligibilit√© et les accords en vigueur dans l‚Äôentreprise (int√©ressement et participation aux r√©sultats de l‚Äôentreprise) ;une pack mutuelle pour toute votre famille et une pr√©voyance ;prise en charge de votre d√©jeuner, adapt√©e selon le poste occup√© et votre lieu de travail ;une plateforme de formation 100 % digitale et gratuite ;une offre collaborateur sur nos produits ;une plateforme sportive en ligne gratuite, proposant plus de 300 activit√©s.Postulez d√®s aujourd‚Äôhui et embarquez au sein d‚Äôune aventure humaine aussi enrichissante que passionnante. Nous avons h√¢te de vous rencontrer !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,Sancare,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-sancare-3751911956?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=J5XnRIu8EDZ2irZBSZIDyw%3D%3D&position=10&pageNum=8&trk=public_jobs_jserp-result_search-card,"Qui sont-ils ?Les h√¥pitaux recueillent de multiples donn√©es de sant√© lors de l‚Äôhospitalisation d‚Äôun patient : comptes rendus m√©dicaux, observations du personnel soignant, r√©sultats d‚Äôexamens, etc.√Ä l‚Äô√©chelle de l‚Äôh√¥pital, cela repr√©sente une quantit√© massive de donn√©es, qui sont largement sous-exploit√©es. Sancare propose des outils pr√©dictifs utilisant les derni√®res avanc√©es en intelligence artificielle pour mettre ces donn√©es au service des h√¥pitaux et de la sant√©.Notre premier produit est d√©j√† utilis√© par une quarantaine de groupement hospitalier. Il permet la d√©tection automatique de diagnostics √† partir de documents en texte libre et autres donn√©es contenus dans les dossiers patients, visualisables dans une interface web intuitive et ergonomique, et fait gagner du temps aux m√©decins et √† leurs assistants administratifs. Nous d√©veloppons en parall√®le un nouvel outil facilitant la conduite d‚Äô√©tudes en vie r√©elle pour √©valuer des m√©dicaments et dispositifs m√©dicaux. Vu le fort impact potentiel de ce projet sur la recherche clinique, l‚Äôattente de la part de diff√©rents acteurs de la sant√© (notamment, h√¥pitaux et laboratoires pharmaceutiques) est consid√©rable.L'√©quipe de Sancare est compos√©e de presque 50 collaborateurs sp√©cialis√©es dans le d√©veloppement informatique, le machine learning et la sant√©. Nous avons de plus la chance d‚Äô√™tre accompagn√©s par des chercheurs reconnus dans le domaine du machine learning, ainsi que par des m√©decins et experts du monde de la sant√©.‚ÄØNous recherchons un(e) Data Engineer avec de solides comp√©tences op√©rationnelles et souhaitant rejoindre une √©quipe dynamique, exp√©riment√©e et motiv√©e, afin d‚Äôacc√©l√©rer l'arriv√©e de nos solutions en rupture dans le monde de la sant√©. Descriptif du posteLa gestion et le traitement de la donn√©e sont au coeur des probl√©matiques de Sancare. Comme chaque h√¥pital dispose de son propre syst√®me d‚Äôinformation, des connecteurs doivent √™tre impl√©ment√©s pour chacun, afin de nourrir les algorithmes de machine learning. Les moyens d‚Äôacc√®s et le format des donn√©es contenues dans les dossiers patients sont tr√®s vari√©s et diff√®rent d‚Äôun √©tablissement √† un autre.De plus, de nombreuses mesures sont √† respecter afin de garantir la s√©curit√© et la confidentialit√© des donn√©es.Missions :D√©veloppement de connecteurs permettant la transmission des donn√©es hospitali√®res entre les SI hospitaliers et les logiciels de SancareD√©veloppement d‚Äôoutils de standardisation et de traitement des donn√©es hospitali√®res en vue de leur utilisation par les algorithmes de machine learningAm√©lioration et maintenance des fonctionnalit√©s existantes de traitement de donn√©esGestion op√©rationnelle des diff√©rents services de traitement de donn√©es, etc. Les avantages‚ÄØ Sancare :Des superbes locaux en plein centre de Paris (Ch√¢telet)Une organisation du travail flexible (109 jours de t√©l√©travail par ann√©e civile pour les salari√©s en forfait jour: soit deux jours de t√©l√©travail possibles par semaine et ce forfait pourra √™tre port√© √† 131 jours de t√©l√©travail si les salari√©s au forfait jour justifient d‚Äôun temps de d√©placement domicile-bureau sup√©rieur √† 3h par jour: soit trois √† quatre jours de t√©l√©travail possibles par semaines pour les personnes √† plus d‚Äô1h30 du bureau)Tickets restaurant√âligibilit√© BSPCEMutuelle AlanHello CSE, etc.Chez Sancare on n‚Äôest jamais √† l‚Äôabri d‚Äôun ap√©ro ou d‚Äôun cours de street-art ! Des retours d‚Äôexp√©rience r√©guliers dans des formats vari√©s (afterworks, s√©minaires, ‚Ä¶) pour valoriser le partage d‚Äôid√©es et la connaissance commune. Profil recherch√©Exp√©rience significative dans le d√©veloppement en Python orient√© objet (3ans √† 5ans)Exp√©rience de d√©veloppement sous LinuxExp√©rience dans la manipulation de donn√©es avec le langage SQLPratique avanc√©e des outils d‚Äôint√©gration continue avec Git et tests unitairesDes qualit√©s d‚Äôautonomie, de flexibilit√© et de responsabilit√©L‚Äôesprit d‚Äô√©quipe et la volont√© de prendre part √† une aventure collectiveUn int√©r√™t pour le monde de la sant√©Sont un plus :Familiarit√© avec Docker et RabbitMqExp√©rience avec les donn√©es de santeÃÅ dans le secteur hospitalierN‚Äôh√©sitez pas √† partager vos projets personnels de d√©veloppement (sur GitHub ou ailleurs). D√©roulement des entretiensEntretien RHTest Technique puis Entretien Technique de pair programing avec l'√©quipe Entretien avec notre CEO


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
"Data Engineer - Scientific Engine (Airflow, DVC)",Descartes Underwriting,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-scientific-engine-airflow-dvc-at-descartes-underwriting-3699925454?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=yQs8ePVldRp7Yvc3GWtKfg%3D%3D&position=11&pageNum=8&trk=public_jobs_jserp-result_search-card,"ABOUT DESCARTES UNDERWRITINGDescartes was born out of the conviction that climate change calls for a revolutionary approach in insurance to better protect corporations, governments, and vulnerable communities. We offer a new generation of parametric insurance that builds resilience against the full spectrum of climate and emerging risks. Utilizing Machine Learning and real-time monitoring from satellite imagery & IoT, our state-of-the-art climate tech provides innovative coverage for all trade sectors in all regions of the world. After a successful Series B raise of $120M USD, Descartes Underwriting is proud to be recognized among the French Tech Next40 and launched Descartes Insurance, a ‚Äòfull stack‚Äô insurer licensed to underwrite risk by the French Regulator (ACPR). With a growing corporate client base (350+ and counting) - our diverse team is headquartered in Paris and operates out of our 13 global offices in North America, Europe, Australia, Singapore, Hong Kong and Japan. ABOUT YOUR ROLEDue to our consistent growth, we are expanding our Data, Software and DevOps team. We are seeking profiles dedicated to data engineering. At the core of the development of our scientific engine modeling climate phenomena, your main missions will be to create, improve and maintain the data pipelines used to train our model and infer the different scenario to make a climate risk assessment. You will have to take initiative and assess the viability of proof of concept projects.You will have to work with data scientists and software engineers to run and develop our models. You will be working along DevOps engineers to reliably put models in production and selected the compute/store instance needed to perform these tasks. Your secondary mission will be to automate the flow of information between the tech and business to monitor climate events.üîî KEY MISSIONS üîîSetup, automate, maintain and update:Connections to external and internal APIsData preparation processModel training and inference processData storage processAssociated CI/CD pipelinesAssociated package versioning and releasing pipelineModularization of code baseNotification tools to inform the team of the status of the operationsSetup data storage, data processing and data visualizing tools, by :Assessing the pains and needs of the teamsBenchmarking the open source and private solutionsAssessing the security, price and reliability of data architectureFollowing the development the evolution of technologies on the topicForecasting the usage of the toolsTracking the cost of the toolsParticipate in:Tech stack selectionDiscussions with tech partnersTraining of software and underwriting teamsSupport and debug of internal usersTECH STACK üñ•Ô∏èCloud provider: GCPCode versioning tool: Git + GitlabOS: LinuxContainer: DockerContainer orchestrator: KubernetesWebsite architecture: LAMPCode base: PythonNotification tool: SlackDATA STACK üóÑÔ∏èTypes: images, timeseries,Storage: GCP bucketVersion: DVC (roll out in progress)Pipeline: Airflow (PoC stage)Data base: to be setup depending on the use casesIn our project, data is collected by sensors (satellite, weather station, IoT). We don‚Äôt work with personal or sensitive data, in most cases the data is publicly available (earthquake magnitude, cyclone track, precipitation ‚Ä¶).EQUIPMENT üñ±Ô∏èLaptop: Dell Latitude 7530OS: you decideABOUT YOU EXPERIENCE & QUALIFICATIONS üë©‚Äçüíªüë®‚Äçüíª[Hard skills]Knowledge of the tech stack or equivalent toolsExperience converting python code to efficient data engineering tools (eg: spark)Experience with DockerExperience with a cloud provider (GCP, AWS or azure)Experience automating a CI/CD pipelineGood knowledge in English and fluency in French[Soft skills]Desire to train junior developers and explain CI/CD and cloud toolsDesire to suggest improvements to the architecture[Nice-to-have]Experience working data science project or scientific codeExperience with KubernetesExperience in HPCContribution to an open source projectMINDSET üí•Strong interest with climate issue (it‚Äôs not a hoax, many people suffer from it)Being comfortable to work alongside corporate insurers (some still wear suits üëî)You enjoy CI/CD automation (or at least appreciate the elegance of a well-crafted pipeline)Strong team spirit and ability to work (you‚Äôll have to review code and have your code reviewed)Rigorous, creative and meticulous mind (we handle large insurance, we take our time)Strong desire to learn (there‚Äôs no limitation to the tech used, we‚Äôre happy to test and learn new tools)Eagerness to work in a multi-cultural environment (policies and teams are from all around the world üó∫Ô∏è)WHY JOIN DESCARTES UNDERWRITING?Join a company with a true purpose ‚Äì help us help our clients be more resilient towards climate risks;A competitive salary, bonus and benefits (Premium Alan health insurance, Swile restaurant vouchers, Navigo reimbursement etc.);The opportunity to grow in your role, as the company does;Commitment from Descartes to it‚Äôs staff of continued learning and development (think annual seminars, training etc.);Be part of a collaborative, diverse team where your ideas are heard;A paid referral scheme for successfully referring peers;Frequent team events.OUR COMMUNITYAt Descartes Underwriting, we are committed to fighting against all forms of discrimination and for equal opportunities. We foster an inclusive work environment that respects all differences.With equal skills, all our positions are open to people with disabilities.HOW TO APPLY?If you want to develop your skills and work in a friendly start-up atmosphere, don't hesitate and send us your application! https://www.descartesunderwriting.com/careers/If you don‚Äôt check all the requirements in the description, don‚Äôt worry. We can try to make some room for you within the company if you‚Äôre motivated to work on climate risk.RECRUITMENT PROCESSStep 1: Call and HR Interview with our Talent RecruiterStep 2: Technical project submitted via GitHubStep 3: Technical interviewStep 4: Manager interviewStep 5: Final round interview with the team(Candidates can opt to have the manager interview before the technical project and interview)


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['Slack']}"
Senior Data Engineer (H/F),Believe,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-h-f-at-believe-3726297642?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=9fA50GJsLAI4XDNhpNAcDg%3D%3D&position=12&pageNum=8&trk=public_jobs_jserp-result_search-card,"Description De L'entrepriseBelieve est l'un des leaders mondiaux du march√© de la musique num√©rique. Believe a pour mission d‚Äôaccompagner les artistes et les labels locaux dans l‚Äô√©cosyst√®me digital en leur offrant des solutions √† chaque √©tape de leur carri√®re et d√©veloppementCe sont plus de 1900 salari√©s dans 50 pays qui accompagnent artistes avec expertise, respect, √©quit√© et transparence.Afin de soutenir notre forte croissance sur tous les continents, nous sommes constamment √† l‚Äôaff√ªt de nouveaux Believers. Rejoignez-nous afin qu‚Äôensemble, nous ayons un impact fort et plus positif sur l‚Äôindustrie musicale‚ÄØ!Believe est cot√©e sur le compartiment A du march√© r√©glement√© d‚ÄôEuronext Paris (Ticker : BLV, ISIN : FR0014003FE9).www.believe.comReady to #setthetone with Believe?Description Du PosteContexteLe Tribe ¬´‚ÄØCustomer Finance‚ÄØ¬ª est compos√© de plusieurs Squad, parmi elles la squad‚ÄØFinance Ingestion qui a pour mission de d√©velopper des outils et des applications pour la collecte de royalties aupr√®s des plateformes de streaming de musique ainsi que pr√©parer les donn√©es afin de faire la distribution des royalties aupr√®s des producteurs de musiques.En tant que Senior Data Engineer, tu int√©gras une √©quipe de Data Engineering travaillant avec les principes du framework agile Scrum. Cette √©quipe est compos√©e essentiellement de 5 Data Engineer et 1 Software Engineer.Nous Avons Un √âcosyst√®me Compos√© DeUn socle de gestion des donn√©es (Delta Lake) plus d‚Äô1.5 milliard de lignes /mois Data processing avec Scala et Spark utilisant le runtime de Databricks Orchestration de nos data pipelines avec Airflow manag√© Des APIs d√©ploy√©es avec AWS Lambda et API Gateway pour faire interagir les utilisateurs avec notre interface front (PHP) AWS RDS pour hoster la base de donn√©es back-end sous PostgreSQL Versionning du code sous GitLab avec un environnement de dev, staging et production Infrastructure sous AWS Les missions du Senior Data Engineer au sein de l‚Äô√©quipe : Accompagner les d√©veloppeurs √† √©crire du code propre, qualitatif et conforme aux standards de l‚Äô√©quipe‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Interagir avec l‚Äôarchitecte, les √©quipes infrastructures Cloud pour concevoir les solutions de data engineering Proposer des am√©liorations continues et √™tre garant de r√©duire les dettes techniques‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ D√©velopper des flux de donn√©es (data pipelines) avec de l‚ÄôApache Spark et du Scala‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Faire de l‚Äôorchestration via Airflow avec du Python‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Maintenir le workflow GitLab afin de garantir une bonne productivit√© de l‚Äô√©quipe de d√©veloppement‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Effectuer des revues de codes des autres membres de l‚Äô√©quipe‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Collaborer les membres de l‚Äô√©quipe dev pour atteindre l‚Äôobjectif du sprint‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ‚ÄØ Faire du support applicatif et fonctionnel de l‚Äôapplication aupr√®s des op√©rationnelQualificationsQualifications du Data Engineer  5-8 ans d‚Äôexp√©rience en Scala  Une maitrise horizontale de tous les composants d‚Äôune plateforme de data Exp√©rience en programmation fonctionnel Connaissance d‚Äôun effect system en Scala (ZIO ou cats) Excellente ma√Ætrise de l‚ÄôAPI Spark en Scala avec pour but de guider l‚Äô√©quipe sur les bonnes pratiques Exp√©rience en d√©veloppement backend Une bonne maitrise des services AWS (API Gateway, Lambda, SNS, SQS, S3, Cloudwatch, VPC) D√©velopper avec un √©tat d‚Äôesprit Keep it Simple, Stupid (KISS) Excellente comp√©tence dans la gestion de relation avec une √©quipe en remote Bonne communication pour g√©rer les diff√©rents points de vue et expliquer les contraintes aux utilisateursOptionnel Exp√©rience en PHP (framewok Symfony ou Laravel) Informations suppl√©mentairesSet the tone with us Chez Believe, nous avons deux c≈ìurs : nos collaborateurs et nos artistes.Nous croyons en la force de nos collaborateurs, qui s'√©panouissent chaque jour en d√©veloppant leur potentiel... Notre objectif est d'offrir √† nos collaborateurs le meilleur environnement possible pour qu'ils puissent s'√©panouir.Rock the jobProgramme de formation et de coaching sur mesureUne politique de t√©l√©travailUn programme de bien-√™tre ""Pauses"" avec de nombreuses activit√©s et animations en interneAcc√®s √† Eutelmed, la plateforme num√©rique de sant√© mentale et de bien-√™tre qui permet de parler √† un psychologue exp√©riment√©Un restaurant d'entreprise sain et √©co-responsableUne assurance sant√© individuelle ou familialeAvantages CEUn rooftopUne salle de sport avec des cours gratuitsSing in harmonyDes groupes d'ambassadeurs pour s'engager sur la r√©duction de l'empreinte carbone et environnementale de Believe et l‚Äô√©quit√© professionnelle Femme/Homme.Mise en place du Forfait mobilit√© durable: remboursement jusqu‚Äô√† 600‚Ç¨ des frais de transport en commun/avec une faible empreinte carbone.Cong√© 2nd parent de 5 jours calendaires r√©mun√©r√©s √† 100% (en plus du cong√© l√©gal paternit√© ou du cong√© d‚Äôadoption, nous ne l‚Äôattribuons pas au cong√© maternit√©)Believe s‚Äôengage √† garantir l‚Äô√©galit√© des chances en mati√®re d‚Äôemploi, sans tenir compte de l‚Äôorigine, du sexe, des m≈ìurs, de l‚Äôorientation sexuelle, du genre, de l‚Äô√¢ge, de la situation de famille, de l‚Äô√©tat de grossesse, d‚Äôune pr√©tendue race, des opinions politiques, des activit√©s syndicales, des convictions religieuses, de l‚Äôapparence physique, du nom de famille, du lieu de r√©sidence, de l‚Äô√©tat de sant√©, ou en situation de handicap.D√©couvrez nos nouveaux locaux : bit.ly/believeoffice
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Big Data Engineer Databricks H/F,Talan,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-databricks-h-f-at-talan-3810332102?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=V0N1zdgOhxOUlVGsK2Cziw%3D%3D&position=13&pageNum=8&trk=public_jobs_jserp-result_search-card,"Talan est un cabinet de conseil en innovation et transformation par la technologie.Depuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en ≈ìuvre leurs projets de transformation et d‚Äôinnovation en France et √† l'international. Pr√©sent sur cinq continents, le groupe pr√©voit de r√©aliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant¬∑e¬∑s et vise √† d√©passer la barre du milliard d‚Äô‚Ç¨ de CA √† horizon 2024.Le Groupe met l'innovation au c≈ìur de son d√©veloppement et intervient dans les domaines li√©s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.Pr√©sent dans les √©v√©nements incontournables du secteur, comme Viva Technology, Talan prend r√©guli√®rement la parole sur les enjeux de ces technologies r√©volutionnaires aux c√¥t√©s d'acteurs majeurs du secteur et de parlementaires (Syntec Num√©rique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny‚Ä¶).Talan est une entreprise responsable, attach√©e √† la diversit√©. Des am√©nagements de poste peuvent √™tre organis√©s pour tenir compte des personnes en situation de handicap.Retrouvez nos engagementsRSEiciet nos actions en faveur de la diversit√©iciJob DescriptionNous sommes √† la recherche d‚Äôun Big Data Engineer Databricks confirm√© qui sera en charge de l‚Äôint√©gration des donn√©es: acquisition, pr√©paration, mod√©lisation et stockage, exposition, . Vous devrez faire preuve d‚Äôun √©tat d‚Äôesprit √† la fois innovant, m√©thodique, orient√© solution (et non probl√®me!), et communiquant.Responsabilit√©sAnalyse des besoins techniques m√©tiers, d√©finition de l‚Äôarchitecture solution et logiciel, r√©f√©rent technique, d√©veloppement et optimisation, code review, maintenir les pratiques Devops ‚ÄúYou build IT, You run IT‚Äù, support √† recette et mise en production, documentation, et parfois assumer le r√¥le de Scrum Master,‚Ä¶Partager techniquement les membres de l‚Äô√©quipe: solutions et code reviews, recommandations, certifications √† r√©aliser, ‚Ä¶Participation √† des meet-up, coding dogo,‚Ä¶Communication: √©criture d‚Äôarticles, retours d‚Äôexp√©rience‚Ä¶QualificationsIssu d‚Äôune formation sup√©rieure (√©cole d‚Äôing√©nieur, master,‚Ä¶)Vous disposez d‚Äôau moins 3 ann√©es d‚Äôexp√©rience dans le domaine du Big Data et particuli√®rement sur le framework Spark (id√©alement Databricks)Ma√Ætrise du d√©veloppement logiciel (Scala, Python,‚Ä¶) et vous disposez de solides exp√©riences dans la mise en place de pipeline de donn√©esExp√©rience sur une plateforme Cloud serait un plus et id√©alement AWSExp√©rience sur des flux temps r√©elserait un plus : Kafka + Spark StreamingMaitrise du langage SQLExp√©rience sur des m√©thodes de stockage: HDFS, S3, ,‚Ä¶Bonnes connaissances en devOps : Jenkins, Gitlab, Maven, ‚Ä¶Connaissance de l‚ÄôAgilit√©Autonomie, organisation, sens du partageBonne communicationOrientation produit et solutionAdditional InformationAVANTAGES :Top 5 du Palmar√®s Great Place to WorkManagement de proximit√© par des expertsOrganisation sous forme decommunaut√©sUn parcours excellence Agile devopsFinancement de plusieurs certifications officielles √† l‚Äôann√©e gr√¢ce √† nos partenaires √©diteursUn acc√®s √† la plateforme CampusTalan avec plus de 1000 formations disponibles d√®s votre arriv√©eUne mobilit√© interne facilit√©eUn engagement aupr√®s des travailleurs en situation de handicapDes √©v√©nements et afterworks r√©guliersSi√®ge parisien situ√© √† Porte MaillotTickets restaurants digitalis√©sMutuelle d‚Äôentreprise prise en charge √† 100%Prime vacancesPrimes de cooptationActionnariat1% logementPartenaire de l'organisme Mobility dans le cadre de l'accompagnement √† la mobilit√© et √† la recherche de logementRTT


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer / DBA MySQL / MariaDB (H/F),euRHasi,"Puteaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-dba-mysql-mariadb-h-f-at-eurhasi-3795382260?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=jYL8idRogd5iH%2FXhyx%2Fpmw%3D%3D&position=14&pageNum=8&trk=public_jobs_jserp-result_search-card,"Description Du PosteLe cabinet EURHASI recrute pour son client un Data Engineer / DBA MySQL / MariaDB (H/F)Notre client est un des un des leaders de la connectivit√© cellulaire pour l‚ÄôInternet des Objets. Parall√®lement, notre client est un leader europ√©en en tant que MVNE (soci√©t√© apportant des solutions technologiques compl√®tes aux MVNO).La mission Le r√¥le du DBA est de concevoir, maintenir, superviser et d√©velopper l‚Äôinfrastructure des bases de donn√©es pour la plateforme Transatel afin de r√©pondre aux exigences de services pour les clients externes et les usages internes. Transatel propose ses services √† l‚Äôinternational pour des grands comptes ayant une haute exigence de disponibilit√© et d‚Äôefficacit√©. Cette activit√© permet aux DBA d‚Äôavoir des responsabilit√©s vari√©es et stimulantes avec de belles opportunit√©s d‚Äô√©volution.Au sein de la DTSI, rattach√©(e) au Responsable Infrastructure et Devops, vous int√©grez une √©quipe de 12 personnes dans les p√©rim√®tres SysAdmins, DBA, Monitoring.Vos principales missions :Assurer le maintien en conditions optimales des bases de donn√©es (performances, disponibilit√©) Optimiser les performances des traitements SQL effectu√©s par les plateformes Transatel Am√©liorer l‚Äôautomatisation des t√¢ches r√©currentes et des tests de supervision Participer aux mises en production des composants d√©velopp√©s et op√©r√©s par Transatel Rafra√Æchir les environnements de d√©veloppement/test avec des donn√©es √† jour et d√©sensibilis√©es Superviser et analyser l‚Äôactivit√© DB, Surveiller les jobs, Traiter les incidents Appliquer la politique de s√©curit√©, G√©rer les utilisateurs Conserver un environnement propre en assurant l‚Äôarchivage des donn√©es et le nettoyage des structures de donn√©es Maintenir la qualit√© des donn√©es maitres et donn√©es de r√©f√©rences, en relation avec les chefs de projets Apporter son expertise aux d√©veloppeurs pour la conception des structures de donn√©es et le d√©veloppement SQL Profil Profil recherch√©Capacit√© d‚Äôanalyse (investigation) m√©thodique et sens relationnel, Bonne gestion du stress, Bonne gestion des priorit√©s et respect des d√©lais, Travail collaboratif dans une direction technique avec des chefs de projets, d√©veloppeurs, sysadmin, r√©seau et t√©l√©com, BDD, Support, Capacit√© r√©dactionnelle, esprit synth√©tique afin de rendre compte des actions et des r√©alisations entreprises, Capacit√© √† transmettre son savoir et son savoir-faire, Exp√©rience de 3 ans minimum (hors stage) en tant que DBA MySQL & Le monde des Telecom ne vous est pas inconnu Anglais technique Votre univers technologique :MySQL/MariaDB, Percona, ColumStore, Galera Cluster, ElasticSearch 6.X Etc. Linux Debian, Centos, Redhat Bash, Python, Ansible Comp√©tences minimum attenduesExp√©rience de plus de 5 ans MySQL  MariaDB Informations contractuelles Les avantagesInt√©ressement Participation T√©l√©travail Mutuelle dentreprise Autresremboursement pass Navigo √† 50% avantages du CE 2 jours de t√©l√©travail par semaine La charte pr√©voit 2 jours de t√©l√©travail par semaine maximum apr√®s 2 mois d‚Äôanciennet√©.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go', 'Bash'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Linux'], 'SoftDB': ['MySQL'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,illi&co,"Croix, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-illi-co-3752842280?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=3XCe3a0RyiDpMYsas906Nw%3D%3D&position=15&pageNum=8&trk=public_jobs_jserp-result_search-card,"Leader Fran√ßais sur le march√© de la carte cadeau multi-enseignes depuis plus de 15 ans, illicado est LA marque embl√©matique du groupe illi&co !Nous avons pour mission de simplifier le quotidien de tous et agir collectivement pour le mieux-√™tre de demain !Nous pensons fi√®rement que chaque jour est une opportunit√© ! Alors, saisissez la VOTRE en r√©pondant √† cette annonce !MISSION :En coh√©rence avec la strat√©gie d‚Äôentreprise et la roadmap data, vous aurez pour principales missions de :- En lien avec l‚Äô√©quipe DevOps, construire, maintenir et faire √©voluer la plateforme de donn√©es;- D√©finir et piloter la coh√©rence de la collecte, la gestion et l‚Äôalimentation des donn√©es internes et externes, en diff√©rents modes : batch, streaming, API (architecture micro-services);- Pr√©parer et mettre en qualit√© les donn√©es pour les rendre disponibles dans les diff√©rents environnement de travail (datalake, datawarehouse, datamart);- V√©rifier la qualit√© des donn√©es, de leur bonne et r√©guli√®re ex√©cution ainsi que de leur utilisation ad√©quate (gestion des co√ªts);- Travailler en √©troite collaboration avec les data analysts, scientists et data stewards et business de l‚Äôentreprise ;- En lien avec l‚ÄôIT et la s√©curit√©, veiller aux r√®gles d'int√©grit√© et de s√©curit√© des donn√©es;- Veille technologique.LES OUTILS :Plateforme data : Google Cloud Platform (Big Query, Airflow)D√©veloppement : Github/GitLab, Docker, Terraform, PythonAnalytiques : QlikOutils gestion de projets: Jira, Confluence, Miro, Drive, Docs, Sheets, SlidesPROFIL RECHERCHE :Exp√©rience d‚Äôau moins 2 ans (apr√®s √©tudes) indispensable en data ing√©nierie (flux, mod√©lisation, run)A l‚Äôaise avec l‚Äôenvironnement Cloud et les infrastructures digitalesCommuniquant, p√©dagogue et fortes capacit√©s relationnellesAnglais (√† l‚Äô√©crit)Pourquoi rejoindre l‚Äôaventure humaine et professionnelle illi&co ?Nous voulons interagir avec toutes nos parties prenantes avec les valeurs qui nous animent, notre BASE :#Bienveillance - Prendre soin de soi et des autres#Audace - Chacun est libre d‚Äôavoir l‚Äôenvie et le courage d‚Äôoser#Simplicit√© - Nous sommes une entreprise o√π on agit avec naturel, clart√© et humilit√©#Enthousiasme - Un collectif d‚Äôhommes et de femmes optimistes et passionn√©sPour avoir un impact positif sur votre environnement #RSEAvantages : Fixe sur 12 mois + variable individuelParticipation/int√©ressement (environ 1,5 mois de salaire) + Actionnariat entrepriseTitres restaurants (sans part salariale)Statut Cadre (+RTT)Forfait mutuelle selon situation prise en charge √† 50% (solo, duo, famille)2,5 jours de t√©l√©travail flexibleIndemnit√© kilom√©trique si vous venez au bureau en v√©loDes bureaux modernes et super lumineux


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': ['JIRA', 'Confluence']}"
Data Engineer - Big data H/F CDI,Amanora Technologies,"Metz, Grand Est, France",https://fr.linkedin.com/jobs/view/data-engineer-big-data-h-f-cdi-at-amanora-technologies-3798913326?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=UU%2BsvM0BEPONK49gwCcGSA%3D%3D&position=16&pageNum=8&trk=public_jobs_jserp-result_search-card,"Fond√© en 2013 par un ancien dirigeant industriel mondial, AMANORA d√©montre un savoir-faire en combinant l'expertise d'un cabinet de recrutement et d'ing√©nierie. Actif √† l'√©chelle nationale en France,AMANORA se positionne dans divers secteurs tels que la m√©tallurgie, la pharmacie, la p√©trochimie, le nucl√©aire, l'a√©ronautique, l'agroalimentaire, ou encore le b√©ton.Amanora Technologies est une soci√©t√© d'ing√©nierie et de recrutement fond√©e en 2013 par un ancien dirigeant de l'industrie. Amanora Technologies intervient partout en France dans des secteurs tels que la m√©tallurgie, la pharmacie, la p√©trochimie, le nucl√©aire, l'a√©ronautique, l'agroalimentaire ou le b√©ton.Jeune talent, ing√©nieur ou manager exp√©riment√©, rejoindre Amanora c'est faire le choix d'int√©grer une entreprise √† taille humaine qui place le plaisir au travail au coeur de ses pr√©occupations.Nous recrutons un(e) Data Engineer - Big data qui sera en d√©l√©gation aupr√®s de notre client, groupe international leader sur le secteur de l'industrie lourde, Dans le cadre des travaux men√©s avec l'√©quipe Data Intelligence de la DTD ,vous interviendrez au sein de l'√©quipe DigitalOps du d√©partement IT Transverse qui est en charge de l'op√©rationnel et contribue √† certains projets du client.Vous √™tes int√©ress√©(e) par une mission vari√©e et motiv√©(e) par le processus de transformation de l'industrie version 4.0 Ce poste est fait pour vous !Principales missions : Contribuer au suivi et pilotage en condition op√©rationnelle des traitements existants en production V√©rifier et optimiser la disponibilit√©, la performance et l'efficacit√© des traitements Pr√©parer le passage en op√©rationnel / maintenance pour l'int√©gration et l'automatisation des flux Concevoir et r√©aliser les d√©veloppements en respectant l'architecture et les standards d√©finis Chiffrer / Estimer la charge des travaux √† r√©aliser R√©aliser les tests (unitaire / int√©gration) et la recette et les automatiser si possible R√©diger les livrables documentaires associ√©s (fonctionnel, technique, proc√©dure op√©rationnelle...) Vous √™tes de formation Ing√©nieur en d√©veloppement informatique / informatique industrielle ou √©quivalent (Bac+5) Vous maitrisez Spark, PySpark, Python, Git (Branch, Merge, Pull, Fetch, Rebase), Hadoop (Cloudera) / Hive / HDFS, SQL / NoSQL, OS : Unix / Linux, Kafka, Suite Elastik (ELK) Vous avez une exp√©rience de 3 ans minimum, id√©alement au service de l'industrie lourde Vous disposez d'une bonne capacit√© d'analyse et de synth√®se, Vous avez des comp√©tences en gestion de projet, r√©daction de documents et proc√©dures, animation de r√©union Vous √™tes curieux, autonome, organis√© et proactif, Vous savez communiquer avec des interlocuteurs vari√©s et avez l'esprit d'√©quipeSi vous reconnaissez que cette opportunit√© correspond √† votre profil, n'h√©sitez pas √† postuler.Primes, environnement stimulant, accompagnement √† la prise de poste, √©quilibre vie personnelle/vie professionnelle 19047535-55584
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Remote or Hybrid (Digital Assets),Turn Block Talent,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-remote-or-hybrid-digital-assets-at-turn-block-talent-3810820768?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=FROM%2FXEIBFkKU3%2Bc1ZQB%2Bg%3D%3D&position=17&pageNum=8&trk=public_jobs_jserp-result_search-card,"About The CompanyOur client is a global fintech company, with offices in NYC, London, Paris, andSingapore. Rapidly growing, they are the leading crypto market data provider for financialinstitutions and enterprises in the digital asset space.Our client is a team of +80 (and growing) passionate individuals with a deep interest in building datasolutions and supporting the growth of the digital finance economy.About The RoleThe Challenge:You will be joining a fast-paced engineering team made up of people with significant experienceworking with terabytes of data. They believe that everybody has something to bring to the table,and therefore put collaborative effort and team-work above all else (and not just from anengineering perspective).You will be able to work autonomously as an equally trusted member of the team, andParticipate In Efforts Such AsAddressing high availability problems: cross-region data replication, disaster recovery,etc.Addressing ‚Äúbig data‚Äù problems: 200+ millions of messages/day, 160B data points since2010Improving our development workflow, continuous integration, continuous delivery and ina broader sense our team practicesExpanding our platform‚Äôs observability through monitoring, logging, alerting and tracingWhat You‚Äôll Be DoingDesign, develop and deploy scalable and observable backend microservicesReflect on our storage, querying and aggregation capabilities, as well as thetechnologies required to meet our objectivesWork hand-in-hand with the business team on developing new features, addressingissues and extending the platformTech StackGolang, Kafka, Redis, Clickhouse, Postgres, Nomad, Terraform and Vault.About YouSignificant experience as a Software/Data/DevOps EngineerKnowledgeable about data ingestion pipelines and massive data queryingWorked with, in no particular order: microservices architecture, infrastructure as a code, self-managed services (eg. deploy and maintain our own databases), distributed services, server-side development, etcThe most important skills for us revolve around two things:What we like to call ‚Äúcore‚Äù knowledge: what‚Äôs a software process, how does it interactwith a machine‚Äôs or the network‚Äôs resources, what kind of constraints can we expect forcertain workloads, etcHow fast you can adapt to a technology you didn‚Äôt know existed 10 minutes agoIn short, we are looking for someone able to spot early on that spending 10 days to migrate datato a more efficient schema is the better solution compared to scaling out a database cluster ina matter of minutes if we are looking to improve performance in the long term.Nice to haveExperience with data scraping over HTTP, WebSocket, and/or FIX ProtocolExperience developing financial product methodologies for indices, reference rates, andexchange ratesKnowledgeable about the technicalities of financial market data, such as the differencebetween: calls, puts, straddles, different types of bonds, swaps, CFD, CDS, options,futures, etcPersonal SkillsHonest: receiving and giving feedback is very important to youHumble: making new errors is an essential part of your journeyEmpathetic: you feel a sense of responsibility for all the team‚Äôs endeavors rather thanfocus on individual contributionsCommitted: as an equally important member of the team, you want to make yourselfheard while respecting everybody‚Äôs point of viewFluent in written and spoken EnglishYou have the utmost respect for legacy code and infrastructure, with some occasionaland perfectly understandable respectful complaintsWhat They OfferAn attractive compensation package, including equity and healthcare.An entrepreneurial environment with a lot of autonomy and responsibilities.Opportunity to work with an internationally diverse team.The hardware of your choice to help you deliver your best work.Good perks (remote-friendly, meal vouchers, multiple team events andstaff surprises).
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Ing√©nieur H/F,Alteca,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-h-f-at-alteca-3798371488?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=gCE3vDni9sp7FXYJD8iNQA%3D%3D&position=18&pageNum=8&trk=public_jobs_jserp-result_search-card,"TRAVAILLER CHEZ ALTECAChez Alteca le management de proximit√©, le bien-√™tre et l'√©volution de nos collaborateurs sont des priorit√©s qui nous permettent, chaque jour, de proposer la meilleure expertise possible √† nos clients.Et c'est gr√¢ce √† ces convictions, que nous sommes aujourd'hui r√©f√©renc√©s aupr√®s de partenaires grands comptes dans les secteurs de la Banque, de l'Assurance ou encore de la Distribution (Si vous souhaitez en savoir plus sur Alteca, RDV sur l'onglet ""Qui sommes-nous ?"").________________________________> En tant que Data Ing√©nieur (H/F), tu seras rattach√©(e) au P√¥le Data de notre Agence toulousaine. Ton Manager sera Christian COT (Responsable du P√¥le) ou l'un de ses R√©f√©rent technique. Interlocuteur privil√©gi√©, il assurera ton int√©gration durant tes trois premiers mois dans l'entreprise, ta mont√©e en comp√©tences, tes points de suivi tout au long de tes missions et tes Entretiens Annuels.> Tu auras √©galement acc√®s √† une communaut√© technique d'experts gr√¢ce aux nombreux Webinar organis√©s tout au long de l'ann√©e, tu pourras aussi participer aux projets de notre Centre de R&D ou encore assister aux MID'INNO (pr√©sentations de nos collaborateurs sur des th√©matiques donn√©es comme la Green Tech, l'IA...).> Rejoindre ALTECA c'est aussi rejoindre une entreprise engag√©e sur la RSE (labellis√©e Ecovadis Silver 2022), pour le bien-√™tre de ses salari√©s (labellis√©e HappyAtWork pour la 5√®me ann√©e cons√©cutive), et dans la formation de ses stagiaires et alternants (labellis√©e HappyTrainees pour la 4√®me ann√©e cons√©cutive).TES MISSIONSEn coordination avec les √©quipes d'un de nos clients grands comptes, tes missions seront les suivantes :Concevoir les Data Models et Data Pipelines : cartographier et documenter les types de donn√©es et leur usage, concevoir les solutions, les processus, √©laborer la strat√©gie de validation des solutionsConcevoir et sp√©cifier l‚Äôinfrastructure : sp√©cifier les solutions d‚Äôacquisition en fonction des flux, les solutions de traitement adapt√©es aux mod√®les, estimer les besoins et co√ªts, sp√©cifier les solutions de gestion des donn√©esAccompagner et guider les √©quipes : pr√©sentation des √©tudes et solutions, accompagnement dans les expertises, les parcours de formation‚Ä¶Mettre en ≈ìuvre l‚Äôinfrastructure, d√©velopper et maintenir les services de traitement de donn√©es, supervision / monitoring des infrastructuresLa majeure partie des projets de nos clients sont sur des environnements techniques r√©cents : Python, FastAPI (ou Django / Flask) et des ORM type SQLAlchemy, Pandas, Numpy, Xarray, ETL, Airflow, BDD (timescaleDB, IngluxDB, MongoDB, Elastic, NoSQL Redis, PostgreSQL), Kafka, Prefect, Nifi, Pandas, Numpy, Xarray, Dask) Docker, Kubernetes, Gitlab et en m√©thodologie Agile Scrum.  Ton profil : dipl√¥m√©(e) d'un Bac+5 dans le domaine de la Data (Universit√© ou Ecole d'Ing√©nieur), tu as au moins 7 ans d'exp√©rience sur un poste similaire et tu sais √©voluer en environnement Agile. Tu poss√®des √©galement une exp√©rience dans le d√©veloppement de logiciel (Python) dans une architecture orient√©e microservices et APITa personnalit√© : tu es une personne organis√©e et rigoureuse. Tu disposes d'un bon relationnel et tu aimes le travail en √©quipe. Tu as la capacit√© de vulgarisation et de d√©monstration. Tu appr√©cies et contribues √† d√©velopper un contexte de travail bienveillant et qui favorise le partage de connaissances, l‚Äôaccompagnement au changement. Enfin, tu et motiv√© pour les grands projets d‚Äôinfrastructure (moyen / long terme)Type de contrat propos√© : temps plein | Niveau de poste : confirm√©________________________________Process de recrutement :ŒΩ Malivanh te contactera pour un premier √©change t√©l√©phonique, puis elle te recevra dans le cadre d'un entretien RH.ŒΩ Si cet entretien est valid√©, tu rencontreras alors Christophe, le Responsable du P√¥le Digital, pour un entretien technique.________________________________ NOS AVANTAGESTransport pris en charge √† 75% | Tickets resto pris en charge √† 60% | Mutuelle prise en charge √† 60%10 jours de RTT en plus des 25 jours de CP | Mode de travail : hybride | Acc√®s au CSE (billetterie, voyages...)Des parcours de formations personnalis√©s (75% de nos collaborateurs ont suivis au moins 1 formation en 2022)En tant que signataire de la charte de diversit√© en entreprise, Alteca favorise un environnement de travail inclusif et respectueux de tous. A comp√©tences √©gales, tous nos postes sont ouverts aux personnes en situation de handicap.Votre chance c'est votre talent, la n√¥tre c'est de le d√©velopper : rejoignez-nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer (H/F),Adsearch,"Nice, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-adsearch-3807376801?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=SAIIILLsSVvtiMhXE7OYZg%3D%3D&position=19&pageNum=8&trk=public_jobs_jserp-result_search-card,"Adsearch vous propose des milliers d''opportunit√©s de carri√®res dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Int√©rim et Freelance sur notre site internet ! En bref : Nice- CDI - Data Engineer Talend (F/H) - Salaire selon exp√©rience - T√©l√©travailAdsearch, cabinet de recrutement bas√© √† Nice vous accompagne dans votre carri√®re pour vous trouver LE poste id√©al.Je recrute pour un client un Data Engineer Talend (F/H) bas√© √† Nice.Vos MissionsCadre du besoinImpl√©mentation des solutions BI - TalendR√©daction des sp√©cifications techniques et fonctionnellesMod√©lisation des syst√®mes d√©cisionnelsOptimisation et monitoringVotre profil ;Vous √™tes id√©alement titulaire d'un Bac+5 dans l'informatiqueVous avez une premi√®re exp√©rience sur un poste similaireTalend n'a plus de secret pour vous ?Ce Que L'on Vous ProposeDes sujets challengeantUne super TeamLe Processus De RecrutementEtape 1 : Entretien de s√©lection avec Adsearch pour d√©finir vos objectifs de carri√®re et votre correspondance avec le posteEtape 2 : Entretien technique avec le clientEt c'est tout ! Pas d'entretien inutile, nous allons directement au but.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst,Hoist Finance,"Marcq-en-Bar≈ìul, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-at-hoist-finance-3800215166?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=1TJfCe8iejJ%2F0MA30e%2Fj5g%3D%3D&position=20&pageNum=8&trk=public_jobs_jserp-result_search-card,"Vous √™tes √† l‚Äô√©coute d‚Äôune nouvelle opportunit√© professionnelle dans le domaine de la Data ?Vous portez un vif int√©r√™t au secteur financier ?Rejoignez-nous ! Hoist Finance est une soci√©t√© financi√®re sp√©cialis√©e dans le rachat et la gestion de portefeuilles de cr√©ances bancaires. Le groupe compte 1 500 collaborateurs dans 13 pays europ√©ens. Propri√©taires des dossiers-clients que nous rachetons aux √©tablissements bancaires, nous sommes 120 collaborateurs en France tourn√©s vers le m√™me objectif : aider nos clients √† devenir libres de dettes.Data Analyst (H/F) Dans le cadre d'un renforcement d'activit√©, rattach√©(e) √† la Responsable Strat√©gies Clients et en collaboration avec la Responsable Analytique, votre principale mission consiste √† fournir des outils d‚Äôaide √† la d√©cision. Il s'agit plus particuli√®rement d'identifier et de r√©pondre aux besoins des diff√©rentes √©quipes en mati√®re d‚Äôanalyses, d‚Äôoutils de reporting, de data visualisation et mise en ≈ìuvre. Gr√¢ce √† la qualit√© de vos analyses, vous participez √† l‚Äôidentification de poches de valeur et contribuez √† l‚Äôam√©lioration des performances. Vos missions plus en d√©tails : Gestion des bases de donn√©es :Validation de la coh√©rence des donn√©es charg√©es en baseParticipation active √† l‚Äô√©laboration du nouveau datalake : test des variables, migration des requ√™tes actuelles‚Ä¶ Maintien et d√©veloppement des process/reporting actuelsAnalyse de performance : Mise en place d‚Äôanalyses de performance de l‚Äôactivit√© (ex : performance des portefeuilles de cr√©ances, productivit√©‚Ä¶)Pr√©conisations (analyse des strat√©gies et proposition de leviers d‚Äôoptimisation)Pr√©sentation aux directions op√©rationnellesR√©alisation de scoring (clients √† potentiel, web, canal de communication‚Ä¶)Affiner le ciblage des clients :Pr√©conisations et s√©lection des clients pour enrichissement de donn√©es, campagnes de communication, clients web‚Ä¶Participation √† la nouvelle strat√©gie d‚Äôenrichissement de donn√©es Environnement technique : Bases de donn√©es SQL, SAS, Tableau, R, MS Excel/VBA, Alteryx Profil recherch√© : Formation sup√©rieure de niveau Bac +5 en Statistiques / Informatique d√©cisionnelle (type Master MIASHS parcours statistique, Master SIAD...), Id√©alement premi√®re exp√©rience de 2 ans minimum (hors stages/alternance) sur une fonction analytique (statistiques, manipulation de donn√©es). Excellentes capacit√©s √† communiquer en transverse et √† pr√©senter des donn√©es complexes et d√©taill√©es dans un format facilitant la compr√©hension. Curiosit√©, rigueur, r√©activit√©, souplesse et d‚Äôune capacit√© d‚Äôadaptation pour intervenir sur des projets vari√©s et aupr√®s d‚Äôinterlocuteurs multiples Un bon niveau d‚Äôanglais √©crit serait un plus.Les conditions contractuelles & avantages : Poste √† pourvoir dans le cadre d‚Äôun CDI ‚Äì statut Cadre. Localisation : Marcq en Baroeul (proximit√© imm√©diate du Tramway ‚Äì Arr√™t Ch√¢teau Rouge). Parking. Package (fixe + variable annuel) compris entre 32 K‚Ç¨ et 38 K‚Ç¨ brut annuel pour 39h / semaine. Tickets restaurant : 9,20 ‚Ç¨ / jour (participation employeur de 5‚Ç¨) Int√©ressement/participation (autour de 1 K‚Ç¨ par an) T√©l√©travail : jusque 2 jours / semaine Mutuelle (prise en charge employeur avantageuse) Remboursements frais de transports √† hauteur de 60% Avantages CSE‚Ä¶Ce que vous trouverez de plus en tant que Data Analyst chez Hoist Finance :  Une √©quipe √† taille humaine, conviviale, qui s‚Äôentraide au quotidien et qui a √† c≈ìur de partager son expertise¬´ Pas de silos ! ¬ª : un champ d‚Äôintervention large permettant une diversit√© de projets : diff√©rents d√©partements (fonctions Supports, fonctions Op√©rationnelles/M√©tiers), donn√©es vari√©es (√©conomiques, financi√®res, sociod√©mographiques, RH‚Ä¶), diff√©rents types de cr√©dits (pr√™t personnel, cr√©dit √† la consommation, d√©couvert bancaire‚Ä¶)Nous sommes dans un contexte en fort changement ! : m√©tiers de la relation-clients en transformation, d√©veloppement de l‚Äôomnicanal / digital pour une exp√©rience clients sur-mesure, intervention sur de nouveaux march√©s‚Ä¶ Notre environnement bouillonne d‚Äôid√©es et de projets ! En tant qu'entreprise inclusive, Hoist Finance s‚Äôengage pour la diversit√© et accorde la m√™me consid√©ration √† toutes les candidatures, sans discrimination.


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer,VEV,"Sophia Antipolis, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/software-engineer-at-vev-3805917872?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=rPPjrEm1azOiCiRo%2BiRQtw%3D%3D&position=21&pageNum=8&trk=public_jobs_jserp-result_search-card,"The ideal candidate will be responsible for developing high-quality applications. They will also be responsible for designing and implementing testable and scalable code.  ResponsibilitiesDevelop quality software and web applications Analyze and maintain existing software applications Design highly scalable, testable code Discover and fix programming bugsQualificationsBachelor's degree or equivalent experience in Computer Science or related field Development experience with programming languages SQL database or relational database skills


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),LittleBigCode,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-littlebigcode-3785355778?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=45ju7PdIAmpC7Eiw3BYtww%3D%3D&position=22&pageNum=8&trk=public_jobs_jserp-result_search-card,"LittleBigCode en quelques mots Notre mission aider les entreprises √† r√©ussir la r√©volution de l‚ÄôIA ! LittleBigCode r√©volutionne le conseil dans l‚ÄôIA en associant √† ses √©quipes d‚Äôexperts, ses propres solutions et m√©thodes permettant de d√©livrer les projets √† l‚Äô√©chelle des organisations avec un tr√®s haut niveau de valeur dans un d√©lai record. Depuis notre cr√©ation fin 2018, nous avons r√©alis√© 80 % de croissance annuelle moyenne, plus de 190 projets dont 88 % pass√©s √† l‚Äô√©chelle et obtenu pas moins de 93 % de satisfaction client. L‚Äô√©quipe LittleBigCode se compose de 80 collaborateurs venant d‚Äôhorizons vari√©s et ayant tous la m√™me envie d‚Äôemmener la soci√©t√© le plus haut possible. Notre culture d‚Äôentreprise pr√¥ne la prise d‚Äôinitiative, de responsabilit√©, la valorisation de l‚Äô√©chec, la bienveillance, la transparence et le fun. Nous y sommes tous tr√®s attach√©s et nous faisons tout notre possible pour la pr√©server via un programme d‚Äôonboarding soutenu et des formations.Notre objectif est de devenir un acteur mondial de premier plan dans le conseil en IA d'ici les 5 prochaines ann√©es ce qui signifie de doubler notre taille annuellement.Le recrutement est la chose la plus importante pour la r√©ussite d‚Äôune entreprise.Description du poste Nous cherchons √† renforcer notre √©quipe technique gr√¢ce √† un profil Data Engineer senior !Ta mission si tu l‚Äôacceptes : accompagner tes clients dans leurs projets data / IA mais √©galement participer activement au d√©veloppement et rayonnement de LittleBigCode.Quel sera ton r√¥le chez nous ?Conseil et expertise aupr√®s de nos clients sur leurs projets strat√©giques :Mod√©lisationConceptionDeliveryFormation, accompagnement & animation :Formation et accompagnement des √©quipes dans leur mont√©e en comp√©tences (en tant que Senior Coach ou Senior Tech)Organisation & Animation des communaut√©s et des Tech-Events (Workshops, Challenge interne, Hackhaton ‚Ä¶)Contributions au d√©veloppement de LittleBigCode :Participation au d√©veloppement de nos solutions internesProposition et cr√©ation de solutions innovantesParticipation aux appels d‚ÄôoffresTon profil Tu es dipl√¥m√©.e d‚Äôune grande √©cole d‚Äôing√©nieur en math√©matique, statistique ou informatique et tu as au moins 5 ans d‚Äôexp√©rience sur cette fonction !Tu es tr√®s solide sur les concepts de mod√©lisation et structuration de donn√©es.Tu ma√Ætrises l‚Äôindustrialisation de pipelines d‚Äôingestion et la mise en production de mod√®les Data Sciences.Tu ma√Ætrises parfaitement les langages : Python, SQL (si possible Scala) et tu sais d√©livrer un code propre facilement maintenable et industrialisable.Tu sais parfaitement utiliser l‚Äôune des plateformes suivantes : Azure, GCP, AWS et connais √©galement tr√®s bien les diff√©rentes typologies de Base de donn√©es.Tu es robuste sur la mise en place et l‚Äôutilisation d‚ÄôETL.Si en plus tu as une exp√©rience les environnements de donn√©es √† haut volume ‚Ä¶


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer confirm√© (H/F),BforBank,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-bforbank-3799165477?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=N314ABCnMsFp8m4SzGXGHg%3D%3D&position=23&pageNum=8&trk=public_jobs_jserp-result_search-card,"Sur le mod√®le d'une ""Tech company"", BforBank place l'humain et le digital au c≈ìur de sa transformation. Notre mission, offrir √† nos clients une exp√©rience bancaire incomparable pour r√©pondre √† leurs besoins et usages mobile. üåü üì±Rejoindre BforBank c‚Äôest rejoindre une √©quipe engag√©e dans un grand projet de d√©veloppement strat√©gique en France et en Europe. Nous sommes aujourd‚Äôhui 350 passionn√©(e)s et recherchons nos talents pour construire la banque de demain. üöÄNous croyons en la force du collectif, chaque jour rassembl√©s autour de nos valeurs, de simplicit√©, d'optimisme et d‚Äôengagement, encourageant chacun √† oser, essayer et accepter d‚Äô√©chouer.üéØ Au sein de la Direction Technologie, la Data Factory a pour objectifs de piloter, d√©finir, d√©ployer et op√©rer les meilleures solutions technologiques r√©pondant aux cas d‚Äôusage data et d‚Äôautomatisations de processus de la banque au travers de plateformes. √âgalement, la Data Factory contribue au d√©veloppement des produits, √† la cristallisation et √† la diffusion des pratiques au sein des Squads BforBank sur les usages data dans la banque. Tu rejoindras une squad en charge de r√©soudre des probl√©matiques m√©tiers en cr√©ant des solutions applicatives utilisant les donn√©es, des data products, avec pour finalit√©s la prise de d√©cision via des moteurs de calcul ou des dashboards, la cr√©ation de flux r√©glementaires, la cr√©ation de data layer ou de reportings. üöÄ Tes missions principales sont les suivantes : ¬∑ Participer aux analyses, √©tudes d‚Äôimpacts et cadrage techniques ¬∑ Concevoir des solutions en respectant les bonnes pratiques d‚Äôarchitecture data et d√©veloppement¬∑ R√©aliser le d√©veloppement de nouveaux data products et assurer la maintenance √©volutive et corrective des data products existants¬∑ R√©diger la documentation technique des data products¬∑ Assurer un support aux testeurs¬∑ Reporter de ton activit√© √† ta Squad et travailler dans une d√©marche d‚Äôefficacit√© collective Concr√®tement tu seras amen√©(e) √† produire les livrables suivants :¬∑ R√©aliser du code applicatif √† l‚Äô√©tat de l‚Äôart sur notre nouvelle Data Platform ¬∑ Cr√©er des data layer et des rapports sur notre outil de Data Visualisation¬∑ R√©diger les documentations techniques li√©es √† ta solution, incluant le mod√®le de donn√©es, les proc√©dures, l‚ÄôordonnancementCe que tu ma√Ætrises :¬∑ Maitrise des services manag√©s de GCP (BigQuery, dataproc, dataflow, CloudSQL ‚Ä¶)¬∑ Maitrise du langage Python, Pandas, Spark ¬∑ Maitrise de la mod√©lisation de base de donn√©es et du langage SQL¬∑ Maitrise d‚Äôune chaine CI/CD (GitLab‚Ä¶) ¬∑ Bonne connaissance de Kafka¬∑ Bonne connaissance d‚Äôun outil d‚Äôint√©gration de donn√©es type ETL (Informatica‚Ä¶)¬∑ Connaissance de l‚Äôinfra as code (Terraform)¬∑ Connaissance d‚Äôun outil de reporting (Looker, BO‚Ä¶) ü§ù Ce poste est fait pour toi si :¬∑ Tu es passionn√©(e) par la Data et leurs usages¬∑ Tu es orient√© r√©solution de probl√®me, est curieux(se) et force de proposition¬∑ Tu appr√©cies le travail en √©quipe¬∑ Tu as un bon relationnel et est rigoureux(se)¬∑ Tu as une bonne capacit√© d‚Äôanalyse et r√©dactionnelle¬∑ Tu t‚Äôadaptes rapidement aux changementsüéì Formation : Tu es dipl√¥m√©(e) d‚Äôun master en √©cole de commerce, √©cole d‚Äôing√©nieur ou √©quivalent.Chez BforBank nous recherchons avant tout des comp√©tences. Tu ne disposes pas du dipl√¥me requis mais as des exp√©riences √©quivalentes ? N'h√©site pas √† postuler !üíº Exp√©rience : Exp√©rience confirm√©e de 3 ans en tant que Data Engineer.En rejoignant BforBank tu trouveras‚Ä¶ ¬∑ Un projet ambitieux de transformation digitale et culturelle √† l‚Äô√©chelon europ√©en, terrain d‚Äôinnovation et d‚Äôouverture d‚Äôesprit ¬∑ Une organisation apprenante, proposant un large choix de formations toute l‚Äôann√©e, et qui favorise l‚Äô√©change avec les autres marques du Groupe¬∑ Une promo RSE multi-m√©tiers qui fait √©voluer en continu les actions de BforBank vers une banque plus responsable¬∑ Une organisation du travail en mode Agile, impliquant un degr√© √©lev√© de collaboration et d'autonomie tout en travaillant avec un groupe de pairs diversifi√©s.¬∑ Une Direction Technologie en pleine expansion, porteuse de nombreux d√©fis strat√©giques Mais aussi‚Ä¶De 2 jours √† 5 jours de t√©l√©travail modulables par semaine, dans la limite de 84 jours par an (frais de fonctionnement pris en charge)25 jours de cong√©s + 16 jours de RTT80% du co√ªt de la mutuelle d‚Äôentreprise pris en charge / couvertAvantages collaborateurs Cr√©dit Agricole : taux et tarifs pr√©f√©rentielsDes frais de transports rembours√©s √† 75%Un restaurant d‚ÄôentrepriseDes douches pour les sportifs et un tarif avantageux aupr√®s d‚Äôune salle de sport toute procheüìç Le poste est bas√© √† La D√©fense, dans des locaux flambant neufs !BforBank s'engage √† garantir l'√©galit√© des chances aux candidats car nous sommes convaincus de la richesse apport√©e par la diversit√© et l'inclusion dans nos √©quipes. Rencontrons-nous ! Le processus de recrutement se d√©roule en 4 √©tapes : üßëüèº‚ÄçüíªCall de 30 minutes avec notre √©quipe Talent Acquisition Echange avec le Data Factory Manager et notre √©quipe Talent Acquisition (pr√©sentiel)Echange avec une personne de l‚Äô√©quipe avec qui tu seras amen√© √† travailler (visio)Echange avec le CTO (visio ou pr√©sentiel) Notre processus de recrutement dure en moyenne 3 semaines et l‚Äô√©quipe Talent Acquisition se tiendra √† ta disposition pour te donner un maximum de visibilit√© sur l‚Äôavanc√©e du process.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data engineer (H/F),Groupe SII,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-groupe-sii-3745315181?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=8bADCPIePWgli9RyyiHyqQ%3D%3D&position=24&pageNum=8&trk=public_jobs_jserp-result_search-card,"Devenez le prochain collaborateur d'SII Nord en tant que :Data Engineer (H/F)Int√©gr√© chez l'un de nos clients, vous intervenez en tant que Data Engineer au sein de l‚Äô√©quipe IT Data. Vous d√©veloppez et g√©rez la maintenance de la plateforme Data et d‚Äôautres outils mais aussi des flux entre les diff√©rentes sources de donn√©es de l‚Äôentreprise.Vous Contribuez √†Concevoir et d√©velopper les futures fonctionnalit√©s de la plateforme Big Data sous Google Cloud Platform,Concevoir les flux d‚Äôalimentation et les tables (structure de donn√©e),Automatiser et industrialiser les flux,Assurer le run applicatif, le cas √©ch√©ant.ProfilDans l'id√©al (oui uniquement dans l‚Äôid√©al, chez nous on ne cherche pas qu‚Äôun CV mais une collaboration durable), de formations sup√©rieure en informatique, type Bac+3/5, vous justifiez d‚Äôune exp√©rience significative en d√©veloppement sur un environnement BI et Big Data.Comp√©tences TechniquesMaitrise des langages suivants : SQL, Python (Java/Scala serait un plus)Connaissances de Google Cloud Dataflow (Python)Anglais n√©cessaire √† l‚Äô√©critNotion de programmation fonctionnelleAu-del√† des comp√©tences techniques, vous fa√Ætes preuve de rigueur, de curiosit√© et aimez relever les challenges. Vous √™tes dot√©(e) d‚Äôun bon sens du service client, √™tes organis√© et pragmatique. Ces qualit√©s vous permettent de mener √† bien le projet.Vous vous reconnaissez dans ces comp√©tences et qualit√©s ? Vous souhaitez bousculer les codes, sortir des sentiers battus et rendre votre dynamisme contagieux ? Alors, rejoignez le mouvement #Fung√©nieur de SII dans lequel la cr√©ativit√© et l‚Äôesprit d‚Äô√©quipe sont mis √† l‚Äôhonneur !Vous √™tes les cr√©ateurs de demain, osez mettre en avant vos comp√©tences, investissez-vous dans des projets innovants et venez relever de nouveaux d√©fis technologiques. Expertise, Innovation et fun est le mix que nous vous proposons !Qui sommes-nous ?Le Groupe SII est une soci√©t√© d‚Äôing√©nierie et de conseils en technologies (ICT) et une entreprise de services num√©riques (ESN). Nous sommes au c≈ìur de l'innovation au service de grands comptes dans des secteurs d'ing√©nierie vari√©s. En 2023, pour la 6√®me ann√©e cons√©cutive, SII France a obtenu le label Great Place To Work¬Æ. Nous avons √©t√© reconnus 3√®me entreprise de ¬´ + de 2500 salari√©s¬ª o√π il fait bon vivre. Nous sommes tr√®s fiers d‚Äôobtenir cette reconnaissance de nos salari√©s !Ce succ√®s est le reflet de notre culture bas√©e sur notre volont√© de proposer √† tous nos salari√©s un cadre de travail √©panouissant pour le d√©veloppement de leurs comp√©tences et carri√®res. En fonction de la mission, il est possible de r√©aliser jusqu‚Äô√† 50 % de t√©l√©travail gr√¢ce √† notre accord d√©di√©.Rejoignez le mouvement #fungenieur dans lequel la passion pour la technologie, la cr√©ativit√©, la proximit√© et l‚Äôesprit d‚Äô√©quipe sont mis √† l‚Äôhonneur.Le Groupe SII est une soci√©t√© handi-accueillante, signataire de la Charte de la diversit√© en entreprise.Alors si ces valeurs vous parlent, rejoignez-nous !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,MindPal,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3810930852?refId=pLtr%2FrGK%2BUcUqqiiGdgNDg%3D%3D&trackingId=aH7RUdp8lLNvaiT0DAi4Ww%3D%3D&position=25&pageNum=8&trk=public_jobs_jserp-result_search-card,"We are looking for Data Engineer!ResponsibilitiesDesigning, creating, and maintaining data processing systems Analyzing and optimizing data processing workflows Collaborating with the team to ensure data quality and efficiency Testing and implementing new solutions RequirementsAt least 2 years of experience in designing and creating data processing systems Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python) Excellent knowledge of databases and SQL language Ability to work in a team and communicate effectively with other departments Communicative English skills Experience with AWS/AWS Glue is a plus We OfferB2B contract Full-time job Remote work and flexible hours


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Thales,"Valbonne, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3733768380?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=aRSz3pEABaX5NCtYHBpAgA%3D%3D&position=1&pageNum=9&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales propose des syst√®mes d‚Äôinformation et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d‚Äôimportance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d‚Äôinformation critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l‚Äôutilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l‚Äôactivit√© Syst√®mes d‚Äôinformation critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces.Le d√©partement IA & Big Data recherche plusieurs Data Engineers (H/F) bas√©s √† Sophia Antipolis (06).QUI ETES-VOUS ?De formation Bac+4 ou Bac +5 (type √©cole d‚Äôing√©nieur), vous poss√©dez de bonnes connaissances dans le domaine de la donn√©e (Data Science, Data Engineering, Stockage), en ing√©nierie logicielle globalement.Une connaissance cloud serait un r√©el atout, qu‚Äôil soit public (AWS, GCP, AZURE) ou priv√©.Les principales activit√©s que vous r√©aliserez sont les suivantes :Mise en place de pipelines de traitement de donn√©esUtilisation de l‚Äô√©tat de l‚Äôart des technologies actuelles d√©di√©es √† ces activit√©s : Kafka / Spark / Spark Streaming / Flink / StormD√©veloppement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie)Utilisation de tous les types de stockage actuels :SQL : Oracle, SQLServer, PostgreSQLNoSQL : Cassandra / MongoDB / HBaseObjet : S3 / MinIOVous avez de bonnes exp√©riences en d√©veloppement logiciel et/ou scripting (principalement Scala & Java).Vous √™tes √† l‚Äôaise en Anglais.Vous √™tes curieux et rigoureux.Vous aimez travailler en √©quipe au quotidien, pour vous le succ√®s n‚Äôest que collectif.Vous vous reconnaissez ? Alors parlons missions ‚Ä¶CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :Le d√©partement IA & Big Data f√©d√®re et coordonne les savoir-faire Algorithmie, Big Data, Data Science et Data Viz au travers d‚Äôune structure permettant d‚Äôacc√©l√©rer la transformation des enjeux Data de nos clients.Nos savoir-faire :Big Data, Intelligence Artificielle, Algorithmie, Expertise ImagerieProjets d‚Äôint√©gration syst√®meNos domaines m√©tier :Maintenance pr√©dictive, Traitement d‚Äôimage pour la sant√©Archivage certifiant, Gestion de contenu, Analyse risque et optimisation de r√©ponseAerospace : Centre de Mission et de Contr√¥le, Dynamique du Vol, Qualit√© Image, Occupation des sols, Sondage Atmosph√©riqueNos partenaires :Recherche : INRIA, CNRS, 3IAExternes : Nvidia, MicrosoftEn collaboration avec les membres de notre d√©partement :Vous contribuerez au d√©veloppement et √† la scalabilit√© de nos plateformes au travers d‚Äôactivit√©s d‚Äôautomatisation, de cr√©ation de services manag√©s et d‚ÄôAPI.Vous accompagnerez nos clients dans leurs projets de valorisation de donn√©es en proposant des solutions techniques et fonctionnelles, √©valu√©es, choisies et opportunes.Vous participerez √† l‚Äôint√©gration des plateformes techniques s√©curis√©es d√©velopp√©es par Thales, faisant appel aux meilleurs technologies actuelles : Welcome - The Punch (punchplatform.com)Vous collaborerez √† nos publications, conf√©rences et webinars.Vous serez partie prenante de la 3√®me r√©volution industrielle impactant tous les secteurs d‚Äôactivit√©, √©nergie, sant√©, industrie, ‚Ä¶La perspective de rejoindre un Groupe innovant vous motive ? Alors rejoignez-nous en postulant √† cette offre.Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
      

        Show more

        


        Show less","{'ProgLanguage': ['Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Ing√©nieur Data (H/F),CITECH,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-h-f-at-citech-3803400445?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=85Pa79zWENcZAf08kBjdQA%3D%3D&position=2&pageNum=9&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseCITECH recrute ! ‚ú® Si vous souhaitez apporter vos comp√©tences dans la r√©alisation de diff√©rents projets, nous avons LA mission pour vous ! Nous recherchons en effet un(e) Ing√©nieur Data (H/F) ‚öìÔ∏è Votre mission est pour un client pr√©sent dans plus de 160 pays et connu pour √™tre l‚Äôun des principaux leaders mondiaux du secteur de la logistique et du transport maritime. L‚Äôinnovation et la digitalisation sont au c≈ìur du projet de d√©veloppement du groupe. L‚Äôorganisation est √† la fois tourn√©e sur l‚Äôhumain et sur l‚Äôagilit√© ce qui permet de structurer le d√©veloppement et ainsi, encourager les salari√©s √† prendre des initiatives et innover.Vous int√©grerez l'√©quipe Data Science afin d‚Äôint√©grer diff√©rents mod√®les de machine learning et flux de transformation de donn√©es dans la plateforme de production de Dataiku.La mission sera li√©e √† de nombreux aspects techniques en termes de d√©veloppement, d'int√©gration, de tests continus, releases en environnement DEVOPS, contraintes de production.Description du posteVous aurez donc les missions principales suivantes :Transformer les projets POC/ML en environnement de productionD√©velopper et optimiser les flux de donn√©esSoutenir l'√©quipe pour l'optimisation de SparkMettre en place et maintenir un pipeline CI/CD adapt√© aux contraintes de l'√©quipe√âtudier et int√©grer les nouvelles technologiesAccompagner l'√©quipe dans l'utilisation des outilsAnalyser, qualifier et r√©soudre ou transmettre les incidentsAm√©lioration continue, suivi de la mise en ≈ìuvreContribuer √† une communaut√© d'int√©grationQualifications‚öôÔ∏è Les comp√©tences attendues sont les suivantes :‚úîÔ∏è Vous √™tes expert en troubleshooting, Continuous Deployment, Continuous Integration (Dataiku) et Continuous Testing.‚úîÔ∏è Vous √™tes expert sur Python et Spark.‚úîÔ∏è Vous avez de tr√®s bonnes comp√©tences en Monitoring et en Tests scenario.‚úîÔ∏è Vous avez une bonne ma√Ætrise du Cloud (AWS), de Kubernetes, en Database (SQL / noSQL) et en Data Science.‚úîÔ∏è Vous √™tes bilingue en anglais.‚òëÔ∏è Tous nos postes sont ouverts aux personnes poss√©dant le statut RQTH.Informations suppl√©mentairesPourquoi rejoindre Citech ? Une ambiance de travail conviviale avec des afterworks organis√©s r√©guli√®rement ! Des missions de longues dur√©es.  Des formations adapt√©es √† vos envies et vos aspirations.  Une mobilit√© que si vous le souhaitez Un accompagnement personnalis√© avec un suivi r√©gulier (autour d‚Äôun caf√© ou un th√©, c‚Äôest vous qui choisissez ) Une mutuelle avantageuse pour vous mais aussi pour les membres de votre famille Une flexibilit√© sur la gestion de vos repas Un statut Cadre et une convention collective SYNTEC.  Prime d‚Äôint√©ressement. Alors qu‚Äôattendez-vous pour nous rejoindre ?100% t√©l√©travail avec d√©placements ponctuels sur Marseille ‚òÄÔ∏èSalaire : 50-55K‚Ç¨ Brut/anFreelance : 400-450‚Ç¨/jR√©f√©rence : 240111_Ing√©nieurData_
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Engineer,Kaiko,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-kaiko-3802164696?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=XrBEpTeHKXDtGYLS39IjBQ%3D%3D&position=3&pageNum=9&trk=public_jobs_jserp-result_search-card,"Kaiko is the leading source of cryptocurrency market data, providing businesses with industrial-grade and regulatory-compliant data. Kaiko empowers market participants with global connectivity to real-time and historical data feeds across the world's leading centralized and decentralized cryptocurrency exchanges. Kaiko‚Äôs proprietary products are built to empower financial institutions and cryptocurrency businesses with solutions ranging from portfolio valuation to strategy backtesting, performance reporting, charting, analysis, indices, and pre-and post-trade.What We DoKaiko provides financial data products and solutions, across three main business units: Market Data: ‚ÄúCEX‚Äù Centralized Exchanges Market Data: we collect, structure and distribute market data from 100+ cryptocurrency trading venues; ‚ÄúDEX‚Äù Decentralized Protocols Market Data: we run blockchain infrastructure in order to read, collect, engineer and distribute venue-level market data from DeFI protocols. Analytics: proprietary quantitative models & data solutions to price and assess risk. Indices: suite of mono-assets rates and benchmarks, as well as cross-assets indices.Kaiko‚Äôs products are available worldwide on all networks and infrastructures: public APIs, private & on-premises networks; private & hybrid cloud set-ups; blockchain native (Kaiko oracles solution).Additionally, Kaiko‚Äôs Research publications are read by thousands of industry professionals and cited in the world‚Äôs leading media organizations. We provide original insights and in-depth analysis of crypto markets using Kaiko‚Äôs data and products.Who We AreWe‚Äôre a team of 80 (and growing) passionate individuals with a deep interest in building data solutions and supporting the growth of the digital finance economy. We‚Äôre proud of Kaiko‚Äôs talented team and are committed to our international representation and diversity. Our people and their values are the foundation of our continued success.About The RoleYou will be joining a fast-paced engineering team made up of people with significant experience working with terabytes of data. We believe that everybody has something to bring to the table, and therefore put collaborative effort and team-work above all else (and not just from an engineering perspective).You will be able to work autonomously as an equally trusted member of the team, and participate in efforts such as:Addressing high availability problems: cross-region data replication, disaster recovery, etc.Addressing ‚Äúbig data‚Äù problems: 200+ millions of messages/day, 160B data points since 2010Improving our development workflow, continuous integration, continuous delivery and in a broader sense our team practicesExpanding our platform‚Äôs observability through monitoring, logging, alerting and tracingWhat you‚Äôll be doing:Design, develop and deploy scalable and observable backend microservicesReflect on our storage, querying and aggregation capabilities, as well as the technologies required to meet our objectivesWork hand-in-hand with the business team on developing new features, addressing issues and extending the platformOur tech stack:Monitoring: VictoriaMetrics, Grafana Alerting: Alert Manager, Karma, Pager DutyLogging: Vector, LokiCaching: FoundationDB, RedisSecrets management and PKI: Vault Configuration management and provisioning: Terraform, AnsibleService discovery: ConsulMessaging: KafkaProxying: HAProxy, TraefikService deployment: Terraform, Nomad (plugged in Consul and Vault), Kubernetes (to a lesser extent, used for non production critical workloads)Database systems: ClickHouse (main datastore), PostgreSQL (ACID workloads)Protocols: gRPC, HTTP (phasing out in favor of gRPC), WebSocket (phasing out in favor of gRPC)Platforms (packaged in containers): Golang, NodeJS (phasing out in favor of Golang), Ruby (phasing out in favor of Golang)About You:Significant experience as a Software/Data/DevOps EngineerKnowledgeable about data ingestion pipelines and massive data queryingWorked with, in no particular order: microservices architecture, infrastructure as a code, self-managed services (eg. deploy and maintain our own databases), distributed services, server-side development, etcNice to haveExperience with data scraping over HTTP, WebSocket, and/or FIX ProtocolExperience developing financial product methodologies for indices, reference rates, and exchange ratesKnowledgeable about the technicalities of financial market data, such as the difference between: calls, puts, straddles, different types of bonds, swaps, CFD, CDS, options, futures, etcLocation: Paris (hybrid)Type of contract: CDIWhat we offer25 paid holidays & RTTsThe hardware of your choiceGreat health insurance (Alan)Meal vouchers (Swile)Contribution to your monthly gym subscriptionContribution to daily commutingRemote-friendlyMultiple team events (annual retreat, casual drinks, etc.)An entrepreneurial environment with a lot of autonomy and responsibilitiesTalent Acquisition ProcessCall with the People team (20 min)Interview with the Hiring Manager (45 min)Technical test / Business Case (1h in meet)Cross team interviews with 2-3 team members (30 min)Offer, reference checkDiversity & InclusionAt Kaiko, we believe in the diversity of thought because we appreciate that this makes us stronger. Therefore, we encourage applications from everyone who can offer their unique experience to our collective achievements.
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Oracle'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Pilote Projets Data / Data Engineer H/F,Emotors,"Carri√®res-sous-Poissy, √éle-de-France, France",https://fr.linkedin.com/jobs/view/pilote-projets-data-data-engineer-h-f-at-emotors-3809167161?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=xZFqwIQ8HSEO%2BG0BoG1m%2BQ%3D%3D&position=4&pageNum=9&trk=public_jobs_jserp-result_search-card,"Emotors est une joint-venture entre les Groupes STELLANTIS et NIDEC, destin√©e √† assurer la conception et la fabrication des nouveaux moteurs √©lectriques pour l‚Äôautomobile. Moteurs √©lectriques qui ont pour vocation √† √™tre int√©gr√©s dans des v√©hicules mild-hybride (MHEV), hybrides rechargeables (PHEV) et v√©hicules √©lectriques (EV).Notre soci√©t√© est bas√©e √† Carri√®res-Sous-Poissy pour sa partie d√©veloppement et √† Tr√©mery, pour son site de fabrication. Aujourd‚Äôhui, 450 collaborateurs travaillent conjointement sur ces 2 sites pour faire de cette co-entreprise un succ√®s et contribuer au d√©veloppement de nouvelles motorisations pour le secteur automobile.Int√©gr√© √† l‚Äô√©quipe AIDA (Automation, It and Digital Accelerator), dont la mission est de g√©rer la digitalisation de tous les m√©tiers Emotors ; vous avez en charge de :Mettre en place une architecture de collecte des donn√©es des diff√©rents syst√®mes : manufacturing, IoT, ERP, PLM, MoM, autres sources et formats vari√©s.Piloter la mise en place d‚Äôune plateforme data au sein d‚ÄôEmotorsVous jouerez un r√¥le cl√© dans la collecte, la transformation, le stockage et la gestion des donn√©es pour soutenir les besoins de l'entreprise. Vous travaillerez au sein de notre √©quipe data constitu√©e de data analyst et scientist et en √©troite collaboration avec les entit√©s Emotors.Responsabilit√©s Principales :Mise en place d‚Äôune architecture de collecte des donn√©es :Concevoir et d√©velopper des pipelines de traitement des donn√©es pour l'extraction, la transformation et le chargement (ETL) des donn√©es.Assurer la qualit√© et la coh√©rence des donn√©es en mettant en place des proc√©dures de nettoyage et de normalisation des donn√©es.G√©rer les bases de donn√©es et entrep√¥ts de donn√©es pour garantir des performances optimales et une disponibilit√© constante.Mettre en place des syst√®mes de collecte de donn√©es en streaming et batch.Mettre en place des solutions de collecte et transformation de donn√©es au plus proche des ligne ‚ÄúEdge‚ÄùAnalyse et Mod√©lisation :Collaborer avec les √©quipes m√©tier pour comprendre leurs besoins en donn√©es et concevoir des mod√®les de donn√©es appropri√©s.Mettre en place des solutions d'analyse de donn√©es, y compris la cr√©ation de rapports et de tableaux de bord.Pilotage de Projet :R√©diger la sp√©cification et piloter la mise en place d‚Äôune plateforme data au sein d‚ÄôEmotorsSuperviser et g√©rer des projets li√©s aux donn√©es, y compris la planification, la coordination des ressources, le suivi des d√©lais et la gestion des risques.Assurer une communication efficace entre les parties prenantes du projet, y compris les √©quipes techniques et m√©tier.S√©curit√© des Donn√©es :Mettre en place des mesures de s√©curit√© des donn√©es pour garantir la confidentialit√© et l'int√©grit√© des informations sensibles.Documentation :Documenter les processus, les pipelines de donn√©es, les mod√®les de donn√©es et les solutions mises en place.Vous √™tes :Issu(e) d‚Äôune formation sup√©rieure en √©cole d‚Äôing√©nieur ou √©cole d‚Äôinformatique.Vous avez de l‚Äôexp√©rience en tant que Data Engineer, de pr√©f√©rence dans un environnement industriel.Curieux(se), organis√©(e), rigoureux, autonome et force de propositionComp√©tences et/ou connaissances :Maitrise du langage Python et SQLSparkMQTT / OPC UAD√©ploiement (APIs, CI/CD, Git, Docker, Kubernetes)Ma√Ætrise d‚Äôune (ou plusieurs) des plateformes cloudBonne connaissance des m√©tiers de conception produit/process, de fabrication industrielle et de la logistiqueOrganisation, esprit d‚Äô√©quipe, aisance relationnelle, curiosit√©, agilit√©, autonomie et esprit d‚ÄôinitiativeExcellentes comp√©tences en communication orale et √©criteConnaissance et int√©r√™t pour l‚Äôindustrie 4.0, les moyens de production et leur am√©lioration continue (dans le milieu automobile)Anglais courantDes d√©placements r√©guliers sur notre site de Tr√©mery (Metz) sont √† pr√©voir.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Ing√©nieur Data Spark (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-spark-f-h-at-thales-3737307284?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=B3zi5cqTzrVSly31r89%2FRw%3D%3D&position=5&pageNum=9&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales est un leader mondial des hautes technologies comptant plus de 81 000collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans lesinnovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligenceartificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire unavenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßantl‚Äôhumain au c≈ìur des d√©cisions.Thalespropose des solutions, services et produits qui aident ses clients ‚Äìentreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour lefonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense,a√©ronautique, espace, et transport.QUI ETES-VOUS ?De formation Ing√©nieur ou Bac+5, Ecole d‚Äôing√©nieur ou Universit√© vous justifiez d'une exp√©rience professionnelle en mise en place de solutions Spark / BI d‚Äôau moins 4 ans.CE QUE NOUS POUVONS ACCOMPLIRENSEMBLE :Nous recherchons un D√©veloppeur Power BI et Azure passionn√© et comp√©tent pourrejoindre notre √©quipe technique. En tant que D√©veloppeur Power BI et Azure,vous jouerez un r√¥le essentiel dans la conception, le d√©veloppement et lamaintenance de nos solutions d'intelligence d'affaires bas√©es sur Power BI etAzure. Vous travaillerez en √©troite collaboration avec les √©quipes m√©tier pourcr√©er des visualisations de donn√©es percutantes et des tableaux de bordinteractifs, tout en exploitant les services cloud Azure pour assurer lascalabilit√© et la s√©curit√© des donn√©es.Vous avez pu acqu√©rir plusieurs des comp√©tences suivantes :Solide exp√©rience dans le d√©veloppement de solutions Power BI, y compris laconception de tableaux de bord interactifs, la cr√©ation de mesures et de KPI,et la transformation des donn√©es.Connaissance approfondie des services cloud Azure, tels que Azure Data Factory,Azure SQL Database, Azure Data Lake, etc.Ma√Ætrise des langages de requ√™te de donn√©es tels que SQL, DAX et M.Compr√©hension des principes de mod√©lisation de donn√©es et d'architecture BI.Exp√©rience dans l'int√©gration de diff√©rentes sources de donn√©es dans Power BI,y compris des bases de donn√©es relationnelles, des services web et des fichiersplats.Capacit√© √† comprendre les besoins m√©tier et √† traduire les exigences ensolutions Power BI efficaces.Bonnes comp√©tences en r√©solution de probl√®mes et en communication pourcollaborer avec les membres de l'√©quipe et les parties prenantes.En nous rejoignant, vous vous verrez confier les missions suivantes :Concevoir et d√©velopper des tableaux de bord interactifs et des rapportspersonnalis√©s en utilisant Power BI.Collecter et analyser les besoins des utilisateurs m√©tier pour d√©finir lesindicateurs cl√©s de performance (KPI) et les exigences de visualisation desdonn√©es.Extraire, transformer et charger (ETL) les donn√©es √† partir de diff√©rentessources dans les solutions Power BI et Azure.Optimiser les performances et la scalabilit√© des solutions Power BI enutilisant les fonctionnalit√©s avanc√©es d'Azure, telles que les entrep√¥ts dedonn√©es Azure, Azure Data Factory, Azure SQL Database, etc.Assurer la s√©curit√© des donn√©es en mettant en place des m√©canismes d'acc√®s etde confidentialit√© appropri√©s dans Power BI et Azure.Collaborer avec les √©quipes m√©tier pour fournir des conseils et desrecommandations sur l'utilisation efficace de Power BI et Azure pour l'analysedes donn√©es.Maintenir et am√©liorer les solutions Power BI existantes en fonction des√©volutions des besoins des utilisateurs.Effectuer des tests et des contr√¥les de qualit√© pour assurer l'exactitude et lacoh√©rence des donn√©es.Nous vous offrons :¬∑ Une diversit√© de projets vous permettant de d√©couvrir l‚Äôensemble de nosm√©tiers,¬∑ Des conditions de travail motivantes et un plan de carri√®re personnalis√©offrant de r√©elles perspectives d‚Äô√©volution,¬∑ La possibilit√© de vous investir dans une entreprise dont la r√©putation estmondiale avec des ambitions constantes d‚Äôinnovations techniques.Innovation, passion, ambition :rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Data Engineer - Rennes - I&D (H/F),Capgemini,"Rennes, Brittany, France",https://fr.linkedin.com/jobs/view/senior-data-engineer-rennes-i-d-h-f-at-capgemini-3803721636?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=9kRLMGjupMx3e2eTa7XCyQ%3D%3D&position=6&pageNum=9&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseCapgemini est un leader mondial, responsable et multiculturel, regroupant 270 000 personnes dans pr√®s de 50 pays.Partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie, le Groupe est guid√© au quotidien par sa raison d‚Äô√™tre : lib√©rer les √©nergies humaines par la technologie pour un avenir inclusif et durable.Fort de plus de 50 ans d‚Äôexp√©rience et d‚Äôune grande expertise des diff√©rents secteurs d‚Äôactivit√©, Capgemini est reconnu par ses clients pour r√©pondre √† l‚Äôensemble de leurs besoins, de la strat√©gie et du design jusqu‚Äôau management des op√©rations, en tirant parti des innovations dans les domaines en perp√©tuelle √©volution du cloud, de la data, de l‚ÄôIntelligence Artificielle, de la connectivit√©, des logiciels, de l‚Äôing√©nierie digitale et des plateformes. Le Groupe a r√©alis√© un chiffre d'affaires de 16 milliards d'euros en 2020.Dans ce contexte, notre practice Insights & Data (I&D) s‚Äôappuie sur une √©quipe de 1300 personnes qui supporte nos clients de tous les secteurs dans leur transformation data. Cette √©quipe combine des comp√©tences m√©tiers avec une forte expertise data, analytique et d‚Äôintelligence artificielle pour mettre en ≈ìuvre des solutions qui visent √† am√©liorer la gestion et la valorisation des donn√©es.Description de la missionVous int√©grez une communaut√© d‚Äôexperts passionn√©s reconnus par nos clients sur des technologies de pointe (Google Cloud Platform, Azure, AWS)Vous interagissez au plus proche de nos clients, des partenaires pour concevoir et mettre en ≈ìuvre des solutions/projets innovants et comp√©titifsVous r√©pondez aux probl√©matiques de nos clients en proposant la meilleure plateforme data dans un environnement AgileVous avez acquis de l‚Äôexp√©rience sur les cadres de r√©f√©rence et patterns d‚Äôarchitecture Data, DevOpsVous adaptez chaque architecture en fonction du contexte gr√¢ce √† votre maitrise des caract√©ristiques fondamentales de chaque solution (catalogue des offres de services manag√©s, performance, s√©curit√©, d√©ploiement des data centers ‚Ä¶)Vous utilisez les solutions d‚Äôint√©gration associ√©es et les solutions d√©cisionnelles ainsi qu‚Äôanalytiques qui viennent consommer les donn√©es manipul√©esVous √™tes en mesure d‚Äôencadrer les √©quipes dans la mise en place des architectures pr√©conis√©es et/ ou des plateformes DataPourquoi nous rejoindre ?En plus de votre quotidien, vous pourrez entreprendre, √™tre form√©, utiliser nos incubateurs pour innover, et vous dessiner une trajectoire de carri√®re personnalis√©e.Vous int√©grerez une √©quipe ambitieuse, fun et dynamique !Une culture forte et bienveillante, et une grande place laiss√©e √† la libert√©Des clients vari√©s, leaders de leur secteurUne approche pragmatique, qui r√©pond aux vrais enjeux des entreprisesUn v√©ritable accompagnement dans l‚Äô√©volution de votre carri√®re Une √©quipe √† taille humaine, en renouvellement et en hyper croissanceUne priorit√© accord√©e au d√©veloppement des collaborateurs ‚Äì un management qui aide les √©quipes √† progresser, √† r√©ussirPas de profil type chez Capgemini, mais quelques ingr√©dients pour laisser la magie op√©rer ... !Dipl√¥m√©(e) de Bac+5 en informatique, vous comptez au moins 6 ans d‚Äôexp√©rience (au sein d‚Äôune ESN ou chez un int√©grateur) en conseil client√®le et une solide culture technologique, un bon niveau d‚Äôanglais.Vous avez des qualit√©s de p√©dagogue, et pour vous la transmission de comp√©tences fait partie de votre quotidien actuel. La phase d‚Äôavant-vente vous int√©resse.CAPGEMINI, Entreprise handi accueillante, conform√©ment √† la norme AFNOR NF X50-783, est √©galement signataire de la charte de la diversit√© en entreprise


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer BI - Nantes F/H,Capgemini,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-bi-nantes-f-h-at-capgemini-3803963477?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=NquEVr1od0A7rYUDH71%2Bvw%3D%3D&position=7&pageNum=9&trk=public_jobs_jserp-result_search-card,"Capgemini en quelques mots Capgemini est un leader mondial, responsable et multiculturel, regroupant 350 000 personnes dans pr√®s de 50 pays. Partenaire strat√©gique des entreprises pour la transformation de leurs activit√©s en tirant profit de toute la puissance de la technologie, le Groupe est guid√© au quotidien par sa raison d‚Äô√™tre : lib√©rer les √©nergies humaines par la technologie pour un avenir inclusif et durable. Fort de plus de 50 ans d‚Äôexp√©rience, Capgemini est reconnu par ses clients pour r√©pondre √† l‚Äôensemble de leurs besoins, de la strat√©gie et du design jusqu‚Äôau management des op√©rations, en tirant parti des innovations dans les domaines en perp√©tuelle √©volution. Insights & Data en quelques mots Dans ce contexte, notre practice Insights & Data (I&D) s‚Äôappuie sur une √©quipe de 1300 personnes en France au sein de 5 villes (Paris, Lille, Nantes, Rennes et Toulouse) qui supportent nos clients de tous les secteurs dans leur transformation data. Cette √©quipe combine des comp√©tences m√©tiers avec une forte expertise data, analytique et d‚Äôintelligence artificielle pour mettre en ≈ìuvre des solutions qui visent √† am√©liorer la gestion et la valorisation des donn√©es. Pour renforcer les √©quipes d‚ÄôI&D, nous recherchons actuellement un.e Data Engineer BI.  A propos du poste : Int√©gr√© au sein d‚Äôune √©quipe projet BI, Big Data ou Data Gouvernance pour des clients intervenant dans des secteurs d'activit√©s divers, vous serez notamment en charge des missions suivantes :Mener les analyses fonctionnelles destin√©es √† traduire les besoins du client,Mener les travaux de conception et de mod√©lisation,Diriger le d√©veloppement de la solution / des traitements d'alimentation du DataWareHouse,Organiser et pr√©parer les travaux de recette utilisateurs,Mettre en place les processus d'industrialisation et mener cette derni√®re.  Pourquoi nous rejoindre ?Une culture forte et bienveillante, et une grande place laiss√©e √† la libert√©Des clients vari√©s, leaders de leur secteurUne approche pragmatique, qui r√©pond aux vrais enjeux des entreprises.Vous arrivez au bon moment pour prendre place dans une √©quipe √† taille humaine, en renouvellement et en hyper croissance.  Pas de profil type chez Capgemini, mais quelques ingr√©dients pour laisser la magie op√©rer ... !  Dipl√¥m√© d'un Bac + 5 en √©cole d‚Äôing√©nieur ou √©quivalent universitaire, vous avez au moins 3 ans d‚Äôexp√©rience en BI ou en lien avec un ETLVous avez d√©j√† encadr√© des √©quipesVous √™tes un(e) passionn√©(e) de la Data, enthousiaste et curieux(se)Vous √™tes pr√™t(e) √† partager de fa√ßon accessible √† une audience non ¬´ data expert ¬ªVous ma√Ætrisez une ou plusieurs des technologies suivantes :BI : SAP BI (Hana, BW, BODS, BI 4), Microsoft BI (SQL Server, SSIS, SSAS, SSRS), Oracle (ODI, OBIEE), Teradata, Informatica (Powercenter), IBM (Datastage, Cognos, TM1), Talend, AB InitioDataviz : Microsoft Power BI, Tableau, QlikviewBig Data : Ecosyst√®me Hadoop (HIVE, PIG, Mahout‚Ä¶), Cloudera, Pivotal, Spark, HNXAnalytics : R, SAS, IBM SPSSEnglish speaker, because we are French but also international  ¬´ Capgemini, Entreprise handi accueillante, conform√©ment √† la norme AFNOR NF X50-783, est √©galement signataire de la charte de la diversit√© en entreprise ¬ª.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Oracle'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,padoa,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-padoa-3806408425?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=UaSmaEBDQcQviluwEPnDKw%3D%3D&position=8&pageNum=9&trk=public_jobs_jserp-result_search-card,"Tu cherches √† donner du sens √† ton talent et √† avoir un impact positif sur le monde ?N√©e en 2016, padoa c‚Äôest 240 collaborateurs passionn√©s autour d‚Äôun logiciel et une offre de services con√ßus pour moderniser les services de sant√© au travail. Sur notre logiciel SaaS, nous g√©rons les dossiers m√©dicaux de 5,5 millions de salari√©s en France. Avec une nouvelle lev√©e de fonds de 80M‚Ç¨ en 2022, nous sommes pr√™ts √† r√©aliser notre mission : Faire du monde du travail un univers de pr√©vention afin d‚Äôam√©liorer la sant√© de millions de personnes ! Pour atteindre notre objectif, nous renfor√ßons r√©guli√®rement nos √©quipes avec les meilleurs talents. Aujourd‚Äôhui, nous recherchons diff√©rentes comp√©tences (strat√©gie, design, tech, data, m√©decine et vente) pour concevoir, am√©liorer, d√©velopper, promouvoir et d√©ployer padoa. Tes missionsAu sein de l‚Äô√©quipe int√©gration, qui compte presque 20 Data Engineers, tu assureras la reprise compl√®te et structur√©e des donn√©es des anciens logiciels m√©tier de nos clients vers les solutions padoa. Pour ce faire, tu devras :Comprendre les besoins en termes de donn√©es de diff√©rents corps de m√©tiers (professionnels de sant√©, ing√©nieurs de pr√©vention, gestionnaires de facturation ...)Analyser et comprendre l‚Äô√©tat et la structuration de la donn√©e de diff√©rents m√©tiers (ex: professionnels de sant√©, gestionnaires de facturation... ) dans les anciennes bases de donn√©es des clientsParticiper √† la prise de d√©cision pour nettoyer et traduire ces donn√©es dans la solution padoaMettre en place un pipeline de donn√©es pour r√©cup√©rer ces donn√©es et les injecter dans notre logiciel (grande diversit√© de donn√©es : + de 250 informations diff√©rentes, avec jusqu‚Äô√† plusieurs millions de points de donn√©es pour certaines informations)Assurer que le pipeline soit robuste, test√© et permettre un maximum de tra√ßabilit√© sur les traitements subis par la donn√©e et les incoh√©rences d√©tect√©es (python + node.Js)¬†Assurer la maintenance et l‚Äô√©volution de la base de donn√©es du produit padoaD√©velopper des fonctionnalit√©s backend qui manipulent de grandes quantit√©s de donn√©esTravailler en collaboration avec les r√©f√©rents m√©tiers ainsi qu‚Äôavec les clients des diff√©rents m√©tiers (professionnels de sant√©, gestionnaires de facturation, etc.)Qualifications cl√©sBAC + 5 en ing√©nierie informatique ou science des donn√©es ou dipl√¥mes d‚Äô√©cole d‚Äôing√©nieur ou √©quivalentDe tr√®s bonnes comp√©tences interpersonnelles : tu sais adapter ton discours √† diff√©rents profils, dont des profils non-techniques De la rigueur et un bon sens de l‚ÄôorganisationDe bonnes connaissances en Python et en SQL¬†Bon √† savoirCarte Swile (ticket de 10‚Ç¨/jour pris en charge √† 60%). Abonnement transport rembours√© √† moiti√© √©videmment ou IK v√©lo pour les plus sportifs avec un parking v√©lo au pied des bureaux. Des locaux bien desservis (place de l‚Äô√©toile / Ternes). 2 jours de t√©l√©travail.Des √©v√©nements d‚Äôentreprise nombreux par √©quipe et all-staff. De nombreuses initiatives internes (green team, club de jeux de soci√©t√©, √©v√©nements sportifs et caritatifs‚Ä¶). Une bonne mutuelle et des petit-dejs √† dispo tous les jours !padoa s'inscrit dans une d√©marche d'inclusion et s'engage √† √©tudier toutes les candidatures aux regards des comp√©tences et qualifications de chacun.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Analytics Engineer (x/f/m),Doctolib,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/analytics-engineer-x-f-m-at-doctolib-3788192686?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=eq51woOT3ApMNxDVB%2BeIyQ%3D%3D&position=9&pageNum=9&trk=public_jobs_jserp-result_search-card,"What You‚Äôll DoWe are looking for an Analytics Engineer to join the team and help us transform the access to healthcare!Important point at Doctolib: the data is fully encrypted and anonymized.You will be part of the Analytics Engineering team which has different goals:Build, maintain, and evolve data products that provide insights and support decision-making across DoctolibCollaborate with stakeholders to understand their data needs Explore data to validate business rulesEvaluate complexityDefine specifications and develop themCommunicate with stakeholders to ensure alignment (constraints, business rules, timeline, project updates)Project management (project split, grooming, timeline)Monitor the product (test and measure)Continuous improvementDefine and implement high level reporting (KPI definitions, Dashboards creation and maintenance)Define roadmaps in collaboration with PMs and stakeholdersEnsure data products quality (monitoring), security (GDPR, legal, infrastructure security), and availability (code optimization, performance monitoring, architecture optimization)Stakeholders guidance, empower data self-service to your stakeholders (train and advice)Everyone in the team is able to develop full stack data skills (from the source to the publication).Your responsibilities within the team include but are not limited to:Work with Business/Engineering teams to challenge the needsBuild and maintain data pipelines (Python)Build and maintain datamarts in Redshift (SQL)Build dashboards for the high level reporting (Tableau)Ensure training on data to end users (Metabase and Tableau)Monitor the quality of the data providedBe a key player to improve our architectureThe team hosts quarterly Data Innovation Days, hackatons for trying new tools/architectures or developing applications you find useful for the team.Our stackETL : AirflowData Warehouse : AWS S3 / RedshiftBI / Reporting : Metabase / TableauGitHubAmazon Web ServicesWho You AreIf you don‚Äôt meet all the requirements below but believe this opportunity matches your expectations and experience, we still encourage you to apply!You could be our next team mate if you:Have at least 2 years of experience as a Analytics Engineer, BI Engineer, Data Engineer or a similar roleLove to use SQL Have some knowledge of PythonKnow Redshift and/or PostgreSQLHave a good understanding of functional aspects of data (Sales, Finance, Web Analytics, Product)Have already used BI tools such as Tableau, Metabase, Superset, Power BI‚Ä¶Have experience in code hosting platform (we are using GitHub)Have good communication skillsAre results-oriented and proactiveHave already worked with business teams and challenged their needsLove to learnSpeak both French & EnglishNow, it would be fantastic if you:Have experience with DBTHave experience with AWS environment (S3/Athena/Firehose...)Have experience with Apache Airflow and DockerAre familiar with the GDPR regulationsWhat We OfferA stock-option program for each DoctoliberQuarterly bonuses and a competitive packageA 6-month dedicated onboarding program - the Doctolib AcademyContinuous training programs on all key competencies (English, soft skills, expertise) Transparent internal mobility opportunities you're welcome to apply for2 days per year to help health charities and create a positive social impact - the Solidarity DaysMental health and wellbeing offer in partnership with moka.careThe Doctolib Parent Care Program, including extended parental leave, meet-ups and inspiring conferencesHigh-quality office spaces supporting collaboration, health and wellbeingA subsidy from the work council to refund part of the membership to a sport club or a creative classA competitive health insurance paid 100% by the company Subsidy for lunch and various food offers in our offices A flexible workplace policy offering both hybrid and office-based modeFlexibility days allowing to work in EU countries and the UK 10 days per year A support for relocation in case of international mobilities and new joiners arriving to France, Germany and Italy from another countryThe interview process HR ScreenTake home test + Case restitutionHiring Manager Interview Job detailsPermanent positionFull Time Workplace : Paris areaStart date: asapRemuneration : fix + bonus on objectives (according to your profile)A stock options plan for every DoctoliberAt Doctolib, we believe in improving access to healthcare for everyone - regardless of where you come from, what you look like. This translates into our recruitment process: Doctolib is an equal opportunity employer. We don't just accept diversity at Doctolib, we respect and celebrate it!The more diverse ideas are heard, the more our product will truly improve healthcare for all. You are welcome to apply to Doctolib, regardless of your gender, religion, age, sexual orientation, ethnicity, disability, or place of origin. If you have a disability, let us know if there's any way we can make the interview process smoother for you! All the information transmitted via this form is processed by Doctolib for the purpose of managing applications. For more information on how Doctolib processes your application data, click here.If you wish to exercise your rights or if you have any questions about the processing of your data, you can write to us at hr.dataprivacy@doctolib.com.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer,MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3805299937?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=uDBP%2Bmk5l1c3D73zBFfNfg%3D%3D&position=10&pageNum=9&trk=public_jobs_jserp-result_search-card,"We are looking for Data Engineer!ResponsibilitiesDesigning, creating, and maintaining data processing systems Analyzing and optimizing data processing workflows Collaborating with the team to ensure data quality and efficiency Testing and implementing new solutions RequirementsAt least 2 years of experience in designing and creating data processing systems Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python) Excellent knowledge of databases and SQL language Ability to work in a team and communicate effectively with other departments Communicative English skills Experience with AWS/AWS Glue is a plus We OfferB2B contract Full-time job Remote work and flexible hours


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER CLOUD (H/F/NB),TRIMANE | Expert BI et Big Data,"Puteaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-cloud-h-f-nb-at-trimane-the-data-intelligence-company-3793473491?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=66I96m3C4p%2FEkOa4bI7ZHg%3D%3D&position=11&pageNum=9&trk=public_jobs_jserp-result_search-card,"En tant que pure Player Data, depuis plus de 15 ans, nous avons pour mission de faciliter l'acc√®s √† l'information en proposant des prestations sur mesure et √† forte valeur ajout√©e. Nous utilisons les technologies de pointe pour cr√©er de la valeur √† partir des donn√©es disponibles, telles que la Data Intelligence, le Big Data, l'Intelligence Artificielle, le Machine Learning ‚Ä¶¬´ Identifier, gouverner, acqu√©rir, traiter, visualiser, analyser et optimiser vos donn√©es pour cr√©er un maximum de valeur ! ¬ªNous proposons aux entreprises un accompagnement adapt√© dans leur projet de transformation Data en respectant la r√©glementation en vigueur telle que la RGPD.Soci√©t√© √† taille humaine, nous recrutons, avant tout, des personnes passionn√©es d√©sirant int√©grer une vraie communaut√© et construire ensemble une relation durable et de confiance.Rejoindre Trimane C'est> Un triple suivi de carri√®re avec vos r√©f√©rents technique, RH et commercial,> Un acc√®s en illimit√© √† nos plateformes de formations via nos activit√©s R&D, des certifications, des formations en interne autour en BI, Big Data, Machine Learning, Blockchain et logiciels software,> Des ateliers de veilles technologiques sur des sujets innovants,> Un CSE avec des afterworks, des escapes games, et autres activit√©s d'√©quipe,> Participer √† l'aventure The Blockchain Group, un groupe d'entrepreneurs, compos√© de diff√©rentes entit√©s proposant des offres de services compl√©mentaires (digital, blockchain, Data...) et des projets communs.Le PosteDans le cadre du d√©veloppement de notre communaut√© Cloud, vous aurez pour principales missions‚ÄØd'accompagner nos clients dans leur transformation digitale par la mise en place de projets cloud.Votre Mission Sera De Concevoir et d√©velopper des outils de traitements et processing de donn√©es D√©ploiement, industrialisation et tests de solutions d√©velopp√©es, Monitoring et analyse de flux de donn√©es. R√©diger les rapports d'analyse de donn√©es, et assurer la pr√©sentation au client Savoir utiliser les outils d'analyse et de visualisation de donn√©es Assurer une veille technologique soutenue en lien avec les √©diteurs Intervenir en tant qu'expert pour conseiller, cadrer et transformer des infrastructures, afin que nos clients puissent garder le contr√¥le et tirer pleinement parti du cloudPoints Forts Du Poste‚ÄØ Rejoignez une √©quipe d'experts et de passionn√©s en Data Participez √† des projets innovants d'envergure nationale et internationale avec de forts enjeux √©conomiques, r√©glementaires, organisationnels et techniques Fonctions pluridisciplinaires‚ÄØ: Conseil, gestion de projet, d√©veloppement, formation, Recherche / Innovation, porteur d'offre Cloud‚Ä¶ Participer et devenir un v√©ritable pilier √† la cr√©ation et au d√©veloppement des activit√©s strat√©giques de TRIMANE gr√¢ce √† un management participatif (bas√© sur des bonus)Profil Formation ing√©nieur ou universitaire de niveau Bac+5 ou plus √† dominante informatique et math√©matiques Une premi√®re exp√©rience r√©ussie en data engineering Connaissance des techniques et outils de traitement de la donn√©e en python, Spark/Hadoop dans un environnement cloud Vous parlez tr√®s bien anglais et fran√ßais vous permettant d'√©changer avec des √©quipes internationales. Vous √™tes curieux, force de proposition, avec une vraie culture du r√©sultat, vous appr√©ciez le travail en √©quipe. Vous aimez les d√©fis et √™tes passionn√© par les enjeux techniques √† forte valeur ajout√©e.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,Bouygues Construction,"Guyancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-bouygues-construction-3802935645?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=swD4%2BNAL2b8o0JXxQA%2F%2F3Q%3D%3D&position=12&pageNum=9&trk=public_jobs_jserp-result_search-card,"Bouygues Construction IT est au service des structures du Groupe et r√©pond aux besoins diversifi√©s des m√©tiers de la Construction, de l'Energie et des Services. Nous les accompagnons dans la r√©alisation de leurs m√©tiers, la digitalisation des processus et le d√©veloppement √† l'international. Nous sommes engag√©s en faveur de la diversit√© et ouverts √† tous les talents.Pr√™t(e) √† participer √† des projets d'envergures ? Rejoignez la Direction DATA de Bouygues Construction IT !En tant que Data Engineer, vous aurez notamment pour responsabilit√©s de : Construire des pipelines de donn√©es en ayant recours √† des technologies et langages vari√©s (TALEND, SnowFlake, Power BI, Python‚Ä¶) Participer √† l‚Äô√©tude de nouvelles solutions Data Mener des √©tudes de faisabilit√© Travailler √† l'am√©lioration continue des pipelines (Bonnes pratiques, optimisations,...) Challenger les √©quipes dans leurs r√©alisations et travailler √† l'am√©lioration des abaques Participer et encadrer les exercices de Code Review Accompagner des projets d'industrialisations Data Science (Dataiku, Snowpark,...) Piloter des projets en lien avec les MOA, nos prestataires ou nos centres de d√©veloppement externes. Participer √† l'animation de l'√©quipe autour de son delivery et sa mont√©e en comp√©tenceVous √™tes dipl√¥m√©(e) d‚Äôune √©cole d‚Äôing√©nieur ou d'un autre diplome Bac+5 li√© √† l'informatique et la data et vous avez au moins 5 ans d‚Äôexp√©rience sur des probl√©matiques de data engineering (construction de pipelines de donn√©es (batch/streaming), industrialisation d‚Äôapplications data science, mod√©lisation de base de donn√©es‚Ä¶) ; Anglais professionnel Vous travaillez en ayant une culture projet en mode AGILE Vous disposez de solides connaissances sur les architectures de donn√©es et le cloud. Vous avez de l‚Äôexp√©rience sur un ou plusieurs environnements cloud (Azure, AWS‚Ä¶) ; Vous disposez de bonnes comp√©tences en Python, SQL Vous avez travaill√© √† l'industrialisation de projet Data et avez des connaissances Data OPS / QOS - QOD


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Ing√©nieur Data Analyst (F/H),Thales,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/ing%C3%A9nieur-data-analyst-f-h-at-thales-3737181947?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=FyboRwMGKaiVYoENeUgsOw%3D%3D&position=13&pageNum=9&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales est un leader mondial des hautes technologies comptant plus de 81 000collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans lesinnovations du num√©rique et de la ¬´ deep tech ¬ª ‚Äì big data, intelligenceartificielle, connectivit√©, cybers√©curit√© et quantique ‚Äì pour construire unavenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßantl‚Äôhumain au c≈ìur des d√©cisions.Thalespropose des solutions, services et produits qui aident ses clients ‚Äìentreprises, organisations, Etats ‚Äì dans cinq grands march√©s vitaux pour lefonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense,a√©ronautique, espace, et transport.QUI ETES-VOUS ?De formation Ing√©nieur ou Bac+5, Ecole d‚Äôing√©nieur ou Universit√© vous justifiez d'une exp√©rience professionnelle en mise en place de solutions DataViz / BI d‚Äôau moins 4 ans.CE QUE NOUS POUVONS ACCOMPLIRENSEMBLE :Nous recherchons un D√©veloppeur Power BI et Azure passionn√© et comp√©tent pourrejoindre notre √©quipe technique. En tant que D√©veloppeur Power BI et Azure,vous jouerez un r√¥le essentiel dans la conception, le d√©veloppement et lamaintenance de nos solutions d'intelligence d'affaires bas√©es sur Power BI etAzure. Vous travaillerez en √©troite collaboration avec les √©quipes m√©tier pourcr√©er des visualisations de donn√©es percutantes et des tableaux de bordinteractifs, tout en exploitant les services cloud Azure pour assurer lascalabilit√© et la s√©curit√© des donn√©es.Vous avez pu acqu√©rir plusieursdes comp√©tences suivantes :Solide exp√©rience dans le d√©veloppement de solutions Power BI, y compris laconception de tableaux de bord interactifs, la cr√©ation de mesures et de KPI,et la transformation des donn√©es.Connaissance approfondie des services cloud Azure, tels que Azure Data Factory,Azure SQL Database, Azure Data Lake, etc.Ma√Ætrise des langages de requ√™te de donn√©es tels que SQL, DAX et M.Compr√©hension des principes de mod√©lisation de donn√©es et d'architecture BI.Exp√©rience dans l'int√©gration de diff√©rentes sources de donn√©es dans Power BI,y compris des bases de donn√©es relationnelles, des services web et des fichiersplats.Capacit√© √† comprendre les besoins m√©tier et √† traduire les exigences ensolutions Power BI efficaces.Bonnes comp√©tences en r√©solution de probl√®mes et en communication pourcollaborer avec les membres de l'√©quipe et les parties prenantes.En nous rejoignant, vous vousverrez confier les missions suivantesConcevoir et d√©velopper des tableaux de bord interactifs et des rapportspersonnalis√©s en utilisant Power BI.Collecter et analyser les besoins des utilisateurs m√©tier pour d√©finir lesindicateurs cl√©s de performance (KPI) et les exigences de visualisation desdonn√©es.Extraire, transformer et charger (ETL) les donn√©es √† partir de diff√©rentessources dans les solutions Power BI et Azure.Optimiser les performances et la scalabilit√© des solutions Power BI enutilisant les fonctionnalit√©s avanc√©es d'Azure, telles que les entrep√¥ts dedonn√©es Azure, Azure Data Factory, Azure SQL Database, etc.Assurer la s√©curit√© des donn√©es en mettant en place des m√©canismes d'acc√®s etde confidentialit√© appropri√©s dans Power BI et Azure.Collaborer avec les √©quipes m√©tier pour fournir des conseils et desrecommandations sur l'utilisation efficace de Power BI et Azure pour l'analysedes donn√©es.Maintenir et am√©liorer les solutions Power BI existantes en fonction des√©volutions des besoins des utilisateurs.Effectuer des tests et des contr√¥les de qualit√© pour assurer l'exactitude et lacoh√©rence des donn√©es.Nous vous offrons :¬∑ Une diversit√© de projets vous permettant de d√©couvrir l‚Äôensemble de nosm√©tiers,¬∑ Des conditions de travail motivantes et un plan de carri√®re personnalis√©offrant de r√©elles perspectives d‚Äô√©volution,¬∑ La possibilit√© de vous investir dans une entreprise dont la r√©putation estmondiale avec des ambitions constantes d‚Äôinnovations techniques.Innovation, passion, ambition :rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,MindPal,"Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-at-mindpal-3803324889?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=kXapIGUzxzyD0EtYNwVacA%3D%3D&position=14&pageNum=9&trk=public_jobs_jserp-result_search-card,"We are looking for Data Engineer!ResponsibilitiesDesigning, creating, and maintaining data processing systems Analyzing and optimizing data processing workflows Collaborating with the team to ensure data quality and efficiency Testing and implementing new solutions RequirementsAt least 2 years of experience in designing and creating data processing systems Proficiency in tools and programming languages related to data engineering (e.g. Hadoop, Spark, Scala, Python) Excellent knowledge of databases and SQL language Ability to work in a team and communicate effectively with other departments Communicative English skills Experience with AWS/AWS Glue is a plus We OfferB2B contract Full-time job Remote work and flexible hours


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA Engineer H/F,LesJeudis,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3788251741?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=faRHKkXSZWo3YWMOVpLXDQ%3D%3D&position=15&pageNum=9&trk=public_jobs_jserp-result_search-card,"MissionDans le cadre de la croissance de notre agence lilloise, nous d√©veloppons notre Practice Data et recrutons des profils Data de divers horizons : Data Analyst, Data Engineer, Data Scientist et Data Gouv.Les besoins m√©tiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversit√© de comp√©tences.Vous pourriez √™tre l'un d'eux et rejoindre Inetum.En tant que Data Engineer, vos principales missions consistent √† :Analyser et retranscrire le besoin clientConcevoir et mettre en ≈ìuvre les solutions permettant de traiter des volumes de donn√©es important afin de les mettre √† disposition des Data Analyst ou Data ScientistVous √™tes le premier maillon de la cha√Æne garantissant l'int√©grit√© et la qualit√© de la donn√©eProfilPour mener √† bien votre r√¥le, il vous faut :Une ma√Ætrise de la conception des entrep√¥ts de donn√©esUne expertise dans le stockage de donn√©es et leurs manipulationsBase de donn√©es : parmi les SGBD MySQL, PostgreSQL, Oracle, Snowflake, BigQuery, etc...NoSQL : parmi MongoDB, Cassandra, HBase, Neo4J, etc...ETL : parmi Talend, Stambia, SSIS, etc...Une app√©tence pour la programmation : parmi Python, Scala, Java, NodeJS, etc..Et si en plus vous disposez des comp√©tences : dans les environnements cloud et/ou dans les technologies BigData : Hadoop, Spark, Kafka, etc...un choix de missions encore plus large s'offre √† vous.Vous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !Notre PlusRejoindre la r√©gion Nord-Est, c'est b√©n√©ficier des avantages d'un Grand Groupe tout en gardant la proximit√© r√©gionale.Nous mettrons tout en ≈ìuvre pour vous apporter un √©quilibre vie perso / vie pro. C'est pourquoi nous vous proposons un rythme hybride (selon les contraintes clients).Inetum a d'ailleurs sign√© un accord de t√©l√©travail en 2021 pour que chaque collaborateur puisse adapter son rythme de travail.Une trajectoire de carri√®re personnalis√©e et adapt√©e √† vos souhaits d'√©volution gr√¢ce √† une implantation √† l'international (26 pays, 7 Fablab), des formations cibl√©es et des projets couvrant l'ensemble de la cha√Æne de valeur IT (+25 fili√®res m√©tiers).Int√©grer un collectif d'experts partageant des valeurs de solidarit√© et d'excellence.OrganisationNous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Cassandra', 'Neo4j', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['MySQL', 'PostgreSQL', 'Oracle', 'Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage Data Engineer H/F,ACENSI,"Montpouillan, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/stage-data-engineer-h-f-at-acensi-3779681692?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=ODyoH1IuNR1U%2Bn1gB70qvQ%3D%3D&position=16&pageNum=9&trk=public_jobs_jserp-result_search-card,"Description De L'offre LE STAGE Rattach√© au responsable du p√¥le Data d‚ÄôACENSI, vous interviendrez dans le cadre des projets groupe √† la maintenance et √† l‚Äô√©volution du SIBI.Dans le cadre du stage, vous aurez notamment pour mission (liste non exhaustive et pouvant √©voluer)De mettre en place une solution cloud (GCP/AWS/Azure) orient√©e dataDe mettre en place les bonnes pratiques de d√©veloppement pour une data pipeline Code  Enchainement (landing, raw, redefined et takeoff)  Les couches de data lineage D‚Äôinitialiser la chaine CI/CDDe r√©aliser des POC sur des sujets diverses et vari√©s orient√© DataDe r√©aliser des rapports via PowerBiDe r√©aliser les documentations aff√©rentes aux t√¢chesTechnologiesCloud : AWS/GCP/AzureLangage : Python/Spark (scala/python)Restitution : PowerBiOptionnel : Jenkins, Github, Confluence, ‚Ä¶Pas de panique ! Vous serez accompagn√© tout au long de votre stage pour monter en comp√©tence !Gr√¢ce √† notre centre de formation interne, vous pourrez √©galement assister √† toutes les formations n√©cessaires √† la r√©alisation de votre stage et l‚Äôaccompagnement vous permettant d‚Äôaboutir √† un CDI.PROFILEtudiant(e) en derni√®re ann√©e d‚Äô√©cole d‚ÄôIng√©nieur / de Management ou de Master Universitaire en Syst√®me d‚ÄôInformation, passionn√©(e) par le Big Data et/ou la Business Intelligence, vous souhaitez mettre vos connaissances et vos comp√©tences au profit d‚Äôune entreprise dynamique.Vous √™tes autonome et organis√©.Vous √™tes dot√© d'un excellent relationnel et d'une forte capacit√© d'int√©gration aux √©quipes projet.Vous avez le sens de l‚Äô√©coute.Un bon niveau d'anglais est souhaitable.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': ['PowerBI'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': ['Confluence']}"
Data engineer Pyspark / SAS H/F,MERITIS,Greater Paris Metropolitan Region,https://fr.linkedin.com/jobs/view/data-engineer-pyspark-sas-h-f-at-meritis-3797402761?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=1qOU3a1U5wIWwu%2F3NXwDBQ%3D%3D&position=17&pageNum=9&trk=public_jobs_jserp-result_search-card,"Nous recherchons un d√©veloppeur en capacit√© de lire et comprendre les programmes SAS sous environnements WPS afin de les r√©√©crire en PySpark dans Databricks.Dans le cadre de sa strat√©gie de migration vers le Cloud, notre client travaille √† moderniser ses outils de projection actuarielle et les installer dans un environnement Azure.  Afin d'op√©rer son mod√®le interne et r√©aliser ses projections, l'√©quipe souhaite moderniser les outils de son processus d'inventaire car ils ne r√©pondent plus aux exigences du groupe. Cette modernisation passe par la r√©√©criture de l'ensemble des programmes SAS en PySpark sous DataBricks.  La mission consistera √† : - Analyser et comprendre l'existant (programmes SAS) - Prendre en charge les d√©veloppements / migration de l'ensemble du processus d'inventaire sous PySpark - √âlaborer les tests unitaires, tests automatiques, tests de non-r√©gression pour contr√¥ler les r√©sultats (comparaison des r√©sultats des programmes SAS avec les nouveaux programmes Python) - Gestion du processus de d√©veloppements et de livraison entre les environnements DataLab et Usecase - Former les √©quipes m√©tiers au codage Python/PySpark afin qu'ils puissent maintenir et faire √©voluer l'ensemble du futur processus - R√©diger la documentation technique dans une haute d√©marche de qualit√© (sp√©cifications, manuel d‚Äôutilisation, rapport de recette...)Expertise souhait√©e- Vous √™tes dipl√¥m√©(e) d'un Bac +5 et justifiez d'au moins 7 ans d'exp√©rience - Expertise dans le codage en langage Python, PysPark - Bon niveau dans le codage en langage SAS - Excellentes qualit√©s relationnelles et volont√© d'interagir avec les √©quipes m√©tiers - Capacit√© de r√©daction de documentations techniques - Des comp√©tences dans la r√©alisation de rapports avec Power Bi seraient un plus  Descriptif de l‚Äôentreprise Meritis est un cabinet de conseil, pilotage et d√©veloppement IT fond√© en 2007 pr√©sent √† Paris, Sophia-Antipolis, Aix-en-Provence, Montpellier, Toulouse, Nantes... Et bient√¥t sur de nouveaux territoires ! Notre mission ? Connecter les meilleurs talents aux entreprises pour leur donner un temps d‚Äôavance.‚Äã Nous accompagnons nos clients dans l‚Äôint√©gralit√© de leurs besoins en transformation num√©rique √† travers de nombreux domaines d‚Äôexpertises : Software Engineering, Finance, Pilotage de projets, Devops, Data, Cloud, Cybers√©curit√© ou encore Agilit√©.‚Äã Intervenant aussi bien dans les secteurs de la Banque, de l'Assurance, des T√©l√©communications que de l'Industrie ou des Transports, aujourd'hui 40% des entreprises du CAC40 sont clientes Meritis.‚Äã Fort de nos valeurs d‚Äôexigence, d‚Äôhumilit√©, de bienveillance et de proximit√©, nous comptons aujourd‚Äôhui plus de 900 collaborateurs.‚Äã Nous mettons un point d‚Äôhonneur √† √™tre proche de nos collaborateurs et √† les accompagner de mani√®re individualis√©e quelles que soient leurs fonctions dans l‚Äôentreprise. Certifi√©e Great Place To Work depuis 2013, notre conception du bien-√™tre au travail va bien au-del√† d'un simple label, ce sont nos collaborateurs qui en parlent le mieux : https://www.glassdoor.fr/Avis/Meritis-Avis-E1163008.htm.‚Äã Vos diff√©rences sont nos atouts. C‚Äôest pourquoi Meritis est engag√©e en faveur de la diversit√© et de la non-discrimination. Tous nos m√©tiers sont accessibles aux personnes en situation de handicap. Si vous avez une question ou pensez √™tre victime ou t√©moin d‚Äôune discrimination, vous pouvez contacter ethiquegroup@meritis.fr. ¬ª


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer DevOps H/F,Inetum,"Courbevoie, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-devops-h-f-at-inetum-3782176029?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=p2XriDapx6oi28pgKtMDuw%3D%3D&position=18&pageNum=9&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre  Informations g√©n√©rales  Entit√© de rattachement  Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste M√©tier M√©tier BS (Business Solutions) - DevOps BS Intitul√© du poste Data Engineer DevOps H/F Contrat CDIDescription De La MissionQui sommes-nous ?Nous sommes une ESN agile et un groupe international. A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 27 000 collaborateurs puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital. Chacun d'entre eux peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde plus positif, innover localement dans 26 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Capital Market, entit√© Inetum en Finance de March√©. Nous accompagnons les acteurs majeurs du secteur de la finance en France et √† l‚ÄôInternational.Cultivant la double comp√©tence technique et fonctionnelle, nous intervenons sur des projets innovants √† haute valeur ajout√©e.Quelles sont nos valeurs ?üèÜ Excellence Notre culture de l‚Äôexcellence na√Æt de notre audace.ü§ù Engagement S‚Äôassocier et grandir ensemble !üõ∞ Innovation Nos FabLab au service de la transformation digitale de nos clients.Missions propos√©esPour accompagner notre forte croissance, nous recherchons des Data Engineer DevOps pour le compte d‚Äôun acteur majeur de la finance de march√© en Europe et dans le monde. Dans ce contexte international et exigeant, vous travaillez sur la conception de solutions Big Data afin de r√©pondre aux besoins des op√©rationnels m√©tiers.Pour mener √† bien ce projet, vous aurez pour responsabilit√©s de Comprendre les enjeux des √©quipes Data et les accompagner. Faire le lien entre les environnements (datalake, datawarehouse et environnement de d√©ploiement du mod√®le) gr√¢ce √† des pipelines sophistiqu√©s √ätre r√©f√©rent et garant des bonnes pratiques pour le d√©veloppement des langages utilis√©s par l'√©quipe. Accompagner les Data Scientists dans l'optimisation de leurs algorithmes Assurer la viabilit√© des solutions de datamining et de machine learning de l'√©quipe Data et les mettre en production.Construire et optimiser des pipelines de donn√©es complexes (ETL et ELT) Coordonner le d√©veloppement et les op√©rations gr√¢ce √† l‚Äôautomatisation des flux de travail, la cr√©ation de services Web pr√©dictifs. D√©ployez ces mod√®les en utilisant les derni√®res techniques et pratiques (API REST, Docker, Tensorflow Serving, etc.) Analyser et r√©soudre les anomalies li√©es aux performances et √† l‚Äô√©volutivit√© des solutions Cloud BI et Big Data Profil Profil souhait√© De formation Ing√©nieur Grande Ecole ou √©quivalent, vous poss√©dez une premi√®re exp√©rience r√©ussite de trois ans minimum sur un poste √©quivalent id√©alement en banque d‚Äôinvestissement ou asset management. Vous √™tes familier avec l‚Äôenvironnement Big Data (data grids, compute grids, REST based architectures, SGBDR, No-SQL Databases, GPUs) Vous avez d√©j√† travaill√© avec la m√©thodologie Agile Une certaine aisance technique est √©galement requise (Jenkins, Docker, Ansible, Git, Scala, Kubernetes, Python/Java, Maven) Une double comp√©tence Cloud (AWS, Google Cloud, Azure) serait un v√©ritable plus Evoluant dans un contexte international, la ma√Ætrise de l'Anglais est n√©cessaire. L‚Äôaisance relationnelle, de l‚Äôautonomie, la gestion des priorit√©s, des capacit√©s d‚Äôanalyse et de synth√®se, ‚Ä¶ le savoir-√™tre est une composante importante dans notre processus de recrutement. Tous nos postes sont ouverts aux personnes en situation de handicap.Et pourquoi Inetum Capital Market ?üòÑ Des missions int√©ressantesü§© Des perspectives d'√©volutions professionnelles et financi√®resüòé Les avantages d'un grand groupe internationalüòâ Un suivi r√©gulier‚úàÔ∏è Une aide √† la mobilit√© g√©ographique que vous soyez localis√© en France ou √† l'√©trangerüë®‚Äçüéì Des formations certifiantesü•≥ Des moments de FUN !Localisation du poste Localisation du poste France, Ile-de-France, 75 Paris Ville CourbevoieCrit√®res candidat Niveau d'√©tudes min. requis Bac+5 Niveau d'exp√©rience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Big Data Engineer,OPEN,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/big-data-engineer-at-open-3808435963?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=uiJc9PYuSGamV1bJWTcWlw%3D%3D&position=19&pageNum=9&trk=public_jobs_jserp-result_search-card,"üìã Contexte de la mission :On s'aper√ßoit de plus en plus que l'usage du Big Data dans tous les secteurs est d√©sormais incontournable.Ces usages permettent d‚Äôanalyser et d‚Äô√©valuer tout type de production humaine et feedbacks clients, afin d'am√©liorer la prise de d√©cision.Si vous √™tes passionn√©(e) par la valorisation de la donn√©e, √† l‚Äôaise avec la manipulation, complexit√© et h√©t√©rog√©n√©it√© d'un gros volumes de donn√©es.Vous √™tes int√©ress√©s par les technologies de pointe et des projets innovants Big Data .Qu‚Äôattendez-vous pour nous rejoindre La Business Unit Open Data IA & Kynapse ?Nous travaillons en direct chez nos clients Grands Comptes, dans leurs locaux, dans nos centres de services, Hybride.Venez rejoindre notre √©quipe !Positionn√© sur les technologies √©mergentes #Data #BI #Cloud ‚Äì notre BU accompagne au quotidien les entreprises et les organisations dans leurs enjeux de transformation industrielle et digitale. Nous vous attendons pour rejoindre l'√©quipe de Kais, notre Directeur des Op√©rations en tant que Consultant Data & IA.Vous aurez la possibilit√© d'intervenir sur des missions au forfait mais aussi chez nos clients en r√©gie dans un contexte agile !üìç Ce qui vous attend :√âtude des solutions techniques et fonctionnelles avec les √©quipes du projetPrise en charge des d√©veloppements n√©cessaires (Spark, Hive, Scala, Hadoop, Python, Java)Concevoir un DatawarehouseTraitement et stockage des donn√©esMettre en place les meilleures solutions big dataConstruction des bases de donn√©esL'application des standards (Clean code, Craftmanshift, TDD, BDD...)Participation aux points de suivi de projet selon la m√©thodologie Agile Scrumüõ†Ô∏è Vous √™tes fait(e) pour ce poste si :Vous disposez de 5 ans d‚Äôexp√©rience minimum dans le monde de la data, Vous maitrisez un ou plusieurs langage(s) technique(s) et l'environnement technique global d'un projet, vous avez d√©j√† travaill√© dans un environnement Agile ainsi que sur ses outils (Python /Java / Spark / Hadoop / Hive / Scala / HBase / Elasticsearch / MongoDB / Cassandra / Cloudera, Hortonwork / AWS / Azure‚Ä¶)Votre envie, votre bonne humeur, votre capacit√© relationnelle et votre rigueur sont √† la hauteur de votre dynamisme . Vous souhaitez vous projeter dans une nouvelle aventure, au sein d'une structure forte, int√©grer une √©quipe Data et r√©f√©rents techniques !Vous maitrisez l‚ÄôAnglais aussi bien √† l‚Äô√©crit qu‚Äô√† l‚Äôoral.ü§ù Au-del√† de la mission, vous pourrez : Intervenir sur diff√©rentes missions dans des secteurs d'activit√©s vari√©s (Secteur public, banque, assurance, t√©l√©coms‚Ä¶)Rejoindre nos Practices ! Notre programme interne de communaut√©s d'experts sur des technologies √©mergentes (Data, Microsoft, Cloud‚Ä¶)Vous engagez √† nos c√¥t√©s et contribuer √† augmenter l‚Äôimpact positif de nos actions : faites de vos comp√©tences des dons √† destination d‚Äôassociations, participez √† des √©v√©nements sportifs associatifs et faites-vous sponsoriser.Notre process de recrutement : un bref √©change t√©l√©phonique, un premier √©change RH d'environ 1h pour parler de vous, de vos aspirations professionnelles et de notre offre, un deuxi√®me √©change avec votre futur Manager et un dernier √©change avec un de nos experts pour parler technique. Ce sont nos Ambassadeurs qui en parlent le mieux, d√©couvrez leurs t√©moignages sans filtre : https://www.youtube.com/watch?v=C4w_dkkVq40 Et vous, qu‚Äôattendez-vous pour √™tre Open ?


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [' MongoDB', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer EMEA (F/M/D),Flowdesk,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-emea-f-m-d-at-flowdesk-3805794445?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=0%2F5%2BVc5Tm7Af0%2FzEi9xHQg%3D%3D&position=20&pageNum=9&trk=public_jobs_jserp-result_search-card,"Flowdesk is seeking a highly motivated Data Engineer to join the team and managed by the Quentin, the Lead Data!The data engineer will be an integral part of the growing data team, working closely with our trading and quantitative departments to provide a platform and tools to answer their analytical needs. The data platform revolves around Dagster deployed on Kubernetes for the orchestration, and dbt on BigQuery for the transformations.The next challenge will be to add support for real-time ingestion and processing of terabytes of market data.ResponsibilitiesDesign, build, and maintain efficient, scalable, and reliable batch and streaming data pipelines to support Flowdesk's trading infrastructureDevelop and maintain data warehouses, data lakes, and other data management systems with a strong focus on logical and physical modelingContribute early on to the definition of the data team's data products in order to maximize ease of access, data quality, and related documentationCollaborate with the software engineering team to integrate data-related functionality into Flowdesk's trading infrastructure and other applicationsLeverage cutting-edge data engineering technologies to continually improve the speed, reliability, and scalability of Flowdesk's data processing capabilitiesDevelop and maintain strong processes and procedures for data quality control, data validation, data documentation and, data integrationCollaborate with cross-functional teams including traders, developers, and compliance officers to ensure that all data used by Flowdesk is accurate, timely, and compliant with relevant regulations and requirementsRequirementsBachelor's or Master's degree in Computer Science, Engineering, or related field3+ years of experience in data engineering or related fieldExperience working with distributed streaming systems (Kafka, Beam, Flink)Knowledge and understanding of the lake-house architecture (Trino, open table format)Experience optimizing modern data warehousing platforms (BigQuery is a plus)Strong communication skills and ability to work collaboratively in a fast-paced an international environmentKnowledge of the data engineering ecosystem (contribution to open source projects is a plus)Strong analytical and problem-solving skills with a keen attention to detailBenefitsüí∏ BSPCEüåç International environment (English is the main language)üöÉ 50% of transportation costs & a sustainable mobility agreementüçî Swile lunch voucher (‚Ç¨9.25 per day, 60% covered)üè• 100% Alan Blue covered for you and your childrenüíª Top of the range equipment: Macbook, keyboard, laptop stand, 4K monitor & headphonesüéâ Team events and offsitesüîú Coming soon : gym memberships, international mobility & lot of other cool benefits !Recruitment processüëÄ Are you interested in this job but feel you haven't ticked all the boxes? Don't hesitate to apply and tell us in the cover letter section why we should meet!üìù Here's what you can expect if you apply:HR interview (30')Technical testTechnical interview (60')Chat with the Head of People (30') and the Head of Department (30') On the agenda: discussions rather than trick questions! These moments of exchange will allow you to understand how Flowdesk works and its values. But they are also (and above all) an opportunity for you to present your career path and your expectations for your next job!
      

        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Flink'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
[CDI] Data Eng Fullstack (Airflow / DBT / sujets BI) - Full remote - 55/90K‚Ç¨ (H/F),Hirestone,France,https://fr.linkedin.com/jobs/view/cdi-data-eng-fullstack-airflow-dbt-sujets-bi-full-remote-55-90k%E2%82%AC-h-f-at-hirestone-3801932614?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=2x0w5JQu4B9CfJVabex3DA%3D%3D&position=21&pageNum=9&trk=public_jobs_jserp-result_search-card,"Cette soci√©t√© est initiatrice de la Ad-tech pour les apps TV de streaming sur le march√© am√©ricain. Ils permettent notamment aux entreprises de plus petite taille, type PME, d‚Äôacc√©der √† la publicit√© TV, de fa√ßon simplifi√©e, cibl√©e et √† moindre co√ªt.Le job :- Ils montent une √©quipe pour supporter les besoins data c√¥t√© business, et cherchent donc un data ing√©nieur avec une app√©tence business et data analyse.- Le Data Warehouse est a cr√©er, ils y a d√©j√† de gros volumes qui vont impliquer des mod√®les de database Olap, donc l'utilisation de Druid, DuckDB ou ClickHouse.- Vous utiliserez Airflow pour int√©grer de la donn√©e provenant de nombreuses sources et scheduler des pipelines.- Utilisation √©galement de DBT pour construire des mod√®les de donn√©es qui scalent et qui vont inclure les besoins produit.- D'autres sujets seront √† venir par la suite, notamment des sujets de straming.Pourquoi c‚Äôest cool ?- Une √©quipe tr√®s s√©nior et un challenge technique pas accessible dans toutes les entreprises ! (Tr√®s gros volumes de donn√©es dans la pub).- Salaire : 55-90k selon profil.- Full Remote, avec rencontre toutes les 6 semaines en r√©gion parisienne pour un event team building et un point sur les avanc√©es.- BSPCE avec objectif revente en 2025-2026, et donc un beau ch√®que √† ce moment l√† :)


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - H/F,Sia Partners,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-sia-partners-3804524646?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=eDNswyR4rifYB2XKqcLkJg%3D%3D&position=22&pageNum=9&trk=public_jobs_jserp-result_search-card,"Sia Partners r√©invente le m√©tier du conseil et apporte un regard innovant et des r√©sultats concrets √† ses clients. Nous avons d√©velopp√© des solutions bas√©es sur l‚ÄôIntelligence Artificielle et le design pour augmenter l‚Äôimpact de nos missions de conseil. Notre pr√©sence globale et notre expertise dans plus de 30 secteurs et services nous permettent d‚Äôaccompagner nos clients dans le monde entier. A travers notre d√©marche ""Consulting for Good"", nous mettons notre expertise au service des objectifs RSE de nos clients et faisons du d√©veloppement durable un levier de performance pour nos clients.Heka.ai est la marque ind√©pendante de Sia Partners d√©di√©e aux solutions d'IA. Nous h√©bergeons de nombreuses solutions SaaS aliment√©es par l'IA qui, associ√©es √† des services de conseil ou utilis√©es ind√©pendamment, fournissent √† nos clients des solutions √† l'√©chelle.Description du posteSia Partners recrute un(e) Data Engineer pour accompagner le d√©veloppement des activit√©s de la Business Unit Data Science.Vous serez amen√©(e) √† participer aux missions Data Science de Sia Partners chez nos clients, ainsi qu‚Äôau d√©veloppement de nos produits Software-as-a-Service Heka.ai. Vous accompagnerez des Data Scientists, Software Engineers et DevOps Engineers dans des projets √† forte composante Data, dans le but de r√©pondre √† des challenges techniques autour du stockage, flux et traitement de donn√©es. Vous contribuerez activement aux choix technologiques, architecturaux et de gouvernance pour faire face aux enjeux de la mise √† l‚Äô√©chelle de projets Data.Les travaux couvriront les th√®mes suivants :Pipelines de donn√©es : d√©veloppement de scripts d‚ÄôETL dans des √©cosyst√®mes Big DataInfrastructures & Services adapt√©s au Machine Learning : veille technologique et mise en place de solutions utiles aux Data Scientists dans l‚Äôentra√Ænement et la mise √† disposition de leurs mod√®les de Machine LearningProgrammation en python : d√©veloppement d'outils ex√©cut√©s c√¥t√© serveur (traitement de donn√©es en masse, exposition des donn√©es via des APIs, ...)Services Cloud: choix d'architecture, utilisation de services de stockage & calculQualificationsDipl√¥m√©(e) d'une formation en √âcole d'Ing√©nieur ou d'une formation de haut niveau dans le domaine des technologies de l‚Äôinformation, vous justifiez d'une premi√®re exp√©rience d'au moins 2 ans en Data, DevOps, Cloud ou Software Engineering.Vous disposez d'un bon niveau en Python, vous permettant de qualifier, enrichir, et traiter de la donn√©e.C‚Äôest un plus si vous ma√Ætrisez un autre langage de programmationVous ma√Ætrisez les bases de donn√©es relationnelles (PostgreSQL, SQLServer, ‚Ä¶)C‚Äôest un plus si vous ma√Ætrisez un autre paradigme de base de donn√©es (Wide-column, Key-value, ‚Ä¶)Vous avez de l‚Äôexp√©rience avec des outils de calcul distribu√©, tels que Hadoop ou Spark ou vous avez de l‚Äôexp√©rience avec des outils de Machine Learning, tels que Tensorflow ou TorchC‚Äôest un plus si vous avez de l'exp√©rience avec les services d‚Äôau moins une plateforme de services Cloud (GCP, AWS, Azure)Pour vous, il est essentiel‚Ä¶d‚Äôaller au fond des choses : Il est important pour vous de comprendre toutes les nuances de votre datasetd‚Äôavoir un √©tat d‚Äôesprit ‚ÄúDo it yourself‚Äù : Monter en comp√©tence sur une technologie en autonomie pour r√©pondre √† une probl√©matique ne vous fait pas peurd‚Äô√™tre curieux(se) : Le monde de la data avance vite, mais vos capacit√©s de veille vous permettent de rester √† jourVous √™tes curieux(se) et aimez travailler en √©quipe ? Vous √™tes reconnu(e) pour votre sens de l‚Äôanalyse et du service client ?Vous souhaitez rejoindre un environnement professionnel dynamique et motivant ? Vous partagez nos valeurs que sont l'excellence, l'entrepreneuriat, l'innovation, le partage, la bienveillance et l'√©quilibre vie personnelle/vie professionnelle ?Vous parlez fran√ßais et anglais couramment dans un contexte professionnel ?Alors rejoignez-nous !Informations suppl√©mentairesPoste bas√© en plein c≈ìur de Paris (m√©tro George V).Pour plus d'information sur notre practice Data Science, consultez notre site https://heka.ai/Sia Partners est un employeur qui souscrit au principe de l‚Äô√©galit√© d‚Äôacc√®s √† l‚Äôemploi. Tous les aspects de l‚Äôemploi, tels que le recrutement, les promotions, la r√©mun√©ration, ou les sanctions sont bas√©s uniquement sur les performances, les comp√©tences, et le comportement des employ√©s ou les besoins de l‚Äôentreprise.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
STAGE INGENIEUR DATA - H/F,"Testia, an Airbus Company","Toulouse, Occitanie, France",https://fr.linkedin.com/jobs/view/stage-ingenieur-data-h-f-at-testia-an-airbus-company-3799408240?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=6xTuf6%2BzKy5zTyskNb1jcw%3D%3D&position=23&pageNum=9&trk=public_jobs_jserp-result_search-card,"TESTIA, filiale du groupe Airbus, est sp√©cialis√©e dans le Contr√¥le de Structures pour l‚Äôindustrie a√©ronautique et spatiale depuis plus de 30 ans.Nous intervenons aupr√®s de nos clients √† travers des contrats d'√©tude au forfait, des missions d'assistance technique ou des formations sp√©cialis√©es pour les donneurs d‚Äôordres et leurs fournisseurs ainsi que pour les compagnies a√©riennes et MRO.Contexte de la mission : Dans le cadre de la croissance de ses activit√©s num√©riques, TESTIA recherche un(e) stagiaire informatique sp√©cialis√© en gestion de la donn√©e.Missions et objectifs du poste : Rattach√©(e) aux services supports de l‚Äôentreprise, vos missions principales consisteront √†:- Participer √† la d√©finition et la documentation des r√®gles de gestion des donn√©es.- Industrialiser et automatiser le nettoyage de la donn√©e selon les sp√©cifications retenues.- G√©rer le cycle de vie de la donn√©e conform√©ment aux directives inscrites dans le RGPD- Cr√©er les tableaux de bord pour les √©quipes m√©tiers- Participer √† la mise en place d‚Äôun outil de Business intelligenceAu sein de l‚Äô√©quipe IT :- Assistance de niveau 1 sur les incidents g√©n√©riques- Accompagnement des utilisateurs dans les changements op√©r√©s par l‚Äô√©quipe IT (migration sur google workspace, suivi des am√©liorations de l‚ÄôERP- Suivre les demandes dans l‚Äôoutil de support GLPI- Avec l'aide de nos sous-traitants IT, garantir la maintenance en conditions op√©rationnelles (et cyber-s√©curis√©) de nos installations physiques (routeurs, switch...)‚ÄãComp√©tences recherch√©es : De formation ing√©nieur Data (de donn√©es) ou g√©n√©raliste, vous avez des comp√©tences op√©rationnelles en IT et une premi√®re exp√©rience r√©ussie (personnelle ou professionnelle) en gestion de bases de donn√©es SQL ou sur l‚Äôutilisation d‚Äôun BI.Des notions en d√©veloppement dans des langages modernes (ex : Python) seraient un plus. Savoir √™tre :Curiosit√© et envie de d√©couvrir de nouveaux outils et services informatiquesSens du service, dynamique, flexible, organis√©(e), rigoureux (se), et autonomeAutres comp√©tences :Bon niveau d'anglais oral et √©critInformations de l‚Äôoffre :  Stage (4 √† 6 mois)Lieu : ToulouseMerci de bien vouloir faire parvenir CV et lettre de motivation par mail √† : recrutement@testia.com


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirm√©(e),SFEIR,Greater Lille Metropolitan Area,https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-e-at-sfeir-3498603998?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=D%2BLuwb2AmfNKwASsj0E3Ow%3D%3D&position=24&pageNum=9&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ? SFEIR, c‚Äôest avant tout une communaut√© de 800 techs, en France, en Belgique et au Luxembourg, unis par la passion, dont 90 √† Lille.Nous aidons nos clients √† :Donner de la valeur √† leurs donn√©es, innover avec l‚ÄôIA ;√ätre compatible avec le futur en d√©veloppant leurs architectures SI, Cloud et Data ;Cr√©er de la valeur gr√¢ce aux API & microservices ;D√©velopper des applications web et mobiles pour am√©liorer leur exp√©rience client et se connecter partout.Et Lille dans tout √ßa ? SFEIR Lille c'est :Une agence cr√©√©e en 2014 par Nicolas Leroy ;Quatre-vingt consultant(e)s qui se connaissent toutes et tous ;Des managers techniques qui comprennent ton m√©tier ;Une dizaine de clients actifs en local et une centaine au niveau du groupe ;Des √©v√©nements en interne et organis√©s chaque mois (afterworks, Meetup, formations) ;Une communaut√© active : une cinquantaine de conf√©rences externes donn√©es en 2022 (Devfest, Devoxx, Meetup‚Ä¶) ;Des locaux dans le centre de Lille, √† 5 minutes des gares !.üí™ Ce qui fait notre force ?1. Notre culture est Digital Native. L‚Äôagilit√© est au c≈ìur de notre fonctionnement.On s‚Äôest inspir√© des pratiques des entreprises Digital Natives pour construire notre succ√®s : agilit√©, rapidit√© dans les prises de d√©cision, organisation d√©centralis√©e, promotion et utilisation de l‚ÄôOpen Source, etc.2. Notre strat√©gie est co-construite par les Techs pour les Techs.La direction g√©n√©rale et la direction de chaque entit√© sont co-lead√©es par un directeur Engineering et un directeur Business.Individuellement, chaque sfeirienne et sfeirien reporte √† un(e) Engineering Manager, lui(elle)-m√™me consultant(e) et a du temps d√©di√© pour manager. Il(Elle) travaille √©troitement avec le Business pour proposer les missions les plus adapt√©es √† chacun(e).3. Notre communaut√© est apprenante et dans le partage.Nous sommes partenaires officiels des trois principaux Cloud Provider (Google Cloud, AWS et Azure), de solutions de gestion de donn√©es (Databricks, dbt ou Snowflake) mais aussi de solutions infra (Linux Foundation, ‚Ä¶).Nous avons nos propres dispositifs de formation (SFEIR Institute, SFEIR School, ‚Ä¶). √áa nous permet de former officiellement nos clients, et tout au long de l‚Äôann√©e, les sfeiriennes et les sfeiriens.Nous sommes pr√©sents √† de nombreux √©v√®nements Techs tant au niveau national que r√©gional : tu as s√ªrement crois√© des sfeiriennes et sfeiriens si tu vas aux Meetup, aux DevFest,‚Ä¶üë©‚Äçüíª üë®‚Äçüíª Qui sont les sfeiriennes et les sfeiriens ? 100% des consultant(e)s sont des techs passionn√©(e)s par leur m√©tier.Ce qui nous rassemble aussi, c‚Äôest notre envie de contribuer √† la communaut√© et √† l‚Äôentreprise.On a une hi√©rarchie plate : on croit que l‚Äôentreprise est plus performante quand elle favorise l‚Äôautonomie et l‚Äôintelligence collective.Tu t‚Äôattendais √† ce qu‚Äôon te parle d‚Äô√©tudes, de dipl√¥mes ou d‚Äôexp√©rience, dans cette section ?Chez SFEIR, on n‚Äôa qu‚Äôun seul crit√®re : c‚Äôest ton niveau technique et ta culture tech. On en reparle un peu plus bas !Ce que tu feras, en tant que Data Engineer confirm√©(e) chez SFEIR ?Dans un contexte retail, Thomas accompagne les √©quipes data dans la construction d‚Äôapplications de pilotage d‚Äôactivit√©, de performance commerciale et d‚Äôaide √† la d√©cision. Utilis√©s par les magasins ou les √©quipes marketplace, ces outils ont un v√©ritable impact sur la performance des domaines. Dans cette mission, Thomas apporte son expertise sur les technologies suivantes : Google Cloud (BigQuery, Firestore, Cloud Run), Looker Studio, Terraform, Github Actions.Jonathan accompagne un grand compte dans la migration d‚Äôun stack data Hadoop vers Google Cloud. L‚Äôapproche Lift and Shift permet de migrer l‚Äôensemble des traitements Spark vers Dataproc. Les technologies suivantes sont au c≈ìur de sa mission : Google Cloud (Dataproc, BigQuery, Cloud Storage), Apache Spark, Python, SQL.La mission de Florian est orient√©e domaine supply. Le projet a pour but l'optimisation du contr√¥le de marchandise lors de la livraison fournisseur. La solution mise en place est un algorithme de Machine Learning qui prend la d√©cision de contr√¥le, en temps r√©el √† partir du contenu de la commande. Il travaille avec les technologies suivantes : Google Cloud (Composer/Airflow, Dataflow/Apache Beam, Firestore, BigQuery, Cloud Monitoring, Vertex AI), Docker, Kafka, GKE, Datadog, FastApi, Github Actions.üëå Comment on va t‚Äôaider √† progresser :Des points mensuels avec ton(a) manager, qui est un(e) tech comme toi ;Des formations et des certifications selon tes besoins ;La possibilit√© de choisir ta mission et d‚Äôen changer lorsque tu en auras fait le tour ;‚Ä¶ Bref, on sera l√† pour t‚Äôaccompagner dans toutes les situations.üöÄ Et si tu souhaites √©voluer ? Nous proposons des possibilit√©s d'√©volution verticales et horizontales. Nous pourrons t'accompagner pour te certifier ou √©valuer sur une autre sp√©cialit√©, ou encore devenir Data Architect.Tu auras √©galement la possibilit√© de prendre des r√¥les en interne si tu le souhaites :√âvaluateur(trice) dans le processus de recrutement ;Formateur(trice) SFEIR School ou SFEIR Institute ;Speaker(euse) lors de conf√©rences, Meetup, talks internes, aupr√®s des √©coles ;Engineering Manager si tu veux manager une √©quipe tout en restant dans la technique ;Staff Engineer si tu veux devenir contributeur(trice) individuel(lle), en apportant ton expertise √† tous les m√©tiers de SFEIR et √† nos clients.Et si tu as d'autres envies, on en discute, chacun(e) est diff√©rent(e) et on fait au cas par cas.üí∞ Combien tu vas gagner chez SFEIR ?A l‚Äôissue des PlayOffs, nos tests techniques, on sera en mesure de d√©terminer tes comp√©tences, et surtout ton potentiel afin de te proposer une r√©mun√©ration adapt√©e.Pour te donner une id√©e, la r√©mun√©ration moyenne au sein de SFEIR Lille pour un(e) Data Engineer confirm√©(e) avec ton exp√©rience d√©marre √† 44 000‚Ç¨ brut par an.Ton salaire sera ensuite revaloris√© chaque ann√©e.Tes comp√©tences, rien que tes comp√©tences !üíª Pr√©sentiel ou t√©l√©-travail ?Les deux, capitaine !La plupart de nos clients sont en mode hybride. Le classique, c‚Äôest 3 jours / 2 jours. üëã La suite des √©v√©nements :Si tu r√©ponds √† cette annonce, un mail arrivera chez Agathe RITOUET, Lisa TOTI, Ga√´lle SPREUX et Khadija YANOURI, les recruteuses de l‚Äôagence de Lille ;L‚Äôune de nous te recontactera sous 2 jours pour un √©change t√©l√©phonique d‚Äôune quinzaine de minutes ;Parce que chacun(e) est unique, un entretien RH te sera propos√© pour comprendre ton parcours et tes envies ;Si tout est ok, on te proposera de passer les PlayOffs. Ce sont nos tests de s√©lection. Tu vas √©changer et faire du pair programming avec 3 sfeiriennes ou sfeiriens en :AlgorithmiqueLangage Python ou SQLConnaissances des outils, et architectures Data.Les √©valuateurs(trices) pourront aussi te donner un aper√ßu de la culture d‚Äôentreprise et de la vie chez nous !Tu pourras aussi discuter avec l‚Äô√©quipe commerciale qui te pr√©sentera nos clients et projets.On revient vers toi au max 2 jours apr√®s les PlayOffs pour te d√©briefer, et :soit, on te dit sur quels aspects tu peux encore progresser et on te donne des billes pour que tu puisses grandir (et pourquoi pas revenir vers nous plus tard);soit, Nicolas Leroy te re√ßoit afin de faire ta connaissance, partager sa vision de SFEIR et te faire une proposition d‚Äôembauche.Si tu as encore des questions, contacte-nous sur LinkedIn !Chez Sfeir, la confiance, la bonne humeur et l'inclusion font partie de notre ADN.#L‚ÄôinclusionEstUneForce: Notre process de recrutement inclusif assure une √©galit√© de traitement et de chance aux candidats de tous horizons.Sinon, clique sur Postuler ‚úåÔ∏è


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': ['Linux'], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data engineer,KION Group,"Marne-la-Vall√©e, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-at-kion-group-3697456771?refId=yd0CzZ499XSkzxQ7HUR3wg%3D%3D&trackingId=YmYFoi8zGgBKW1%2Bfn%2B6KbA%3D%3D&position=25&pageNum=9&trk=public_jobs_jserp-result_search-card,"For more than 100 years, STILL has been providing tailor-made intralogistics solutions worldwide. Joining us is an opportunity to evolve in a stimulating environment, where professionalism and rigor rhyme with friendliness and cooperation. Reference of technological innovation and pioneer of the electric trolley, it is together that we provide ever more efficient solutions, which perfectly meet the challenges of our customers.Want to play a key role in the ever-changing material handling industry?The STILL team is waiting for you!What we offer:As a Data Engineer ""princing and production"", what is our objective ?To extract and analyse data from the various IT systems in order to successfully implement new pricing strategies and processes.Working with technologies like SAP, SAP Business Warehouse, Power BI, AzureTranslate pricing and sales planning demands into technical requirements, architecture concepts and interface definitionsFind clever, automated and intelligent solutions and implement those in an independent mannerCreate advanced reports and analysis with Power BIDevelop scalable and robust data pipelinesData and analysis support in pricing and sales planning related projectsTasks and Qualifications:University degree with a focus on data analytics or a comparable qualificationPractical experience in dealing with mass dataExperience with SAP and SAP Business WarehouseExperience in a manufacturing companyStrong analytical and conceptual skillsGoal-oriented communication to describe problems and complex issuesLanguage skills English (B2)


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer (AWS),Accor,"Issy-les-Moulineaux, √éle-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-aws-at-accor-3798445083?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=np7W4vwLGgaPc2t%2BEZf2BA%3D%3D&position=1&pageNum=10&trk=public_jobs_jserp-result_search-card,"Bienvenue chez ACCOR, groupe h√¥telier, leader dans le secteur de l‚Äôhospitalit√©. Nous sommes un √©cosyst√®me de 40 marques dans 110 pays, de talents et de solutions, pr√™ts √† s'engager dans les possibilit√©s infinies de l'avenir. Accor vous propose une nouvelle fa√ßon de vivre, de travailler, de vous divertir et de d√©velopper votre activit√© professionnelle gr√¢ce √† une exp√©rience client personnalis√©e. Groupe engag√©, nous veillons plus que jamais √† √©voluer dans le respect de notre patrimoine commun. D√©couvrez notre culture, nos valeurs et nos ambitions sur https://group.accor.com/ DescriptionLa Digital Business Factory a pour objectif de proposer des produits et des services digitaux diff√©renciants de premier plan, tant aux clients qu‚Äôaux propri√©taires de nos h√¥tels, afin d‚Äôacc√©l√©rer la transformation du mod√®le d‚Äôex√©cution, de favoriser les m√©thodes de travail agiles, et de renforcer le programme d‚Äôinnovation en misant sur les capacit√©s technologiques. Notre organisation est compos√©e de +600 talents (internes et externes) aux expertises product management, tech et data.  Domaine : Data  En 2021, Accor a regroup√© au sein de la ""Digital Factory"" ses diff√©rentes √©quipes Data sous la responsabilit√© unique d'un Chief Data Officer. Notre mission premi√®re est de fournir √† l'ensemble de l'entreprise - des Hotels √† la Direction, en passant par les diff√©rents M√©tiers - des produits Data et Analytics servant de multiples usages. Avec un fort red√©marrage post-COVID, nous sommes en pleine modernisation (passage au Cloud massif) et transformation/mise √† l‚Äô√©chelle - env. 150 pers aujourd‚Äôhui organis√©es en Tribu/Squad & Chapter inspir√© du mod√®le Spotify - et accompagnons les √©quipes pour inscrire cette double culture ""Tech"" & ""Produit"" dans la dur√©e. La richesse de cet √©cosyst√®me, l'esprit d'innovation et le sens du ""service"" caract√©ristique √† la culture hotelli√®re d'Accor sont les forces qui nous motivent au quotidien.  Aper√ßu du poste : Au sein de la Tribe Data Platform dans le d√©partement Data Engineering, nous recrutons des Cloud Data Platform Engineer pour renforcer les √©quipes en charge de cr√©er et maintenir les briques et services technologiques qui composant notre plateforme Accor ¬´ Welcome Data ¬ª.  Vous participez √† la d√©finition, conception, d√©veloppement et maintenance des produits qui composent l‚Äôoffre de Service en accord avec la vision d‚Äôarchitecture du d√©partement DATA. Au quotidien, vous int√©grez une Feature Team compos√©e d'une dizaine de personnes maximum aux profils vari√©s (PO, Cloud Data Engineer, QA, FlyingOps, Scrum Master), sous la supervision directe du ""Tech Lead"".  Missions et responsabilit√©s : Au quotidien, vos missions au sein de la Feature Team sont : D√©velopper les produits et services de la plateforme DATA utilis√©s par les √©quipes de Data Engineer d‚ÄôAccor Travailler en √©quipe √† l‚Äô√©laboration et d√©finitions des fonctionnalit√©s produits Assurer la conformit√©, la maintenabilit√© et la qualit√© du code (TDD, Sonar, etc.) D√©tecter, analyser et r√©soudre les incidents ou anomalies survenant sur les produits de l'√©quipe. (Build it / run it) Contribuer aux chantiers transverses (usine logicielle-CI/CD, supervision, catalogue, etc.). Participer activement √† la vie de la feature team rythm√©e par les c√©r√©monies agiles. Assurer la coh√©rence des services propos√©s Respecter et promouvoir les patterns de d√©veloppement. Participer √† l'animation de la communaut√© ""Data Tech"" (diffusion bonnes pratiques, capitalisation code, veille techno, etc.) QualificationsProfil recherch√© Dipl√¥m√©(e) en informatique, analyse de donn√©es & Big Data, MIAGE, conseils aux entreprises, ou √©quivalent. Au moins 3 ann√©es d‚Äôanciennet√© en lien avec les domaines de la Data et le Cloud. Comp√©tences Data & Cloud requises : Indispensable : DevOps sur AWS : infra as code avec terraform, CDK principalement sur composants ¬´ serverless ¬ª (Lambda, DynamoDB, SQS) Backend: Python, Java, Typescript Gitlab SQL Souhaitable : Splunk (SPL) Node js, docker Front end : React JSSnowflake  Comp√©tences g√©n√©rales attendues : Culture de la s√©curit√© en mode ¬´ least access policy ¬ª Culture du FINOPS, obsession de l‚Äôoptimisation des couts Culture & techniques DevOps Connaissances et mise en ≈ìuvre des m√©thodologies Agile : Scrum & Kanban Collaboration et travail en √©quipe Bonne communication orale et √©crite Autonomie et proactivit√© Gestion des priorit√©s, risques et alertes Anglais op√©rationnel requis.  Mindset recherch√© : Encourage la transparence, un climat de confiance : travail & revue entre pairs. Culture du feedback, droit √† l‚Äôerreur. √ätre force de proposition, recherch√© l‚Äôam√©lioration continue. Curiosit√© (veille techno, etc.) et innovation  Additional informationPourquoi travailler chez Accor ? Nous sommes bien plus qu‚Äôun leader mondial. Nous vous accueillons comme vous √™tes et vous pouvez trouver le m√©tier et la marque qui correspond √† votre personnalit√©. Faites ce que vous aimez, prenez soin du monde qui vous entoure, osez challenger le status quo ! #BELIMITLESS D√©couvrez la vie qui vous attend chez Accor, https://careers.accor.com/.  Quels avantages Accor offre √† ses collaborateurs ? Accor et plus particuli√®rement la DIGITAL FACTORY propose une exp√©rience de travail unique √† ses collaborateurs o√π l‚Äôexcellence rime avec bienveillance : T√©l√©travail √©tendu : pr√©sence sur site de minimum 4 jours /mois en fonction des rituels d'√©quipes. Prise en charge d‚Äôun forfait d‚Äô√©quipement et Indemnit√©s journali√®res offertes. Am√©lioration continue : hackathons, partenariats technologiques d‚Äôexception, plateforme d√©di√©e √† la formation Digitech Academy & certifications, programme de formation pour l‚Äôensemble de nos salari√©s √† l‚Äôagilit√©, √† la culture OKR, formations d√©di√©es Product Management, AWS.  Les avantages collaborateurs Accor c‚Äôest aussi : un v√©ritable √©quilibre de vie : Work Everywhere : acc√®s personnel offert √† plus de 500 espaces de Coworking dont beaucoup au sein de nos h√¥tels. Une opportunit√© √©galement de partir √† la rencontre de nos collaborateurs h√¥teliers ! Programme ALL Heartists : avantages, s√©jours et exp√©riences inoubliables dans toutes nos adresses Accor, dans le monde entier. Plus de 70 partenaires r√©partis selon diff√©rents univers (Voyages, Gourmet, Bien-√™tre et Sport, etc.) pour satisfaire toutes vos envies. Et sur notre site d‚ÄôIssy les Moulineaux : caf√© √† volont√©, restaurant d‚Äôentreprise avec des prestations gourmandes et de qualit√©, salle de fitness, conciergerie d‚Äôentreprise.  des avantages financiers attractifs : Une participation Groupe et un int√©ressement, avec abondements de l‚Äôentreprise si versements dans PEEG/PERCOL, Un Forfait Mobilit√© durable de 700‚Ç¨/an maximum vers√© aux collaborateurs utilisant des moyens de d√©placements verts, une prise en charge du pass NAVIGO √† hauteur de 75%, Un CSE qui vous accompagne dans le financement de vos activit√©s : Culture, vacances, sport, No√´l, √©v√©nements familiaux‚Ä¶  Sans oublier, l‚Äôaccompagnement tout au long de votre carri√®re au sein du Groupe : Learning & development : un Talent management au c≈ìur de notre strat√©gie RH & un catalogue de formation d‚Äôexcellence, ouvrant de nombreuses perspectives de mobilit√©s intra fili√®res et internationales Un programme de cooptation de 1500‚Ç¨ bruts, pour r√©compenser votre participation aux recrutements de profils qualifi√©s.   Nous sommes engag√©s pour la Diversit√© & l‚ÄôInclusion : ¬´ La diversit√© & l‚ÄôInclusion pour Accor, c‚Äôest accueillir chacun et chacune dans le respect de ses diff√©rences en donnant la priorit√© aux seules qualit√©s et comp√©tences. Notre ambition est de d√©velopper l‚Äôemploi, mieux accueillir, offrir d‚Äôexcellentes conditions de travail et favoriser l‚Äô√©volution de l‚Äôensemble des collaborateurs et notamment des personnes en situation de handicap. N‚Äôh√©sitez pas √† nous faire part de vos √©ventuels besoins sp√©cifiques afin que nous puissions les prendre en consid√©ration. ¬ª


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Ing√©nieur / Engineer,EPIGONE,"√éle-de-France, France",https://fr.linkedin.com/jobs/view/data-ing%C3%A9nieur-engineer-at-epigone-3802056482?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=EqGcKlKUsjYJdWRAm3GFdg%3D%3D&position=2&pageNum=10&trk=public_jobs_jserp-result_search-card,"√Ä propos d'Epigone :Epigone est une entreprise sp√©cialis√©e dans le conseil, se concentrant principalement sur les secteurs de l'assurance, de la banque et de la finance. Fond√©e par un actuaire en 1999, l'entreprise b√©n√©ficie de plus de 20 ans d'exp√©rience dans ces domaines sp√©cifiques.Chiffres cl√©s :50 collaborateurs5 millions de chiffre d'affaires2019 int√©gration au groupe MoOngy (8 000 collaborateurs)Domaines d'intervention :Epigone intervient √† travers quatre principaux p√¥les m√©tiers pour r√©pondre aux besoins vari√©s de ses clients :Op√©rationnel M√©tierMa√Ætrise d'Ouvrage (MOA)Ma√Ætrise d'≈íuvre (MOE)ProgicielProfil Souhait√© :‚úì Dipl√¥m√©(e) d'une √©cole d'ing√©nieurs ou √©quivalent Bac +5‚úì Bonne ma√Ætrise de l'anglais‚úì Une exp√©rience sup√©rieur √† 4 ans r√©ussie (si possible en banque / finance / assurance)‚úì Ma√Ætrise de Databricks‚úì Ma√Ætrise PySparkVous √™tes motiv√©(e) et avez envie de monter en comp√©tences ? Postulez ! On vous attend !


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Session Juin 2024 H/F,Fitec Formation,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-session-juin-2024-h-f-at-fitec-formation-3805573776?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=s%2FG7MDk7XfrhPVvuCNKV7g%3D%3D&position=3&pageNum=10&trk=public_jobs_jserp-result_search-card,"Fitec, organisme de formation d√©di√© √† la reconversion et l'√©volution professionnelle des actifs dans les m√©tiers du num√©rique, vous propose formation + CDI avant m√™me de d√©buter une formation.Comment √ßa marcheFitec vous met en relation avec les principaux employeurs sur les m√©tiers du digital. D√®s qu'un match avec une entreprise fonctionne, cette derni√®re vous fera une proposition d'embauche conditionn√©e par le fait de suivre une formation.A l'issue de la formation, vous serez capable de : D√©finir et piloter le choix et la mise en place d'une solution informatique adapt√©e √† une organisation G√©rer et optimiser des bases de donn√©es pour de grandes √©chelles.  Impl√©menter des pipelines de donn√©es efficaces.  Assurer la s√©curit√© et la conformit√© des syst√®mes de donn√©es.  Travailler avec des technologies de cloud computing.  Collaborer avec des √©quipes pour int√©grer des solutions de donn√©esLa formation d√©marrera le 19 juin et se terminera le 20 septembre 2024 √ätre titulaire d'une certification professionnelle ou d'un dipl√¥me de niveau 6 (bac+3) dans le domaine du management de projets, de l'informatique ou du d√©veloppement et justifiant d'au moins une ann√©e d'exp√©rience professionnelle dans ce secteur.  ou √™tre titulaire d'une certification professionnelle ou d'un dipl√¥me de niveau 5 (bac+2) dans le domaine du management de projets, de l'informatique ou du d√©veloppement et justifiant d'au moins trois ans d'exp√©rience professionnelle dans ce secteur.  Rigoureux, cr√©atif, vous avez un sens aigu du service client, √ätre mobile, dynamique et capable de vous adapter rapidement, Avoir des comp√©tences dans le domaine de l'analyse de donn√©es (R, Matlab...), la mod√©lisation et/ou le d√©veloppement (Java, Python, C++, JavaScript, HTML...). 19162255-55584


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R', 'MATLAB'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer,Understanding Recruitment,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-at-understanding-recruitment-3798350920?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=ghbMo9qNi9llcTYcMX4gNA%3D%3D&position=4&pageNum=10&trk=public_jobs_jserp-result_search-card,"Software Engineer - Elixir üöÄ Tech: Elixir, Phoenix, Terraform, AWSü§ù Healthtechüí∑ ‚Ç¨50,000 - ‚Ç¨70,000 + Benefits including a 10% bonusüìç Paris - ideally you'll go into the office 2 days a week but they will look at every 2 weeksüìà Company Size ‚Äì 40‚úÖ Interview process: 4 stages ‚Äì Intro chat with Talent Team, Chat with CTO, Technical Interview then final with CEOWhy apply? You'll join a Series A funded SaaS health tech that partners with leading clinical organisations.You‚Äôll build the next generation of their products that offer real-time assistance to their partners.Reporting directly to the CTO you'll design products using Elixir & Phoenix, pushing to AWS.They are hiring multiple engineers due to growth You‚Äôll have: üëç Experience writing high quality code, ideally with Elixir or at least want to learn itüëç Experience creating distributed system architectureüëç Experience building concurrent, real-time systemsApply or drop me a DM for more infoüì±Mobile: +44 (0) 7791 141 227üìßEmail: agillard@understandingrecruitment.co.uküìÜBook a call: https://calendly.com/agillardUnderstanding Recruitment is passionate about equity, diversity and inclusion.We seek individuals from the widest talent pool and encourage underrepresented talent to apply for vacancies with us.We are committed to recruitment processes that are fair for all, regardless of background and personal characteristics.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst - FRANCE (H/F),Capgemini Engineering,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-france-h-f-at-capgemini-engineering-3806453709?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=h0seOluE%2Fw6jAc4LhMsOww%3D%3D&position=5&pageNum=10&trk=public_jobs_jserp-result_search-card,"CAPGEMINICapgemini, qu'est-ce que cela √©voque pour vous ? Pour nous, c'est une success story √† la fran√ßaise ! Celle d'une startup devenue une r√©f√©rence mondiale en mati√®re de conseil et de services informatiques.Leader de la convergence des mondes physique et virtuel, nous agissons en partenaire de nos clients industriels pour concevoir, mettre en ≈ìuvre, s√©curiser et d√©manteler des produits et infrastructures complexes. Nous participons √† la transformation et √† l‚Äôoptimisation des entreprises de demain.Capgemini Engineering est la marque du groupe Capgemini r√©unissant les services d‚Äôing√©nierie et de R&D. On accompagne la convergence des mondes physique et num√©rique. Conjugu√©e avec l‚Äôensemble des capacit√©s du Groupe, elle aide les entreprises √† acc√©l√©rer leur transformation vers l‚ÄôIntelligent Industry. Capgemini Engineering compte plus de 52 000 ing√©nieurs et scientifiques dans plus de 30 pays, dans des secteurs tels que l‚Äôa√©ronautique, l‚Äôautomobile, le ferroviaire, les communications, l‚Äô√©nergie, les sciences de la vie, les semi-conducteurs, les logiciels et l‚ÄôInternet, le spatial et la d√©fense, et les biens de consommation.VOTRE MISSIONVous √™tes passionn√©(e) par le domaine de la Data et vous souhaitez prendre part √† un projet d‚Äôenvergure dans le secteur des telecom ? Rejoignez notre √©quipe Digital Engineering de Capgemini Engineering, en tant que Data Analyst. Vous √™tes responsable de :Comprendre le besoin m√©tier, √©valuer les charges et concevoir les solutions techniques et fonctionnellesR√©diger le cahier des charges et d√©crire sous forme de sp√©cificationsAssurer le lien entre le besoin m√©tier et les possibilit√©s fonctionnelles et informatiquesFournir aux √©quipes techniques les documents projetsEcrire les cahiers de recette applicativeAssurer la coordination et le suivi de la recette fonctionnelle avec les experts m√©tiersFormer et assurer le support aux experts m√©tiers dans l‚Äôutilisation des outilsCE QUE NOUS RECHERCHONSVous √™tes Ing√©nieur(e) ou titulaire d'un dipl√¥me √©quivalent de niveau bac+5 en informatique sp√©cialis√© en business intelligence. Id√©alement vous justifiez d‚Äôune exp√©rience r√©ussie dans le d√©veloppement / int√©gration de solutions BI (Minimum 2 ans).Vous ma√Ætrisez Power BI, le langage SQL, le requ√™tage de donn√©es. La connaissance d‚Äôun ETL est un r√©el plus.Enfin, vous avez le sens des priorit√©s, vous √™tes reconnu(e) pour votre capacit√© √† cr√©er du lien avec les √©quipes techniques et les √©quipes m√©tiers.Vous avez √©galement la capacit√© √† vous int√©grer dans des projets et des √©quipes existantes dans un contexte de transformation.Vous vous reconnaissez dans la description du profil et vous souhaitez en savoir plus ? Postulez d√®s maintenant !Alors, rejoignez Capgemini et choisissez le futur qui vous ressemble ! CAPGEMINI, entreprise handi accueillante, conform√©ment √† la norme AFNOR NF X50-783, est √©galement signataire de la charte de la diversit√© en entreprise


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer (Graduated) (H/F),Alstom,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-graduated-h-f-at-alstom-3735951792?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=00Bz99ep0jE2DxetwnYPqg%3D%3D&position=6&pageNum=10&trk=public_jobs_jserp-result_search-card,"POURQUOI REJOINDRE L'AVENTURE ALSTOM ? √Ä la t√™te des entreprises qui s‚Äôengagent vers un avenir plus vert, Alstom d√©veloppe et commercialise des solutions de mobilit√© qui apportent les fondements durables pour l'avenir des transports. Notre portefeuille de produits s'√©tend des trains √† grande vitesse, m√©tros, monorails et tramways jusqu‚Äôaux syst√®mes int√©gr√©s, services sur mesure, infrastructures, signalisation et solutions de mobilit√© num√©rique. Nous rejoindre, c'est rejoindre une entreprise bienveillante, responsable et innovante o√π plus de 70 000 personnes ouvrent la voie √† une mobilit√© plus verte et plus intelligente, dans le monde entier.Au sein de notre activit√© signalisation nous concevons les nouvelles solutions intelligentes permettant l‚Äôexploitation des r√©seaux de transports ferroviaires.Nos m√©tiers en innovation, informatique, cybers√©curit√©, √©lectronique et en t√©l√©communications construisent l‚Äôintelligence des trains de demain afin de r√©pondre aux besoins de mobilit√© plus durable.Nous recherchons des personnes curieuses dot√©es d‚Äôun esprit novateurs et qui ont √† c≈ìur de r√©inventer la mobilit√© en la rendant plus intelligente et plus durable.Localis√©e √† Saint-Ouen-sur-Seine, centre d‚Äôexcellence mondial, plus de 1000 collaborateurs vous y attendent. CE QUE NOUS POUVONS REALISER ENSEMBLE : Dans le cadre de notre activit√© Alstom Digital & Integrated Systems, le Centre de D√©veloppement de Saint-Ouen est en charge de concevoir les principales Solutions de Signalisation CBTC Urbaines d'Alstom : Urbalis 400, Syst√®me d√©ploy√© sur plus de 100 projets dans le Monde, et Urbalis Fluence, notre dernier et plus innovant Syst√®me de Signalisation urbain.Rattach√©(e) au Software Leader au sein du Service Design Logiciel PA (Pilote automatique), vous intervenez en tant que Software Designer au sein d‚Äôune √©quipe de d√©veloppement.Votre r√¥le est de :   D√©velopper des fonctionnalit√©s dans la descente du cycle en V logiciel selon le process issu de la Cenelec 50128-2011  Participer √† l‚Äôanalyse des besoins du client interne pour collaborer √† l‚Äô√©laboration de la sp√©cification syst√®me, prenant en compte les contraintes de d√©finition du produit (plateforme, niveau de s√©curit√©, testabilit√©, ressources) et de process, en utilisant vos comp√©tences en signalisation ferroviaire  Elaborer les sp√©cifications logicielles correspondantes, en vue de leur d√©veloppement dans le respect du process en vigueur, prenant en compte les contraintes d‚Äôarchitecture, de performance, de s√©curit√©, de qualit√©, de co√ªts, de testabilit√©, et de maintenabilit√©. Assurer leur impl√©mentation incluant le codage (en Ada95 ou en C selon le cas), et des tests designers associ√©s  Contribuer aux actions d‚Äôam√©lioration continue du m√©tier  QUEL EST VOTRE PROFIL ?  De formation minimum Bac 5, ing√©nieur ou dipl√¥me universitaire en G√©nie Logiciel, vous avez une premi√®re exp√©rience dans un contexte similaire sur des probl√©matiques de sp√©cification/conception de syst√®mes embarqu√©s √† forte contrainte s√©curitaire.  Vous avez des comp√©tences en programmation temps r√©el, et avez id√©alement d√©j√† d√©velopp√© des applications dans le domaine de la signalisation ferroviaire dans le respect des normes de la CENELEC 50128. Une exp√©rience en programmation Ada95 et l‚Äôutilisation de la m√©thode B seraient appr√©ci√©es.  Vous √™tes int√©ress√©(e) par le domaine des transports ferroviaires et vous √™tes motiv√©(e) pour d√©montrer votre capacit√© √† innover et travailler dans un contexte international. Forte sensibilit√© technique, rigueur, efficacit√© op√©rationnelle, esprit d‚Äô√©quipe, aisance relationnelle et sens de l‚Äôinitiative sont vos atouts pour r√©ussir dans ce poste.  Anglais indispensable.  Localisation : Vous serez bas√© dans nos locaux √† Saint-OuenRejoindre Alstom vous permettra de d√©velopper votre carri√®re dans un environnement de travail diversifi√© et international.Vous contribuerez au succ√®s d'un acteur mondial incontournable qui se positionne √† la pointe de l'innovation et des modes de transports durables pour ses clients et les voyageurs. Notre culture d'entreprise est fond√©e sur l'innovation, la diversit√©, l'entrepreneuriat, la responsabilit√© sociale et l'√©thique. Nous partageons des valeurs communes: l'esprit d'√©quipe, la confiance et le sens de l'action. Les perspectives d'√©volution qu'offre Alstom en France et √† l'international vous donneront l'opportunit√© d'√™tre acteur de votre carri√®re professionnelle et de contribuer directement au d√©veloppement de la mobilit√© durable dans le monde.Alstom garantit l'√©galit√© des chances et s'engage en tant qu‚Äôemployeur √† cr√©er un environnement de travail inclusif o√π tous sont encourag√©s √† atteindre leur plein potentiel, et o√π les diff√©rences individuelles sont valoris√©es et respect√©es. Tous les candidats qualifi√©s sont consid√©r√©s dans nos processus de recrutement sans tenir compte de l‚Äôorigine, de la couleur de peau, de la religion, du sexe, de l'orientation sexuelle, de l'identit√© de genre, de l'√¢ge, de la nationalit√©, de la nature du handicap ou de toute autre caract√©ristique prot√©g√©e par la loi locale
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Analytics Data engineer - internship,Equativ,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/analytics-data-engineer-internship-at-equativ-3798660173?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=sHSgNkrxaOhRoT4wfKK2Pg%3D%3D&position=7&pageNum=10&trk=public_jobs_jserp-result_search-card,"Your missionHelping the company be fully data-driven is not just a buzzword, it is our mission at Equativ. We, the Data Analytics team at Equativ, maximize efficiency by enabling easy and permanent access to quality data, valuable insights & rigorous thinking. Our responsibility is to ensure our local and central teams, clients and partners, make informed business decisions. To do so, we leverage huge volumes of data (Equativ handles 150Bn Auctions per Day) in a state-of-the-art tech stack (AirFlow, Snowflake, Tableau‚Ä¶) in order to provide actionable insights to all teams at Equativ!What you'll doReporting to the manager of the Analytics team, your mission will be to maintain and upgrade our data pipelineDay-to-day maintenance of our data pipeline: Ensure data pipeline ingestion accuracy in due timeFollow-up on data quality issues raised by internal customersImprovement of sourcing processes:Migrate from Talend data flows to Python scripts for our sourcing jobsDevelop resources to make Data Analysts autonomous in sourcing data in our Snowflake database (through ready-to-use scripts or small interfaces)Developing new projects on our main platforms (Tableau & Snowflake)Leverage new resources to make the most out of Snowflake (Streamlit, Snowpark‚Ä¶)Identify new ways to structure our data sources in Tableau while reducing the loading time for the userParticipate in the restructuring of our data marts (schemas, stages & permissions)Communication:Sync with Data Analysts to make sure that their requests are properly prioritizedSynchronize with other technical teams (Core-Data, Infra) to gather requirements of the migration and ensure a smooth transitionUnderstand business needs to suggest the most efficient technical solution. About youPragmatic & hands-on mindset is required: you‚Äôll have latitude to explore different options, but you need to go for the most effective solutionTechnical knowledge of Python & SQL is a mustKnowledge of collaboration platforms (Gitlab) & Agile processes is a plus.You can demonstrate your ability to solve problems end to endYou are fluent in Englishüëã About usEquativ is the new single name for Smart Adserver, DynAdmic, LiquidM and Nowtilus ‚Äî four proven innovators in advertising technology. The vertically integrated company provides brand and privacy-safe solutions that empower its clients to achieve maximum impact while respecting the rights of consumers. The union combines client expertise and engineering excellence to serve the interests of both the supply- side and demand-side with equal professionalism and technical sophistication.Headquartered in Paris and New York, Equativ operates globally with a team of more than 550 people in 20 offices. Equativ offers the market its own independent ad server, SSP, buyer tools, and media services to fulfill the promise of advertising technology. Learn more at Equativ.com.The company is ranked on the Deloitte Technology Fast 500 EMEA and in the Financial Times‚Äô FT 1000: Europe‚Äôs Fastest-Growing Companies.Equativ (formerly Smart AdServer) has been awarded the HappyIndex@Work label and is proud to be among the best companies in the ChooseMyCompany ranking, recognized for its flexible working environment.Come and lead the charge with us in building a transparent ecosystem based on quality!Equativ is an equal opportunity employer. Equal access to employment, services, and programs are available to everyone, regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity, or Veteran status. If you require reasonable accommodation throughout the application and/or interview process, please contact the recruitment team at ta-team@equativ.com
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Junior Data Engineer,Constellium,"Voreppe, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/junior-data-engineer-at-constellium-3791294675?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=k7MlASqYOj4SJMhxYhO10Q%3D%3D&position=8&pageNum=10&trk=public_jobs_jserp-result_search-card,"C  -TEC RECRUTE  Junior Data Engineer (all genders) Constellium is a world leader in the development and manufacture of high value-added aluminium products and solutions for a wide range of markets and applications, focusing in particular on aerospace, automotive and packaging. Constellium also has nearly 12,000 employees worldwide.We are committed to minimizing the environmental impact of our operations and improving the life cycle footprint of aluminium throughout the value chain. In our company, safety is essential, it is one of our core values without compromise. Our Research and Technology Center, C-TEC Constellium Technology Center, based in Grenoble (Voreppe - 38), employs about 240 people.By joining our company, you will discover a multicultural company (more than 18 nationalities) which is committed to diversity and the well-being of its employees. You will also discover an R&D center rich by its expertise and by the benevolence of its employees.The Digital core team is deploying Industry 4.0 technologies everywhere in the group to create our future world-class manufacturing processes. In the context of a replacement, C-TEC is hiring a Junior Data Engineer.  Responsibilities: In the frame of our global digital strategy, the focus of this role is to set data solutions to bring value for our business.The job holder will have to: Design, build and maintain data flows  Manage SQL databases and support users on data access  Design and grow our data repository on the cloud  Watch, benchmark, test and implement solutions around data on Azure  Help our plants to structure and process their data  Support our developers on data transfer and modeling  Run basic data analysis and support data scientists on model industrialization The job holder will need good communication skills to share his results and achievements to non-IT / data specialists.Contribute to C-TEC's zero accident policy by enforcing all EHS rules, writing GTPs (General Work Permits) when necessary, conducting safety visits, reporting any accidents or near accidents and being mindful of the safety of others. Profile : A masters-level qualification in computer science linked to data management.A first experience in a data engineer position with achievements regarding the following fields: SQL / data modeling  Coding in Python  Software architecture  ETL (ideally Azure Data Factory)  Data Architecture / Datalake organization  Knowledge of Azure Cloud environment and GitHub would be a plus, but is not mandatory The ideal candidate will have: Strong interest in data and manufacturing topics.  Proven ability to learn and deliver.  Willingness to interact with various profiles (including non-IT).  Curiosity to evaluate innovative technologies from the digital world. Professional Working Proficiency in written and spoken in English and French are required to interact with team members and other plants. Job requirements: The position implies business trips to plants in Europe and in the USA. We offer:  Attractive Salary  Profit-sharing  Bonus  Annual working days system, with work time reduction  Staff canteen  Important benefits from the work council  Remote work


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - H/F - CDI,Polyconseil,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-cdi-at-polyconseil-3583593428?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=jCX%2FQjnp5rkfm2D7cXEGhA%3D%3D&position=9&pageNum=10&trk=public_jobs_jserp-result_search-card,"Expert de la transformation num√©rique depuis 1989, Polyconseil poss√®de un positionnement atypique, alliant expertise en conseil et r√©alisation de produits digitaux. Nos √©quipes s'int√®grent sur toute de la cha√Æne de valeur, afin d‚Äôavoir une vue d‚Äôensemble d‚Äôun projet et d‚Äôen ma√Ætriser chaque √©tape : cadrage des besoins, pr√©conisations, conception, d√©veloppement et d√©ploiement de solutions innovantes et complexes.Nous accompagnons aussi bien des grands comptes, que des institutions publiques ou des start-ups, dans des secteurs vari√©s tels que : M√©dias, Assurance, Mobilit√©, A√©rospatial, √âcologie, etc.Nous intervenons sur des projets √† forte valeur ajout√©e et apportons un accompagnement sur-mesure √† nos clients, en constituant des √©quipes multidisciplinaires de D√©veloppeur(se)s, Product Managers, Digital Consultant(e)s, UI / UX Designers, Data Scientists et InfraOps.Polyconseil est fond√© sur des valeurs d‚Äôexcellence, de bienveillance et d‚Äôentraide favorisant la responsabilisation et la mont√©e en comp√©tence graduelle de tous nos collaborateurs.Pourquoi rejoindre Polyconseil ?Vous intervenez sur des missions √† impact et voyez le r√©sultat de vos actionsVous √™tes responsabilis√©(e) et √©voluez dans un environnement propice √† l‚Äôapprentissage et √† la progression, au contact de talents qui se tirent vers le hautVous travaillez dans une ambiance √† la fois d√©tendue et stimulante, pr√¥nant esprit d‚Äô√©quipe et prise d‚ÄôinitiativesVous profitez d‚Äôune vie interne riche en √©v√©nements (sportifs, culturels, culinaires‚Ä¶)Votre √©quilibre vie pro / vie perso est respect√© et vous b√©n√©ficiez d‚Äôune politique de t√©l√©travail flexibleVous rejoignez nos locaux r√©cents en plein Paris (Paris 9, m√©tro Grands Boulevards, lignes 8-9)Vous avez acc√®s √† la participation, plan √©pargne entreprise avec abondement, tickets restaurant‚Ä¶Vos missionsInt√©gr√©(e) au sein de l‚Äô√©quipe Data, vous intervenez notamment sur :Le d√©veloppement, d√©ploiement et maintenance de pipelines d‚ÄôETL/ELTLa mise en place d‚ÄôAPIs et de backends applicatifsLa d√©finition et mise en place de mod√®les de donn√©es, administration de base de donn√©esL‚Äôutilisation de plateformes et outils CloudLa compr√©hension et application de principes d‚ÄôarchitectureLa supervision et monitoring d‚ÄôapplicationsEntour√©(e) de nos experts, vous montez rapidement en comp√©tence sur les technologies suivantes : Python, Apache Spark, MongoDB, ElasticSearch, Airflow, et participez au d√©veloppement de nouveaux produits innovants dans le cadre de notre Datalab.En fonction de vos app√©tences, vous aurez √©galement la possibilit√© de vous impliquer sur des sujets transversaux pour accompagner notre croissance : recrutement, r√©ponses aux AOs, organisation d‚Äô√©v√©nements, chantiers internes (RSE‚Ä¶) etc.Principales technologies √† utiliser ou √† d√©couvrirLangages : Python, SQL, DBT, SparkBases de donn√©es : PostgreSQL, base de donn√©es NoSQL (MongoDB, ELK‚Ä¶)Orchestration : Airflow, LuigiDevOps : Git, CI/CD, Docker, Kubernetes/Nomad, Ansible‚Ä¶Outils Cloud : AWS, GCP, Azure, Snowflake, Databricks‚Ä¶Autres : KafkaQuelques Exemples De MissionsD√©veloppement et commercialisation en SaaS d‚Äôun syst√®me de gestion intelligente de la politique de stationnement pour une centaine de villes en FranceSolution d‚Äôoptimisation du pricing des produits vendus via une plateforme de ventes aux ench√®res en ligneD√©veloppement d‚Äôune plateforme de suivi et de pr√©diction des incidents sur un parc ITD√©veloppement from scratch d‚Äôun feature store √† destination des data scientists d‚Äôun acteur de la r√©assuranceAlgorithmes de d√©tection de fraude aupr√®s d‚ÄôassureursConception d‚Äôune plateforme data temps r√©√©l sur AWSVos moyens pour r√©ussirFormation : d√®s votre arriv√©e, vous avez acc√®s √† un large panel de formations et ressources documentaires pour approfondir vos connaissances sur vos sujets de pr√©dilection ou bien d√©couvrir des sujets nouveaux par simple curiosit√©. Nous finan√ßons √©galement des formations AWSManagement op√©rationnel : vous √™tes accompagn√©(e) par un manager de mission et un Talent Manager tout au long de votre parcours chez nousContact constant avec d‚Äôautres m√©tiers / √©quipes au sein de nos locauxVotre profilIssu(e) d'une √©cole d'ing√©nieurs ou d‚Äôune √©cole sp√©cialis√©e en d√©veloppement informatique, vous poss√©dez minimum 2 ann√©es d‚Äôexp√©rience en Data Engineering et ma√Ætrisez Python et SQL. Une exp√©rience ou une formation sp√©cifique (ex : Udemy) avec le calcul distribu√©, le traitement des donn√©es temps r√©el ou les bases de donn√©es NoSQL est un plus. Avoir d√©j√† travaill√© avec un ou plusieurs fournisseurs de cloud (AWS, GCP, Azure notamment) est √©galement appr√©ci√©.Nous recherchons avant tout un fit humain, et de futur(e)s coll√®gues avec qui nous prendrons plaisir √† travailler chaque jour.Alors, Si Comme Nous Vous Poss√©dezUne curiosit√© naturelle pour le monde du num√©rique Un go√ªt pour le challengeUne envie de progresser et d‚Äôapprendre Un esprit d‚Äô√©quipe √† toute √©preuveUne r√©elle volont√© de transmettre vos connaissances et d‚Äôaider les autresUne tr√®s bonne ma√Ætrise de la langue fran√ßaise ‚Ä¶n‚Äôh√©sitez pas √† nous envoyer votre candidature !Polyconseil est une entreprise engag√©e, handi-accueillante et inclusive


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['PostgreSQL', 'Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Ansible', 'Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer - Lyon - H/F,Lincoln France,Greater Lyon Area,https://fr.linkedin.com/jobs/view/data-engineer-lyon-h-f-at-lincoln-3697110169?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=3C2AVv9HeGzv1atgdt9P%2BA%3D%3D&position=10&pageNum=10&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre Lincoln pour mettre en ≈ìuvre des solutions Big Data adapt√©es aux enjeux de nos clients ?Ce que l'on vous proposeRejoindre LINCOLN, c‚Äôest rejoindre un cabinet de conseil reconnu pour son expertise data depuis plus de 30 ans, en proposant des prestations d‚Äôexpertise, de conseil et d‚Äôaccompagnement en Modern BI, Big Data et Science de la donn√©e.Vous progresserez au sein d‚Äôune √©quipe de 380 experts de l‚Äôing√©nierie Vous √©voluerez ainsi dans un environnement technique stimulant et en constante √©volution : architectures distribu√©es ; s√©curisation, configuration et optimisation de plateformes ; gouvernance QoD ; industrialisation de projets data science‚Ä¶Enfin, vous perfectionnerez vos comp√©tences gr√¢ce √† notre Lincoln Academy, v√©ritable institut de formation interne et data-dock√©.Ce que l‚Äôon attend de vousEn int√©grant nos √©quipes de consultants, vous participez √† la mise en ≈ìuvre des solutions Big Data adapt√©es aux enjeux de nos clients.En tant que Data Engineer, vous aurez pour mission :Mettre en place et accompagner au d√©ploiement d‚Äôarchitectures Big DataConcevoir, d√©velopper, superviser et optimiser les flux d‚Äôalimentation de donn√©es √† forte volum√©trieAccompagner techniquement les √©quipes de d√©veloppementSuperviser et diagnostiquer des jobs en productionsVos atouts pour mener √† bien cette mission Des fondamentaux th√©oriques acquis en cursus √©cole d‚Äôing√©nieurs informatique ou universitaire avec une sp√©cialisation data, avec une exp√©rience d‚Äôau minimum 3 ans d‚Äôexp√©rience en d√©veloppement Big Data (les profils juniors ne seront pas contact√©s)Une sensibilit√© √† la m√©thodologie Agile (Definition of ready, definition of done, valeurs SCRUM)Une ma√Ætrise de l‚Äô√©cosyst√®me Hadoop (Hive, Spark,‚Ä¶)Connaissances des environnements Cloud (id√©alement AWS et/ou Azure)La connaissance de Databricks est un v√©ritable plusMa√Ætrise des langages de programmation (Python, Scala, SQL)Compr√©hension des documentations techniques en anglaisLa cerise sur le g√¢teau : dot√©(e) d‚Äôun bon relationnel, vous aimez travailler en √©quipe et √™tes rigoureux. Votre dynamisme et votre curiosit√© vous permettent √©galement d‚Äô√™tre autonome.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Stage (F/H/X),iAdvize,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-stage-f-h-x-at-iadvize-3799307113?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=%2FOj7IZRhjJJ%2FWY1lyU8Olg%3D%3D&position=11&pageNum=10&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseEn associant le meilleur de l‚Äôhumain et l‚Äôintelligence artificielle, la plateforme conversationnelle d‚ÄôiAdvize permet aux marques d‚Äôoffrir √† grande √©chelle, √† leurs clients, une exp√©rience d‚Äôachat en ligne authentique et personnalis√©e.Les consommateurs ont massivement adopt√© le Messaging dans leur vie quotidienne. Ils sont 85% √† vouloir interagir avec une marque comme ils le font avec leurs proches: via messaging. C‚Äôest simple, personnel et engageant.En tant que fournisseur d'une solution compl√®te pour l‚Äôavant-vente et le service client, iAdvize n'a qu'une seule mission depuis sa cr√©ation en 2010 : rendre les marques conversationnelles. Pour offrir cette exp√©rience √† grande √©chelle, nous d√©ployons des copilotes virtuels propuls√©s par l‚ÄôIA, fiables, connect√©s et en parfaite conformit√© :iAdvize Copilot‚Ñ¢ for Shoppers : Boostez les ventes en ligne en 24/7 gr√¢ce √† un assistant √† l‚Äôachat propuls√© par l‚ÄôIA. Levez les freins √† l'achat et augmentez les conversions. iAdvize Copilot‚Ñ¢ for Agents : Augmentez la vitesse, l'efficacit√© et la qualit√© de service de vos conseillers gr√¢ce √† des copilotes propuls√©s par l‚ÄôIA g√©n√©rative de confiance. iAdvize c'est aussi plus de 200 talents pr√©sents √† Nantes (notre si√®ge social), Paris (FR), D√ºsseldorf (DE) et Boston (US) ; Nous sommes fiers d‚Äô√™tre une Great Place to Work et un Laur√©at FrenchTech Next 40 et 120.Le bien √™tre de nos collaborateurs est essentiel pour nous et de nombreuses initiatives sont port√©es chaque ann√©e par nos √©quipes pour que nous puissions tous √©voluer dans un contexte de travail propice √† l'√©panouissement personnel comme professionnel.Convaincus par l'atout majeur que repr√©sente la diversit√© dans nos √©quipes, nous sommes fiers de compter plus de 45% de femmes dans nos effectifs.Nous sommes √©galement convaincus qu‚Äôune croissance durable n‚Äôest r√©alisable qu‚Äôen prenant en compte des objectifs ambitieux d‚Äôun point de vue soci√©tal & environnemental. Nous avons lanc√© depuis 2022 un groupe de travail pluridisciplinaire sur les enjeux RSE, afin de r√©duire nos √©missions carbones, nouer des partenariats responsables et accompagner la transformation conversationnelle du e-commerce vers un mod√®le plus durable.Vous pouvez retrouver plus d'informations et des photos de nos locaux sur notre page Welcome to the jungle.Description du posteL'opportunit√© : Vous rejoindrez l'√©quipe Data au sein du d√©partement Product & Engineering. Vous serez sous la responsabilit√© du Senior Data Engineer et l'aiderez √† concevoir, construire, am√©liorer et maintenir la stack data. Vous aurez l'opportunit√© de participer √† une gamme √©tendue de t√¢ches, allant de la surveillance de l'infrastructure de donn√©es √† la mise en ≈ìuvre de changements critiques, ainsi que de la collecte de donn√©es pour r√©pondre aux d√©fis business. Votre travail implique des actions √† plus long terme ainsi que des interventions op√©rationnelles quotidiennes, vous offrant ainsi une exp√©rience r√©aliste du r√¥le de Data Engineer.Vous collaborez avec des Data Scientists et des Analystes, ainsi qu'avec l'√©quipe Engineering Platform et √©ventuellement avec des parties prenantes commerciales.Vous acquerrez de l'exp√©rience dans un environnement technique riche : Google Big Query, Apache Airflow, Amazon Athena, Elasticsearch, Tableau.Les missions : Surveillance de l'ex√©cution des pipelines de donn√©esContribuer √† la migration des processus ETLImpl√©menter des √©volutions dans la stack d'ing√©nierie des donn√©es (par exemple, automatisations, syst√®mes d'alerte, tra√ßabilit√©, documentation)Contribuer √† la mise √† jour ou √† la configuration de nouveaux pipelines de collecteEffectuer des extractions ad hoc et/ou des corrections BI pour r√©pondre aux besoins urgents de l'entrepriseQualificationsVous avez une exp√©rience en programmation, des comp√©tences en manipulation de donn√©es et des connaissances de base des environnements cloud. Vous √™tes √† l'aise avec la gestion de plusieurs t√¢ches et des d√©lais. Les comp√©tences relationnelles, la motivation et le d√©sir d'am√©lioration personnelle sont fondamentaux pour r√©ussir dans ce r√¥le.Comp√©tences techniquesBonne connaissance de Python (usage g√©n√©ral, avec un accent sur la manipulation de structures de donn√©es)Bonne connaissance de SQLFamiliarit√© avec les environnements Linux et la ligne de commande (CLI)Compr√©hension des processus et de l'orchestration ELT/ETLBonus I : Exp√©rience avec au moins un fournisseur de Cloud majeur (AWS, GCP, Azure, ...)Bonus II : Connaissance d'Airflow, Docker, Terraform, Big QueryBonus III : Connaissance de Tableau ou d'autres outils BIComp√©tences relationnellesBonnes comp√©tences en communication : Vous interagissez avec d'autres r√¥les li√©s √† la Data, ainsi qu'avec des ing√©nieurs et des analystes commerciaux. Vous devrez adapter votre style de communication √† diff√©rents publics. La connaissance de l'anglais et du fran√ßais est obligatoireCapacit√© √† s'adapter aux changements de priorit√©s et √† respecter des d√©lais strictsProactivit√© et ouverture √† assumer des t√¢ches impr√©vues si la situation l'exigeInformations suppl√©mentairesContrat : Stage Lieu de travail : poste √† pourvoir √† Nantes (si√®ge social, proche gare Sud)Date de d√©but : d√®s que possibleCharte de t√©l√©travail en place (3 jours par semaine, possible apr√®s l'onboarding). La soci√©t√© iAdvize est attach√©e √† la diversit√© de ses √©quipes et pratique une stricte politique de non-discrimination au recrutement. Rejoindre iAdvize, c‚Äôest‚Ä¶Participer au d√©veloppement d‚Äôune scale-up fran√ßaise ambitieuse, internationale et dynamique. Rejoindre une promotion de nouveaux, et participer √† un programme d‚Äôonboarding d‚Äôune semaine qui vous formera sur notre produit, notre strat√©gie, notre march√©, nos techniques de ventes. Travailler dans des conditions de travail agiles, o√π vous pourrez √™tre force de proposition pour apporter vos id√©es.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Apache Airflow'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Docker'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
DATA ENGINEER H/F,METEOJOB by CleverConnect,"Olivet, Centre-Val de Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-meteojob-by-cleverconnect-3804853067?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=Cu0b%2BoajFrhUFWO%2BGQb5VA%3D%3D&position=12&pageNum=10&trk=public_jobs_jserp-result_search-card,"EntrepriseAx√©r√©al : un groupe coop√©ratif agricole et agroalimentaire fier de ses racines locales et de son implantation mondiale.Rejoignez le groupe Ax√©r√©al et ses filiales pour prendre part √† notre ambition collective : transformer durablement le mod√®le agricole et alimentaire dans un contexte dynamique et stimulant.Engagez-vous aux c√¥t√©s de 11 000 agriculteurs collectivement associ√©s et de 4 000 collaborateurs dans des projets innovants et ambitieux.Evoluez dans un groupe international - 18 pays - aux activit√©s multiples - Malt, Meunerie et Alimentation animale - et qui r√©alise un chiffre d'affaires de 4,3 milliards d'euros.Rencontrez des managers qui vous feront confiance et vous permettront de vous √©panouir dans un contexte de travail propice √† l'esprit d'initiative et √† l'autonomie.Convaincu ? Alors, apportez votre contribution en candidatant ci-dessous en quelques clics et d√©crochez un poste qui a du sens !Dans le cadre de sa politique diversit√©, Ax√©r√©al √©tudie, √† comp√©tences √©gales, toutes candidatures dont celles de personnes en situation de handicap.Description Du PosteRattach√© √† la Direction Syst√®mes d'Information (DSI), vous int√©grez une √©quipe de 4 personnes. Votre r√¥le, consiste mettre en place la collecte et la mise √† disposition des donn√©es au sein de l'entreprise, √™tre en charge d'industrialiser et mettre en production des traitements sur les donn√©es (par exemple : mise √† disposition de tableaux de bord, int√©gration de mod√®les statistiques) en lien avec les √©quipes m√©tiers et les √©quipes qui les analysent.C'est un r√¥le central et tr√®s important, situ√© au coeur de notre d√©veloppement ! Le Data Engineer est le maillon essentiel pour fournir les donn√©es fiables aux m√©tiers leur permettant de cr√©er leurs nouveaux produits et services.Les missions sont compos√©es des actions suivantes ;Acheminement de la donn√©e ; Recueillir les besoins m√©tiers des diff√©rentes unit√©s demandeuses et utilisatrices de solutions de collecte et stockage de la donn√©e. D√©velopper les solutions techniques de collecte de la donn√©e via des API. D√©velopper des solutions techniques de stockage de la donn√©e (Hadoop). R√©aliser les tests unitaires et d'int√©gration. Mettre en place et maintenir les batchs, c'est-√†-dire les automatisations d'une s√©rie de traitements.Mise √† disposition des donn√©es aux √©quipes utilisatrices ; Industrialiser et automatiser le nettoyage de la donn√©e selon les sp√©cifications retenues. G√©rer, maintenir et documenter de multiples bases de donn√©es (via l'importation de donn√©es externes en open data ou de donn√©es internes par exemple). G√©rer le cycle de vie de la donn√©e conform√©ment aux directives inscrites dans le RGPD. Assurer le suivi de production et la maintenance.Mise en production de mod√®les statistiques dans les applications ; D√©velopper l'industrialisation de mod√®les statistiques ou de machine learning. Impl√©mentation du suivi de la validit√© du mod√®le statistique. Assurer le suivi de production et la maintenance.Suivi des projets de d√©veloppement ; √âtablir les sp√©cifications techniques √† partir de l'analyse des besoins. Reporter l'activit√© aupr√®s du chef de projet. Autres activit√©s √©ventuelles ; Automatiser la cr√©ation de tableaux de bord aux √©quipes m√©tiers (envoi de fichiers via des applications d√©di√©es). Assurer une veille technologique sur les outils big data. √âcrire la documentation relative aux bases de donn√©es (r√®gles de gestion, dictionnaire des variables‚Ä¶).Dans le cadre de sa politique diversit√©, le groupe Ax√©r√©al √©tudie, √† comp√©tences √©gales, toutes candidatures dont celles de personnes en situation de handicap.Description Du ProfilDe formation Bac+5 √©cole d'ing√©nieur orient√© d√©veloppement, ou master sp√©cialis√© en data, avec une sp√©cialisation Big Data, vous √™tes passionn√© par l'innovation et les technologies li√©es aux domaines Data Analytics & AI. Ma√Ætrise de l'environnement technique du cloud provider (GCP ) Ma√Ætrise des bases de donn√©es (BigQuery) Ma√Ætrise de langages de programmation (Java, Python, Spark, Scala, Sql,‚Ä¶) Ma√Ætrise des outils de gestion de flux et de manipulation de donn√©es ETL/ELT (Semarchy DI, Google DataFlow, Dataproc, etc ‚Ä¶) Connaissance des m√©thodes de d√©veloppement agile Ma√Ætrise des syst√®mes d'exploitation (Unix, Windows‚Ä¶)Vous appr√©ciez travailler en √©quipe et poss√©dez un excellent relationnel ? C'est parfait, car le poste n√©cessite de travailler avec des interlocuteurs multiples et demande ainsi une grande adaptabilit√©.Aussi, vos capacit√©s organisationnelles, votre autonomie, votre sens de l'initiative, votre rigueur et votre orientation r√©sultat sont autant d'atouts qui vous permettront d'exceller dans la fonction.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': ['Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer F/H,CGI,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-cgi-3738615749?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=8W9XLa1kaOwFefUF3%2BafjQ%3D%3D&position=13&pageNum=10&trk=public_jobs_jserp-result_search-card,"Description de posteBig Data, Data Science, Data analyse, Data architecture, ... √áa n‚Äôa pas de secret pour vous ?Que vous commenciez votre carri√®re professionnelle ou que vous soyez sp√©cialiste de l‚Äôune de ces disciplines, int√©grer notre communaut√© Data, c‚Äôest l‚Äôassurance de progresser, innover, partager, vous certifier et rendre service √† nos clients.Si vous souhaitez int√©grer nos √©quipes √† Nantes et accompagner les plus grands acteurs de secteurs vari√©s, cette annonce est susceptible de vous int√©resser.Fonctions et responsabilit√©sSous la responsabilit√© d'un Chef de Projet / Scrum Master, vos principales missions sont : Analyser, conseiller, et faire des recommandations de fa√ßon √† am√©liorer l'efficience et l'efficacit√© des solutions techniques mises en place Recueillir les besoins m√©tiers et des √©quipes data Assurer une veille technologique r√©guli√®re Concevoir et mettre en place les traitements de donn√©es Tester et valider les d√©veloppements r√©alis√©s R√©aliser la documentation technique des d√©veloppements r√©alis√©s Participer √† l'√©laboration et la r√©vision de normes / documentation technique dans le cadre du projet D√©velopper ses comp√©tences et connaissances des architectures Data Etre garant de la mise en place, du suivi et de l'exploitation des outils d√©ploy√©sEn rejoignant CGI, vous b√©n√©ficiez notamment d‚Äôune offre compl√®te de formations (techniques, m√©tiers, d√©veloppement personnel,‚Ä¶), de flexibilit√© gr√¢ce √† notre accord t√©l√©travail (jusqu‚Äô√† 3 jours de t√©l√©travail par semaine), d‚Äôune politique de cong√©s avantageuse (27 jours de cong√©s pay√©s, RTT, cong√©s anciennet√© et enfant malade,‚Ä¶) et d‚Äôun package d‚Äôavantages int√©ressant (r√©gime d‚Äôachats d‚Äôactions, participation, CSE,...).Qualit√©s requises pour r√©ussir dans ce r√¥leDe formation Bac +5, vous disposez d'une exp√©rience d'au moins deux ans dans la conception et le d√©veloppement.Vous ma√Ætrisez un ou plusieurs ETL.V√©ritable passionn√©, vous √™tes rigoureux et dot√© d'un bon sens de la collaboration.CGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, √† l‚Äô√©volution de carri√®res des hommes et des femmes et au bien-√™tre de nos salari√©s LGBT+. Dans un souci d‚Äôaccessibilit√© et de clart√©, le point m√©dian n‚Äôest pas utilis√© dans cette annonce. Tous les termes employ√©s se r√©f√®rent aussi bien au genre f√©minin que masculin.Allier savoir et faireAlors que la technologie s‚Äôinscrit au c≈ìur de la transformation num√©rique de nos clients, nous savons que les individus sont au c≈ìur du succ√®s en affaires.Lorsque vous rejoignez CGI, vous devenez un conseiller de confiance, collaborant avec vos coll√®gues et clients pour proposer des id√©es exploitables qui produisent des r√©sultats concrets et durables. Nous appelons nos employ√©s ""membres"" parce qu‚Äôils sont actionnaires et propri√©taires de CGI. Ils ont du plaisir √† travailler et √† grandir ensemble pour b√¢tir une entreprise dont nous sommes fiers. C‚Äôest notre r√™ve depuis 1976. Il nous a men√©s l√† o√π nous sommes aujourd‚Äôhui ‚Äì l‚Äôune des plus importantes entreprises ind√©pendantes de conseil en technologie de l‚Äôinformation (TI) et en management au monde.Chez CGI, nous reconnaissons la richesse que la diversit√© nous apporte. Nous aspirons √† cr√©er une culture √† laquelle nous appartenons tous et collaborons avec nos clients pour cr√©er des communaut√©s plus inclusives. En tant qu‚Äôemployeur qui pr√¥ne l‚Äô√©galit√© des chances pour tous, nous voulons donner √† tous nos membres les moyens de r√©ussir et de s‚Äô√©panouir. Si vous avez besoin d‚Äôun accompagnement sp√©cifique durant le processus de recrutement et d‚Äôint√©gration, veuillez nous en informer. Nous serons heureux de vous aider.Pr√™t √† faire partie d‚Äôune entreprise qui est gage d‚Äôexcellence? Rejoignez CGI ‚Äì o√π vos id√©es et vos actions changent la donne.
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Chef'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst H/F,Inetum,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-inetum-3782175235?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=Qio%2FTBF9SulAe1ZAwsyypQ%3D%3D&position=14&pageNum=10&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre  Informations g√©n√©rales  Entit√© de rattachement  Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste M√©tier M√©tier AS (Application Services) - Technique AS Intitul√© du poste Data Analyst H/F Contrat CDIDescription De La MissionDans le cadre de la croissance de notre agence lilloise, nous d√©veloppons notre Practice Data et recrutons des profils Data de divers horizons Data Analyst, Data Engineer, Data Scientist et Data Gouv. Les besoins m√©tiers de nos clients et la multitude des technologies font qu'il nous faut nous appuyer sur une diversit√© de comp√©tences. Vous pourriez √™tre l‚Äôun d‚Äôeux et rejoindre Inetum.En tant que Data Analyst, vos principales missions consistent √† Analyser et retranscrire le besoin client Identifier, extraire et exploiter les sources d'acquisition de donn√©es les plus pertinentes Valoriser de la donn√©e D√©velopper l'outil de data visualisation pour accompagner les √©quipes m√©tiers dans leurs aides √† la d√©cision √ätre le lien entre les √©quipes m√©tier pour les accompagner dans la mise en ≈ìuvre des nouveaux outils Profil Pour mener √† bien votre r√¥le, il vous faut parler SQL couramment un niveau avanc√© sur Excel et/ou Google Spreadsheet une ma√Ætrise d'un outil d√©cisionnel comme PowerBI, Qlik, Tableau ou encore Google Data StudioVous vous reconnaissez dans ces quelques lignes, alors rencontrons-nous !Notre plus Rejoindre la r√©gion Nord-Est, c‚Äôest b√©n√©ficier des avantages d‚Äôun Grand Groupe tout en gardant la proximit√© r√©gionale. Nous mettrons tout en ≈ìuvre pour vous apporter un √©quilibre vie perso / vie pro. C‚Äôest pourquoi nous vous proposons un rythme hybride (selon les contraintes clients) Une trajectoire de carri√®re personnalis√©e et adapt√©e √† vos souhaits d'√©volution gr√¢ce √† une implantation √† l‚Äôinternational (26 pays, 7 Fablab), des formations cibl√©es et des projets couvrant l‚Äôensemble de la cha√Æne de valeur IT (+25 fili√®res m√©tiers) Int√©grer un collectif d‚Äôexperts partageant des valeurs de solidarit√© et d‚Äôexcellence Int√©grer une entreprise ayant une strat√©gie affirm√©e de certifications de ses collaborateursLocalisation du poste Localisation du poste France, Nord, 59 Nord Ville LilleCrit√®res candidat Niveau d'√©tudes min. requis Bac+5 Niveau d'exp√©rience min. requis Plus de 2 ans
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
SOFTWARE ENGINEER / INGENIEUR INFORMATIQUE (H/F),Akkodis,"Gennevilliers, √éle-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-ingenieur-informatique-h-f-at-akkodis-3788244655?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=z2h75vpEXOiGxnVmBegKWA%3D%3D&position=15&pageNum=10&trk=public_jobs_jserp-result_search-card,"La ligne de service Talent d‚ÄôAkkodis France recrute un SOFTWARE ENGINEER/ING√âNIEUR INFORMATIQUE (H/F) en CDI √† Gennevilliers. Notre client est une entreprise fran√ßaise sp√©cialis√©e dans la conception et la fabrication d'√©quipements de haute technologie.Rattach√©(e) au Responsable Bureau d‚Äô√âtudes Informatique, vous prenez en charge l‚Äôinterface de l‚Äôensemble des composants √©lectroniques d‚Äôun instrument de microanalyse de surface. Un programme qui propose des fonctions de r√©glage et d‚Äôacquisition ainsi qu‚Äôun programme graphique interactif.Vos principales missions :Prendre connaisse du cahier des charges fonctionnel du composant √† d√©velopper, d√©finir l‚Äôergonomie et tests de validation.Analyser les sp√©cifications techniques du composant √† d√©velopper.Concevoir l‚Äôarchitecture logicielle, le d√©coupage en modules, l‚Äôinterface externe, les tests d‚Äôint√©gration du composant.D√©velopper les modules, d√©finir et r√©aliser les tests unitaires.Participer aux tests fonctionnels et √† la validation du composant. Profil recherch√© :Titulaire d‚Äôune formation Bac+4/5 sp√©cialis√©e en informatique industrielle ou m√©catronique / g√©n√©raliste.Vous disposez de 5 √† 7 ans d'exp√©rience dans un poste similaire, secteur de l‚Äôinstrumentation. Id√©alement : connaissance en physique des particules charg√©es.Vous √™tes √† l‚Äôaise avec le syst√®me d‚Äôexploitation Windows.Vos bases en programmation vous permettent de maitriser C/C++ et C#.La programmation d‚ÄôIHM en WPF ne vous est pas inconnu ;Vous comprenez les principes de fonctionnement d‚Äôint√©gration de composants externes (widgets, graphes, images).Vous avez eu l‚Äôoccasion de travailler en programmation temps r√©el (RTOS, VXWORKS, Nucleus ou VRTX) et/ou en programmation LABVIEW.Vous avez de bonnes capacit√©s r√©dactionnelles et un bon esprit de synth√®se,Vous √™tes curieux et vous avez le go√ªt de l‚Äôinnovation.La ma√Ætrise de l‚Äôanglais est indispensable pour ce poste (oral / √©crit).Les d√©placements professionnels sont occasionnels et peuvent repr√©senter 5 % de l‚Äôactivit√©.A propos de nousAkkodis, est un acteur mondial de l‚Äôing√©nierie et de l‚ÄôIT et un leader dans la smart industrie. Nous accompagnons nos clients dans leurs projets de transformation digitale via 4 lignes de service : Consulting, Solutions, Talent et Academy. Akkodis est un partenaire technologique de confiance pour ses clients √† l‚Äô√©chelle internationale. Nous co-cr√©ons et nous imaginons des solutions de pointe pour r√©pondre aux d√©fis majeurs de notre soci√©t√©, qu'il s'agisse d'acc√©l√©rer la transition √©nerg√©tique et de d√©velopper la mobilit√© verte, ou encore de construire des approches centr√©es sur les utilisateurs.Dot√©s d‚Äôune forte culture de l‚Äôinclusion et de la diversit√©, nos 50 000 experts en IT et en ing√©nierie, pr√©sents dans 30 pays, allient les meilleures comp√©tences technologiques √† une connaissance transverse de toutes les industries pour fa√ßonner un futur plus durable. Nous sommes passionn√©s par l‚Äôid√©e d‚Äôinventer ensemble un avenir meilleur.Akkodis Talent est la ligne de service d‚ÄôAkkodis en France qui combine tout le savoir-faire en termes de recrutement du groupe Adecco avec l‚Äôexpertise technologique d‚ÄôAkkodis. Les √©quipes d‚ÄôAkkodis Talent r√©pondent aux enjeux RH de leurs clients en les accompagnant sur leurs projets de recrutement temporaire via l‚Äôint√©rim ou CDD, ou permanents via des recrutements en CDI.Akkodis Talent est une marque du groupe Adecco


        Show more

        


        Show less","{'ProgLanguage': ['C++', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Windows'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),FAB Group,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-fab-group-3796635086?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=C4DLw0FyWeoenFKoPDElrg%3D%3D&position=16&pageNum=10&trk=public_jobs_jserp-result_search-card,"FAB Group (www.fab-group.fr) est un cabinet de conseil en recrutement et management de transition. Notre r√¥le est de trouver les meilleurs talents pour nos clients et les plus belles opportunit√©s professionnelles pour tous les candidats qui nous font confiance.Depuis 2007, nous accompagnons nos partenaires et talents avec une approche bas√©e sur 3 piliers qui ont fait notre r√©putation : sp√©cialisations sectorielles, rigueur et transparence.Nous pla√ßons l'humain au coeur de notre r√©flexion, en veillant √† prendre en compte chaque projet individuellement et en mettant en place de v√©ritables coachings de nos candidats et de nos clients. La construction de liens solides avec chacun d'entre eux est la force de notre cabinet. La disponibilit√© est un √©l√©ment central de notre ADN.Sous la marque FAB IT & Digital, nos √©quipes de sp√©cialistes accompagnent les Directions des Syst√®mes d'Information de tous secteurs d'activit√© dans leurs recrutements (gouvernance, MOA, √©tudes et d√©veloppement, infrastructures, s√©curit√© et digital).Aujourd'hui, nous recherchons pour l'un de nos clients, un acteur du secteur assurantiel, de premier plan, un Data Engineer F/H bas√© √† Paris(75).Vos principales missions seront les suivantes : Administrer les usages SnowFlake et devenir le r√©f√©rent technique de la solution dans le projet de migration sur SnowPark n√©cessitant de bonnes comp√©tences Spark Industrialiser les pipelines et applications (optimisation, supervision,...) Coordination avec les √©quipes projets IT ou m√©tier la mise en exploitation D√©veloppement des automates en script shell Veiller √† la qualit√©, √† la performance, √† la fiabilit√© et l'am√©lioration continue des traitements Data Suivi du RUN, support production, suivi des incidents, gestion des habilitations. Vous avez au moins 3 ans d'exp√©rience dans le domaine du Big Data et si possible avec une exp√©rience d'industrialisation et de supervision de Production:Technologies requises : Snowflake, Spark HadoopTechnologies souhait√©es : Kubernetes, Daitaiku, PySpark, Apache Sqoop, pipelines CI/CD (Jenkins, Gitlab...)Vous √™tes rigoureux et avez une aisance dans la communication avec les √©quipes fonctionnelles et techniques;Vous avez des bases en anglais technique pour collaborer efficacement avec les diff√©rents interlocuteurs internationaux; 18941510-55584
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Jenkins'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Kubernetes'], 'Collaboration': []}"
Data Engineer / Talend Big Data (H/F),Micropole,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-talend-big-data-h-f-at-micropole-3706046900?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=T3oDS7wWM5gYvxSdv5b9YQ%3D%3D&position=17&pageNum=10&trk=public_jobs_jserp-result_search-card,"Rejoignez le Groupe Micropole. Devenez un(e) #InnovativePeople ! Mission En R√©sum√©Poste : Data Engineer Talend Big DataLocalit√© : Levallois-PerretType de contrat : CDINiveau d‚Äôexp√©rience : au moins 3 ansVous √™tes passionn√©(e)s par la data ? Vous √™tes convaincus que l‚Äôoptimisation du patrimoine data des entreprises est la cl√© de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider √† se transformer pour pr√©parer d√®s √† pr√©sent leur futur ? Vous √™tes au fait des derni√®res tendances et pr√™t √† explorer de nouveaux territoires ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?Si vous avez r√©pondu ¬´‚ÄØOui‚ÄØ¬ª √† chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.Alors, pr√™t √† rejoindre l‚Äôaventure Micropole ? N‚Äôattendez plus !Au sein de notre agence bas√©e √† Levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer - Talend Big Data (F/H) , vous accompagnerez les directions m√©tiers dans l'√©valuation de l'efficacit√© de leur processus et dans leur strat√©gie pour optimiser leur performance.Dans vos‚ÄØ missions quotidiennes , vous serez amen√©(e) √†‚ÄØ:D√©velopper et maintenir des cas d‚Äôusages clients avec les outils et les infrastructures Big Data. Mod√©liser et analyser des donn√©es dans le Cloud. Garantir la s√©curit√© / compliance des donn√©es‚ÄØ; Apporter votre r√©flexion sur des probl√©matiques m√©tiers √† travers l‚Äôexploitation et la compr√©hension des donn√©es. Identifier les sources de donn√©es les plus pertinentes et restituer des r√©sultats de fa√ßon concise et visuelle‚ÄØ; R√©aliser une veille technologique pour √™tre √† la pointe sur les solutions Cloud & Data‚ÄØ; Participer au d√©veloppement de notre centre d‚Äôexcellence.  Profil Vos Comp√©tences TechniquesVous avez un minimum de 3 ann√©es d‚Äôexp√©rience sur des projets Data avec Talend Spark ou SSIS. Vous ma√Ætrisez au minimum un langage de programmation (Spark, Scala ou SQL)‚ÄØ; Vous avez une maitrise des th√©ories et outils de mod√©lisation de donn√©es, Vous maitrisez des outils et framework d‚Äôindustrialisation, IaC, CI/CD et/ou gestion de version, Vos AtoutsVous √™tes passionn√©(e), rigoureux(se), curieux(se) et √† l‚Äô√©coute‚ÄØ; Vous avez un bon niveau d‚Äôanglais qui vous permet d‚Äôintervenir sur des projets √† dimension internationale‚ÄØ; Vous d√©velopperez votre cr√©ativit√© et votre curiosit√© gr√¢ce √† une veille technologique accrue qui vous permettra de challenger les besoins de vos clients. Vous souhaitez vous impliquer dans le d√©veloppement d‚Äô√©quipes et de communaut√©s techniques autour du Cloud et des solutions Data. Devenir #INNOVATIVE PEOPLE C‚Äôest :Int√©grer une communaut√© de 1200 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine.Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale.Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud : AWS, Microsoft, Salesforce, GCP.Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus.S‚Äôassurer d‚Äôune innovation continue gr√¢ce √† : notre √©cosyst√®me de partenaires technologiques ; notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR ; nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients ; notre management par les talents naturels.Processus De RecrutementChez Micropole, le processus de recrutement est r√©actif et transparent.Etape 1 ‚Äì si votre profil correspond √† nos besoins, vous √™tes recontact√©s dans les 72 heures qui suivent votre candidature par Lamia notre Talent Specialist. Une qualification t√©l√©phonique ou physique est organis√©e rapidement avec Dimitri ;Etape 2 - Un premier entretien est programm√© avec Dimitri en physique ou visioEtape 3 ‚Äì Vous rencontrez un manager technique avec l‚Äôun de nos experts.En fonction du poste, vous pouvez passer des √©tapes suppl√©mentaires (entretien suppl√©mentaire ou test technique)LA VIE CHEZ MICROPOLE, C‚ÄôestUne vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole ;Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles ;Une politique de formation attractive et √©clectique (certifications prises en charge) ;Un travail en √©quipe valoris√© pour une meilleure coh√©sion ;Participation √† des projets internes sur la base du volontariat.Comp√©tencesSQLSCALASPARKTALENDSSIS


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA Engineer (H/F),Adsearch,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-adsearch-3801834663?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=qrTmGdaGtCbBu%2FC9KkGoAw%3D%3D&position=18&pageNum=10&trk=public_jobs_jserp-result_search-card,"Adsearch vous propose des milliers d''opportunit√©s de carri√®res dans toute la France pour les profils d''experts, cadres et managers. Que ce soit pour un emploi ou pour une mission, Adsearch c''est le cabinet de recrutement qu''il vous faut !Retrouvez toutes nos offres d'emploi en CDI, CDD, Int√©rim et Freelance sur notre site internet ! Introduction !En Bref : CDI - DATA Engineer (H/F) - Nantes - 50K-55K - T√©l√©travail partiel - Editeur de logicielSolenn dAdsearch, Consultante sp√©cialis√©e IT (Infrastructure, Data, S√©curit√©), recrute pour lun de ses partenaires, Editeur de logiciel nantais, un DATA ENGINEER H/F.Vos missions √† r√©aliser !Dans un contexte de remplacement, vous devenez le nouveau DATA Engineer de lentreprise et endossez les responsabilit√©s suivantes : Construire des mod√®les et sch√©mas pour r√©pondre aux besoins Proc√©der √† de lanalyse DATA pour les clients Int√©grer un nouvel outil BI Cr√©ation de rapports personnalis√©s et r√©daction de documentation Cibler des opportunit√©s de communication DATA Contribuer √† lam√©lioration continue et les projets strat√©giques √† venirVotre process de recrutement (peut-√™tre r√©alis√© en 2 semaines!)! Entretien n1 en visio avec votre Consultante Adsearch Entretien n2 par t√©l√©phone avec le Service RH Entretien n3 en pr√©sentiel avec le Responsable Technique Entretien n4 en pr√©sentiel avec la Direction G√©n√©raleVotre profil attendu ! Vos connaissances techniques : Outil BI, ETL, outils mod√®les et statistiques.SQL, SGBD, Looker, Vues et NoSQL. Vos comp√©tences acquises : Au minimum 2 ans d'exp√©rience sur l'ing√©nierie DATA. Aisance de compr√©hension et d'expression en Anglais. Votre posture professionnelle : Curieux, force de proposition, esprit d'analyse et d'√©quipe, guid√© par l'am√©lioration continue !Vos leviers de motivations !Poste en autonomie & responsabilit√© compl√®teCadre de travail convivialEntreprise √† taille humaine, dynamique et r√©put√©eT√©l√©travail partielDe nombreux avantagesCe poste est peut-√™tre LE VOTRE alors candidatez sans tarder pour vous positionner et √©changer avec Solenn d'ADSEARCH !
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst,eXalt,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-at-exalt-3791770040?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=tipuW0PnYs3bHZ3COBC5fw%3D%3D&position=19&pageNum=10&trk=public_jobs_jserp-result_search-card,"Qui sont-ils ?Cabinet de conseil en Transformation Digitale, eXalt est avant tout une formidable aventure humaine, et une communaut√© de plus de 700 collaborateurs, bas√©s √† Paris (si√®ge social), mais √©galement √† Lyon, Lille, Nantes, Bordeaux, Aix-en-Provence, Bogota et bient√¥t New-YorkFond√©e en juillet 2018 autour des valeurs d‚Äôintrapreneuriat, de co-apprentissage et de co-construction, eXalt inscrit son d√©veloppement dans un engagement fort aupr√®s de ses clients et de ses √©quipes. Multi-sp√©cialiste, le groupe d√©cline son mod√®le dans diff√©rents domaines √† travers ses filiales d√©di√©es :Le Product Management & la Gestion de Projet au sein d‚ÄôeXalt P&PLa Finance de March√© au sein d‚ÄôeXalt Fi,La Tech au sein d‚ÄôeXalt IT,La Cybers√©curit√© au sein d‚ÄôeXalt ShieldLa Data au sein d‚ÄôeXalt ValueDescriptif du posteeXalt Value, filiale du groupe sp√©cialis√©e sur les m√©tiers de la Data, et recherche son/ sa nouveau/elle Data Analyst pour aller √† la conqu√™te de nouveaux projets ! Vous √©voluerez dans un contexte multi soci√©t√©s et challengeant.Vous serez rattach√©(e) √† notre bureau parisien.Vos principales missions seront de :Comprendre les probl√©matiques m√©tiers et les traduire de mani√®res analytiquesExtraire les donn√©es n√©cessaires √† l‚Äôanalyse.D√©finir et r√©aliser le nettoyage de la base de donn√©es.S‚Äôassurer la qualit√© des donn√©es tout au long de leur traitementAnalyser et exploiter les donn√©esCr√©er des dashboards via des outils de visualisationsEffectuer une veille sur les nouvelles technologies et solutions logicielles d‚Äôanalyse des donn√©es.Profil recherch√©Nous recherchons avant tout une personne anim√©e par l‚Äôesprit et l‚ÄôADN d‚ÄôeXalt ‚òÄÔ∏è ayant l‚Äôenvie de prendre part √† un superbe challenge et √† notre aventure !Vous √™tes dipl√¥m√©(e) d‚Äôun Bac+5Vous b√©n√©ficiez d‚Äôune exp√©rience d‚Äôau moins 4 ans en tant que Data AnalystVous avez une expertise en base de donn√©es et gestion de base de donn√©es (SQL/ NoSQL)Vous maitrisez des outils de data visualisation (Tableau, Qlikview, PowerBI) et/ou des outils de fouille et analyse de donn√©es (Dataiku)Vous avez une aisance r√©dactionnelle & relationnelleVous avez une passion pour les chiffres et le go√ªt pour l‚ÄôinnovationVous √™tes reconnu(e) pour votre rigueur, votre organisation et votre adaptabilit√©.L‚Äôanglais professionnel est requis


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'PowerBI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer en alternance F/H,Treez Data Management üìäüìàüñ•Ô∏è,"Villeneuve-d‚ÄôAscq, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-en-alternance-f-h-at-treez-data-management-%F0%9F%93%8A%F0%9F%93%88%F0%9F%96%A5%EF%B8%8F-3807132988?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=gznNvg%2B4XiqwluReNJ05Hw%3D%3D&position=20&pageNum=10&trk=public_jobs_jserp-result_search-card,"Ta mission ?Sous la responsabilit√© de l‚Äôun de nos consultants s√©niors et apr√®s une p√©riode de formation, tu interviendras dans des missions techniques notamment autour de l‚Äôoutil POWER BI et concernant toute la cha√Æne d√©cisionnelle depuis la collecte des donn√©es jusqu‚Äô√† leur restitution :Alimentation d‚Äôentrep√¥ts de donn√©es (datawarehouse)D√©veloppement de bases de donn√©es multidimensionnelles (Cubes)D√©veloppement de rapportsD√©veloppement d‚ÄôalgorithmesMod√©lisation pr√©dictive.Au-del√† de ces missions techniques, tu acquerras avec l‚Äôexp√©rience des comp√©tences de conseil et d‚Äôaccompagnement du client pour atteindre un profil de consultant junior.En fonction de tes app√©tences, tu pourras √©galement int√©grer des √©quipes aux comp√©tences sp√©cifiques :Power Platform/Power Apps.Data Performance/XLCUBED.Qui es-tu ?Tu es en cours de cursus de formation ou de sp√©cialisation en informatique d√©cisionnelle / Data Sciences et recherches une mission pas planqu√©e, dans laquelle tu continueras d'apprendre et seras rapidement impliqu√©.e dans des missions de production.Tu ma√Ætrises le langage SQL pour des requ√™tes simples √† complexes, voire pour la conception et la mod√©lisation de bases de donn√©es. Id√©alement, tu ma√Ætrises √©galement SQL Server.Si en plus, tu as d√©j√† approch√© la BI Microsoft (Power BI) en cours ou lors d‚Äôune premi√®re exp√©rience, c‚Äôest le top !Nous cherchons aussi (surtout !) une personnalit√© qui a envie de rejoindre une petite et conviviale √©quipe de passionn√©.e.s dot√©.e.s d'une volont√© de toujours avancer.L‚Äôalternant que nous recrutons aujourd'hui pourra √™tre le/la Consultant/e Treez de demain, donc tu recherches un stage puis Alternance ou Alternance directement pour ton master.Et nous ? Qui sommes-nous ?TREEZ a √©t√© cr√©√©e en 2015 par 3 associ√©s (Olivier, Arnaud & R√©mi), passionn√©s de longue date par la BI. Aujourd‚Äôhui compos√©e de 45 consultant.e.s sp√©cialis√©.es en Data Microsoft (BI, Data Sciences, Self-services BI, Machine Learning), l‚Äô√©quipe TREEZ conseille ses clients et met en pratique les nouveaux usages de la donn√©e, en aidant ses clients √† exploiter leur potentiel insoup√ßonn√©. Int√©ressant, n‚Äôest-ce pas ?!Dans le cadre de notre croissance et de notre envie de transmettre, nous proposons chaque ann√©e un contrat d‚Äôalternance au sein de notre agence de Villeneuve d'Ascq.Aurais-tu envie de rejoindre la grande famille Treez ? L‚Äôaventure te tente ?Transmets-nous vite ta candidature ! :)


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer (H/F),Devoteam G Cloud,"Levallois-Perret, √éle-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-h-f-at-devoteam-g-cloud-3163051864?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=YFSMAN%2FOZZgwhLCfzcsC%2FA%3D%3D&position=21&pageNum=10&trk=public_jobs_jserp-result_search-card,"Description de l'entrepriseDevoteam G Cloud a pour mission de conseiller et d'accompagner les soci√©t√©s dans leur transformation digitale avec les solutions Google Cloud.Avec plus de 1.300 clients et 1 000 000 d'utilisateurs d√©ploy√©s, Devoteam G Cloud s'impose depuis 10 ans comme 1er partenaire EMEA de Google Cloud sur l'int√©gration des nouvelles plateformes SaaS.En savoir plus : http://devoteamgcloud.com.Bas√©e √† Paris et Lyon, Devoteam G Cloud est le leader europ√©en de la distribution de produits Google Cloud toute solution confondue.  Description du posteTu auras pour mission d‚Äôaccompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l‚Äô√©cosyst√®me solutions open source associ√©.Int√©gr√©(e) √† une √©quipe d‚Äôexperts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d‚Äô√©tudier et cadrer les besoins clientsPr√©coniser les solutions et architectures ciblesD√©finir les m√©thodologies de d√©ploiement et plans de migrationR√©diger les dossiers d‚Äôarchitecture et sp√©cifications techniquesConstruire les architectures de donn√©esConcevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els)Construire et d√©ployer les pipelines de donn√©es (ETL)Assurer la migration des donn√©es vers les nouveaux environnementsAnalyser les donn√©esAnalyser les donn√©es sources afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, Tableau, QlikView, DataStudio‚Ä¶)S√©lectionner, entra√Æner, √©valuer et d√©ployer des mod√®les pr√©dictifs en s‚Äôappuyant sur les outils standards du domaine (TensorFlow, Keras, Scikit Learn)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les √©quipes clients aux m√©thodes et concepts du cloudTu seras accompagn√©(e) en interne pour monter rapidement en comp√©tences sur GCP dans l‚Äôobjectif de devenir certifi√© Google sur ta practice.  Qualifications Dipl√¥m√©(e) d'une √©cole d'ing√©nieurs ou d'un Master 2 en Informatique, tu disposes d'une exp√©rience significative au sein de projets Data : architecture, traitement ou analyse de donn√©es.Tu ma√Ætrises au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (Scala, R, Python, Java).Tu as de bonnes comp√©tences dans de l‚Äôarchitecture des syst√®mes, bases de donn√©es, m√©thodologies d‚ÄôanalyseTu es passionn√©(e) par la Business Intelligence, le Big Data, l‚ÄôInternet des objets (IoT) et le Machine LearningUne connaissance des outils Data des Cloud Providers publiques (Google Cloud Platform, Microsoft Azure, AWS, ‚Ä¶) est un plus.Tu as une solide compr√©hension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et √† l‚Äô√©coute, tu poss√®des un r√©el esprit d‚ÄôanalyseTa ma√Ætrise de l'anglais te permettra de g√©rer des projets en contexte international  Informations suppl√©mentairesLe Groupe Devoteam oeuvre pour l'√©galit√© des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m√©rite et lutte activement contre toute forme de discrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure', 'Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,LesJeudis,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3788257066?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=m6ADYxk5L33oOS0dYtPhqQ%3D%3D&position=22&pageNum=10&trk=public_jobs_jserp-result_search-card,"MissionDans le cadre de son d√©veloppement, Inetum recrute un Data Engineer (H/F) pour sa branche Applications Services.Le Data Engineer interviendra chez l'un de nos clients sur des projets BI et/ou Big Data avec une approche Data Driven et ce, en m√©thode agile.Le Data Engineer Sera En Charge De Apporter une expertise en Big Data permettant la manipulation de donn√©es Accompagner nos clients dans la r√©alisation de projets dans un contexte Big Data et Cloud Participer √† des POCs (Proof Of Concept) permettant de valider les principes techniques et algorithmiques pour des projets Concevoir des plateformes permettant de traiter des volumes importants de donn√©es D√©velopper des pipelines de donn√©es pour assembler les donn√©es en provenance de multiples syst√®mes D√©velopper des applications d'injection et de traitements massifs sur des volum√©tries importantes Participer √† l'industrialisation d'applications partiellement r√©alis√©es (optimisation du code, optimisation des performances, utilisation maximis√©e des possibilit√©s des outils et du cluster disponible) Mettre en place des bases de donn√©es (SQL, NoSQL...)ProfilDe formation ing√©nieure en informatique (Bac+5), vous avez √©volu√© dans le monde du d√©veloppement (langages Java, Scala, python, R, Spark, Tensorflow) avec une culture Devops, une ma√Ætrise des BDD, du Shell/Unix...Vous disposez d'une exp√©rience significative dans le d√©veloppement (2/3ans) et une exp√©rience √©galement sur une distribution Hadoop (Cloudera, Horthonworks ou MAP-R).Vous √™tes √† l'aise avec les principes du cloud, une premi√®re exp√©rience avec l'un des cloud provider suivant : AWS, Azure, GCP serait un plus...Vous avez un esprit d'analyse, orient√© sur la mise en place d'algorithmes de manipulation de donn√©es volumineuses, sur la mani√®re de les rendre plus performantes (parall√©lisation, distribution de charge) et dans des conditions de hautes disponibilit√©s.Vous appr√©ciez le travail en √©quipe et les challenges.Vous poss√©dez des qualit√©s de communication qui vous am√®ne naturellement √† partager vos connaissances avec vos clients et vos collaborateurs.Si vous vous reconnaissez, n'h√©sitez pas √† postuler !OrganisationNous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': ['TensorFlow'], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst H/F,IDKIDS.COMMUNITY,"Roubaix, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-idkids-3806035968?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=ft%2FO4u5aAeMBHc9%2FD%2FqdvQ%3D%3D&position=23&pageNum=10&trk=public_jobs_jserp-result_search-card,"Chez OKAIDI, nous sommes bien plus qu‚Äôun r√©seau de magasins. Nous sommes des acteurs au service du bien-√™tre des enfants. Envie de prendre part √† cette aventure ?En tant que Data Analyst, tu contribues par tes actions √† la satisfaction de nos clients et √† la performance de l'entreprise. Tu garantis la connaissance client omnicanal et multimarque, indispensable au pilotage de l'activit√© et √† l'√©laboration de nos strat√©gies de prospection et de fid√©lisation.Le programme de ton futur job !‚òëÔ∏è Comprendre pr√©cis√©ment les probl√©matiques marketing, e-commerce et retail et les traduire de mani√®re analytique.‚òëÔ∏è Accompagner les marques dans l'analyse des performances, l'optimisation de leur action et l‚Äôalimentation de leur r√©flexion strat√©gique.‚òëÔ∏è Piloter et analyser les op√©rations marketing tel que l'A/B testing, la publicit√© en ligne, l'e-mailing.‚òëÔ∏è Explorer, qualifier et valoriser les donn√©es de navigations, de transactions et de produits, dans une dimension client.‚òëÔ∏è D√©velopper et automatiser des dashboards en fonction des demandes internes.‚òëÔ∏è Utiliser des m√©thodes statistiques basiques et avanc√©es pour am√©liorer la connaissance client.Le poste de Data Analyst H/F est √† pourvoir en CDI, il est bas√© √† Roubaix.Alors, cap ou pas cap ? Ce poste est fait pour toi si ‚úîÔ∏èTu as une exp√©rience de minimum 3 ans en tant que Data Analyst / Business Analyst.‚úîÔ∏èTu as une capacit√© √† aller facilement vers l‚Äôautre et √† cr√©er du lien avec les √©quipes.‚úîÔ∏èTu es reconnu pour tes capacit√©s d‚Äôanalyse et ton esprit de synth√®se‚úîÔ∏èTu es c√¢bl√© business afin de bien comprendre les probl√©matiques digitales, marketing et commerciales.‚úîÔ∏èTu sais faire rimer curiosit√©, autonomie et rigueur dans l'accompagnement des sujets confi√©s.‚úîÔ∏èTu es au top ü§© si tu ma√Ætrises les outils d'analyse de donn√©es (SAS, RStudio, GCP) et le langage SQL.Ce que l‚Äôon peut t‚Äôoffrir ?Les afterworks les plus convoit√©s du groupe #BestTeamLa possibilit√© d‚Äô√©voluer en interne au sein des nombreuses marques du groupeUn √©quilibre vie pro / vie perso respect√© ‚öñÔ∏èUn management bienveillant et de proximit√©La possibilit√© de r√©aliser une journ√©e solidaire chaque ann√©e avec ton √©quipeEt bien-s√ªr : le remboursement des frais de transport √† 50%, carte tickets resto Swile, mutuelle, avantages du CSE, remise au personnel, et primes.Tu veux en savoir plus sur nous ? Int√©grer IDKIDS, c‚Äôest prendre part √† une formidable aventure humaine au sein d‚Äôune entreprise engag√©e !Chez nous, l‚Äôengagement c‚Äôest du solide üí™Acteur du d√©veloppement √©motionnel, moteur et intellectuel de l‚Äôenfant #WECARE+ de 52 000 enfants aid√©s dans le monde gr√¢ce √† notre fonds de dotation.Le coton bio d√©j√† utilis√© depuis + de 15 ans dans nos collections OKAIDI / OBAIBI ! La mise au point d‚Äôun coton recycl√© fabriqu√© √† partir de v√™tements usag√©s 1 tonne de plastique et 5 tonnes de carton √©conomis√©s gr√¢ce √† 98% de packagings OXYBUL √©co-con√ßus üì¶Pr√©curseur de la seconde vie du produit avec nos √èDTROC depuis + de 7 ans ‚ôªÔ∏è50 cr√®ches anim√©es par des projets de sens favorisant la mixit√© sociale, les liens interg√©n√©rationnels, l‚Äôinclusion d‚Äôenfants en situation de handicap üë∂Et petit bonus, producteur de miel made in Roubaix #biodiversit√© üêù En bref, IDKIDS c‚Äôest bon pour les Enfants, essentiel pour les Parents et engag√© pour la Plan√®te !Cerise sur le g√¢teau, en rejoignant OXYBUL, vous int√©grerez l‚Äô√©cosyst√®me IDKIDS compos√© :Des marques produits : Oka√Ødi, Oba√Øbi, Jacadi, Oxybul Eveil et Jeux, Catimini et Absorba Des marques de services : Rigolo Comme La Vie, N‚ÄôJoy, ConsoBabyDes marques m√©dias : JoyVox, BubblemagUne fondation d‚Äôentreprise : We Act For Kids Fond‚Äôactions#63pays #1300magasins #6000collaborateurs #3millionsdeclients #WEACTFORKIDSEt si tu faisais sourire ton avenir chez √èDKIDS ? :-)Dans le respect de ses engagements RSE et de sa charte diversit√©, IDKIDS √©tudie toutes les candidatures dont celles des personnes en situation de handicap.#RejoignezOKAIDI
      

        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer (H/F),Thales,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-thales-3804599575?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=QRbum27rcAL60NQY7hl2HQ%3D%3D&position=24&pageNum=10&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Thales propose des syst√®mes d‚Äôinformation et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d‚Äôimportance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d‚Äôinformation critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l‚Äôutilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l‚Äôactivit√© Syst√®mes d‚Äôinformation critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d‚Äôinformation afin de faire face aux ruptures technologiques et aux cybermenaces.QUI ETES-VOUS ?Int√©gr√©(e) au centre de comp√©tences ¬´ Augmented Data ¬ª de Brest, vous interviendrez sur des projets de d√©veloppement de syst√®mes d‚Äôinformation ¬´ Data oriented ¬ª.Au sein de ce centre, vous rejoindrez nos Data Engineers, Data Architects et Data Scientists.De formation Ing√©nieur ou Bac +5, Ecole d‚Äôing√©nieur ou Universit√© vous justifiez d'une exp√©rience professionnelle en mise en place de solutions Big Data d‚Äôau moins 2 ans et id√©alement d‚Äôune premi√®re exp√©rience r√©ussie en animation d‚Äô√©quipe et/ou pilotage de lots techniques.COMP√âTENCES :Plusieurs des affirmations suivantes vous caract√©risent : Vous √™tes passionn√©(e) par le Digital, les donn√©es, les enjeux qu‚Äôelles repr√©sentent et les technologies Big Data avec lesquelles les manipuler (Hadoop, Nifi, Kafka, ElasticSearch, Spark, Storm, HBase, Cassandra, etc.). Vous √™tes familiaris√©(e) avec les diff√©rentes plateformes et outils qui y sont reli√©s. Vous savez et aimez coder avec des langages de programmation commun√©ment utilis√©s pour la manipulation de donn√©es (Python, Java, SQL) sur des architectures distribu√©es en production. Vous savez impl√©menter des cha√Ænes de traitement optimis√©es. Vous √™tes familiaris√©(e) avec les concepts et technologies d‚Äôint√©gration continue (Git) et les outils de d√©ploiement (Docker). Vous √™tes familiaris√©(e) avec les frameworks Agile tels que Scrum ou Kanban. Vous √™tes motiv√©(e), appliqu√©(e), organis√©(e) et curieux(se) dans votre travail au quotidien. Vous √™tes titulaire d‚Äôun dipl√¥me d‚Äôing√©nieur ou Master, id√©alement avec une sp√©cialisation sur les m√©tiers de la donn√©e et du Big Data. Vous parlez fran√ßais et, id√©alement, anglais (√©crit et oral)CE QUE NOUS POUVONS FAIRE ENSEMBLE:En tant que Data Engineer, vos missions seront les suivantes : Comprendre les besoins et les enjeux du client autour de ses donn√©es. Concevoir des solutions innovantes de traitement de donn√©es r√©pondant aux besoins, impl√©menter des cha√Ænes de traitements Big Data et les d√©ployer √† l‚Äô√©chelle dans des environnements de production. Contribuer √† la d√©finition d‚Äôarchitecture de donn√©es et √† l‚Äôop√©rationnalisation de plateformes de donn√©es. Pr√©senter vos propositions de conception et r√©sultats aupr√®s du client et de votre √©quipe. Partager et √©changer vos connaissances et exp√©riences dans le Data Engineering avec votre √©quipe. Contribuer √† la pr√©paration et √† l‚Äôanimation d‚Äôateliers avec les interlocuteurs requis. Effectuer un reporting r√©gulier √† votre manager sur l‚Äôavancement de vos activit√©s ainsi que sur les risques potentiels identifi√©s.Nous vous offrons : Une diversit√© de projets vous permettant de d√©couvrir plusieurs environnements techniques et fonctionnels ainsi que l‚Äôensemble de nos m√©tiers au sein du groupe Thales, Des conditions de travail motivantes et un plan de carri√®re personnalis√© offrant de r√©elles perspectives d‚Äô√©volution, La possibilit√© de vous investir dans une entreprise dont la r√©putation est mondiale avec des ambitions constantes d‚Äôinnovations techniques, Un cadre de travail privil√©gi√© dans des bureaux situ√©s √† un endroit dynamique du port de commerce de Brest, La possibilit√© de t√©l√©-travailler jusqu‚Äô√† 10 jours par mois.Alors n'attendez plus, rejoignez-nous !Thales reconna√Æt tous les talents : la diversit√© est notre meilleur atout.Le poste pouvant n√©cessiter d'acc√©der √† des informations relevant du secret de la d√©fense nationale, la personne retenue fera l'objet d'une proc√©dure d‚Äôhabilitation, conform√©ment aux dispositions des articles R.2311-1 et suivants du Code de la d√©fense et de l‚ÄôIGI 1300 SGDSN/PSE du 09 ao√ªt 2021.Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd‚Äôhui.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'R'], 'DataBase': ['SQL', 'Cassandra', 'HBase', 'Elasticsearch'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': ['HBase'], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Software Engineer,Lever Middleware Test Company 2,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-at-lever-middleware-test-company-2-3787335392?refId=UKTqQ62snV8SxVzvqovROQ%3D%3D&trackingId=i3SA50Xm3er5oFgFfthD6Q%3D%3D&position=25&pageNum=10&trk=public_jobs_jserp-result_search-card,"This is a software engineer role.This is paragraph format.Responsibilities123Requirements123Please join us!Lever builds modern recruiting software for teams to source, interview, and hire top talent. Our team strives to set a new bar for enterprise software with modern, well-designed, real-time apps. We participated in Y Combinator in summer 2012, and since then have raised $73 million. As the applicant tracking system of choice for Netflix, Eventbrite, ClearSlide, change.org, and thousands more leading companies, Lever means you hire the best by hiring together.Lever is an equal opportunity employer. We are committed to providing reasonable accommodations and will work with you to meet your needs. If you are a person with a disability and require assistance during the application process, please don‚Äôt hesitate to reach out! We celebrate our inclusive work environment and welcome members of all backgrounds and perspectives. Learn more about our team culture and commitment to diversity and inclusion.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - MOE BI H/F,GRDF,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-moe-bi-h-f-at-grdf-3806857264?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=QVLkbE19RwhPhN%2F8OnTF0g%3D%3D&position=1&pageNum=11&trk=public_jobs_jserp-result_search-card,"Vous √™tes motiv√©(e) :  pour mettre vos comp√©tences au service d‚Äôun acteur majeur de la transition √©nerg√©tique, expert et distributeur du gaz naturel‚ÄØ?  pour participer √† l‚Äôavenir de la distribution du gaz naturel‚ÄØ(compteur communicant, technologies du r√©seau intelligent, d√©veloppement du biogaz et du GNV, ‚Ä¶)‚ÄØ?  Vous souhaitez acqu√©rir un v√©ritable savoir-faire technique gazier‚ÄØdans une entreprise qui investit dans les innovations digitales ?  Rejoignez-nous‚ÄØ√† GRDF ! GRDF, filiale ind√©pendante d‚ÄôENGIE, est le principal gestionnaire de r√©seau de distribution de gaz naturel en France.GRDF distribue le gaz naturel √† plus de 11 millions de clients, pour qu‚Äôils disposent du gaz quand ils en ont besoin, quel que soit leur fournisseur.Pour cela, et conform√©ment √† ses missions de service public, GRDF con√ßoit, construit, exploite, entretient le plus grand r√©seau de distribution d‚ÄôEurope (198 886 km) et le d√©veloppe dans plus de 9 500 communes, en garantissant la s√©curit√© des personnes et des biens et la qualit√© de la distribution.Chaque jour, ce sont 11 431 femmes et hommes qui s'investissent dans leur mission. Partout en France, des √©quipes sont pr√™tes √† intervenir 24h/24 et 7j/7 pour fournir le meilleur service possible.Au sein de la R√©gion Ile de France, GRDF recrute‚ÄØ: Un(e) Data Engineer ‚Äì MOE BI H/F La Direction Syst√®me d'Information de GRDF, cr√©atrice de valeur et partenaire des m√©tiers, a pour mission d‚Äôassurer le fonctionnement, la cr√©ation et l'adaptation du SI conform√©ment aux besoins des utilisateurs tout en veillant √† la ma√Ætrise des co√ªts projet, ainsi qu‚Äôen MCO.Vous serez Data Engineer/MOE BI dans le p√¥le BI Management √† la DSI et rejoindrez une stream m√©tier, pour laquelle vous devrez assurer le MCO des applicatifs BI existant et conduire le(s) projet(s) BI dans un contexte de refonte de l‚Äô√©cosyst√®me sur une nouvelle plateforme data analytics.Accompagn√© par le responsable MOA, vous serez en lien direct avec les √©quipes de d√©veloppement et devez assurer le delivery des projets de votre stream. Vous assurez √©galement le maintien en condition op√©rationnel des applicatifs de votre stream et √™tes le garant technique de ces derni√®res. Dans ce contexte vous validez les conceptions techniques dans les normes et bonnes pratiques, vous assurez la recette technique et assistez la MOA SI et le m√©tier dans leur recette, vous garantissez les mises en production et mises en service. Missions : Vous aurez en charge les missions suivantes : Piloter les projets Data, avec l'ensemble des parties prenantes, M√©tiers, MOA, AMOA, MOE, Administrateur technique, etc.  Garantir des solutions SI optimales et conformes √† la strat√©gie de GRDF ainsi qu'aux besoins exprim√©s du m√©tier, en termes de qualit√©, performances, co√ªt et d√©lai dans le respect des processus de gestion en vigueur √† la DSI,  Valider la mod√©lisation et la conception de la solution fonctionnelle et technique,  Planifier et suivre les d√©veloppements,  Coordonner les recettes techniques et fonctionnelles et contr√¥ler la conformit√© avec les engagements du projet,  Organiser et suivre la comitologie projet et MCO,  Conduire le changement,  Proposer les am√©liorations de process, ainsi qu'assurer une veille technologique.  Profil recherch√© : Vous √™tes titulaire d‚Äôun dipl√¥me Bac +5 en IT, avec une sp√©cialit√© en syst√®me d‚Äôinformation et data.Vous connaissez la m√©thodologie de gestion de projets, disposez d‚Äôun solide bagage technique autour des technologies BI et de leur impl√©mentation. Vous maitrisez les principes de mod√©lisation des Datawares et Datamarts, et les bonnes pratiques autour de la conception des syst√®mes BI sur toute leur composante. Vous avez √©galement des qualit√©s requises : organisation,  rigueur,  esprit d‚Äô√©quipe,  pro-activit√©,  esprit de synth√®se,  capacit√©s d‚Äô√©coute et de communication,  bonne expression √©crite et orale,  tr√®s bonnes capacit√©s relationnelles. Vous savez analyser les besoins exprim√©s par les m√©tiers et d√©finir la faisabilit√© technique (une bonne connaissance du SQL est requise) et en d√©finissant les √©changes et la mod√©lisation BI.Vous travaillerez en √©troite collaboration avec les d√©veloppeurs et √©quipes de conduite technique ainsi que les MOA SI.Vous poss√©dez une aptitude √† comprendre et int√©grer les probl√©matiques m√©tier et les contraintes d'urbanisme et d'architecture, pour une bonne insertion du projet dans les patterns Data Analytics d√©finis.Une exp√©rience significative en gestion de projets informatiques, dans le domaine Data Analytics/D√©cisionnel. Informations compl√©mentaires L‚Äôemploi est r√©gi par l‚Äôobligation de respect des engagements du code de bonne conduite de GRDF, lequel est constitu√© des principes d‚Äôind√©pendance, de non-discrimination, de protection des informations commercialement sensibles, d‚Äôobjectivit√© et de transparence. En tant qu‚ÄôEmployeur responsable, GRDF valorise la diversit√© des profils de ses collaborateurs. Son engagement est reconnu par les Labels Diversit√© et Egalit√© professionnelle. Lieu de travail : 6 rue de Condorcet , 75009 PARIS (D√©m√©nagement pr√©vu √† Saint Denis en 2025)


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer H/F,LesJeudis,"Bordeaux, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-h-f-at-lesjeudis-3804516142?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=WpM7FAerVc9TLhHULXxtdA%3D%3D&position=2&pageNum=11&trk=public_jobs_jserp-result_search-card,"Qui sommes-nous ?NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶).Nous sommes experts du digital aussi bien sur de l'accompagnement strat√©gique qu'op√©rationnel.Fort du succ√®s, NEXTON conna√Æt aujourd'hui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, confiance et performance.Et pour toi ? Notre politique de d√©veloppement des comp√©tences dynamique saura te s√©duire avec un programme de suivi de carri√®re sur-mesure.NEXTON recrute unDATA ENGINEER H/F, enCDI, √†Bordeaux !Qui sommes-nous ?NEXTON c'est avant tout une entreprise qui accompagne ses clients dans leur transformation digitale. Tous les jours, nous travaillons avec des grands comptes et des pures players (SNCF, Orange, BNP PARIBAS‚Ä¶).Nous sommes experts du digital aussi bien sur de l'accompagnement strat√©gique qu'op√©rationnel.Fort du succ√®s, NEXTON conna√Æt aujourd'hui un d√©veloppement significatif, autour de ses valeurs piliers : coh√©sion, confiance et performance.Et pour toi ? Notre politique de d√©veloppement des comp√©tences dynamique saura te s√©duire avec un programme de suivi de carri√®re sur-mesure.Le ContexteTu es rattach√© √† l'√©quipe innovative Data& IT en qualit√© de data engineer de notre client. Son √©quipe con√ßoit, d√©veloppe et exploite une grande partie des donn√©es et solutions Data √† destination des utilisateurs internes pour la France et l'international.Les MissionsConcevoir et d√©velopper des solutions Data/IA √† des fins analytics& dashboardingAccompagner les m√©tiers dans la compr√©hension des Analytics et mise en oeuvre de solution""data driven""Mettre en oeuvre des solutions industrielles exploitables, mesurables et op√©rablesCommuniquer et traduire les r√©sultats complexes et leur implications aux parties prenantes de l'entrepriseCapitaliser sur les solutions pour cr√©er de nouveaux produits, de nouveaux services et de nouvelles opportunit√©s de digitalisation, de valorisation de la donn√©eCollaborer avec les data scientist et data ops dans la construction d'une culture ax√©e sur les donn√©esParticiper activement √† la communaut√© de data scientists et de data ing√©nieursG√©rer un √©cosyst√®me de partenaires data science et assurer un haut niveau d'expertiseAssurer un r√¥le de veille technologique sur tous les outils autours de la data, IA et BIContribuer au d√©veloppement des membres de l'√©quipe BI et Big DataTu as √©tudi√© les syst√®mes d'informations, la Big Data ou le traitement de donn√©es lors d'un parcours sup√©rieur de type √©cole d'ing√©nieurs (BAC+5).Ta capacit√© √† r√©gler des probl√®mes techniques complexes et ton autonomie dans la recherche de solutions li√©es √† la Big Data font partie de tes qualit√©s professionnelles.Tu travailles de mani√®re autonome dans un contexte agile, un minimum de quatre ann√©es d'exp√©riences sur un poste de data engineer est attendu pour √™tre op√©rationnel sur ce poste.NEXTON c'est aussi et surtout de nombreux moments de rencontres tout au long de l'ann√©e : Des communaut√©s : 2 Meet Up par mois pour partager et √©changer avec des experts De nombreux moments de rencontres professionnels et extra professionnels tout au long de l'ann√©e Des moments privil√©gi√©s avec ton managerPr√™t √† nous rejoindre ?Rencontrons-nous !


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': ['Orange'], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Full-stack Software Engineer,Skeepers,"Marseille, Provence-Alpes-C√¥te d'Azur, France",https://fr.linkedin.com/jobs/view/full-stack-software-engineer-at-skeepers-3780879052?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=%2FdZvmfMGZeoc9gGNzrcLyg%3D%3D&position=3&pageNum=11&trk=public_jobs_jserp-result_search-card,"SKEEPERS is a group that is changing the world of customer experience. With a strong international ambition, SKEEPERS helps brands generate value by and for their customers.With its' one for all platform, SKEEPERS provides brands with a complete solution that allows them to prescriptively activate data collected from customer feedback for marketing purposes.Recognised as a high-growth group, SKEEPERS has already made it into the Next40 ranking of the forty most innovative French start-ups!To accompany our development, we are constantly looking for new talents who are ready to make a difference on an international scale!Created in 2019, SKEEPERS reached 450 employees internationally across 6 countries: France, Spain, Italy, Brazil, Canada, and also USA.SKEEPERS is the right place for you if you are a Go-Getter; someone who likes to deliver results, ready to roll up their sleeves to make things happen, and a positive challenger.About the role:You will join the R&D team of Skeepers (100 staff), a talented team working on the development of all Skeepers Solutions. In a SaaS company like SKEEPERS, the Engineering team is the main engine of our growth. Your work will have a direct impact on our end customers and your taste for challenge will allow the whole group to grow.Within the R&D department, you will join a squad to work on our solutions.Responsibilities:Reporting directly to the Director of Engineering and supported by the Team Lead, you will take part in the development of the platform. Your main missions will be the following:Collaborate with team members to develop high-traffic low-latency applications while delivering high-availability and performance Build, optimize, and scale the platform and infrastructure Evangelize best software development practices (DDD, TDD, CICD) Perform code reviews and design reviews to ensure compliance with development standards Maintain high standards of software quality within the team by establishing best practices and habits Technical stack:Backend: PHP SymfonyFrontend: AngularDatabase: MySQL, PostgreSQL, MongoDB, NoSQLContainer: Kubernetes / Docker CI/CD: Gitlab Cloud provider: AWS & GCPOther: Redis, Talend, Kafka, ELK, Jira, ... Requirements+5 years of experience in software and web development At least 4 years as a developer working with Agile Method Demonstrated project management and delivery experience You can communicate effectively with other team members to explain and advocate your choicesGood organization and problem-solving skillsAnalytical mindset and good executive reporting skillsFluent in English BenefitsA division at the forefront of innovation in terms of marketing technology.‚ÄØ A team that is passionate about their work and highly effective in the areas of expertise, enabling you to quickly develop your skills.‚ÄØ ‚ÄØThe opportunity to play a strategic role within a dynamic structure in an innovative and competitive market. The opportunity to participate in seminars and other events organised by the group in France or abroad.‚ÄØ A possibility to work in a hybrid way from home or from the office depending on your work/life balance.‚ÄØ Restaurant tickets with the Swile Card Health insurance company, ... A prospect of internal development thanks to the structuring of the group on a national and international scale.‚ÄØ‚ÄØ The opportunity to be part of a group that develops an entrepreneurial and intrapreneurial spirit: let your creativity and your desires speak for themselves!


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['MySQL', 'PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': ['JIRA']}"
Data analyst H/F,Inetum,"St.-Ouen, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-inetum-3782168962?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=M0ahXxZqb04iinrEzXxcEg%3D%3D&position=4&pageNum=11&trk=public_jobs_jserp-result_search-card,"D√©tail de l'offre  Informations g√©n√©rales  Entit√© de rattachement  Nous sommes une ESN agile, un groupe international certifi√© Top Employer Europe 2023.A l'√®re de la post-transformation digitale, nous mettons tout en ≈ìuvre pour que chacun de nos 28 000 athl√®tes du digital puisse se renouveler perp√©tuellement, en vivant positivement son propre flow digital.Chacun de nos talents peut ainsi fa√ßonner son parcours de carri√®re selon ses app√©tences, entreprendre de mani√®re pragmatique avec ses clients pour un monde √† impact positif, innover localement dans 27 pays et harmoniser son investissement professionnel et son bien-√™tre personnel.Rejoignez Inetum. Live your positive digital flow.Tous nos postes sont ouverts aux personnes en situation de handicap.Description du poste M√©tier M√©tier AS (Application Services) - Technique AS Intitul√© du poste Data analyst H/FDescription De La MissionLes missions du Data Analyst sont vari√©esRecueil et extraction des sources de donn√©es pertinentes et de qualit√© qu‚Äôil traduit ensuite en donn√©es statistiques ;Traitement, exploitation et int√©gration des donn√©es dans un data warehouse (entrep√¥t de donn√©es) ;Cr√©ation de dashboards, mise en place de KPIs et reporting des performances pour donner une vision coh√©rente des r√©sultats aux diff√©rentes √©quipes ;Mise en place de process/requ√™tes et automatisation ; Production d‚Äôanalyses m√©tiers et de recommandations aux managers ;Gestion des outils d‚Äôanalyses pour que les d√©cideurs internes et les clients puissent suivre l‚Äô√©volution de leurs produits ; Veille technologique des nouveaux outils visant √† l‚Äôam√©liorer l‚Äôanalyse des donn√©es. Profil Le Data Analyst poss√®de des comp√©tences techniques avec la maitrise de divers outils et logiciels (Excel, Web Analytics, BI, SAS, VBA, Python etc.), ainsi que des langages de programmation tel que R. Il doit √† la fois faire preuve d‚Äôune grande aisance r√©dactionnelle et avoir une passion pour les chiffres et les statistiques. Son orientation business et son aisance relationnelle avec les m√©tiers lui permettent de r√©aliser des recommandations pertinentes et de simplifier les probl√©matiques techniques. Rigoureux, organis√©, r√©actif et d'esprit analytique, le Data Analyst pourra ainsi √™tre capable d‚Äôapporter une vision coh√©rente des tendances d‚Äôactivit√© de l'entreprisLocalisation du poste Localisation du poste France Ville Saint OuenCrit√®res candidat Niveau d'√©tudes min. requis Bac+5 Niveau d'exp√©rience min. requis Plus de 2 ans Comp√©tences ExcelPythonVBA Langues Anglais (Courant)Fran√ßais (Bilingue)


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirm√© (F/H),Micropole,"Niort, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-f-h-at-micropole-3742749162?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=1Sh7V99xYvatFPtXhOVmRw%3D%3D&position=5&pageNum=11&trk=public_jobs_jserp-result_search-card,"Rejoignez le Groupe Micropole. Devenez un(e) #InnovativePeople ! Mission Comme nous, vous √™tes passionn√©(e) par la donn√©e et convaincu(e) que la validation du  patrimoine data des entreprises  est la cl√© de leur performance ? Vous voulez accompagner les entreprises dans leur strat√©gie data driver et les aider √† se transformer gr√¢ce aux nouvelles technologies qu'am√®ne le Cloud, pour pr√©parer d√®s √† pr√©sent leur futur ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitales, au sein d‚Äôune agence √† taille humaine o√π r√®gnent entraide et convivialit√© et engag√©e en faveur d‚Äôun num√©rique plus responsable au service de clients principalement implant√©s r√©gionalement ?Rejoignez l'aventure Micropole √† Niort !Vous viendrez renforcer une √©quipe niortaise soud√©e qui porte l‚Äôesprit d‚Äô√©quipe, ayant √† c≈ìur de faire de votre int√©gration un succ√®s et de vous accompagner dans votre mont√©e en comp√©tences.En int√©grant Micropole vous aurez l'opportunit√© d'intervenir sur des projets data innovants, riches et vari√©s et participerez activement au rayonnement de l'agence sur le bassin niortais.Dans vos missions quotidiennes , vous serez amen√©(e) √†:Participer au recueil des besoins des m√©tiers ;R√©diger les dossiers de conception technique ;Mod√©liser les entrep√¥ts de donn√©es ;D√©velopper des flux de donn√©es via des ETL,Concevoir des tableaux de bord via des outils de reporting et datavisualisation ;Accompagner la ma√Ætrise d‚Äôouvrage dans la validation de livrables, les tests, l‚Äôassistance √† la recette et la conduite du changement sur le projet. Profil Vos Comp√©tences TechniquesVous ma√Ætrisez la manipulation des donn√©es (pr√©paration, mod√©lisation, restitution),Vous ma√Ætrisez parfaitement au moins un ETL du march√© (Informatica, Talend, BigQuery, Datafactory,...) et la cr√©ation de tableaux de bord (Power BI, Tableau, QlikSense, SAP BO, ...),Python ou SQL n‚Äôont plus de secrets pour vous,Vos atouts :Dipl√¥m√©(e) d‚Äôune formation sup√©rieure en Informatique parcours BI, Data, Aide √† la D√©cision,Vous poss√©dez une exp√©rience d'au moins 3 ans dans la fonction,Votre esprit d‚Äôanalyse, de synth√®se, votre organisation et vos capacit√©s r√©dactionnelles sont souvent reconnus,Vous appr√©ciez travailler en √©quipe, dans un contexte multi-projets.DEVENIR #INNOVATIVE PEOPLE C‚ÄôEST‚ÄØ: Int√©grer une communaut√© de 1200 experts passionn√©s r√©partis entre la France, la Belgique, le Luxembourg, la Suisse, l‚ÄôEspagne et la Chine.Construire ensemble les solutions strat√©giques et innovantes de demain pour accompagner nos clients dans leur transformation data et digitale.Participer au d√©veloppement de nos 4 centres d‚Äôexcellences cloud‚ÄØ: AWS, Microsoft, Salesforce, GCP. Evoluer continuellement au travers de formations et de certifications sur les plus grandes technologies gr√¢ce √† Micropole Campus.S‚Äôassurer d‚Äôune innovation continue gr√¢ce √†‚ÄØ: Notre √©cosyst√®me de partenaires technologiques Notre acc√©l√©rateur de start‚Äôup databoost‚ÄôR Nos lieux d‚Äôinnovations ¬´ innovativeSpaces ¬ª et de co-construction avec les clients Notre management par les talents naturels La Vie Chez Micropole, C‚Äôest‚ÄØUne vie interne rythm√©e pour se familiariser √† la culture d‚Äôentreprise et aux valeurs de Micropole‚ÄØ; Des √©v√®nements internes r√©guliers pour partager les connaissances aussi bien techniques que fonctionnelles‚ÄØ; Une politique de formation attractive et √©clectique (certifications prises en charge) ; Un travail en √©quipe valoris√© pour une meilleure coh√©sion‚ÄØ; La participation √† des projets internes sur la base du volontariat. Processus De Recrutement‚ÄØChez Micropole, le processus de recrutement est r√©actif et transparent.Si votre profil correspond √† nos attentes, vous √™tes recontact√©(e)s dans les 72 heures qui suivent votre candidature par nos Talent Specialist en r√©gion pour un premier √©change t√©l√©phonique puis un entretien est planifi√© avec l'un d'entre eux sur site √† distance,  Vous rencontrez le Manager de l‚Äô√©quipe Data de Niort pour un second entretien. MICROPOLE GRAND-OUESTMicropole Grand Ouest regroupe les agences de Nantes, Niort, Rennes. Avec un d√©veloppement rapide sur le Data, le Digital et Cloud, les √©quipes portent l‚Äôensemble de la proposition de valeur du Groupe.Pr√©sent au plus pr√®s de l‚Äô√©cosyst√®me de partenaires, de r√©seaux professionnels et d‚Äôacteurs du d√©veloppement √©conomique, nous accompagnons nos clients des secteurs de l‚Äôassurance-banque, du retail, de l‚Äôagro-alimentaire, de l‚Äôindustrie et du public dans leur transformation data et digitale, notamment au travers de m√©thodologies innovantes comme le Datathinking¬Æ ou Lego Serious Play¬Æ.L‚Äôagence Grand Ouest, sous l‚Äôimpulsion de sa Directrice d‚ÄôAgence, Adeline Chaye, investit et met en place des m√©thodes, comp√©tences et expertises pour le d√©veloppement d‚Äôun num√©rique responsable au sein des organisations.√Ä PROPOS DU GROUPE MICROPOLEGroupe international de conseil et technologies innovantes, MICROPOLE est sp√©cialis√© dans les domaines de la Data & Digital. Depuis ses 14 agences situ√©es en Europe et en Chine, les 1100 #INNOVATIVE PEOPLE du Groupe (consultants, data scientists, architectes IT, experts m√©tiers, ing√©nieurs, UX designers‚Ä¶) accompagnent leurs clients partout dans le monde sur l'ensemble des phases de leurs projets, du conseil √† leur r√©alisation, et sur la conduite du changement.MICROPOLE r√©alise 35% de son chiffre d‚Äôaffaires √† l‚Äôinternational et est cot√© sur le march√© Eurolist compartiment C d‚ÄôEuronext Paris, segment Next Economy.Pour en savoir plus‚ÄØ: https://www.linkedin.com/company/micropole/mycompany/Mot du manager Dans une ambiance familiale, rejoignez notre agence d'experts et de consultants (Digital & Data) en plein centre de Niort et devenez √† votre tour un acteur incontournable de la r√©ussite des projets de nos clients !


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau', 'Power BI'], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Viz Engineer H/F,METEOJOB by CleverConnect,"Brest, Brittany, France",https://fr.linkedin.com/jobs/view/data-viz-engineer-h-f-at-meteojob-by-cleverconnect-3805814276?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=Sg3d0SEpl8Y5ejoqBCIcMQ%3D%3D&position=6&pageNum=11&trk=public_jobs_jserp-result_search-card,"EntrepriseChez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent √† construire un avenir plus s√ªr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L'intelligence humaine est le moteur derri√®re la technologie qui fait la renomm√©e de Thales. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour r√©pondre aux besoins actuels et futurs de nos clients, nous ma√Ætrisons plus d'une centaine de disciplines, de l'optique √† la physique quantique, du traitement du signal √† la connectivit√© et √† l'intelligence artificielle. Rejoindre Thales, c'est repousser les limites de la technologie et la mettre au service du progr√®s et du d√©veloppement durable de nos soci√©t√©s. C'est donc √™tre au c≈ìur d'une formidable aventure technique. Une attention port√©e √† l'√©quilibre des collaborateurs au service de leur r√©ussite. C'est pourquoi, notamment, nous nous effor√ßons de cr√©er un environnement de travail accueillant et d'accorder la flexibilit√© n√©cessaire √† l'√©quilibre entre vie professionnelle et vie personnelle. Nous savons que cet √©quilibre est essentiel √† votre √©panouissement et √† la r√©ussite des projets que nous vous confierons. Des parcours professionnels riches. Chez Thales, nous jouons collectif. Ce qui signifie travailler en √©quipe, c√¥toyer des experts et donc apprendre et d√©velopper ses comp√©tences en permanence tout en faisant b√©n√©ficier le Groupe de son savoir-faire. C'est aussi la possibilit√© d'√©voluer, de changer de fonction ou d'activit√©, voire de pays.Description Du PosteQUI SOMMES-NOUS ?Thales propose des syst√®mes d'information et de communication s√©curis√©s et interop√©rables pour les forces arm√©es, les forces de s√©curit√© et les op√©rateurs d'importance vitale. Ces activit√©s, qui regroupent radiocommunications, r√©seaux, syst√®mes de protection, syst√®mes d'information critiques et cybers√©curit√©, r√©pondent aux besoins de march√©s o√π l'utilisation des nouvelles technologies num√©riques est d√©terminante. Thales intervient tout au long de la cha√Æne de valeur, des √©quipements aux syst√®mes en passant par le soutien logistique et les services associ√©s.Nos √©quipes de l'activit√© Syst√®mes d'information critiques et cybers√©curit√© fournissent des services et des solutions globales optimisant la performance, la r√©silience et la s√©curit√© des syst√®mes d'information afin de faire face aux ruptures technologiques et aux cybermenaces.L'√©quipe de la BI Factory recherche un(e) Data Viz Engineer (H/F)QUI ETES-VOUS ?De formation Ing√©nieur ou Bac +5 (√©cole d'ing√©nieur ou Universit√©), vous justifiez d'une exp√©rience professionnelle dans le monde de la DataViz / BI d'au moins 3 ans autour des solutions Qlik ou Power BI.Vous souhaitez mettre √† disposition votre expertise dans le monde de la Data et continuer √† d√©velopper vos comp√©tences dans les aspects : Big Data, Data valorisation, Data Vizualisation, Data engineering et/ou Data Science et √™tes dot√© d'un bon relationnel.Vous √™tes pragmatique, curieux et organis√© et aimez le travail bien fait.Vous √™tes autonome, capable de travailler dans un environnement en √©volution permanente et avez le sens du service (engagement et livraison)Vous √™tes familier avec les pratiques agiles.Votre niveau d'anglais vous permet de r√©diger des documents ou d'animer des r√©unions en anglais par t√©l√©phone/visio dans un contexte international.Vous vous reconnaissez ?Ce Que Nous Pouvons Accomplir EnsembleLe domaine de la Data est devenu aujourd'hui un enjeu majeur dans la strat√©gie des entreprises et leur transformation digitale. C'est pourquoi nous r√©pondons aux besoins de nos client en leur offrant des solutions high-tech reposant d'une part sur notre connaissance des m√©tiers, et d'autre part sur notre capacit√© d'innovation et notre savoir-faire autour de la Data (collecte, traitement, analyse, valorisation).Vous serez int√©gr√©(e) dans le centre de comp√©tences ¬´ Augmented Data ¬ª de Brest, au sein de l'√©quipe BI Factory.La BI Factory, c'est une √©quipe d√©di√©e agile √† taille humaine qui adresse les besoins Data Vizualisation & Business Intelligence au sein du Groupe Thales et √©galement pour nos clients hors Groupe.Vous interviendrez sur une diversit√© de projets de d√©veloppement de syst√®mes d'information de nos clients locaux, mais aussi nationaux (domaines D√©fense, Banque, Assurance, Energie).Au Sein De Ce Centre, Vous Rejoindrez Notre √âquipe De Data Engineers, Data Architects Et Data Scientistes Install√©e √† Brest. Data Viz Engineer, Vous Vous Verrez Confier Les Missions Principales Suivante Mener des ateliers de cadrage avec les utilisateurs finaux afin de recueillir tout d'abord leurs besoins puis ensuite leur pr√©senter votre travail, Participer √† la conception de l'architecture g√©n√©rale des syst√®mes d√©cisionnels de nos clients, √ätre force de proposition et orienter les choix techniques en fonction de votre exp√©rience et de la politique technique du groupe, Impl√©menter les solutions valid√©es par nos clients, Etre le garant de la qualit√© technique des solutions produites et du respect de l'architecture initiale, Contribuer au sein du d√©partement √† l'effort d'animation technique, de veille technologique et d'innovation au sein des groupes de travail mis en place, Partager vos connaissances au sein de la communaut√© BI Thales en pr√©sentant vos exp√©riences sur vos travaux r√©cents et approches innovantes.Nous Vous Offrons Une diversit√© de projets vous permettant de d√©couvrir plusieurs environnements techniques et fonctionnels ainsi que l'ensemble de nos m√©tiers au sein du groupe Thales, Des conditions de travail motivantes et un plan de carri√®re personnalis√© offrant de r√©elles perspectives d'√©volution, La possibilit√© de vous investir dans une entreprise dont la r√©putation est mondiale avec des ambitions constantes d'innovations techniques, Un cadre de travail privil√©gi√© dans des bureaux situ√©s √† un endroit dynamique du port de commerce de Brest, La possibilit√© de t√©l√©-travailler jusqu'√† 10 jours par mois.Nous sommes toujours en phase ? Alors n'attendez plus, rejoignez-nous ! Thales reconna√Æt tous les talents : la diversit√© est notre meilleur atout. Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd'huiLe poste pouvant n√©cessiter d'acc√©der √† des informations relevant du secret de la d√©fense nationale, la personne retenue fera l'objet d'une proc√©dure d'habilitation, conform√©ment aux dispositions des articles R.2311-1 et suivants du Code de la d√©fense et de l'IGI 1300 SGDSN/PSE du 09 ao√ªt 2021.Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd'hui.
      

        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Power BI'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer GCP (F/H),Apside,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-gcp-f-h-at-apside-2902806697?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=wZ1Qg1H5dEplHh%2BPBVhM0A%3D%3D&position=7&pageNum=11&trk=public_jobs_jserp-result_search-card,"Envie de rejoindre une entreprise apprenante ? Engag√©e pour t‚Äôaccompagner dans ton √©volution professionnelle et dans tes projets personnels ?Rejoins Apside pour travailler sur les projets de demain !Le poste ?Pour le compte de notre client acteur mondial de la beaut√© et cosm√©tique, tu interviendras dans la transformation d‚Äôun projet worlwide, o√π tu devras d√©velopper la Data Platform et l'ensemble des services Data qui seront expos√©s aux diff√©rentes √©quipes du client. Aussi, tu seras amen√© √† d√©velopper des use cases data. Dans ce sens, tes missions seront les suivantes : Designer l'architecture et d√©velopper la solutionD√©finir et d√©velopper les Data Model√ätre garant de la qualit√© du code√ätre DevOps (Utilisation/mise en place de chaine CI/CD et support niveau L3 des d√©veloppements)Environnement technique :GCP (BigQuery, Cloud Run, Cloud Build)SQL PythonDevOps (Github)API DevelopmentTerraformM√©thodologie AgileToi ? Tu as d√©j√† travaill√© sur Google Cloud Platform (GCP) ?Tu es autonome, rigoureux, et bon communiquant ? Tu souhaites participer √† un projet d‚Äôenvergure associant cloud et Big Data ? Et la suite ?Tu rencontres d‚Äôabord l‚Äô√©quipe RH pour parler de tes attentes, ton projet, ton futur ! Puis les managers pour parler concret : missions, projets, parcours de carri√®re, et bien s√ªr salaire et avantages J Et tu discutes avec un de nos Tech Leads, pour √©valuer tes comp√©tences/ te challenger.Les infos en plus !T√©l√©travail ! üòäUn salaire attractif en fonction de ton exp√©rience + diff√©rents avantagesUn groupe en pleine croissance avec un management bienveillantEt une √©volution personnalis√©e avec la possibilit√© de se former via une plateforme interneTu souhaites donner un nouvel √©lan √† ta carri√®re ? Rejoins la vie Apsidienne !Pour en savoir plus √† www.apside.com


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': ['Terraform'], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer - Toulouse H/F,Expleo Group,"Haute-Garonne, Occitanie, France",https://fr.linkedin.com/jobs/view/data-engineer-toulouse-h-f-at-expleo-group-3803168961?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=f%2B5PD5xg2nvPqFHmfBYfzQ%3D%3D&position=9&pageNum=11&trk=public_jobs_jserp-result_search-card,"En savoir plus  Soyez vous-m√™me.  Devenez qui vous voulez. Acteur mondial de l‚Äôing√©nierie, de la technologie et du conseil, Expleo accompagne des entreprises reconnues dans leur innovation afin d‚Äôacc√©l√©rer leur r√©ussite.Nous nous appuyons sur plus de 40 ans d‚Äôexp√©rience dans le d√©veloppement de produits complexes, l‚Äôoptimisation des processus de fabrication et la performance des syst√®mes d‚Äôinformation.Notre exp√©rience sectorielle nous permet d‚Äôapporter √† nos clients une expertise approfondie propre √† stimuler l‚Äôinnovation √† chaque √©tape de la cha√Æne de valeur.Le groupe r√©alise un chiffre d‚Äôaffaires annuel de plus d‚Äôun milliard d‚Äôeuros. Expleo  est un groupe responsable qui s‚Äôengage √† placer l‚Äô√©thique et la diversit√© au centre de ses pratiques, ainsi qu‚Äô√† ≈ìuvrer pour une soci√©t√© plus durable et plus s√ªre.Chez Expleo, √©panouissez-vous au c≈ìur d‚Äôune communaut√© de 19 000 collaborateurs hautement qualifi√©s qui fournissent des solutions √† forte valeur ajout√©e dans 30 pays.Nos postes sont accessibles aux personnes en situation de handicap.Pourquoi nous rejoindre ? Un accompagnement technique sur le terrain  Des formations continues via nos experts techniques  Des valeurs humaines entre nos collaborateurs  La diversit√© de nos √©quipes  Une mont√©e en comp√©tences tout au long de sa carri√®re  Travailler sur des projets de grandes ampleurs  Mission Notre offre ?Au sein du d√©partement Digital & Emerging Technologies, vous accompagnerez nos clients sur les enjeux li√©s √† la Data et √† la mise en production de solutions innovantes en travaillant en √©quipe selon la m√©thode Agile.Localisation ?L‚Äôopportunit√© se situe √† Toulouse (31).Votre r√¥le ?  Concevoir et optimiser des solutions de pipelines de donn√©es (On-Premise, Hybrid, Cloud)  R√©aliser des audits d‚Äôarchitecture data et des pr√©conisations d‚Äô√©volution  Participer aux d√©veloppements techniques  R√©pondre aux enjeux vari√©s autour de la donn√©e (cr√©ation/migration de datalakes, Move-to-cloud, industrialisation de produits de data science...)  Assurer le reporting technique du projet au client  R√©aliser une veille technologique afin de proposer des solutions innovantes  Accompagner des ing√©nieurs Data juniors dans leur mont√©e en comp√©tences  Profil Qui √™tes-vous ?Dipl√¥m√©(e) d‚Äôune formation sup√©rieure (Bac +5), vous avez une premi√®re exp√©rience significative (3 ans exp hors √©tudes).Vos comp√©tences ?  Expert(e) d'un ou de plusieurs langages suivants : Python, SQL, Java, Scala  Connaissance d'au moins un Cloud Provider : GCP, AWS, Azure, Snowflake, etc  Connaissance du management de bases de donn√©es (SQL, NoSQL) et de l'√©cosyst√®me BigData  Connaissance des principes et des √©l√©ments de Hadoop (HDFS, Hive, HBase), d'Apache Spark et/ou de Kafka  Connaissance des principes du CI/CD (ex : Git)  Connaissances des outils de virtualisation, de conteneurisation (Docker) et d'orchestration (Kubernetes)  Int√©r√™t pour les architectures microservices (REST API's)  Anglais courant Quels sont nos avantages ? Politique interne sur le t√©l√©travail  CSE  13 RTT  Tickets restaurant  Pr√©voyance Sant√©  Compte Epargne temps  Prime de vacances  Prime de cooptation Quel est notre process de recrutement ?Vous √™tes contact√© par un sp√©cialiste du recrutement lors d‚Äôun √©change t√©l√©phonique.√Ä la suite de cela, nous organisons un entretien √† la fois technique et RH.Une d√©cision peut √™tre prise d√®s cet entretien pour une embauche.Quoi qu‚Äôil arrive, vous aurez un retour de notre part.Vous souhaitez en savoir plus sur nos activit√©s =>  EXPLEOLa localisation des postes n‚Äôest qu‚Äôindicative, une mobilit√© g√©ographique sur le territoire national peut √™tre requise si la mission client le n√©cessite ou si une nouvelle mission est propos√©e . A bient√¥t dans nos √©quipes !  üòä


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R'], 'DataBase': ['SQL', 'NoSQL', 'HBase'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': ['HBase'], 'Automation': ['Kubernetes'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
Data Engineer (Snowflake),MindPal,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-snowflake-at-mindpal-3783808070?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=50%2BxtdahCBGnGKvUc1fENQ%3D%3D&position=10&pageNum=11&trk=public_jobs_jserp-result_search-card,"We are looking for experienced Data Engineers with knowledge of Snowflake platform.ResponsibilitiesCreating and managing data in the Snowflake environment Designing and implementing ETL (Extract, Transform, Load) solutions for transferring data between various sources and platforms Optimizing the performance of Snowflake databases, including designing and implementing data structures and using indexes appropriately Automating data processing workflows using tools such as Airflow or other workflow management tools Deploying and configuring tools to monitor and report on the performance of the Snowflake system RequirementsMinimum 1 year of experience as a Data Engineer Ability to use Snowflake Very good knowledge of SQL and programming in Python Ability to work with databases, including the Snowflake platform Knowledge of ETL tools and data integration Ability to work in a team and good communication skills Fluent English in speaking and writing We OfferB2B contract type Full-time job Remote and flexible working hours


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': ['Snowflake'], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Embedded Software Engineer,5V Tech,"St.-Marcellin, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/embedded-software-engineer-at-5v-tech-3796385518?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=tP4ELVVmTZhVTBxGq5eJ%2FQ%3D%3D&position=11&pageNum=11&trk=public_jobs_jserp-result_search-card,"Embedded Software Engineerüìç St.-Marcellin, Near Grenoble - FranceüìÑ CDI, Permanent positionüí∂ UP TO ‚Ç¨70,000 Per Year Salary üè° Hybrid Working FlexibilityThis company is a French multinational that designs and manufactures digital building infrastructure systems, including smart lighting control, power management, climate automation, and wireless gateways.They are searching for a Senior Embedded Software Engineer to join their dynamic R&D team (near Grenoble) to take a vital role in the design, development, and integration of software for connected products running Embedded Linux on STM32 and nRF MCUs with BLE, Matter, Wi-Fi, Thread, Zigbee, and 5G connectivity options.This will provide the opportunity to make your mark on the connected device industry and provide cutting-edge solutions for new intelligent commercial spaces.You Will Be...¬∑ Creating functional and technical specifications of Embedded Software;¬∑ Designing, Developing, and Integrating Embedded Software for Embedded Linux systems, including wireless protocol stacks for BLE, ZigBee, Matter, Thread, etc;¬∑ Focusing on Cybersecurity and Quality adherence in software development;¬∑ Working with groups from France, Germany, and Australia.If You Have...¬∑ Strong experience in Embedded Software Development for Embedded Linux environments;¬∑ An affinity for C and modern C++ versions...¬∑ Experience developing software for wireless systems and integrating relevant protocol stacks; - This is very nice to haveThen this could be just the opportunity for you! APPLY NOW to discuss further.5V Tech are acting as an Employment Agency for the purposes of this job vacancy. We offer a reward scheme if you can recommend someone for this position, up to ¬£250 for you and an additional ¬£250 to a charity of your choice, 5V Tech are recognised talent solutions experts within IoT and Deep Tech working across Europe, the UK, and North America.


        Show more

        


        Show less","{'ProgLanguage': ['C++', 'R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': ['Linux'], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer- F/H - Comptabilit√© (H/F),Seyos,"Nantes, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-comptabilit%C3%A9-h-f-at-seyos-3801396458?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=VHte5aDdp8r3XO21k2uThg%3D%3D&position=12&pageNum=11&trk=public_jobs_jserp-result_search-card,"Cette offre d‚Äôemploi est fournie par P√¥le emploi DescriptionDescriptif du poste: Notre client est un groupe comptable international qui a √©t√© fond√© il y a plus de six d√©cennies. En France, notre client dispose d'un r√©seau de 16 agences couvrant l'ensemble du pays. L'objectif de notre client est de standardiser son infrastructure √† l'√©chelle nationale. Chiffres cl√©s : - 1200 Collaborateurs en France et 110 sur l'agence de Nantes - 135 millions de CA en France et 6 millions pour l'agence de Nantes - 6 groupe comptable mondiale Le p√¥le conseil assiste une client√®le vari√©e, compos√©e de PME et d'ETI, qu'elles soient fran√ßaises ou internationales (dans des secteurs tels que le Retail, l'√ânergie, le Private Equity, l'Industrie, la Sant√©, les Services, etc.). Dans le cadre du d√©veloppement de son activit√©, notre client recherche un Ing√©nieur Data - H/F Vos missions : - Examiner la qualit√© des donn√©es et des processus en collaboration avec les Data Analysts. - Conception et am√©lioration des flux de donn√©es et de traitements d'information - Mise en place d'un Datalake Environnement technique : Python, Spark, SQL, Azure (data factory), AWS (S3, Athena, Redshift), Localisation : Nantes (Saint-Herblain) R√©mun√©ration : 40 000 - 50 000 Euros selon profil T√©l√©travail : 2 jours Les avantages : - 13 mois - 13 jours de RTT - Tickets Restaurant (60% de prise en charge) - Mutuelle - Participation au Transport - Horaires flexibles Profil recherch√©: - Vous avez une Premi√®re exp√©rience r√©ussie sur un poste similaire - Vous √™tes curieux(se), organis√©(e), autonome, rigoureux(se) et poss√©dez un bon relationnel - Vous ma√Ætrisez le langage de programmation Python - Vous avez des connaissances Big DataPROFIL SOUHAIT√âExp√©rienceExp√©rience exig√©e de 2 An(s)Source: Pole emploi (https://www.pole-emploi.fr)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
DATA ENGINEER (F/H),METEOJOB by CleverConnect,"Saint-Herblain, Pays de la Loire, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-meteojob-by-cleverconnect-3805843296?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=HXBu%2F3gjooMt6oq7eehpEw%3D%3D&position=13&pageNum=11&trk=public_jobs_jserp-result_search-card,"EntrepriseExpectra, leader en France de l'int√©rim sp√©cialis√© et du recrutement en CDI de cadres et agents de ma√Ætrise.Les consultants du D√©partement Informatique - Infog√©rance vous proposent des opportunit√©s de carri√®re. Nous recherchons pour le compte de notre client, expert en audit, conseil (IT, RISK, industrie...), expert comptable, DATA ENGINEER (F/H) dans le cadre du d√©veloppement d'un p√¥le conseil BI.Pourquoi rejoindre cette entreprise ?Rejoindre cette entreprise, c'est s'engager aupr√®s d'une organisation √† taille humaine qui valorise le bien-√™tre de ses salari√©s ainsi que leur √©volution professionnelle.Description Du PostePr√™t(e) √† relever de passionnants challenges en tant que Data Engineer (F/H) au sein d'un nouvel √©tablissement ?Rejoignez notre client pour g√©rer et optimiser le flux des donn√©es, contribuez aux d√©veloppements de leurs clients tout en am√©liorant continuellement leurs processus.Vos Missions Seront Les Suivantes Audit de la qualit√© des donn√©es et des processus en relation avec les Data Analyst F/H Conduite de la gestion du produit : planification et animation Conception de l'architecture des flux de donn√©es et des traitements, ainsi que des optimisations pertinentes D√©veloppement des lacs de donn√©es : mise en ≈ìuvre des connecteurs, contr√¥les et transformations Encadrement et coaching des collaborateurs juniors.D√©couvrez Cette Offre All√©chanteContrat: CDIT√©l√©travail partiel possible 2 jours / semaineLe salaire est √† partir de 40 000 ‚Ç¨ par an et n√©gociable selon vos exp√©riences et comp√©tences.Description Du ProfilId√©alement dot√©(e) d'une formation big data et d√©cisionnel, de niveau BAC+5 et justifiant d'une premi√®re exp√©rience en ESN ou en entreprise, vous d√©tenez une expertise ing√©nierie data plus particuli√®rement sur les technologies Microsoft : Azure Synapse, Apache Spark, Azure Databricks, Azure Stream analytics ou encore Azure Data Factory . Vous aimez le travail en √©quipe et particuli√®rement au sein d'une √©quipe dynamique.Vous Ma√Ætrisez Id√©alement Les TechnologiesAmazon : S3, Athena, RedshiftLangages : SQL, Python, Spark (Python et SQL)
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer AWS,Apside,"La Garenne-Colombes, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-aws-at-apside-3798361466?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=rejKmmrkzdqXahOj%2FdjMVQ%3D%3D&position=14&pageNum=11&trk=public_jobs_jserp-result_search-card,,"{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark', 'Databricks'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
"Data engineer ‚Äì Paris, France (H/F)",Astek,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-%E2%80%93-paris-france-h-f-at-astek-3779836007?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=kE9eYBPgPKtzRTC3kSWkeQ%3D%3D&position=15&pageNum=11&trk=public_jobs_jserp-result_search-card,"CDIParis - FrancePubli√©e il y a 2 moisCe Que Nous Pouvons Accomplir Ensemble :Venez rejoindre l‚Äô√©quipe digital et data, en tant que  Data  Engineer (H/F ) et intervenez sur nos projets d‚Äôinnovation dans le secteur financier !Votre mission (‚Ä¶si vous l‚Äôacceptez !) : D√©veloppement de la collecte, pr√©-traitements, stockage, mod√©lisation, monitoring et transformation de donn√©es.  Participation √† la mise en place des normes de d√©veloppement (GitFLow)  Administration Hadoop/Hive  D√©veloppement des producers et consumers Kafka  M√©thodologie Agile : Travailler en conformit√© avec la m√©thodologie Agile en place.  Mise en place de la chaine CI/CD. Stack technique : Python, Hadoop, Hive, Kafka, Azure.Les Atouts Du Projet :Vous √©voluerez au sein d‚Äôune √©quipe agile, r√©active et d√©termin√©e.Vous :Vous √™tes issu(e)  d‚Äôune formation BAC + 5 type √©cole d‚Äôing√©nieur ou √©quivalent universitaire  et vous justifiez d‚Äôau moins 3 ans d‚Äôexp√©rience en tant que data engineer. Vous √™tes attir√©(e) par le challenge technologique, vous √™tes organis√©(e), autonome et bon communiquant. Une exp√©rience dans le secteur bancaire est un plus !Enfin, vous √™tes curieux et d√©termin√©(e) ! L‚Äôinformatique est une passion pour vous plus qu‚Äôun m√©tier !NOUS ?Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 7200 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde et ayant r√©alis√© un chiffre d‚Äôaffaires de 500 M‚Ç¨ en 2022.‚ú® Tous les d√©tails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : blog.groupeastek.com.Rencontrons-nous !Vous vous √™tes reconnu sur l‚Äôannonce et Astek vous pla√Æt ?Lindsey, votre talent acquistion, vous contactera pour en savoir plus sur vous !Alors, on tente l‚Äôaventure ?Caract√©ristiques de l'emploiCat√©gorie ConsultantPostuler en ligneNom *Pr√©nom *Email *Un email valide est requis.T√©l√©phone *Un num√©ro de t√©l√©phone valide est requis.Joindre un CV *Vous :Vous √™tes issu(e)  d‚Äôune formation BAC + 5 type √©cole d‚Äôing√©nieur ou √©quivalent universitaire  et vous justifiez d‚Äôau moins 3 ans d‚Äôexp√©rience en tant que data engineer. Vous √™tes attir√©(e) par le challenge technologique, vous √™tes organis√©(e), autonome et bon communiquant. Une exp√©rience dans le secteur bancaire est un plus !Enfin, vous √™tes curieux et d√©termin√©(e) ! L‚Äôinformatique est une passion pour vous plus qu‚Äôun m√©tier !NOUS ?Cr√©√© en France en 1988, Astek est un acteur mondial de l‚Äôing√©nierie et du conseil en technologies, pr√©sent sur les 5 continents. Fort de son expertise dans de nombreux secteurs industriels et tertiaires, Astek accompagne ses clients internationaux dans le d√©ploiement intelligent de leurs produits et de leurs services, et dans la mise en ≈ìuvre de leur transformation digitale.Depuis sa cr√©ation, le Groupe a fond√© son d√©veloppement sur une forte culture d‚Äôentrepreneuriat et d‚Äôinnovation, et sur l‚Äôaccompagnement et la mont√©e en comp√©tence de ses 7200 collaborateurs qui s‚Äôengagent chaque jour √† promouvoir la compl√©mentarit√© entre les technologies num√©riques et l‚Äôing√©nierie des syst√®mes complexes.Rejoignez un Groupe en fort d√©veloppement en France et √† travers le monde et ayant r√©alis√© un chiffre d‚Äôaffaires de 500 M‚Ç¨ en 2022.‚ú® Tous les d√©tails sur le Groupe sur le site astekgroup.fr. Et vous pouvez aussi nous suivre sur notre blog : blog.groupeastek.com.Rencontrons-nous !Vous vous √™tes reconnu sur l‚Äôannonce et Astek vous pla√Æt ?Lindsey, votre talent acquistion, vous contactera pour en savoir plus sur vous !Alors, on tente l‚Äôaventure ?


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': ['Hadoop'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Software Engineer - ProcessOut (Golang),Checkout.com,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/software-engineer-processout-golang-at-checkout-com-3796165620?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=uTzzpfhL%2BgZFbacSsY0z1A%3D%3D&position=16&pageNum=11&trk=public_jobs_jserp-result_search-card,"Company DescriptionCheckout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We‚Äôre the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Binance, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.We empower passionate problem-solvers to collaborate, innovate and do their best work. That‚Äôs why we‚Äôre on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we‚Äôre just getting started. We‚Äôre building diverse and inclusive teams around the world ‚Äî because that‚Äôs how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.Job DescriptionThe roleThis role will sit in the team responsible for maintaining and evolving a Payment Orchestration Platform called ProcessOut. This platform was acquired by Checkout.com in March 2020 and is already powering many large and famous brands like Glovo, NordVPN, and Bolt (with many more that we can‚Äôt name and even more to come).We are a self-sufficient team that operates in a fully agile way. We are supported by our very own Product and DevOps teams, and we build and evolve our product together.When it comes to technical stack, we are hosted in AWS, use EKS and our primary development language is Go. As we always strive to use the best tool for the job, we use a combination of Redis, DynamoDB and Postgres for the persistence layer, and REST, gRPC and queues for communication.We are experiencing constant growth in the number of handled transactions, new clients and integrations. That‚Äôs why we pay very close attention to the elegant design and scalability of the platform. We are looking for dedicated engineers who would like to join us on our journey.How You‚Äôll Make An ImpactWork together with other backend engineers and DevOps engineers on scaling our platform. Contribute to services and overall architecture by discussing, putting forward ideas on enhancements and actively contributing to our codebases. Cooperate with the Product team on designing, building and releasing new features. QualificationsWhat we‚Äôre looking for At least 3 years of software development experience, including at least 1 year with GoKnow your way around the web-related tech (HTTP, TLS, proxies, API conventions...)Worked with RESTful APIs and with gRPCExperience deploying applications as a part of a service-oriented architectureCurious and unafraid of digging deeper to understand how systems of all kinds workAdditional InformationApply without meeting all requirements statement If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.We believe in equal opportunitiesWe work as one team. Wherever you come from. However you identify. And whichever payment method you use.Our clients come from all over the world ‚Äî and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.When you join our team, we‚Äôll empower you to unlock your potential so you can do your best work. We‚Äôd love to hear how you think you could make a difference here with us.We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We‚Äôll be happy to support you.Take a peek inside life at Checkout.com viaOur Culture video https://youtu.be/BEwnpHuadSwOur careers page https://www.checkout.com/careersOur LinkedIn Life pages bit.ly/3OaoN1U Our Instagram https://www.instagram.com/checkout_com/


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': ['VPN'], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Senior Software Engineer (F/H),AXA en France,"Wasquehal, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/senior-software-engineer-f-h-at-axa-en-france-3798515116?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=ss6Ktty7V1EHg9BjQWqzqg%3D%3D&position=17&pageNum=11&trk=public_jobs_jserp-result_search-card,"Afin de renforcer ses √©quipes, AXA France recherche un Software Engineer Exp√©riment√© F/H.Vous int√©grerez des √©quipes organis√©es en features teams (dev, tech lead, testeurs, PO), qui utilisent √† la fois les m√©thodologies Agile Scrum et Kanban.Tous nos projets appliquent les principes du software craftsmanship (TDD, BDD, Code Legacy, Clean Code, Code reviews, automatisation, ...) permettant d'am√©liorer en continu la qualit√© des applications.ENVIRONNEMENT TECHNIQUE :ReactJSBackend √† partir de .NET Framework 4.7Microsoft AzureDevOps (CI/CD)Container + PaaSVous serez amen√© √† travailler sur des projets √† destination de nos assur√©s ou nos agents.Les sujets sont vari√©s et challengeant :Souscription multicanale permettant le d√©marrage du process en ligne et la finalisation optionnelle en agenceD√©claration de sinistres en ligne en selfcareMutualisation des contrats sur une seule plateformeS√©curisation d‚Äôapplications web et mobileEt autres...Responsabilit√©sAu sein d‚Äôune ¬´ squad ¬ª de 6 √† 8 d√©veloppeurs, votre mission consistera √† :D√©livrer des solutions op√©rationnelles et de qualit√© en respectant les principes d‚Äôarchitecture et les bonnes pratiques de d√©veloppement, de s√©curit√© et d‚ÄôUXRenforcer les comp√©tences d‚Äôing√©nierie de votre √©quipe gr√¢ce √† la pratique de revue de codes collectives, le partage des pratiques d‚Äôing√©nierie/Craft de la guilde de dev et la formationContribuer √† la culture Tech de la guilde de dev et √† l‚Äôinnovation AXA √† travers la veille technologique, les travaux de nos communaut√©s de pratique et les synergies avec des acteurs externes. QualificationsTitulaire de formation sup√©rieure en informatique7 ans d‚Äôexp√©rience minimum sur les technos .NET et React JSInt√©r√™t particulier pour les best practices (TDD, BDD, Clean Code‚Ä¶)Adepte du travail en √©quipeContribuer √† la transformation de notre entreprise o√π le client est au centre de nos enjeux est essentiel pour vous


        Show more

        


        Show less","{'ProgLanguage': ['R'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
QA Data Engineer (F/H),Hilti Group,"Boulogne-Billancourt, √éle-de-France, France",https://fr.linkedin.com/jobs/view/qa-data-engineer-f-h-at-hilti-group-3799264603?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=1S0arC%2F06hP10Tk3RDjQRA%3D%3D&position=18&pageNum=11&trk=public_jobs_jserp-result_search-card,"What's the role?We‚Äôre looking for a highly skilled QA Data Engineer who‚Äôll act as a testing specialist within the wider Marketing & Sales Data and Digital Impact Measurement team, ensuring the accuracy of our large-scale data pipelines. As a QA engineer you will play a central role in in crafting and defining our testing approach at a pivotal time for our digital strategy. Being part of the data infrastructure team focusing on building scalable data services and pushing towards innovation and impact in across our organization.Who is Hilti?If you‚Äôre new to the industry, you might not have heard of us. We provide leading-edge tools, technologies, software and services for the global construction sector. We have a proud heritage, built over 75 years, and a worldwide reputation for pioneering products and exceptional service. With 30,000 people in more than 120 countries we operate with a unique direct sales model and generate around 250,000 customer interactions every day.What does the role involve?You will be responsible for testing and ensuring the accuracy of key data platforms, services and pipelines used across Digital Marketing & Sales initiatives.Taking hands on part in code reviews and maintaining high quality data services that produce tangible business value.In this light, you will review requirements, specifications, and technical design implementations to provide timely and meaningful feedback while creating detailed, comprehensive, and well-structured test plans and test cases for our diverse data products. You will also estimate, prioritize, and plan testing activities to identify bugs by means of regression testing and monitoring. Overall, you will develop and execute automation scripts to identify, record, document thoroughly, and track results ensuring new and existing data products meet data quality expectations.We have more than 200,000 interactions with our customers every day. It‚Äôs how we get to know their businesses, understand their needs and develop the precise products and services that will help them.What do we offer?To further accelerate in digital marketing, we are building our Global Digital Hub in Paris. You will experience the agile mentality combining the stabilityof a sound business model and the working environment of an award-winning culture. You can make an impact from day one in an international and diverse team by shaping the future of digital at Hilti and revolutionize customer interactions. You‚Äôll be the owner of your professional development and will have the ownership to design your career map.Job benefits: From 60k to 82k‚Ç¨ package  25 vacation days + RTT  Childcare  Health insurance fully covered  Retirement plans What you need is: Min. 2-3 years of experience as a QA Engineer (preferably in automatisation using Python )  Experience with public cloud infrastructure (preferably AWS)  Experience in writing clear, concise, and comprehensive test plans and test cases (manual & test automation)  Hands-on experience with both white box and black box testing  Hands-on experience with automated testing tools  Good understanding of API based integration i.e. REST, XML, Microservices etc.  Ability to quickly understand domains and develop a test strategy.  Knowledge of agile methodologies and continuous delivery (including continuous deployment tools)  A problem solver, with an eye for detail and a keen focus on data quality.  Knowledge of structured or custom ETL/ELT management (Airflow, Luigi, etc.), including, ideally, solid understanding of the AWS cloud.  Knowledge of ‚ÄúBig Data‚Äù/NoSQL platforms and services (Druid, MongoDB, Kafka)  Fluency in English Why should you apply?We‚Äôre investing more than ever in our digital transformation. As a company whose lifeblood is innovation, we give our customers the next level of digital offerings on an impressive global scale! For you, it means unrivalled opportunities to work in a ‚Äòstart-up within‚Äô environment, develop an international career and really have an impact on the shape of things to come.During your interviews, you will meet several members of the digital team including leadership. This way you get to know more about us, and we get to know more about you.Tempted to apply? Click ‚Äúapply now‚Äù and send us your resume (English version) today!Do you want to know more? Go to https://careers.hilti.com/en/digital-marketingJoin us and #TransformDigital
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Scala', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL', ' MongoDB'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': ['Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Stage ‚Äì Data Engineer (H/F) ‚Äì Paris,Cr√©dit Agricole Technologies et Services,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/stage-%E2%80%93-data-engineer-h-f-%E2%80%93-paris-at-cr%C3%A9dit-agricole-technologies-et-services-3799016250?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=8kh%2BokaRsn3TXwcZWfzBHg%3D%3D&position=19&pageNum=11&trk=public_jobs_jserp-result_search-card,"A la recherche d‚Äôun stage de 6 mois √† partir de mars 2023 ?  NOUS REJOINDRE C‚ÄôEST ‚Ä¶ Int√©grer le partenaire IT des Caisses R√©gionales Cr√©dit Agricole, banques mutualistes et solidaires, B√©n√©ficier d'un parcours d'int√©gration d√©di√© aux √©tudiants et d'un accompagnement de proximit√©, Participer et √™tre moteur de projets riches et formateurs dans un cadre qui offre la libert√© d'innover, Evoluer dans une entreprise apprenante qui mise sur l'intelligence collective √† travers des formations, et des ateliers (th√©matiques d√©veloppement personnel, Tech ou M√©tier) tout au long de l'ann√©e Faire partie d‚Äôune entreprise humaine et inclusive qui met en place des actions concr√®tes en faveur de l'√©galit√© professionnelle et de la diversit√© (99/100 sur l‚Äôindex √©galit√© Femmes / Hommes en 2022), Travailler dans un environnement alliant modernit√© et bien-√™tre (espaces agiles et de cr√©ativit√©, t√©l√©travail (2 jours), engagements RSE) ; L‚Äô√©quilibre vie professionnelle/vie personnelle est un sujet au c≈ìur de notre politique RH, Faire partie de la communaut√© interne des Jeunes talents et profiter de nombreuses animations et de moments de partage avec les stagiaires et alternants CA-TS.   TA TEAM ET TES MISSIONS Tu rejoindras La squad Usage Data et IA ayant pour mission d‚Äôindustrialiser les cas d‚Äôusages Datascience en utilisant des mod√®les algorithmiques d‚ÄôIA avec l‚Äôaide de technologies avanc√©es et langages Big DATA.  Le sujet principal de ton stage est le suivant : participer √† l‚Äôindustrialisation d‚Äôun moteur de recommandation client bas√© sur l‚ÄôIA : Next Best Offer (NBO). NBO vise √† trouver la meilleure offre personnalis√©e pour un client en fonction de son profil, ses int√©r√™ts, son comportement, son historique bancaire, ses pr√©f√©rences.  Accompagn√©(e) de ta tutrice Clara, tes missions principales seront : Participer √† l‚Äôindustrialisation du moteur de recommandation : -Contribuer au d√©veloppement et √† l‚Äôindustrialisation des pipelines des traitements de pr√©-processing, d‚Äôentrainement, de pr√©diction et de post-processing,-Participer √† la mise en place de l‚Äôordonnancement des diff√©rents traitements, -Participer √† l‚Äôex√©cution des tests (test d‚Äôint√©gration, test unitaires),-Contribuer √† la r√©daction de la documentation,Participer √† la fabrication du monitoring de la solution (calcul de m√©triques et restitution). Environnement Tech Python -Numpy -Pandas -Matplotlib -Keras -Tensorflow -Pytest Pyspark Plateforme CDP Hive / HDFS Docker SQL (Teradata) Suite ELK Gitlab   TON PROFIL Tu es en formation informatique, ing√©nieur avec une sp√©cialit√© data & IA, Id√©alement, tu as une premi√®re exp√©rience (professionnelle ou projet scolaire) dans le domaine, Tu appr√©cies le travail en √©quipe et tu fais preuve de curiosit√©, Tu fais preuve d‚Äôautonomie et de rigueur, Tu es √† l‚Äôaise avec un mode de feedback r√©gulier sur tes activit√©s, ton ressenti.  EN TOUTE TRANSPARENCE ‚Ä¶ Ta candidature sera analys√©e par nos recruteuses et si cette derni√®re est retenue, tu seras contact√©(e) sous 10 jours pour un premier √©change RH t√©l√©phonique. Si cet entretien RH est concluant, tu rencontreras ton/ta futur(e) tuteur/tutrice pour un entretien plus op√©rationnel. Ainsi tu en sauras plus sur tes coll√®gues, tes missions et l‚Äôenvironnement technique li√©s au poste. Un bon moment pour poser tes questions !  Notre d√©lai moyen de retour apr√®s ton dernier entretien ? 2 semaines maximum   ET APRES TA FORMATION ? Chez CA-TS ton exp√©rience est gagnante-gagnante, nous voulons tout faire pour que tu continues l'aventure avec nous. Tu auras acc√®s en priorit√© √† nos offres disponibles en CDI.  Avec le temps et selon tes app√©tences, tu pourras continuer √† d√©velopper tes comp√©tences et connaissances, √™tre accompagn√©‚àôe ou accompagner (formations, int√©gration, mentorat/tutorat, actions marque employeur).


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['Pandas', 'NumPy', 'R'], 'BigData': ['Spark'], 'MachingLearning': ['TensorFlow', 'Keras'], 'DataView': ['Matplotlib'], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git', 'Docker'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker'], 'Collaboration': []}"
Data Engineer (F/H),LesJeudis,"V√©lizy-Villacoublay, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-f-h-at-lesjeudis-3788991516?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=8LoKSygyaNU9Uqk8l4jNrg%3D%3D&position=20&pageNum=11&trk=public_jobs_jserp-result_search-card,"QUI SOMMES-NOUS ?Au sein du site de V√©lizy, nos √©quipes hautement qualifi√©es con√ßoivent et produisent des amplificateurs de puissance (tubes √† ondes progressives, klystrons, gyrotrons, sous-syst√®mes pour les Grandes Infrastructures de Recherche, etc.) √† destination des march√©s D√©fense, S√©curit√©, Spatial et Scientifique. Chaque jour nos cadres, ing√©nieurs, techniciens et op√©rateurs mettent en commun leurs savoir-faire unique au service de l'innovation.QUI SOMMES-NOUS ?Thales est un leader mondial des hautes technologies comptant plus de 81 000 collaborateurs pr√©sents sur tous les continents. Le Groupe investit dans les innovations du num√©rique et de la""deep tech""- big data, intelligence artificielle, connectivit√©, cybers√©curit√© et quantique - pour construire un avenir de confiance, essentiel au d√©veloppement de nos soci√©t√©s, en pla√ßant l'humain au c≈ìur des d√©cisions. Thales propose des solutions, services et produits qui aident ses clients - entreprises, organisations, Etats - dans cinq grands march√©s vitaux pour le fonctionnement de nos soci√©t√©s : identit√© et s√©curit√© num√©riques, d√©fense, a√©ronautique, espace, et transport.QUI ETES-VOUS ?De formation Ing√©nieur ou Bac+5, Ecole d'ing√©nieur ou Universit√© vous justifiez d'une exp√©rience professionnelle d'au moins 4 ans.Comp√©tences TechniquesComp√©tences en d√©veloppement (Shell unix, Perl, PHP, Python, git, github)PostGreSQLPythonCe Que Nous Pouvons AccomplirensembleL'acc√©l√©ration de la transformation digitale des m√©tiers du Groupe s'appuie sur les actions suivantes :Construire une infrastructure technique performante et s√ªreMieux mobiliser nos ressources""Tech&Data""pour g√©n√©rer de la valeurGagner en agilit√© et en efficacit√© dans notre mani√®re de servir les m√©tiersProposer √† nos clients une meilleure exp√©rience num√©riqueVous serez int√©gr√© au sein d'une √©quipe agile et √† ce titre vous r√©aliserez la mission en collaboration avec les membres de l'√©quipe et dans les standards de d√©veloppement du groupe.A Ce Titre, Vous Serez En ChargeDu d√©veloppement de nouvelles fonctionnalit√©s sur la plateformeDu maintien en condition op√©rationnelle de l'application,De la mise en ≈ìuvre et l'√©vang√©lisation des bonnes pratiques de d√©veloppement au sein de l'√©quipe,De la r√©solution des recommandations d'architecture et de s√©curit√© sur la plateforme,De la mise en ≈ìuvre de pipeline de build, tests, d√©ploiementEn nous rejoignant, vous vous verrez confier les missions suivantes :Code pour en am√©liorer la qualit√©, la performance, la s√©curit√©, et la maintenabilit√©Bonnes pratiques en mati√®re de d√©veloppementFonctionnalit√©s compl√©mentaires permettant d'am√©liorer l'exp√©rience des utilisateurs finaux, en fonction de leurs besoins et retours d'exp√©rience.Recueil de l'existant : r√©cup√©ration, tests et mise en repository des codes / scripts / donn√©es utilis√©s dans les prototypesDocumentation du fonctionnement des prototypes : cin√©matique globale, description des fonctionsAm√©liorations (qualit√©, performance, s√©curit√©) sur les parties qui seront reprises des prototypesEvolutions fonctionnelles suite aux √©changes avec les utilisateurs finauxDesign de la solution tactique bas√©e sur les socles digitaux du groupe. Solutions de backup en cas de d√©lais sur la disponibilit√© des socles groupes.Tests unitaires et globauxConduite du changement des entit√©s internesSupport aux entit√©s internes / utilisateurs finaux sur l'exploitation de la solutionNous Vous OffronsUne diversit√© de projets vous permettant de d√©couvrir l'ensemble de nos m√©tiers,Des conditions de travail motivantes et un plan de carri√®re personnalis√© offrant de r√©elles perspectives d'√©volution,La possibilit√© de vous investir dans une entreprise dont la r√©putation est mondiale avec des ambitions constantes d'innovations techniques.Innovation, passion, ambition :rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd'hui.Innovation, passion, ambition : rejoignez Thales et cr√©ez le monde de demain, d√®s aujourd'hui.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': [], 'DevTools': ['Git'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Cloud Data Engineer - H/F,Devoteam G Cloud,"Lille, Hauts-de-France, France",https://fr.linkedin.com/jobs/view/cloud-data-engineer-h-f-at-devoteam-g-cloud-3801924922?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=IjWV73VGiNBqMK7hFXAmBw%3D%3D&position=21&pageNum=11&trk=public_jobs_jserp-result_search-card,"Tu auras pour mission d‚Äôaccompagner les grands comptes et les PME dans leurs transformation digitale par la mise en place de projets data avec Google Cloud Platform et l‚Äô√©cosyst√®me solutions open source associ√©.Int√©gr√©(e) √† une √©quipe d‚Äôexperts techniques, tu auras pour missions de :Analyser les besoins clientsAnimer des ateliers afin d‚Äô√©tudier et cadrer les besoins clientsPr√©coniser les solutions et architectures ciblesD√©finir les m√©thodologies de d√©ploiement et plans de migrationR√©diger les dossiers d‚Äôarchitecture et sp√©cifications techniquesConstruire les architectures de donn√©esConcevoir et mettre en place des syst√®mes de donn√©es r√©silients et s√©curis√©s (data warehouse, data lake, syst√®mes temps-r√©els)Construire et d√©ployer les pipelines de donn√©es (ETL / ELT)Assurer la migration des donn√©es vers les nouveaux environnementsAnalyser les donn√©esAnalyser les donn√©es sources afin d‚Äôidentifier et √©valuer des cas d‚Äôusage m√©tierMettre en oeuvre des outils de Business Intelligence et visualisation (Looker, DataStudio‚Ä¶)Accompagner et formerAssurer une veille technologique continue sur les solutions cloudAccompagner et former les √©quipes clients aux m√©thodes et concepts du cloudTu seras accompagn√©(e) en interne pour monter rapidement en comp√©tences sur GCP dans l‚Äôobjectif d‚Äô√©tendre tes certifications Google sur ta practice.Ton profilDipl√¥m√©(e) d'une √©cole d'ing√©nieurs ou d'un Master 2 en Informatique, tu disposes d'une exp√©rience significative (2 ans) au sein de projets Data : architecture, traitement ou analyse de donn√©es.Tu ma√Ætrises au minimum un langage de programmation appliqu√© √† l‚Äôanalyse de donn√©es (Scala, R, Python, Java).Tu as de bonnes comp√©tences dans l‚Äôarchitecture des syst√®mes, bases de donn√©es, m√©thodologies d‚Äôanalyse. Tu sais te rep√©rer dans le vaste √©cosyst√®me Data et tu sais notamment quelle brique utiliser en fonction des cas d‚Äôusages.¬†Tu es passionn√©(e) par la Business Intelligence, le Big Data, l‚ÄôInternet des objets (IoT) et le Machine LearningTu poss√®des la certification Google Cloud Platform - Professional Data EngineerTu as une solide compr√©hension de la dimension technique et fonctionnelle des projets ITCurieux(se), autonome et √† l‚Äô√©coute, tu poss√®des un r√©el esprit d‚ÄôanalyseTa ma√Ætrise de l'anglais te permettra de g√©rer des projets en contexte internationalLe Groupe Devoteam ≈ìuvre pour l'√©galit√© des chances, pour la promotion de ses collaboratrices et de ses collaborateurs au m√©rite et lutte activement contre toute forme de discrimination. Nous sommes persuad√©s que la diversit√© contribue √† la cr√©ativit√©, au dynamisme et √† l'excellence de notre organisation. Tous nos postes sont ouverts aux personnes en situation de handicap.


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'Java', 'Scala', 'R', 'Go'], 'DataBase': [], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Google Cloud Platform'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Analyst  - H/F,E.Leclerc,"Mont-de-Marsan, Nouvelle-Aquitaine, France",https://fr.linkedin.com/jobs/view/data-analyst-h-f-at-e-leclerc-3806613411?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=EbysG1l4x15Yc5jrc1TJzg%3D%3D&position=22&pageNum=11&trk=public_jobs_jserp-result_search-card,"DescriptionAu sein du service Data Management, situ√© √† Mont-de-Marsan (40), de la DSI du GALEC, vous serez en charge de mettre en ≈ìuvre des outils informatiques, des techniques et des m√©thodes statistiques pour permettre de contr√¥ler et analyser efficacement les donn√©es produits chez Leclerc et aider √† leur mise en qualit√©.A Ce Titre, Vos Principales Missions Seront DePiloter le projet de nouvelle brique d‚Äôanalyse pour l‚Äô√©quipe,Participer √† l‚Äô√©laboration des nouveaux outils pour la modernisation de l‚Äôactivit√© Data Management : outil de collecte, outil de contr√¥le qualit√©, outil de suivi des anomalie/des collectes, analyse, suivi contacts fournisseurs,Travailler avec l'√©quipe automatisation de la DSI pour simplifier, automatiser les process existants,Analyser les process existants et √™tre force de propositions pour des optimisations, simplifications ou automatisation n√©cessaires,Collaborer avec les diff√©rents p√¥les du service pour comprendre leurs besoins en mati√®re d'analyse de donn√©es et proposer des solutions appropri√©es,Concevoir, d√©velopper et maintenir des tableaux de bord et des rapports sur BO, Looker studio et tout autre nouvel outil,Travailler en collaboration avec les diff√©rents acteurs internes et externes au GALEC,Effectuer des analyses ponctuelles et approfondies li√©es aux probl√©matiques de qualit√© de donn√©es produits,Participer √† la conception et √† l'optimisation des architectures de donn√©es pour assurer la performance et la fiabilit√© des syst√®mes d'analyse,Mettre en ≈ìuvre des m√©thodes et outils d‚Äôanalyse de donn√©es avanc√©es pour analyser et interpr√©ter des ensembles de donn√©es complexes afin de d√©tecter les anomalies dans la qualit√© de donn√©es produits.ProfilDe formation bac + 5 universitaire ou ing√©nieur en Data Sciences (statistiques, IA), vous avez acquis une exp√©rience de 10 √† 15 ans dans l‚Äôanalyse de donn√©es. Une exp√©rience dans le domaine de la grande distribution serait un plus.Vous avez un esprit analytique, √™tes autonome, proactif(ve) et rigoureux(se).Vous avez une bonne communication √©crite et orale.Vous avez une approche proactive de la r√©solution des probl√®mes.En Termes De Comp√©tences Techniques, VousMa√Ætrisez les langages de type Python et des outils ou librairies facilitant l‚Äôanalyse de donn√©es,Ma√Ætrisez les bases de donn√©es SQL et NoSQL, Savez analyser flux JSON, utiliser des API externes, Savez concevoir et mettre en ≈ìuvre des mod√®les statistiques et des algorithmes pr√©dictifs,Avez une connaissance sur les outils BI et de datavisualisation. Nous recherchons des personnalit√©s dynamiques, sachant prendre des initiatives et qui souhaitent s‚Äôimpliquer dans les √©volutions de notre secteur et du mouvement. Il est important que nos candidats d√©montrent un r√©el engagement, des valeurs communes aux valeurs fortes port√©es par le mouvement Leclerc depuis sa fondation.Le sens du collectif, l'esprit de coh√©sion et d'√©quipe, la volont√© d'innover et de transmettre seront les √©l√©ments cl√©s de la r√©ussite de votre int√©gration.En rejoignant le Galec, vous pourrez valoriser et d√©montrer votre potentiel, d√©velopper vos comp√©tences et acqu√©rir une exp√©rience enrichissante, √† travers des passerelles entre les diff√©rents march√©s, m√©tiers et entit√©s du Mouvement !Mieux nous connaitreLe Mouvement E.LECLERC est un groupement coop√©ratif dont les adh√©rents sont les propri√©taires de magasins, soit 592 entrepreneurs, dont Michel-Edouard Leclerc est le porte-parole. Le Mouvement E.leclerc compte 133 000 collaborateurs, qui travaillent collectivement √† la r√©ussite de nos 721 magasins (hypers, supers et express), 690 Drives et 2 541 enseignes sp√©cialis√©es.Le Galec est l'entit√© au c≈ìur du syst√®me, c'est m√™me le r√©acteur ! Le Galec conjugue les talents d‚Äôune √©quipe de plus de 824 collaborateurs qui travaillent ensemble au service du front de vente omnicanal de l‚ÄôEnseigne, c‚Äôest-√†-dire les hyper/supermarch√©s, les magasins sp√©cialis√©s, le drive, le site marchand E.Leclerc et E.Leclerc relais.
      

        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': ['Tableau'], 'Statistics': [], 'CloudComputing': [], 'DevTools': [], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer Confirm√© (H/F),EXAKIS NELITE,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/data-engineer-confirm%C3%A9-h-f-at-exakis-nelite-3807583818?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=vabK3k47FyZ6q4zpETmsYA%3D%3D&position=23&pageNum=11&trk=public_jobs_jserp-result_search-card,"Exakis Nelite, entit√© du groupe Magellan Partners, est le premier partenaire pure-player Microsoft ind√©pendant en France avec l‚Äôambition de devenir le premier partenaire Europ√©en et en Afrique Francophone avec sa forte pr√©sence au Maroc.N√©s du rapprochement de 2 leaders sp√©cialistes de l‚Äôint√©gration des solutions Microsoft, nous allions expertise technique et fonctionnelle pour r√©pondre concr√®tement aux enjeux de demain : acc√©l√©ration de la transformation digitale, Cybers√©curit√©, Intelligence Artificielle, IoT, Data, transformation vers le cloud Azure, Services Cognitifs et Intelligence Artificielle‚Ä¶En rejoignant la communaut√© Exakis Nelite dans l‚Äôune de nos agences, repr√©sentant 650 collaborateurs, vous int√©grerez une √©quipe passionn√©e et impliqu√©e dans les projets les plus innovants. Vous rejoindrez une structure construite autour de valeurs tourn√©es vers ses collaborateurs : intelligence collective, convivialit√© et bienveillance.Exakis Nelite a re√ßu la certification Great Place to Work et se place 5√®me en 2023 parmi les entreprises o√π il fait bon travailler en France !Poste et missionsEn tant que Data Engineer confirm√©(e) vous serez responsable du d√©veloppement, de la gestion et de l'optimisation des solutions de donn√©es bas√©es sur la plateforme Azure pour r√©pondre auxbesoins m√©tiers du client :- Conception et d√©veloppement de solutions de donn√©es : concevoir, d√©velopper etmettre en ≈ìuvre des pipelines de donn√©es efficaces et √©volutifs sur la plateforme Azure, en utilisant des technologies telles qu'Azure Synapse et Azure Data Factory.- Optimisation des performances : assurer la performance, la fiabilit√© et lascalabilit√© des solutions de donn√©es existantes en optimisant les requ√™tes SQL, ensurveillant les performances et en mettant en ≈ìuvre des bonnes pratiques.- Collaboration avec l'√©quipe architecturale : travailler en √©troite collaboration avecl'architecte senior de la plateforme de donn√©es pour garantir l'alignement dessolutions de donn√©es avec la vision globale de l'architecture.- Gestion des donn√©es : Mettre en place des processus de gestion des donn√©es, ycompris la collecte, la transformation, le stockage et la distribution des donn√©es demani√®re s√©curis√©e et conforme aux r√©glementations en vigueur.- Documentation et bonnes pratiques : documenter les solutions de donn√©es, lesprocessus et les bonnes pratiques pour assurer la tra√ßabilit√© et la reproductibilit√© destravaux.- Veille technologique : rester √† jour avec les derni√®res avanc√©es technologiques dans ledomaine du Big Data et des technologies Azure pour continuellement am√©liorer les solutionsexistantes.Profil recherch√© - Au moins 5 d'exp√©rience en tant que Data Engineer, avec une expertise av√©r√©e dansl'√©cosyst√®me Azure.- Solide exp√©rience dans la conception et le d√©veloppement de pipelines de donn√©es avec Azure Synapse, Azure Data Factory, et Azure DevOps.- Ma√Ætrise des langages de requ√™te SQL et des comp√©tences en mod√©lisation de donn√©es.- Capacit√© √† travailler en √©quipe et √† communiquer efficacement avec des interlocuteurs m√©tiers.- Certification Azure (par exemple, DP203 Azure Data Engineer) serait un atout.Ce poste offre une opportunit√© passionnante de contribuer √† la transformation des donn√©es en utilisant les derni√®res technologies Azure. Vous serez au c≈ìur de la prise de d√©cision bas√©e sur les donn√©es et contribuera directement √† la r√©ussite du client.


        Show more

        


        Show less","{'ProgLanguage': ['Scala', 'R'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': [], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Consultant BI / Azure Data Engineer H/F,Talan,"Paris, √éle-de-France, France",https://fr.linkedin.com/jobs/view/consultant-bi-azure-data-engineer-h-f-at-talan-3797837777?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=mQ2RnHhjvdaqlkbnSgsUuw%3D%3D&position=24&pageNum=11&trk=public_jobs_jserp-result_search-card,"Talan est un cabinet de conseil en innovation et transformation par la technologie.Depuis 20 ans, Talan conseille les entreprises et les administrations, les accompagne et met en ≈ìuvre leurs projets de transformation et d‚Äôinnovation en France et √† l'international. Pr√©sent sur cinq continents, le groupe pr√©voit de r√©aliser un chiffre d'affaires de 600 millions d'euros en 2022 pour plus de 6000 consultant¬∑e¬∑s et vise √† d√©passer la barre du milliard d‚Äô‚Ç¨ de CA √† horizon 2024.Le Groupe met l'innovation au c≈ìur de son d√©veloppement et intervient dans les domaines li√©s aux mutations technologiques des grands groupes, comme le Big Data, l'IoT, la Blockchain et l'Intelligence Artificielle.Pr√©sent dans les √©v√©nements incontournables du secteur, comme Viva Technology, Talan prend r√©guli√®rement la parole sur les enjeux de ces technologies r√©volutionnaires aux c√¥t√©s d'acteurs majeurs du secteur et de parlementaires (Syntec Num√©rique, Forum de l'intelligence artificielle, French Fab Tour, Forum de Giverny‚Ä¶).Talan est une entreprise responsable, attach√©e √† la diversit√©. Des am√©nagements de poste peuvent √™tre organis√©s pour tenir compte des personnes en situation de handicap.Retrouvez nos engagementsRSEiciet nos actions en faveur de la diversit√©iciJob DescriptionVOTRE ROLE SUR NOS PROJETS :Vous interviendrez sur des projets de:Mise en place de Modern Data PlatformInterconnexion d‚Äôapplications op√©rationnelles en temps r√©elAu sein d‚Äô√©quipes projet, votre r√¥le sera de:Concevoir et mettre en place des flux d‚Äôint√©gration de donn√©esGarantir la qualit√© des d√©veloppementsR√©diger des sp√©cifications fonctionnelles et techniquesMod√©liser l‚Äôentrep√¥t de donn√©esMettre en place des solutions de suivi et pilotage des flux de donn√©esProposer des solutions d‚ÄôoptimisationMettre en place ou faire √©voluer des cha√Ænes CI/CDVOTRE ROLE CHEZ TALAN :Au sein du p√¥le Tech For Data, vous contribuerez √† la croissance et la prosp√©rit√© de la communaut√© au travers des activit√©s suivantes:Benchmark de solutions et conseil aupr√®s de nos clients sur les solutions technologiques √† adopter, en lien avec leurs besoinsR√©alisation de POC (Proof Of Concept)Partage de connaissances et formations internesPassage de certificationsVeille technologiqueParticipation √† la r√©daction de r√©ponse √† appel d‚ÄôoffreQualificationsDipl√¥m√© d‚Äôun Bac+5 en informatique/data, vous justifiez d‚Äôune exp√©rience d‚Äôau moins 3 ans sur des probl√©matiques d‚Äôint√©gration, traitement et mise en qualit√© de donn√©es en ayant mis en ≈ìuvre des flux de donn√©es sur AZURE (la ma√Ætrise d‚Äôautres solutions de traitement de donn√©es est un plus).Vous avez une premi√®re exp√©rience dans des environnements incluant entre autres Azure Data services :Azure Data FactoryAzure SQLAzure Synapse (sql pool, spark pool)Azure blob storageAzure DatalakesStream AnalyticsEventHubVous ma√Ætrisez les concepts de mod√©lisation de donn√©es et les architectures de type DataLake, DWH, Datamarts (la connaissance de la mod√©lisation Datavault est un plus).Vous savez √©voluer dans un environnement avec un mod√®le de donn√©es complexe et √©volutif.Vous disposez d‚Äôun tr√®s bon relationnel et vous √™tes reconnu pour votre capacit√© √† √©voluer efficacement avec des interlocuteurs aussi bien techniques que non-techniques.Force de proposition, vous savez mobiliser autour de vos id√©es et de vos projets.Vous savez √©voluer dans un contexte data ops et avez une connaissance des cha√Ænes CI / CD (Gitlab, Azure Devops, ...)La ma√Ætrise de la m√©thodologie Agile est un plus.Ensemble r√©alisons de nouveaux projets Talantueux!!VOTRE SOUHAIT D‚ÄôEVOLUTION:Si vous √™tes passionn√© par l‚Äôinnovation, et souhaitez √©largir vos comp√©tences techniques dans la data, acc√©der √† des fonctions de management de projet et d‚Äô√©quipe, participer au d√©veloppement commercial et organisationnel, ou tout simplement pouvoir valoriser vos prises d‚Äôinitiatives et d√©velopper de nouveaux terrains de jeux, alors rejoignez-nous!Additional InformationAvantages:Top 3 du Palmar√®s Great Place to WorkManagement de proximit√© par des expertsOrganisation sous forme decommunaut√©sUn parcours excellence Agile devopsFinancement de plusieurs certifications officielles √† l‚Äôann√©e gr√¢ce √† nos partenaires √©diteursUn acc√®s √† la plateforme CampusTalan avec plus de 1000 formations disponibles d√®s votre arriv√©eUne mobilit√© interne facilit√©eUn engagement aupr√®s des travailleurs en situation de handicapDes √©v√©nements et afterworks r√©guliersSi√®ge parisien situ√© au 14‚Äì20,rue Pergol√®se, √†Paris16√®me (pr√®s de Porte Maillot et de l'Avenue de la Grande Arm√©e)Tickets restaurants digitalis√©sMutuelle d‚Äôentreprise prise en charge √† 100%Prime vacancesPrime de participationPrime de cooptationActionnariat1% logementPartenaire de l'organisme Mobility dans le cadre de l'accompagnement √† la mobilit√© et √† la recherche de logementRTT.


        Show more

        


        Show less","{'ProgLanguage': ['R', 'Go'], 'DataBase': ['SQL'], 'DataAnalytics': ['R'], 'BigData': ['Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['Azure'], 'DevTools': ['Git'], 'Os': [], 'SoftDB': [], 'SoftBigDataProcessing': [], 'Automation': [], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': [], 'Collaboration': []}"
Data Engineer,IDEAL MATCH,"Lyon, Auvergne-Rh√¥ne-Alpes, France",https://fr.linkedin.com/jobs/view/data-engineer-at-ideal-match-%E2%8E%AE-cabinet-de-recrutement-tech-it-3791420764?refId=e8facLUnZ%2B%2BUyr2K3G0DlQ%3D%3D&trackingId=bym7UoJROVdpakIx0v0tVA%3D%3D&position=25&pageNum=11&trk=public_jobs_jserp-result_search-card,"Pr√©sentation de la soci√©t√©Pionni√®re en mati√®re de Data immobili√®re, cette soci√©t√© cr√©√©e il y a plus de 30 ans compte aujourd‚Äôhui plus de 120 collaborateurs. Elle propose des solutions permettant de r√©aliser des analyses de march√© pour l‚Äôensemble des acteurs du foncier, de l‚Äôam√©nagement et de l‚Äôimmobilier (promoteurs, bailleurs, am√©nageurs et collectivit√©s) afin de les accompagner dans la r√©ussite de leurs projets, dans la compr√©hension de leurs march√©s et dans le d√©veloppement de leurs strat√©gies.Afin de garantir la mise en ≈ìuvre du Dataflow de la soci√©t√©, notre client recherche un Data Engineer pour renforcer son √©quipe.DescriptionAu sein d‚Äôune √©quipe Data compos√©e de 3 personnes, vous serez amen√© √† collaborer avec les diff√©rents p√¥les pour comprendre leurs besoins en donn√©es.Votre Mission :Participer √† la conception d'architectures de donn√©esEffectuer la mise en ≈ìuvre de pipelines de donn√©esS'assurer de la qualit√© et de la s√©curit√© des solutions mises en placeAssurer l‚Äôint√©gration et d‚Äôindustrialisation des sources de donn√©es dans une perspective de r√©duction du time to market des nouvelles sourcesOptimiser les performances des infrastructures de donn√©esMigrer le cloud interne de l‚Äôentreprise vers des cloud publiquesMettre en place des outils de machine learning et IAStack technique: Spark, Hadoop, Airflow, Python 3+, Talend, Azure, AWS, Docker, Kubernetes, Git, Jenkins, SQL/NoSQL, PostgreSQLExigencesVous √™tes id√©alement titulaire d‚Äôun bac +5 dans l‚ÄôinformatiqueVous avez au minimum 2 ans d‚Äôexp√©rience en tant que Data EngineerVous avez une app√©tence pour le machine learning et id√©alement l‚ÄôIAVous √™tes rigoureux, autonome, ouvert d‚Äôesprit et aimez travailler en √©quipeAvantages2 jours de t√©l√©travail par semaineMutuelle familiale rembours√©e √† 80%Ticket restaurant 8.5‚Ç¨Participation / int√©ressement9-12 RTT


        Show more

        


        Show less","{'ProgLanguage': ['Python', 'R', 'Go'], 'DataBase': ['SQL', 'NoSQL'], 'DataAnalytics': ['R'], 'BigData': ['Hadoop', 'Spark'], 'MachingLearning': [], 'DataView': [], 'Statistics': [], 'CloudComputing': ['AWS', 'Azure'], 'DevTools': ['Git', 'Docker', 'Jenkins'], 'Os': [], 'SoftDB': ['PostgreSQL'], 'SoftBigDataProcessing': [], 'Automation': ['Kubernetes', 'Airflow'], 'InfrastructureAsCode': [], 'NetworkSecurty': [], 'Virtualisation': [], 'Containers': ['Docker', 'Kubernetes'], 'Collaboration': []}"
